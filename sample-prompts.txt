You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.

Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚ÄéMessages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them.

Message : ‚Äé~‚ÄØNirant created this group

Message : ‚ÄéThis group was added to the community ‚ÄúGenerative AI‚Äù

Message : ‚ÄéAnyone in the community ‚ÄúGenerative AI‚Äù can request to join this group by messaging group admins.

Message : ‚Äé<attached: 00000012-PHOTO-2023-04-14-20-37-09.jpg>

Message : Has anyone used LangChain with Azure endpoints instead of OpenAI  directly ?

Message : https://python.langchain.com/en/latest/modules/models/llms/integrations/azure_openai_example.html
Quoted Message : Has anyone used LangChain with Azure endpoints instead of OpenAI  directly ?

Message : Tried this?

Message : Yup I‚Äôve tried this 
It‚Äôs working for simple examples

Im looking to implement agents and not able to find documentation for it
Quoted Message : Tried this?

Message : They have examples for custom LLM agents, not sure if that helps

Message : Using gpt-3.5 response as it is from Azure endpoint response and then customising it for use is a huge headache for me currently ü•≤
Quoted Message : They have examples for custom LLM agents, not sure if that helps

Message : ‚Äé<attached: 00000020-PHOTO-2023-04-14-20-48-45.jpg>

Message : Prompt was simple ‚ÄúTell me a joke‚Äù nothing more

Message : This has happened before too
Quoted Message :  2023_04_14_3AD2560D2B6C0CA098E9.jpeg

Message : ‚Äé~‚ÄØNirant changed the group description

Message : ‚Äé~‚ÄØNirant changed the group description

Message : https://colin-scott.github.io/personal_website/research/interactive_latency.html

Message : wow
Quoted Message : https://colin-scott.github.io/personal_website/research/interactive_latency.html

Message : latency for 2000 Bytes over commodity network went from 2000NS in year 2009 to 44 NS in 2020 . üòÆ

Message : CTO of Stability AI is talking about Stability diffusion if anyone is interested 

https://www.twitch.tv/lablabai

Message : ChatGPT for Robotics
https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/

Message : Fire optics became more widely adopted over this time üòä
Quoted Message : latency for 2000 Bytes over commodity network went from 2000NS in year 2009 to 44 NS in 2020 . üòÆ

Message : It's fun to see these numbers and trends as a way to understand industry directions and opportunities. 

For examples, iirc, bezos decided to jump into Amazon after seeing the exponential growth of the internet

Message : ‚Äé<attached: 00000040-PHOTO-2023-04-14-23-33-38.jpg>

Message : https://colab.research.google.com/drive/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing

Here‚Äôs a small colab notebook I put together - It searches through a webpage and does Q&A in about 80 lines of code.

Message : you have it in your name
Quoted Message : https://colab.research.google.com/drive/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing\n\nHere‚Äôs a small colab notebook I put together - It searches through a webpage and does Q&A in about 80 lines of code.

Message : ‚Äé<attached: 00000043-PHOTO-2023-04-15-06-14-19.jpg>

Message : Awesome üëèüèΩ
Quoted Message :  2023_04_15_3EB0F396FFD378F6816001.jpeg

Message : Enjoy ü´°
Quoted Message :  2023_04_15_3EB0F396FFD378F6816001.jpeg

Message : on a different note: Are any there any React devs available for a paid weekend project? Appreciate any leads, DM Me.

Message : Has anyone here been able to get the latest controlnet v1-1 nightly release models working with inpainting? There is one controlnet model which is for inpainting, any inputs on how that would fit with multi controlnet? I got the models working with multi controlnet but have not been able to do so for inpainting yet.

Message : https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb

Karpathy strikes again! Using svm for embeddings search

Message : Sounds very cool, must put into gooey
Quoted Message : Has anyone here been able to get the latest controlnet v1-1 nightly release models working with inpainting? There is one controlnet model which is for inpainting, any inputs on how that would fit with multi controlnet? I got the models working with multi controlnet but have not been able to do so for inpainting yet.

Message : You may check Haystack. It provides very easy abstraction.

https://haystack.deepset.ai/
Quoted Message :  2023_04_14_3ABAC22CE17203DA7A81.jpeg

Message : Would love to see some comparisons at production level scale

Indexing latency, querying latency etc
Quoted Message : Sounds very cool, must put into gooey

Message : This was about controlnet inpainting
Quoted Message : Sounds very cool, must put into gooey

Message : We are not at production level scale yet anways üòÖ about 1% of dukaan probably
Quoted Message : Would love to see some comparisons at production level scale\n\nIndexing latency, querying latency etc

Message : Enterprise Document Search in Azure - MSFT recommends using Azure Cognitive Search with Azure OpenAI . I would be interested to know your thoughts . Azure Cognitive Search may be costly

Message : Another Option is traditional - Upload documents embeddings into a Vector DB and do semantic search

Message : Interested to know from the community of production level deloyments

Message : This is what we‚Äôre live with.
Quoted Message : Another Option is traditional - Upload documents embeddings into a Vector DB and do semantic search

Message : Thank you @91963283xxxx  . Size of the DB = ? and your choice of Vector DB = ?

Message : twitter discussion for this https://twitter.com/karpathy/status/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19
Quoted Message : https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb\n\nKarpathy strikes again! Using svm for embeddings search

Message : 10681 vectors and pinecone
Quoted Message : Thank you @9196xxxxxxxx  . Size of the DB = ? and your choice of Vector DB = ?

Message : Thanks so much

Message : Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies.
Quoted Message : https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb\n\nKarpathy strikes again! Using svm for embeddings search

Message : https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman

Message : Yes, works great though when you don't have too many data refreshes/updates.
Quoted Message : Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies.

Message : I have a friend called gpt 4. Fairly reasonably priced. üòã
Quoted Message : on a different note: Are any there any React devs available for a paid weekend project? Appreciate any leads, DM Me.

Message : immediately reminded me of spam detection PoCs :P
Quoted Message : Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This is what we‚Äôre live with.
Quoted Message : Another Option is traditional - Upload documents embeddings into a Vector DB and do semantic search

Message : Thank you @91963283xxxx  . Size of the DB = ? and your choice of Vector DB = ?

Message : twitter discussion for this https://twitter.com/karpathy/status/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19
Quoted Message : https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb\n\nKarpathy strikes again! Using svm for embeddings search

Message : 10681 vectors and pinecone
Quoted Message : Thank you @9196xxxxxxxx  . Size of the DB = ? and your choice of Vector DB = ?

Message : Thanks so much

Message : Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies.
Quoted Message : https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb\n\nKarpathy strikes again! Using svm for embeddings search

Message : https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman

Message : Yes, works great though when you don't have too many data refreshes/updates.
Quoted Message : Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies.

Message : I have a friend called gpt 4. Fairly reasonably priced. üòã
Quoted Message : on a different note: Are any there any React devs available for a paid weekend project? Appreciate any leads, DM Me.

Message : immediately reminded me of spam detection PoCs :P
Quoted Message : Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies.

Message : True! I recently pushed a project thru the deadline and practically - copilot helped w a good chunk of front end code . GPT for all those complex Cloud formation templates .
Quoted Message : I have a friend called gpt 4. Fairly reasonably priced. üòã

Message : has anyone figured good ways to reduce time in getting output from an LLM?

or if you have some ideas, please shoot: I'll try them out and get back on if they work.

Message : also anyone knows if there's a mathematical formula to calculate highlighted words in bionic reading technique?

not able to find it anywhere as of now

wanted to experiment with converting a text to it's bionic reading format and then pass that to LLM as input instead of plain text to save on tokens, increase context and increase speed of reading of output.

Message : Introduced to this recently for a similar problem statement
https://rapidapi.com/bionic-reading-bionic-reading-default/api/bionic-reading1
Quoted Message : also anyone knows if there's a mathematical formula to calculate highlighted words in bionic reading technique?\n\nnot able to find it anywhere as of now\n\nwanted to experiment with converting a text to it's bionic reading format and then pass that to LLM as input instead of plain text to save on tokens, increase context and increase speed of reading of output.

Message : wow amazing. thanks a lot, been searching for 2-3 days
Quoted Message : Introduced to this recently for a similar problem statement\n https://rapidapi.com/bionic-reading-bionic-reading-default/api/bionic-reading1

Message : https://twitter.com/pratyush_r8/status/1647104801950552064

Message : Interesting thought. I always thought bionic reading just highlights the first 2-3 characters of each word.

Wouldn't the algorithm just be to always highlight named entities and never highlight connectors/stowpords?
Quoted Message : also anyone knows if there's a mathematical formula to calculate highlighted words in bionic reading technique?\n\nnot able to find it anywhere as of now\n\nwanted to experiment with converting a text to it's bionic reading format and then pass that to LLM as input instead of plain text to save on tokens, increase context and increase speed of reading of output.

Message : ‚Äé<attached: 00000082-PHOTO-2023-04-15-16-57-13.jpg>
Quoted Message : Interesting thought. I always thought bionic reading just highlights the first 2-3 characters of each word.\n\nWouldn't the algorithm just be to always highlight named entities and never highlight connectors/stowpords?

Message : ‚Äé<attached: 00000086-PHOTO-2023-04-15-18-54-47.jpg>

Message : I have a question and I think people here would be well suited to answer

Message : If projects like langchain are open-source, then why do they raise money? What are the economics here?

Message : Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition?

Message : Fowarded a thread I'm having elsewhere. Let me know if anyone has any understanding about this.

Message : Users and distribution. As a man once said, your monetisation techiniques are very different when you have 10K users vs 10M users

Message : Managed Services. Including enterprise. See dbt cloud for reference.
Quoted Message : If projects like langchain are open-source, then why do they raise money? What are the economics here?

Message : OpenSUSE and RedHat open sourced their code. Still profitable by providing training and support

Message : Don't know about langchain plans apart from the distribution, but generally open-source companies go in the self hosted and Cloud hosted startegies
Quoted Message : Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition?

Message : What‚Äôs dbt cloud? Heard this from my investors too
Quoted Message : Managed Services. Including enterprise. See dbt cloud for reference.

Message : Also people don't like writing code or reading docs. This is also the Fixie thesis
Quoted Message : Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition?

Message : That'd be off topic. I love dbt too. Happy to talk more on DM
Quoted Message : What‚Äôs dbt cloud? Heard this from my investors too

Message : I'd wager Llama Index should/will raise too if they build a company around it

Message : Hosted cloud version - that‚Äôs a great value prop Id pay for. Like mongodb

Message : It's a fantastic model. A wrapper around Foss. With a lot of successes

1. Confluent on Kafka
2. Vercel with Nextjs
3. Clickhouse
4. Supabase with postgres+

Message : Cal.com has turned that into a pretty decent content model as well

Message : Like elasticsearch went into AWS?
Quoted Message : Don't know about langchain plans apart from the distribution, but generally open-source companies go in the self hosted and Cloud hosted startegies

Message : Anyone here who has invested in such a business model before?

Message : Won't compare to AWS services, but more like mongodb, appsmith, vercel etc.
Quoted Message : Like elasticsearch went into AWS?

Message : Where you get hooked to the service by first using it on your instances, but as team/complexity grows, you prefer to just use their hosted offerings

Message : Vercel and NextJS is a great example

Message : Gotcha
Quoted Message : Where you get hooked to the service by first using it on your instances, but as team/complexity grows, you prefer to just use their hosted offerings

Message : Makes sense

Message : Yeah, and when you try using NextJS on AWS amplify, it had terrible build times (as per my last experience). We had no choice, but to use the Vercel hosting
Quoted Message : Vercel and NextJS is a great example

Message : Is anyone familiar with AI for crime detection (loud noises etc)

Message : Redhat $1B
Hashicorp $0.5B ARR
Both are open source companies

https://twitter.com/adamhjk/status/1618795275665162247
Quoted Message : Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition?

Message : https://twitter.com/anoushkavaswani/status/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19
ü§Ø New use cases

Message : https://www.linkedin.com/feed/update/urn:li:activity:7053046289256632320

We are live with our Talk with Kundan Kumar Descript

Welcoming you all for this insightful conversation üôèüôèüôè

Message : https://twitter.com/foyerwork/status/1647282584907579393?s=20

Message : ‚Äé<attached: 00000115-PHOTO-2023-04-15-22-43-02.jpg>
Quoted Message : https://twitter.com/anoushkavaswani/status/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19\nü§Ø New use cases

Message : AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot. https://aws.amazon.com/codewhisperer/

Message : https://aws.amazon.com/blogs/machine-learning/how-accenture-is-using-amazon-codewhisperer-to-improve-developer-productivity/
Quoted Message : AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot. https://aws.amazon.com/codewhisperer/


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Makes sense

Message : Yeah, and when you try using NextJS on AWS amplify, it had terrible build times (as per my last experience). We had no choice, but to use the Vercel hosting
Quoted Message : Vercel and NextJS is a great example

Message : Is anyone familiar with AI for crime detection (loud noises etc)

Message : Redhat $1B
Hashicorp $0.5B ARR
Both are open source companies

https://twitter.com/adamhjk/status/1618795275665162247
Quoted Message : Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition?

Message : https://twitter.com/anoushkavaswani/status/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19
ü§Ø New use cases

Message : https://www.linkedin.com/feed/update/urn:li:activity:7053046289256632320

We are live with our Talk with Kundan Kumar Descript

Welcoming you all for this insightful conversation üôèüôèüôè

Message : https://twitter.com/foyerwork/status/1647282584907579393?s=20

Message : ‚Äé<attached: 00000115-PHOTO-2023-04-15-22-43-02.jpg>
Quoted Message : https://twitter.com/anoushkavaswani/status/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19\nü§Ø New use cases

Message : AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot. https://aws.amazon.com/codewhisperer/

Message : https://aws.amazon.com/blogs/machine-learning/how-accenture-is-using-amazon-codewhisperer-to-improve-developer-productivity/
Quoted Message : AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot. https://aws.amazon.com/codewhisperer/

Message : https://blog.lucas-simon.com/amazon-codewhisperer-vs-github-copilot#heading-final-thoughts

Actually, a good comparison

Message : Any sci-fi enthusiasts here ? üòÉ

Has anyone read ‚ÄúThe Last Question‚Äù by Isaac Asimov?

Message : Yeah it‚Äôs great
Quoted Message : Any sci-fi enthusiasts here ? üòÉ\n\nHas anyone read ‚ÄúThe Last Question‚Äù by Isaac Asimov?

Message : This is even better - it‚Äôs also very timely because of AI

Message : https://www.gregegan.net/MISC/CRYSTAL/Crystal.html

Message : Doesn‚Äôt the Multivac sound eerily similar to today‚Äôs LLMs /Auto-GPT ?

Message : You ask a question ,it finds answers 
Or you set an objective it goes about fulfilling it

Message : Yeah lol, Asimov basically predicted AGI

Message : I guess Turing had already predicted it before him though

Message : Asimov did do that in many stories ,I‚Äôve read basically all of his books 

What‚Äôs remarkable is not prediction of AGI

It‚Äôs how the Multivac being used is very similar to how we are using ChatGPT
Quoted Message : Yeah lol, Asimov basically predicted AGI

Message : Yeah agreed!

Message : The interface is similar, but I think the big difference is that LLMs are conceptually structured, but untethered from reality. That I think is the big difference between multivac and LLMs

Message : Like it understands conceptually that colors should cluster together, but doesn‚Äôt really understand a color

Message : Multimodality will help a lot with that

Message : On the color front I just happened to come across this paper :) 

https://arxiv.org/abs/2109.06129
Quoted Message : Like it understands conceptually that colors should cluster together, but doesn‚Äôt really understand a color

Message : Agreed they are largely conceptually structured
Quoted Message : The interface is similar, but I think the big difference is that LLMs are conceptually structured, but untethered from reality. That I think is the big difference between multivac and LLMs

Message : Great share thanks üôèüèΩ
Quoted Message : On the color front I just happened to come across this paper :) \n\nhttps://arxiv.org/abs/2109.06129

Message : Like in the ‚Äúlast question‚Äù the question asked over eons is can entropy be reversed. The fact that it took sooo long to answer because it is such a difficult question based on its understanding of reality was amazing

Message : But thank you for bringing up Asimov‚Äôs work, that man was my first brush with sci-fi and a genius

Message : It kept updating its understanding of reality 

And one huge step which might seem trivial was interfacing of such AIs with real world

The way we are building agents/tools with LLMs now,I think the day is not far off where we design interfaces for AIs to interact in real world
Quoted Message : Like in the ‚Äúlast question‚Äù the question asked over eons is can entropy be reversed. The fact that it took sooo long to answer because it is such a difficult question based on its understanding of reality was amazing

Message : Glad to meet a fellow Asimov fan! 
I was also introduced to sci-fi thorough the works of Asimov üôåüèª
Quoted Message : But thank you for bringing up Asimov‚Äôs work, that man was my first brush with sci-fi and a genius

Message : Cixin Liu is my all time favorite
Quoted Message : Glad to meet a fellow Asimov fan! \nI was also introduced to sci-fi thorough the works of Asimov üôåüèª

Message : Draft Community Guidelines for this WA group. Will hopefully make it easier for you to decide for yourself what is off topic ü•≤

Suggestions, rebuttals most welcome on that PR!

https://github.com/NirantK/nirantk.github.io/pull/7

Message : ‚Äé<attached: 00000141-PHOTO-2023-04-16-09-52-36.jpg>

Message : Very cool, curious was it generated using AutoGPT, it seems to have 1 numbering only but also working links.
Quoted Message :  2023_04_16_3EB0C02E7707908FC6A8FD.jpeg

Message : Get yourself an admin that defines community guidelines in git ü´Ç
Quoted Message : Draft Community Guidelines for this WA group. Will hopefully make it easier for you to decide for yourself what is off topic ü•≤\n\nSuggestions, rebuttals most welcome on that PR!\n\nhttps://github.com/NirantK/nirantk.github.io/pull/7

Message : ‚Äé<attached: 00000144-PHOTO-2023-04-16-10-05-31.jpg>
Quoted Message : Very cool, curious was it generated using AutoGPT, it seems to have 1 numbering only but also working links.

Message : off-topic - orion's arm is a cool website for sci-fi enthusiasts.
Quoted Message : Any sci-fi enthusiasts here ? üòÉ\n\nHas anyone read ‚ÄúThe Last Question‚Äù by Isaac Asimov?

Message : Sci-fi thats relevant to this group\n\nhttps://qntm.org/mmacevedo

Message : Sci-fi thats relevant to this group

https://qntm.org/mmacevedo

Message : Huge fan here. Probably read Asimov, Clark and Heinlein all through college and masters. Kept me sane and got me excited about the future. 

And feel even more privileged to be working in tech/ai and seeing a lot of parallels.

Btw, a lot of Clarks stories paved the way for real science like Geo-synchronous satellites.

Eternals from Asimov is a great book if anyone wants to spend their Sunday reading
Quoted Message : Glad to meet a fellow Asimov fan! \nI was also introduced to sci-fi thorough the works of Asimov üôåüèª

Message : Does anyone have a link to that service which let's you use chatGPT interface built on top of the API? Just using your API key?

Message : I figured that's cheaper than buying chatGPT plus

Message : https://www.chatbotui.com/
Quoted Message : Does anyone have a link to that service which let's you use chatGPT interface built on top of the API? Just using your API key?

Message : And also, how is the context window handling of such services? Surely they'll lose the memory ability once the past chats get out of the max token limit?

Message : Is this the one you are looking for?
Quoted Message : https://www.chatbotui.com/

Message : Seems so
Quoted Message : Is this the one you are looking for?

Message : Thank you

Message : I mostly use plus because it lets me use GPT-4 with large context windows and that turns out to be cost efficient. Do consider that.
Quoted Message : I figured that's cheaper than buying chatGPT plus

Message : Can anyone share some guidance on how many documents would be required for fine-tuning, ballpark could be fine? Some fine-tuning resources would also be great!


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Huge fan here. Probably read Asimov, Clark and Heinlein all through college and masters. Kept me sane and got me excited about the future. 

And feel even more privileged to be working in tech/ai and seeing a lot of parallels.

Btw, a lot of Clarks stories paved the way for real science like Geo-synchronous satellites.

Eternals from Asimov is a great book if anyone wants to spend their Sunday reading
Quoted Message : Glad to meet a fellow Asimov fan! \nI was also introduced to sci-fi thorough the works of Asimov üôåüèª

Message : Does anyone have a link to that service which let's you use chatGPT interface built on top of the API? Just using your API key?

Message : I figured that's cheaper than buying chatGPT plus

Message : https://www.chatbotui.com/
Quoted Message : Does anyone have a link to that service which let's you use chatGPT interface built on top of the API? Just using your API key?

Message : And also, how is the context window handling of such services? Surely they'll lose the memory ability once the past chats get out of the max token limit?

Message : Is this the one you are looking for?
Quoted Message : https://www.chatbotui.com/

Message : Seems so
Quoted Message : Is this the one you are looking for?

Message : Thank you

Message : I mostly use plus because it lets me use GPT-4 with large context windows and that turns out to be cost efficient. Do consider that.
Quoted Message : I figured that's cheaper than buying chatGPT plus

Message : Can anyone share some guidance on how many documents would be required for fine-tuning, ballpark could be fine? Some fine-tuning resources would also be great!

Message : https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
Quoted Message : Can anyone share some guidance on how many documents would be required for fine-tuning, ballpark could be fine? Some fine-tuning resources would also be great!

Message : Thanks for sharing, was actually looking specifically for ways to fine-tune model with custom data than In-context learning. Any inputs on rough data size required for it could be helpful.

Message : I love sci-fi,

This maybe not in the similar line but there's
Ray Bradbury's The Illustrated Man
which is quite intriguing.
Quoted Message : Any sci-fi enthusiasts here ? üòÉ\n\nHas anyone read ‚ÄúThe Last Question‚Äù by Isaac Asimov?

Message : +1 
Even I‚Äôd like to know this

Only thing I‚Äôve read on are InstructGPT with 13k QnA pairs and Dolly LLM with 15k QnA pairs

How is domain specific tuning achieved ?
Quoted Message : Thanks for sharing, was actually looking specifically for ways to fine-tune model with custom data than In-context learning. Any inputs on rough data size required for it could be helpful.

Message : https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html

Message : https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm

Message : These are articles by Databrick on how they‚Äôve tuned the open source Dolly LLM for reference if anyone is interested 

Might need more deeper expertise to understand how to train on custom data domains

Message : I am trying to use sentence transformers and OpenAI combined and making a Docker Image. Obviously the image is quite big [ > 4 GB ] , did anybody try deploying this type of thing to Kubernetes / AKS / EKS ?

Message : Doing it in a VM is ok and works fine. Interested to know the community viewpoints

Message : Anyone who has performed Model Distillation?

Message : I am curious - what‚Äôs your use case?  Use different models based on inference request parameters/tasks?
Quoted Message : I am trying to use sentence transformers and OpenAI combined and making a Docker Image. Obviously the image is quite big [ > 4 GB ] , did anybody try deploying this type of thing to Kubernetes / AKS / EKS ?

Message : Standard ones [ Q&A , Chatbot]. The reason I am using Sentence Transformers instead of OpenAI embeddings to save cost

Message : Oh I see, so using embeddings from ST to do information retrieval and then add the context into OpenAI prompt?
Quoted Message : Standard ones [ Q&A , Chatbot]. The reason I am using Sentence Transformers instead of OpenAI embeddings to save cost

Message : Correct

Message : OpenAI embeddings are good but they would charge. Hence alternative ST , but con is image is huge

Message : In the VM it works fine but when containerize ing it is becoming huge [ which is obvious ]

Message : May be deploying the model separately behind a service endpoint could be a way to go. That way you wont have to distribute the model in the application containers.

Message : Yes that's correct ; but the model itself is huge [ ST with all its fanfare Torch and ‚Ä¶ ] ; Are you suggesting deploying the Model in a VM and exposing as a service ?

Message : Yeah

Message : Thank you for your views

Message : I am just wondering how the community is thinking about using OpenAI for everything [ Embeddings and Chat Completion ]. My views are Embeddings can be done using ST and Hugging Face and reduce cost

Message : I agree.

Message : Have seen it start to work with 200 odd examples. OpenAI suggest 1000+ for accuracy. 

I think the dolly training is different than fine-tuning. But not sure
Quoted Message : Thanks for sharing, was actually looking specifically for ways to fine-tune model with custom data than In-context learning. Any inputs on rough data size required for it could be helpful.

Message : Sorry I'm not sure i understand. Do you mean the image is large because of storing the vectors?
Quoted Message : In the VM it works fine but when containerize ing it is becoming huge [ which is obvious ]

Message : Different than the OpenAI fine-tuning*
Quoted Message : Have seen it start to work with 200 odd examples. OpenAI suggest 1000+ for accuracy. \n\nI think the dolly training is different than fine-tuning. But not sure

Message : I am using Sentence Transformers for Word Embedding. The ST has dependencies on Torch and NVIDIA libraries , hence the image is large

Message : Your standard flow is Embeddings + Chat Completion [ Very Himalaya level flow ] . For Embeddings to minimize cost using ST

Message : and Context / Chat Completion using OpenAI / Azure OpenAI

Message : It‚Äôs not recommended to use fine tuning where you can get away with embeddings.

Message : How many GBs are we talking about?
Quoted Message : In the VM it works fine but when containerize ing it is becoming huge [ which is obvious ]

Message : > 5GB
Quoted Message : How many GBs are we talking about?

Message : One solution from one helpful community member is to convert ST into ONNX format

Message : and this would reduce the size

Message : Any other solutions / viewpoints would be highly appreciated . even the approach is wrong with reason would also be highly appreciated

Message : I love this community . So very quick and helpful members

Message : wait, I thought finetuning means providing extra/specific information to the model which it already doesn‚Äôt know. And, generating embeddings using relevant documents is a part of the process. Am I fundamentally wrong?
Quoted Message : It‚Äôs not recommended to use fine tuning where you can get away with embeddings.

Message : ‚Äé<attached: 00000195-PHOTO-2023-04-16-12-42-37.jpg>

Message : https://stackoverflow.com/questions/63521958/is-this-a-right-way-to-descrease-size-of-my-docker-images

There is one answer here related to cuda, but I'm sure you have already done this
Quoted Message : Any other solutions / viewpoints would be highly appreciated . even the approach is wrong with reason would also be highly appreciated

Message : Harrison is really open about their strategy and sharing the plans. 

In the last webinar he mentioned they‚Äôre just focusing on open source rn
Quoted Message : Don't know about langchain plans apart from the distribution, but generally open-source companies go in the self hosted and Cloud hosted startegies

Message : https://medium.com/@TheHaseebHassan/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696
Quoted Message : One solution from one helpful community member is to convert ST into ONNX format


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : > 5GB
Quoted Message : How many GBs are we talking about?

Message : One solution from one helpful community member is to convert ST into ONNX format

Message : and this would reduce the size

Message : Any other solutions / viewpoints would be highly appreciated . even the approach is wrong with reason would also be highly appreciated

Message : I love this community . So very quick and helpful members

Message : wait, I thought finetuning means providing extra/specific information to the model which it already doesn‚Äôt know. And, generating embeddings using relevant documents is a part of the process. Am I fundamentally wrong?
Quoted Message : It‚Äôs not recommended to use fine tuning where you can get away with embeddings.

Message : ‚Äé<attached: 00000195-PHOTO-2023-04-16-12-42-37.jpg>

Message : https://stackoverflow.com/questions/63521958/is-this-a-right-way-to-descrease-size-of-my-docker-images

There is one answer here related to cuda, but I'm sure you have already done this
Quoted Message : Any other solutions / viewpoints would be highly appreciated . even the approach is wrong with reason would also be highly appreciated

Message : Harrison is really open about their strategy and sharing the plans. 

In the last webinar he mentioned they‚Äôre just focusing on open source rn
Quoted Message : Don't know about langchain plans apart from the distribution, but generally open-source companies go in the self hosted and Cloud hosted startegies

Message : https://medium.com/@TheHaseebHassan/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696
Quoted Message : One solution from one helpful community member is to convert ST into ONNX format

Message : Nice article to convert ST into ONNX format
Quoted Message : https://medium.com/@TheHaseebHassan/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696

Message : ‚Äé<attached: 00000200-PHOTO-2023-04-16-13-24-39.jpg>

Message : Haha
Quoted Message :  2023_04_16_3A08B3CAE732BCBDB9E3.jpeg

Message : This is quite neat. I missed pinned messages for this!
Quoted Message :  2023_04_16_B696BA9AAD0852599438FE05342D45AB.jpeg

Message : Fine tuning adjusts the weights of a model, with more training samples. Embedding are usually used for similarity search(among other things).
Quoted Message : wait, I thought finetuning means providing extra/specific information to the model which it already doesn‚Äôt know. And, generating embeddings using relevant documents is a part of the process. Am I fundamentally wrong?

Message : calculating embeddings is a part of adding ‚Äúmore training samples‚Äù, right? Or not necessarily‚Ä¶?
Quoted Message : Fine tuning adjusts the weights of a model, with more training samples. Embedding are usually used for similarity search(among other things).

Message : These things are orthogonal to each other.
Quoted Message : calculating embeddings is a part of adding ‚Äúmore training samples‚Äù, right? Or not necessarily‚Ä¶?

Message : Are you talking about fine tuning the embedding model or something?

Message : These things are nuanced based on the context :)

Message : ah

Message : Think of it this way

Fine-tuning is changing the model itself to better represent your target datasets input->output mapping.

Embeddings and similarity search does not change the model. Model's "intelligence" remains the same. All it does is use that intelligence to differentiate the topics you care about (that is, the text whose embeddings you index)
Quoted Message : wait, I thought finetuning means providing extra/specific information to the model which it already doesn‚Äôt know. And, generating embeddings using relevant documents is a part of the process. Am I fundamentally wrong?

Message : You can say embeddings is an LLM's mother tongue. It understands text by converting in into an embedding to understand the meaning and relation between words. Finetuning is giving the llm lot's of examples to learn a particular new skill or subject
Quoted Message : calculating embeddings is a part of adding ‚Äúmore training samples‚Äù, right? Or not necessarily‚Ä¶?

Message : I used "differentiate" in a explanatory flavour

99% of the times embeddings search is used to look for similarity in the text you care about

The accuracy with which your similarity search will work depends entirely on the model's "intelligence". The more weights and the more variance there is in the model's dataset, the better it's embeddings will work for similarity search.
Quoted Message : Think of it this way\n\nFine-tuning is changing the model itself to better represent your target datasets input->output mapping. \n\nEmbeddings and similarity search does not change the model. Model's \"intelligence\" remains the same. All it does is use that intelligence to differentiate the topics you care about (that is, the text whose embeddings you index)

Message : https://twitter.com/tree_industries/status/1647416130753945601?s=46

Message : I imagine gpt3.5 and gpt4 embeddings will be much better for similarity search

Message : Anyway gpt3 embeddings are 1536 in length
3.5 and 4 should be even higher if they are bottlenecked by the 1536 degrees of freedom

Message : I see‚Ä¶.
Quoted Message : I used \"differentiate\" in a explanatory flavour\n\n99% of the times embeddings search is used to look for similarity in the text you care about\n\nThe accuracy with which your similarity search will work depends entirely on the model's \"intelligence\". The more weights and the more variance there is in the model's dataset, the better it's embeddings will work for similarity search.

Message : just trying to understand, so if this ‚Äúintelligence‚Äù depends on the models‚Äô weights, variance, etc which is obviously the case (basically upgrading from gpt3 to gpt4), there are ways to finetune, i.e., add more weights, etc. ourselves also? instead of waiting for a new release like gpt5?

Message : I so long thought finetuning just means giving it more documents (storing the embeddings in a db)‚Ä¶ i didn‚Äôt know there are ways to make the model smarter without burning huge computation powers

Message : Check this out https://huggingface.co/spaces/microsoft/HuggingGPT
Quoted Message : I so long thought finetuning just means giving it more documents (storing the embeddings in a db)‚Ä¶ i didn‚Äôt know there are ways to make the model smarter without burning huge computation powers

Message : Hmm ,think of embeddings as transformations (At very high level)

When you create an embedding you transform something which was represented in letters to be represented in numbers
This is usually called text embedding

When you do a QnA over embeddings it‚Äôs not making the model smarter

You convert that query to a number
And then use similarity search to find another number just like it

What you see in QnA bots is one more step
After finding the similar number you put it into prompt and then ask it to synthesize it into a user friendly format


What each model does in embedding is to represent a meaning to more accurate degree in form of numbers .GpT embeddings could be better than GPT-3 for this
Quoted Message : I so long thought finetuning just means giving it more documents (storing the embeddings in a db)‚Ä¶ i didn‚Äôt know there are ways to make the model smarter without burning huge computation powers

Message : ya I understood that‚Ä¶
Quoted Message : Hmm ,think of embeddings as transformations (At very high level)\n\nWhen you create an embedding you transform something which was represented in letters to be represented in numbers\nThis is usually called text embedding \n\nWhen you do a QnA over embeddings it‚Äôs not making the model smarter \n\nYou convert that query to a number \nAnd then use similarity search to find another number just like it \n\nWhat you see in QnA bots is one more step \nAfter finding the similar number you put it into prompt and then ask it to synthesize it into a user friendly format\n\n\nWhat each model does in embedding is to represent a meaning to more accurate degree in form of numbers .GpT embeddings could be better than GPT-3 for this

Message : When you fine tune a model
It actually updates the weights
From what I have understood

You can ask a question directly to the model after training and it will be able to answer
Usually called zero shot prompting


Fine tuning improved zero shot prompting over any domain you train it on

Message : what is the ‚Äúprocess‚Äù of ‚Äòfinetuning‚Äô then if not generating and storing embeddings?

Message : Providing it with prompts?

Message : to use those embeddings more smartly?

Message : larger dof is not good for longer run, latency wise, too.
Quoted Message : Anyway gpt3 embeddings are 1536 in length\n3.5 and 4 should be even higher if they are bottlenecked by the 1536 degrees of freedom

Message : Calling the api and updating the weights for your use cases.
Quoted Message : what is the ‚Äúprocess‚Äù of ‚Äòfinetuning‚Äô then if not generating and storing embeddings?

Message : Weights being updated with example data

Message : Can I get a more comprehensive guide on how to ‚Äòupdate these weights‚Äô please?
it‚Äôd be very helpful‚Ä¶. thank you very much
Quoted Message : Calling the api and updating the weights for your use cases.

Message : https://platform.openai.com/docs/guides/fine-tuning

Message : Providing with example date like rightly said 

I‚Äôve read on chat-gpt like models
They have been trained on pairs of questions and answers


Embeddings are not stored in the model ,models are only used to create embeddings.
Quoted Message : Providing it with prompts?

Message : There was recent tweet from someone about comparing fine-tuning and prompting. Will see if I can find it. That had some details of effects of fine tuning and what prompting can deliver.

Message : Tweet about a paper

Message : Make sure if finetuning is really necessary for your usecase (computational costs involved) or if you can simply  use a external vector database like pinecone or weaviate instead.
Quoted Message : Can I get a more comprehensive guide on how to ‚Äòupdate these weights‚Äô please?\nit‚Äôd be very helpful‚Ä¶. thank you very much

Message : I had read a little bit of this when I was initially exploring, but never tried myself: ```question and answer pairs to additionally create adversarial questions and context pairs```
https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-3-train-qa.ipynb
Quoted Message : Providing with example date like rightly said \n\nI‚Äôve read on chat-gpt like models\nThey have been trained on pairs of questions and answers \n\n\nEmbeddings are not stored in the model ,models are only used to create embeddings.

Message : What do you people think of this?
Quoted Message : https://twitter.com/tree_industries/status/1647416130753945601?s=46

Message : This is interesting but needs more finesse. 

Like give more details about the family, names that are popular, what are some personality traits that go with names in popular culture.

Baby names typically have conversations with so many "stakeholders" as part of the process of discovering, filtering and fine-tuning.

GPT can make this process accessible to more, elevate the level of intelligence perhaps of such conversations and also showcase more avenues that for that user was previously unknown.
Quoted Message : What do you people think of this?

Message : Hey, not sure if this was asked here before, but how do we determine a good chunk size to use while converting a huge text dump + documents into embeddings. From what I understand a smaller chunk size make the extractions more "precise" while doing emb search but at the cost of much more computations wheras it's the opposite with large chunk size and also with larger chunk sizes we can't keep too many of the chunks in the final LLM prompt for answering the question. Any other ways of looking at this?

Message : I think langchain's conversation memory types can be combined to optimise for your chunks
Quoted Message : Hey, not sure if this was asked here before, but how do we determine a good chunk size to use while converting a huge text dump + documents into embeddings. From what I understand a smaller chunk size make the extractions more \"precise\" while doing emb search but at the cost of much more computations wheras it's the opposite with large chunk size and also with larger chunk sizes we can't keep too many of the chunks in the final LLM prompt for answering the question. Any other ways of looking at this?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://platform.openai.com/docs/guides/fine-tuning

Message : Providing with example date like rightly said 

I‚Äôve read on chat-gpt like models
They have been trained on pairs of questions and answers


Embeddings are not stored in the model ,models are only used to create embeddings.
Quoted Message : Providing it with prompts?

Message : There was recent tweet from someone about comparing fine-tuning and prompting. Will see if I can find it. That had some details of effects of fine tuning and what prompting can deliver.

Message : Tweet about a paper

Message : Make sure if finetuning is really necessary for your usecase (computational costs involved) or if you can simply  use a external vector database like pinecone or weaviate instead.
Quoted Message : Can I get a more comprehensive guide on how to ‚Äòupdate these weights‚Äô please?\nit‚Äôd be very helpful‚Ä¶. thank you very much

Message : I had read a little bit of this when I was initially exploring, but never tried myself: ```question and answer pairs to additionally create adversarial questions and context pairs```
https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-3-train-qa.ipynb
Quoted Message : Providing with example date like rightly said \n\nI‚Äôve read on chat-gpt like models\nThey have been trained on pairs of questions and answers \n\n\nEmbeddings are not stored in the model ,models are only used to create embeddings.

Message : What do you people think of this?
Quoted Message : https://twitter.com/tree_industries/status/1647416130753945601?s=46

Message : This is interesting but needs more finesse. 

Like give more details about the family, names that are popular, what are some personality traits that go with names in popular culture.

Baby names typically have conversations with so many "stakeholders" as part of the process of discovering, filtering and fine-tuning.

GPT can make this process accessible to more, elevate the level of intelligence perhaps of such conversations and also showcase more avenues that for that user was previously unknown.
Quoted Message : What do you people think of this?

Message : Hey, not sure if this was asked here before, but how do we determine a good chunk size to use while converting a huge text dump + documents into embeddings. From what I understand a smaller chunk size make the extractions more "precise" while doing emb search but at the cost of much more computations wheras it's the opposite with large chunk size and also with larger chunk sizes we can't keep too many of the chunks in the final LLM prompt for answering the question. Any other ways of looking at this?

Message : I think langchain's conversation memory types can be combined to optimise for your chunks
Quoted Message : Hey, not sure if this was asked here before, but how do we determine a good chunk size to use while converting a huge text dump + documents into embeddings. From what I understand a smaller chunk size make the extractions more \"precise\" while doing emb search but at the cost of much more computations wheras it's the opposite with large chunk size and also with larger chunk sizes we can't keep too many of the chunks in the final LLM prompt for answering the question. Any other ways of looking at this?

Message : https://python.langchain.com/en/latest/modules/memory/how_to_guides.html

Message : https://trib.al/HIuiF1K

Message : Is it possible for a specialized piece of hardware (ASICs or FPGAs) to speed up the embedding search ?

Message : Hey @91773788xxxx can we summarize the things going on here with GPT. It's getting really hard and time consuming to catch up with 50+ messages on WA. As more people are joining, the number of messages here is just exploding üòÖ

Message : This guy is literally raising funds via his github repository

Message : https://github.com/jdagdelen/hyperDB

Message : someone said langchain will probably integrate this by end of the day

Message : it's a joke apparently

Message : yea it opens up that nyan cat youtube video üòÑ
Quoted Message : it's a joke apparently

Message : ‚Äé<attached: 00000252-PHOTO-2023-04-16-17-45-59.jpg>

Message : ‚Äé<attached: 00000254-PHOTO-2023-04-16-17-48-11.jpg>
Quoted Message : https://github.com/jdagdelen/hyperDB

Message : I tried asking GPT for this. This is what it responded with.

Summary:
Links/Websites Discussed:

Twitter discussion: https://twitter.com/karpathy/status/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19
The Verge article on GPT-5 rumors: https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman
Bionic Reading API: https://rapidapi.com/bionic-reading-bionic-reading-default/api/bionic-reading1
GitHub Copilot knockoff for free by AWS: https://aws.amazon.com/codewhisperer/
Community Guidelines for WA group: https://github.com/NirantK/nirantk.github.io/pull/7
ChatGPT UI for API: https://www.chatbotui.com/
Fine-tuning large language models: https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html
Databrick's Dolly LLM: https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm
Sci-fi story "The Last Question" by Isaac Asimov: https://www.gregegan.net/MISC/CRYSTAL/Crystal.html
Paper on understanding color: https://arxiv.org/abs/2109.06129
Open-source project: https://qntm.org/mmacevedo
Sci-fi story "The Illustrated Man" by Ray Bradbury
Question_answering_using_embeddings notebook: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
Article on decreasing Docker image size: https://stackoverflow.com/questions/63521958/is-this-a-right-way-to-descrease-size-of-my-docker-images
Article on PyTorch ONNX Sentence Transformer Optimization: https://medium.com/@TheHaseebHassan/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696
Topics Discussed:

Generative AI community
Vector DB and semantic search
Production-level deployments
Fine-tuning and in-context learning
GPT-5 rumors
Bionic reading technique
Open-source projects and their economics
AI for crime detection
Model distillation
Sci-fi stories and their relevance to AI
Fine-tuning large language models
Sentence Transformers and OpenAI
Deploying large models to Kubernetes
ChatGPT API usage and context window handling
Using embeddings for cost reduction
Converting Sentence Transformers to ONNX format
Quoted Message : Hey @9177xxxxxxxx can we summarize the things going on here with GPT. It's getting really hard and time consuming to catch up with 50+ messages on WA. As more people are joining, the number of messages here is just exploding üòÖ

Message : A smart summariser Bot for WhatsApp groups will be really helpful. 
If anyone is enthu to build something, loop me in!

Message : im very inspired by this. gonna launch my own database next week. have a killer name in mind.
Quoted Message :  2023_04_16_3EB04CFA02E8F6D66B5F.jpeg

Message : post by Vespa founder https://bergum.medium.com/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5

Message : IPython ChatGPT extension
https://github.com/santiagobasulto/ipython-gpt

Message : Neat, this can work with Google Colab in theory too
Quoted Message : IPython ChatGPT extension\nhttps://github.com/santiagobasulto/ipython-gpt

Message : ‚Äé<attached: 00000266-PHOTO-2023-04-16-22-35-11.jpg>

Message : or is it just ranking them and using the closest match to the input

Message : Good questions

Message : Would love to hear what people have to say

Message : Auto GPT does have an intermediate summary phase where it tries to break the webpage down to 8192 token chunks

Summarises each chunk

And then summarises the summaries of the chunks obtained in the step above

Message : Not sure whqts happening in here though
Can't imagine it to be wildly different from autoGPT approach
Quoted Message :  2023_04_16_3EB02B7E746032C7F813D0.jpeg

Message : makes sense..
Quoted Message : Not sure whqts happening in here though\nCan't imagine it to be wildly different from autoGPT approach

Message : Anyone here who has worked extensively with these agents?

Message : There are few different things:

1. The OpenAI Plugin does NOT do summarisation. It simply does a search and select. This is similar to their Retrieval Plugin in that way. The _context_ window limits do not apply in the same way there because OpenAI has confirmed that these are smaller, lightly finetuned models for specific tasks. E.g. is it possible they can parse HTML in a 32K GPT4 model and use it? Yes.

2. AutoGPT or most GPT4 products use the map-reduce/combine approach from Langchain, which @91997100xxxx described
Quoted Message :  2023_04_16_3EB02B7E746032C7F813D0.jpeg

Message : @91966317xxxx uses them almost daily to run his company and cribs about how broken they are
Quoted Message : Anyone here who has worked extensively with these agents?

Message : If you do not like to use LLM for HTML parsing then this tool I found does a great job. But use it at arm distances because it is GPL3 licensed.

https://trafilatura.readthedocs.io/en/latest/
Quoted Message : There are few different things:\n\n1. The OpenAI Plugin does NOT do summarisation. It simply does a search and select. This is similar to their Retrieval Plugin in that way. The _context_ window limits do not apply in the same way there because OpenAI has confirmed that these are smaller, lightly finetuned models for specific tasks. E.g. is it possible they can parse HTML in a 32K GPT4 model and use it? Yes. \n\n2. AutoGPT or most GPT4 products use the map-reduce/combine approach from Langchain, which @9199xxxxxxxx described

Message : not extensively yet but have the same experience.

since for now my workflow to be executed was limited on a theme level so I went ahead with a classifier to detect task, and then LLM to extract details of the task to be done and do the tasks in code and output by LLM again.

custom and less useful agent but doesn't break on prod
Quoted Message : Anyone here who has worked extensively with these agents?

Message : for now my plan is also to keep adding new tasks in classifier and seperating their workflow standalone

previously tried with the agent too but things were happening randomly most of the times and without any control.

I'm yet to go through the new blog that Chip has posted but it might have good nuggets - if anyone has already went through, feel free to DM me if something better is already possible

Message : There are strategies in langchain for this.. map_reduce, refine, ...
Quoted Message : Auto GPT does have an intermediate summary phase where it tries to break the webpage down to 8192 token chunks\n\nSummarises each chunk\n\nAnd then summarises the summaries of the chunks obtained in the step above

Message : Will read up on it. What's the umbrella term langchain uses for these?
Quoted Message : There are strategies in langchain for this.. map_reduce, refine, ...

Message : https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html
Quoted Message : Will read up on it. What's the umbrella term langchain uses for these?

Message : memory chains or conversation memory
Quoted Message : Will read up on it. What's the umbrella term langchain uses for these?

Message : those are different I think
Quoted Message : memory chains or conversation memory

Message : Summarisation sounds about right

Message : Memory is retrieval
Summarisation is computational

Message : Sorry. You are right. It's summarization
Quoted Message : those are different I think

Message : btw folks langchain discord has a "ask-kapa-langchain" channel for asking doubts. very useful bot while building with langchain. it's based on the langchain docs, codebase.

Message : they also have integrated https://www.mendable.ai/ into their documentation, works like a bot, could be similar. Does the bot also allows to ask query on discord chat?
Quoted Message : btw folks langchain discord has a \"ask-kapa-langchain\" channel for asking doubts. very useful bot while building with langchain. it's based on the langchain docs, codebase.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : There are strategies in langchain for this.. map_reduce, refine, ...
Quoted Message : Auto GPT does have an intermediate summary phase where it tries to break the webpage down to 8192 token chunks\n\nSummarises each chunk\n\nAnd then summarises the summaries of the chunks obtained in the step above

Message : Will read up on it. What's the umbrella term langchain uses for these?
Quoted Message : There are strategies in langchain for this.. map_reduce, refine, ...

Message : https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html
Quoted Message : Will read up on it. What's the umbrella term langchain uses for these?

Message : memory chains or conversation memory
Quoted Message : Will read up on it. What's the umbrella term langchain uses for these?

Message : those are different I think
Quoted Message : memory chains or conversation memory

Message : Summarisation sounds about right

Message : Memory is retrieval
Summarisation is computational

Message : Sorry. You are right. It's summarization
Quoted Message : those are different I think

Message : btw folks langchain discord has a "ask-kapa-langchain" channel for asking doubts. very useful bot while building with langchain. it's based on the langchain docs, codebase.

Message : they also have integrated https://www.mendable.ai/ into their documentation, works like a bot, could be similar. Does the bot also allows to ask query on discord chat?
Quoted Message : btw folks langchain discord has a \"ask-kapa-langchain\" channel for asking doubts. very useful bot while building with langchain. it's based on the langchain docs, codebase.

Message : yeah. the kapa langchain bot is discord based. when you ask a question, it generates the answer in a thread
Quoted Message : they also have integrated https://www.mendable.ai/ into their documentation, works like a bot, could be similar. Does the bot also allows to ask query on discord chat?

Message : Does this also have automated screening of resumes?

Message : https://www.skillate.com/

this one claims to do automated screening
Quoted Message : Does this also have automated screening of resumes?

Message : https://leoforce.com/

and this for automated sourcing. something like this focussed on tech hiring would be huge.

Companies pay $50k-100k for manual sourcing tools like Gem crm

Message : Gottit ,I was planning on building an automated screening in my company 

Goal was to use semantic search driven similarity results

Ethically it struck me as very wrong,this process would end up in adversarial selection üòÖ

Only people savvy enough to manipulate resumes to match job requirements would be screened as a result who might or might not be the candidates we want

And some genuine candidates could be left out
Quoted Message : https://www.skillate.com/\n\nthis one claims to do automated screening

Message : How do you solve for this issue if automated screening is used?
Quoted Message : https://leoforce.com/\n\nand this for automated sourcing. something like this focussed on tech hiring would be huge. \n\nCompanies pay $50k-100k for manual sourcing tools like Gem crm

Message : I abandoned working on the prototype all together because of these issues ü•≤
Quoted Message : Gottit ,I was planning on building an automated screening in my company \n\nGoal was to use semantic search driven similarity results \n\nEthically it struck me as very wrong,this process would end up in adversarial selection üòÖ\n\nOnly people savvy enough to manipulate resumes to match job requirements would be screened as a result who might or might not be the candidates we want\n\nAnd some genuine candidates could be left out

Message : Sounds a lot like the SEO - google war

Message : It's perennial

Message : One party is trying to deliver the best results to its usere

Message : The other party is trying to hack around that delivery logic

Message : True. The other side of this spectrum is someone building a resume builder to job candidates so that the resume is maximally similar to JD
Quoted Message : Sounds a lot like the SEO - google war

Message : Never ending arms race

Message : Yes, it's unethical. But if you won't use it, someone else probably will
Quoted Message : Gottit ,I was planning on building an automated screening in my company \n\nGoal was to use semantic search driven similarity results \n\nEthically it struck me as very wrong,this process would end up in adversarial selection üòÖ\n\nOnly people savvy enough to manipulate resumes to match job requirements would be screened as a result who might or might not be the candidates we want\n\nAnd some genuine candidates could be left out

Message : even today, recruiters don't do the first touch on resumes in big corps.

there are always softwares altho at keyword match capability probably and people already hack it by adding "java spring" in white font so it's not visible to naked eye
Quoted Message : Gottit ,I was planning on building an automated screening in my company \n\nGoal was to use semantic search driven similarity results \n\nEthically it struck me as very wrong,this process would end up in adversarial selection üòÖ\n\nOnly people savvy enough to manipulate resumes to match job requirements would be screened as a result who might or might not be the candidates we want\n\nAnd some genuine candidates could be left out

Message : Then the other side will start too :)
Semantic Resume Builder
Do a semantic search over target JDs
Take inputs from user on experience
Generate resume which would be most similar to Job requirements
Quoted Message : Yes, it's unethical. But if you won't use it, someone else probably will

Message : There is also the matter of possible bias which the AI solutions might have. Which is difficult to solve for and a very sensitive issue.

Message : And then use chat GPT during the interview
Quoted Message : Then the other side will start too :)\n Semantic Resume Builder \nDo a semantic search over target JDs \nTake inputs from user on experience \nGenerate resume which would be most similar to Job requirements

Message : Boom

Message : Slightly off track but it reminds me of this dialogue from Batman Begins :)

Jim Gordon : What about escalation?
Batman : Escalation?
Jim Gordon : We start carrying semi-automatics, they buy automatics. We start wearing Kevlar, they buy armor piercing rounds.
Quoted Message : And then use chat GPT during the interview

Message : I‚Äôm seeing many companies ask candidates to come in person to the office for interviews for this very reason üòÇ
Quoted Message : And then use chat GPT during the interview

Message : ‚Äé<attached: 00000310-PHOTO-2023-04-17-01-11-40.jpg>
Quoted Message :  2023_04_16_3A08B3CAE732BCBDB9E3.jpeg

Message : The _‚Äúactions‚Äù_ settings say it can retrieve upto 500 rows, but I‚Äôve only been able to reach that limit for small, tokenised, chunked datas in each row

Message : ‚Äé<attached: 00000312-PHOTO-2023-04-17-01-46-01.jpg>

Message : anyone here who can share some basic dope on how some people are creating realistic music with AI?

Message : Check:

https://google-research.github.io/seanet/musiclm/examples/

https://github.com/riffusion/riffusion
Quoted Message : anyone here who can share some basic dope on how some people are creating realistic music with AI?

Message : thanks ‚úÖ

I run riffusion everyday while coding, didn't check they had a paper too üòÖ
Quoted Message : Check:\n\nhttps://google-research.github.io/seanet/musiclm/examples/\n\nhttps://github.com/riffusion/riffusion

Message : so there's no elevenlabs like product yet - right?

where you plugin sample voice, and prompt to generate some music? surprised if not.
Quoted Message : Check:\n\nhttps://google-research.github.io/seanet/musiclm/examples/\n\nhttps://github.com/riffusion/riffusion

Message : https://gooey.ai/text2audio/

Message : Folks .. this is an amazing lecture on the question whether GPT4 is really AGI ? I highly recommend watching it. 
https://www.youtube.com/watch?v=qbIk7-JPB2c

The speaker is Senior Principal Research Manager at Microsoft Research and and ex-assistant professor at Princeon.  http://sbubeck.com/

Message : Summary of this in a thread here - https://twitter.com/psurya1994/status/1647628166792372224?s=20
Quoted Message : Folks .. this is an amazing lecture on the question whether GPT4 is really AGI ? I highly recommend watching it. \nhttps://www.youtube.com/watch?v=qbIk7-JPB2c\n\nThe speaker is Senior Principal Research Manager at Microsoft Research and and ex-assistant professor at Princeon.  http://sbubeck.com/

Message : Sharing the original paper here as well for completeness. The talk, thread are based off this and paper has some amazing examples
https://arxiv.org/abs/2303.12712

Message : If you'd like to present a paper summary e.g. Reflexion, Sparks of AGI, Amazon's MM-CoT at the meetup this Saturday, happy to help you outline and prepare. Please DM me soon!

Message : BLR Generative April meetup: 
https://hasgeek.com/generativeAI/april-meetup/

Message : Here is one about review of fine tuning techniques  https://arxiv.org/abs/2303.15647 . There is one more, will see if I can find it which spoke more specifically prompting vs fine-tuning.
Quoted Message : There was recent tweet from someone about comparing fine-tuning and prompting. Will see if I can find it. That had some details of effects of fine tuning and what prompting can deliver.

Message : Are we also calling model distillation as fine-tuning now? I see them both being used interchangeably on interwebs

Message : Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https://bit.ly/lsip-dataverse-ep4

On another note, would love to hear the group's thoughts on how they see the BI layer being affected?

Message : https://www.indiatoday.in/technology/news/story/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12

Anyone aware of this, whether they used GPT4?

Message : This seems to be GPT-3.5
Quoted Message : https://www.indiatoday.in/technology/news/story/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12\n\nAnyone aware of this, whether they used GPT4?

Message : Someone tested using GPT-4 and they reported 21/108 questions being solved by GPT-4 

https://twitter.com/amuseddaman/status/1647367373354328065?s=46&t=icC0fizZK8E3ONsDVuGFWA


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Summary of this in a thread here - https://twitter.com/psurya1994/status/1647628166792372224?s=20
Quoted Message : Folks .. this is an amazing lecture on the question whether GPT4 is really AGI ? I highly recommend watching it. \nhttps://www.youtube.com/watch?v=qbIk7-JPB2c\n\nThe speaker is Senior Principal Research Manager at Microsoft Research and and ex-assistant professor at Princeon.  http://sbubeck.com/

Message : Sharing the original paper here as well for completeness. The talk, thread are based off this and paper has some amazing examples
https://arxiv.org/abs/2303.12712

Message : If you'd like to present a paper summary e.g. Reflexion, Sparks of AGI, Amazon's MM-CoT at the meetup this Saturday, happy to help you outline and prepare. Please DM me soon!

Message : BLR Generative April meetup: 
https://hasgeek.com/generativeAI/april-meetup/

Message : Here is one about review of fine tuning techniques  https://arxiv.org/abs/2303.15647 . There is one more, will see if I can find it which spoke more specifically prompting vs fine-tuning.
Quoted Message : There was recent tweet from someone about comparing fine-tuning and prompting. Will see if I can find it. That had some details of effects of fine tuning and what prompting can deliver.

Message : Are we also calling model distillation as fine-tuning now? I see them both being used interchangeably on interwebs

Message : Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https://bit.ly/lsip-dataverse-ep4

On another note, would love to hear the group's thoughts on how they see the BI layer being affected?

Message : https://www.indiatoday.in/technology/news/story/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12

Anyone aware of this, whether they used GPT4?

Message : This seems to be GPT-3.5
Quoted Message : https://www.indiatoday.in/technology/news/story/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12\n\nAnyone aware of this, whether they used GPT4?

Message : Someone tested using GPT-4 and they reported 21/108 questions being solved by GPT-4 

https://twitter.com/amuseddaman/status/1647367373354328065?s=46&t=icC0fizZK8E3ONsDVuGFWA

Message : Also IMO these tests are very misleading ,it‚Äôs performance on zero shot prompting of JEE questions would obviously be poor 


Like someone else had pointed out  let GPT-4 have access to Wolfram plugin and/or fine tune on corpus of 30 yrs JEE questions ,it could score decent enough

Message : Present LLMs fake understanding

So if you don't train it sufficiently on data you are testing it on, it is going to fail

We can fine tune a model that is good at solving jee problems, but might fail on other simpler tasks
Quoted Message : https://www.indiatoday.in/technology/news/story/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12\n\nAnyone aware of this, whether they used GPT4?

Message : Plus we don‚Äôt really know what prompting strategy they have used, they might have simply kept the question and asked for the answer. Having a simple CoT based promoting strategy will probably lead to much better scores

Message : Isn't having access to a Wolfram plugin basically cheating?
Quoted Message : Also IMO these tests are very misleading ,it‚Äôs performance on zero shot prompting of JEE questions would obviously be poor \n\n\nLike someone else had pointed out  let GPT-4 have access to Wolfram plugin and/or fine tune on corpus of 30 yrs JEE questions ,it could score decent enough

Message : It is sort of consistent with the fact that it cannot do complex math. For now. Physics and chemistry it can reproduce well with decent reasoning

Message : I‚Äôm 100% sure the ones reporting failure of GPT on JEE would be copy pasting questions in ChatGPT
Quoted Message : Plus we don‚Äôt really know what prompting strategy they have used, they might have simply kept the question and asked for the answer. Having a simple CoT based promoting strategy will probably lead to much better scores

Message : "Significant gains are visible in the accuracy of the GPT4 model, in decreasing order of Chemistry(‚ú®36%‚ú®), Physics(14%), and Maths(3%) over ChatGPT on our challenge set" thread says

Message : I‚Äôm curious to see the performance with Wolfram access + textbook content retrieval. Even though it‚Äôs kinda like cheating, considering the complexity of JEE it‚Äôs still impressive if it can solve with content retrieval and tools access as well

Message : Also we're forgetting the value of negative marking

If you prompt GPT4 to skip the question if it's not confident then I'm sure it will score much better

Message : Exactly, these people just post results with some general prompting and then give a wrong impression
Quoted Message : Plus we don‚Äôt really know what prompting strategy they have used, they might have simply kept the question and asked for the answer. Having a simple CoT based promoting strategy will probably lead to much better scores

Message : Not sure how else to train a LLM to solve complex math 

No amount of fine tuning can help it be proficient in complex maths I think
Quoted Message : Isn't having access to a Wolfram plugin basically cheating?

Message : Also perhaps there is some value in prompting it to skip math more than chem and physics

Message : Since it's dumber at maths

Message : +1 on this 

Also even humans iterate on a question for getting answers

If there was a way to incorporate feedback while it solves JEE questions then perhaps we could see better results
Quoted Message : Also we're forgetting the value of negative marking\n\nIf you prompt GPT4 to skip the question if it's not confident then I'm sure it will score much better

Message : In Zero shot prompting you‚Äôre just posting a question and taking at face value the first answer GPT provides

Message : Someone can experiment autogpt with jee and see where it leads

Message : Will be still useless with math I am guessing

Message : And also many low hanging fruit problems in JEE are repeat questions with slightly different values

I'm sure if there's a a vector db of all the past questions and test papers it will do much better in collecting all these low hanging fruits

Message : Also I'm sure GPT finishes the entire test in like 5 to 10 minutes

There should be a secondary review pass where it is prompted to check it's solutions with proper logical reasoning. There is a chance that it might revise a few of its previously wrong answers.

Message : And also sequential questions. Where one question's answer leads to the context of next one. I'm sure whoever implemented this experiment did not take into account the previous questions context and prompted GPT to answer it in isolation. 

There should be a question context window which looks at N-1 and N+1 question when GPT is on question N. And verify if these questions are interrelated. If they are, then use all three questions in context window.

Message : Anyone wants to join hands and work on this with me?

Message : Sure!

Message : Also had another idea if anyone is up to collab: https://replit.com/bounties/@JosephJacks/llm-ify-any-app

Message : It still can't do math calculations, that must have been main reason why it failed brutally. I think it must have scored great in reasoning questions.
I also tried few math questions to GPT-4 from last year paper, the method was 80% correct but still the final answers were wrong.
Quoted Message : Also IMO these tests are very misleading ,it‚Äôs performance on zero shot prompting of JEE questions would obviously be poor \n\n\nLike someone else had pointed out  let GPT-4 have access to Wolfram plugin and/or fine tune on corpus of 30 yrs JEE questions ,it could score decent enough

Message : Making a group
Quoted Message : Sure!

Message : Anyone else?

Message : A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider
Quoted Message : And also sequential questions. Where one question's answer leads to the context of next one. I'm sure whoever implemented this experiment did not take into account the previous questions context and prompted GPT to answer it in isolation. \n\nThere should be a question context window which looks at N-1 and N+1 question when GPT is on question N. And verify if these questions are interrelated. If they are, then use all three questions in context window.

Message : actually interesting idea, I could give this a try‚Ä¶
Quoted Message : Also IMO these tests are very misleading ,it‚Äôs performance on zero shot prompting of JEE questions would obviously be poor \n\n\nLike someone else had pointed out  let GPT-4 have access to Wolfram plugin and/or fine tune on corpus of 30 yrs JEE questions ,it could score decent enough

Message : Clip it up
Quoted Message : A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider

Message : Not going to help 100% of the time but that is indeed very valuable context

Message : I doubt clip would be effective with academic diagrams, worth a shot but i'm skeptical

Message : Let's see

Message : If it isn't then we'll just prompt it to be a little hesitant in answering diagram based questions

Message : CLIP + some OCR logic + some prompting on top of that maybe idk

Message : Can probably glue up something like Amazon's MM-CoT and see if that helps with diagrams and figures? cc @91824021xxxx
Quoted Message : A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider

Message : I'm sure folks in this group can do much better than what these guys did

Message : I've already made a group with @91779654xxxx

Message : We'll crack it soon!

Message : Happy to have more folks on board

Message : OCR is definitely required
Quoted Message : CLIP + some OCR logic + some prompting on top of that maybe idk


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I doubt clip would be effective with academic diagrams, worth a shot but i'm skeptical

Message : Let's see

Message : If it isn't then we'll just prompt it to be a little hesitant in answering diagram based questions

Message : CLIP + some OCR logic + some prompting on top of that maybe idk

Message : Can probably glue up something like Amazon's MM-CoT and see if that helps with diagrams and figures? cc @91824021xxxx
Quoted Message : A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider

Message : I'm sure folks in this group can do much better than what these guys did

Message : I've already made a group with @91779654xxxx

Message : We'll crack it soon!

Message : Happy to have more folks on board

Message : OCR is definitely required
Quoted Message : CLIP + some OCR logic + some prompting on top of that maybe idk

Message : Flip your work to FOSS and post weekly updates :)
Quoted Message : I'm sure folks in this group can do much better than what these guys did

Message : are we opening a fiitjee for llms now :p
Quoted Message : Making a group

Message : If you start fine tuning it then definitely it‚Äôs FIITJEE

Message : overFIITJEE

Message : After all aren‚Äôt students ‚Äúfine tuned‚Äù for cracking JEE ? üòù

Message : We can also skip image related questions in first try? and see how it performs on questions with no images.

Message : I am already in process of writing a paper on this. Should be up on arxiv by this weekend
Quoted Message : Making a group

Message : Problem:
Problem: Albus gets three types of questions:
1. Internal company wiki
2. AI
3. Support questions
How can we decide what type of question it is? Langchain agents have the framework but it would need to be programmed. Has anyone worked on something like this?

Message : Working on similar problem statement currently 
I‚Äôm evaluating this framework from GPT-Index

https://twitter.com/jerryjliu0/status/1647626532519841793?s=46&t=icC0fizZK8E3ONsDVuGFWA

Message : Should we spin off a separate group for speculative fiction enthusiasts?
Quoted Message : Any sci-fi enthusiasts here ? üòÉ\n\nHas anyone read ‚ÄúThe Last Question‚Äù by Isaac Asimov?

Message : You can create a separate prompt for determining the question type. In the prompt you can keep the three options in MCQ format at the end of the prompt so you can easily parse the output. Keep this prompt at the very beginning before the retrieval part
Quoted Message : Problem:\nProblem: Albus gets three types of questions:\n1. Internal company wiki\n2. AI\n3. Support questions\nHow can we decide what type of question it is? Langchain agents have the framework but it would need to be programmed. Has anyone worked on something like this?

Message : Already exists: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Quoted Message : Should we spin off a separate group for speculative fiction enthusiasts?

Message : Thank you!
Quoted Message : Already exists: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : ‚Äé<attached: 00000386-PHOTO-2023-04-17-11-39-08.jpg>

Message : I agree we need better terms. Not sure what to call soft-prompting. It's not distillation. Customer don't want to use OpenAI + only davinci knows enough context to generate valid outputs but still needs fine tuning on data not publicly available. But they are insanely expensive to serve ($.12/1k token, that's 10Rs per output).
Quoted Message : Here is one about review of fine tuning techniques  https://arxiv.org/abs/2303.15647 . There is one more, will see if I can find it which spoke more specifically prompting vs fine-tuning.

Message : So we are in this world of fine tuning local models. To be able to serve/train them reasonably, you need small models. Anyone else fine-tuning local models or using fine tuned davinci.

Message : Btw did anyone try to ask chat GPT4 to solve ie Itodov?
Quoted Message :  2023_04_17_3AEDDCC0C499AF588C43.jpeg

Message : Imo atleast for the physics part for waves i did try. Let me know if anyone is able to try with questions of IE Irodov üòÖ
Quoted Message : Btw did anyone try to ask chat GPT4 to solve ie Itodov?

Message : Models like MatCha or DePlot are trying to answer based on diagrams. https://huggingface.co/docs/transformers/main/model_doc/matcha , https://huggingface.co/docs/transformers/main/model_doc/deplot
Quoted Message : A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider

Message : for diagrams, there's Google's Pix2Struct. trained on 9 tasks. links:

https://github.com/google-research/pix2struct
https://replicate.com/cjwbw/pix2struct
https://twitter.com/search?q=Pix2Struct

Message : Vicuna-7B runs in Chrome Canary on M2 Macs with WebGPU
https://simonwillison.net/2023/Apr/16/web-llm/

Message : Super exciting direction because this means we can have LLMs which are private to _user_, not just _organisation_

Message : Perhaps, some day we'll have lightly finetuned weights for every person and you just take them from one company to the next like you do with your personal phones today

Message : Giving me Blade runner 2049/Her vibes.
Quoted Message : Perhaps, some day we'll have lightly finetuned weights for every person and you just take them from one company to the next like you do with your personal phones today

Message : _Apple silently beefing up their little ml cores inside iphones_
Quoted Message : Perhaps, some day we'll have lightly finetuned weights for every person and you just take them from one company to the next like you do with your personal phones today

Message : We already have that at a very small scale, your phone keyboard is personalised
Quoted Message : Perhaps, some day we'll have lightly finetuned weights for every person and you just take them from one company to the next like you do with your personal phones today

Message : Fun fact: Person behind WebLLMs also developed XGBoost, TVM and MXNet
Quoted Message : Vicuna-7B runs in Chrome Canary on M2 Macs with WebGPU\nhttps://simonwillison.net/2023/Apr/16/web-llm/

Message : yup. google did some very impressive stuff for on-device ML for Assistant and Gboard apps, a few years back.
Quoted Message : We already have that at a very small scale, your phone keyboard is personalised

Message : Before my current product, I wanted to build an AI-enabled analytics product. Some thoughts on this:
- Incumbents have a big advantage here IMO, more so than other areas
- Anyone who has semantics on the data will definitely build AI on top. Because the data is structured, it feels easier to do so.
- I do think there is a large business to be built here but it needs go much further
- Being able to ask causal questions (e.g. why did conversion fall in X area last week?), have the machine do the work and get an answer for you feels very powerful

Always happy to chat about this :)
Quoted Message : Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https://bit.ly/lsip-dataverse-ep4\n\nOn another note, would love to hear the group's thoughts on how they see the BI layer being affected?

Message : Talk about a boss-mode Github
https://github.com/tqchen
Quoted Message : Fun fact: Person behind WebLLMs also developed XGBoost, TVM and MXNet

Message : Goat
Quoted Message : Talk about a boss-mode Github\nhttps://github.com/tqchen

Message : Fine-tuning davinci doesn't really work is what I have heard
Quoted Message : So we are in this world of fine tuning local models. To be able to serve/train them reasonably, you need small models. Anyone else fine-tuning local models or using fine tuned davinci.

Message : Prompt engineering davinci is almost always better than fine-tuning it

Message : For those not familiar with naming conventions: 
davinci and GPT3 are the same. That is an original instruction - finetuned LLM and not a Chat LLM

GPT3.5-Turbo and GPT4 are Chat LLMs with a conversational mode

Message : The Analogy i like to use is: what if just a handful of people at a company knew how to Google stuff? The whole place would struggle to make decisions based on data. We see the same thing happening with data analysis. 

We‚Äôre trying to solve this at https://www.probeai.app/
Quoted Message : Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https://bit.ly/lsip-dataverse-ep4\n\nOn another note, would love to hear the group's thoughts on how they see the BI layer being affected?

Message : Can I get access? Trying to integrate something similar for our data warehouses
Quoted Message : The Analogy i like to use is: what if just a handful of people at a company knew how to Google stuff? The whole place would struggle to make decisions based on data. We see the same thing happening with data analysis. \n\nWe‚Äôre trying to solve this at https://www.probeai.app/

Message : DMing
Quoted Message : Can I get access? Trying to integrate something similar for our data warehouses

Message : https://www.together.xyz/blog/redpajama

Message : who's picking all these names üòÇ

Message : An Indian employee of huggingface worked on this and published it

https://huggingface.co/blog/lora
Quoted Message : who's picking all these names üòÇ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Goat
Quoted Message : Talk about a boss-mode Github\nhttps://github.com/tqchen

Message : Fine-tuning davinci doesn't really work is what I have heard
Quoted Message : So we are in this world of fine tuning local models. To be able to serve/train them reasonably, you need small models. Anyone else fine-tuning local models or using fine tuned davinci.

Message : Prompt engineering davinci is almost always better than fine-tuning it

Message : For those not familiar with naming conventions: 
davinci and GPT3 are the same. That is an original instruction - finetuned LLM and not a Chat LLM

GPT3.5-Turbo and GPT4 are Chat LLMs with a conversational mode

Message : The Analogy i like to use is: what if just a handful of people at a company knew how to Google stuff? The whole place would struggle to make decisions based on data. We see the same thing happening with data analysis. 

We‚Äôre trying to solve this at https://www.probeai.app/
Quoted Message : Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https://bit.ly/lsip-dataverse-ep4\n\nOn another note, would love to hear the group's thoughts on how they see the BI layer being affected?

Message : Can I get access? Trying to integrate something similar for our data warehouses
Quoted Message : The Analogy i like to use is: what if just a handful of people at a company knew how to Google stuff? The whole place would struggle to make decisions based on data. We see the same thing happening with data analysis. \n\nWe‚Äôre trying to solve this at https://www.probeai.app/

Message : DMing
Quoted Message : Can I get access? Trying to integrate something similar for our data warehouses

Message : https://www.together.xyz/blog/redpajama

Message : who's picking all these names üòÇ

Message : An Indian employee of huggingface worked on this and published it

https://huggingface.co/blog/lora
Quoted Message : who's picking all these names üòÇ

Message : During my research days I came across this dataset called LOL dataset

Message : It was a dataset of low light pictures and their well-lit versions

Message : I think I even used it in my papers and cited it

Message : Ohh I know this one: paperswithcode.com/dataset/lol

Message : Yes exactly that!

Message : It was the wild West in 2017 

People would just publish all sorts of crazy improvements with no reproducibility - no code and no exhaustive description of algorithms

Message : How could anyone compare their claims to these unreproducable publications

Message : Paperwithcode.com was quite helpful to compare my research with others

Message : Haha lol yes. I remember those days. I spent months trying to make a sota model work for our data, then failed to reproduce then rebuilt with some more data then fine tune and rebuild and so on. Eventually I realised their sota was reproducible but nothing else worked.
Quoted Message : It was the wild West in 2017 \n\nPeople would just publish all sorts of crazy improvements with no reproducibility - no code and no exhaustive description of algorithms

Message : PSA: Please inform whosoever you're sharing the invite link with that this group is a firehose and somewhat technical in it's spirit. 
It'll save them time and spare the rest of us from getting ```left``` notifs.

Message : but the lora paper didn't have any indian author
https://arxiv.org/abs/2106.09685
Quoted Message : An Indian employee of huggingface worked on this and published it\n\nhttps://huggingface.co/blog/lora

Message : LoRA is from MSFT, that blog is from Huggingface DevRel ‚Äî which has a couple of Indian origin folks in Europe
Quoted Message : but the lora paper didn't have any indian author\nhttps://arxiv.org/abs/2106.09685

Message : yes

Message : You exactly know my pain ü´Ç
Quoted Message : Haha lol yes. I remember those days. I spent months trying to make a sota model work for our data, then failed to reproduce then rebuilt with some more data then fine tune and rebuild and so on. Eventually I realised their sota was reproducible but nothing else worked.

Message : Were you working for a research group back then? Or was this an industrial task?

Message : @91805009xxxx

Message : Oh my bad
I thought the huggingface team was the one named this
Quoted Message : but the lora paper didn't have any indian author\nhttps://arxiv.org/abs/2106.09685

Message : Huggingface built a wrapper around multiple finetuning methods, called it PEFT: https://github.com/huggingface/peft

That blog is specifically PR for that

Message : ‚Äé<attached: 00000443-PHOTO-2023-04-17-19-32-26.jpg>

Message : for my startup üôÇ Bewgle.
Quoted Message : Were you working for a research group back then? Or was this an industrial task?

Message : My salutations
Quoted Message : for my startup üôÇ Bewgle.

Message : Can't help but admire any founder ready to roll their sleeves up and get their hands dirty in some R&D

Message : https://twitter.com/NathanLands/status/1647864974323204096
relevant to our previous conversation on more companies entering the space. Google and Amazon both launched code completion etc - getting very similar to OpenAI

Message : Which LLM will you use ... I did benchmarking on all open source ones against GPT4.. all open source ones are bad üòû.. and really the only one commercially available is Dolly 2.. it can't compare to GPT4.
Quoted Message : for my startup üôÇ Bewgle.

Message : Just ask each of them - "What is Bengaluru? Be concise" and see all of them spectacularly fail. üò´

Message : So Magi is Bards sister? / is this a rebrand because of all the bad press from the bard launch?

The underlying is still Lambda. These multiple launches are confusing and shows massive desperation.

https://twitter.com/gergelyorosz/status/1647905401432571904?s=46&t=5aQS86mRo7ytzWcjKYKPUQ
Quoted Message : https://twitter.com/NathanLands/status/1647864974323204096\nrelevant to our previous conversation on more companies entering the space. Google and Amazon both launched code completion etc - getting very similar to OpenAI

Message : Not PaLM?

Message : Is it PaLM? not sure.
Quoted Message : Not PaLM?

Message : it's Google. multiple launches, rebranding of the same product is their forte üòÇ
Quoted Message : So Magi is Bards sister? / is this a rebrand because of all the bad press from the bard launch?\n\nThe underlying is still Lambda. These multiple launches are confusing and shows massive desperation. \n\nhttps://twitter.com/gergelyorosz/status/1647905401432571904?s=46&t=5aQS86mRo7ytzWcjKYKPUQ

Message : We build some models and ensemble some others. Our use case is deliberately narrow- we don‚Äôt need super powers. Besides, the problem with LLMs is that you have no control over them at all. If an LLM doesn‚Äôt behave the way you want it to, what will you do? Prompt tinkering is ok but it assumes that the LLM is perfect. And it isn‚Äôt. There are other issues with prebuilt LLMs as well which makes it tough to use in an enterprise environment.
Quoted Message : Which LLM will you use ... I did benchmarking on all open source ones against GPT4.. all open source ones are bad üòû.. and really the only one commercially available is Dolly 2.. it can't compare to GPT4.

Message : @1267303xxxx
Quoted Message : Which LLM will you use ... I did benchmarking on all open source ones against GPT4.. all open source ones are bad üòû.. and really the only one commercially available is Dolly 2.. it can't compare to GPT4.

Message : LLM Components to decide and weigh memory in Langchain, from the Generative Agents paper. Implements 2 agents talking to each other as well. 
https://twitter.com/hwchase17/status/1647987713449263106

Message : i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?

Message : especially in this case related to generative AI

Message : Has any of you worked with LLMs for math problem solving, or used chain-of-reason prompting? We're delving into the problem solving use case and would love to discuss if you have.

Message : A good starting point:
1. https://www.youtube.com/watch?v=j1DvCavAmhE
2. https://www.froihofer.net/students/how-to-write-a-computer-science-paper/

Note that writing a paper is a different skillset from doing research or engineering, in the same way that interviewing for a job is a different skill from doing the job.

Would encourage others to directly DM the friend :)
Quoted Message : i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?

Message : Grab hold of a prof. Or.. Enterprise researchers can help if you intern with them.
Quoted Message : i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?

Message : Did you try something improve controllability. We are also having issues, esp when you need executable or near executable like outputs. Think DSL like outputs etc.
Quoted Message : We build some models and ensemble some others. Our use case is deliberately narrow- we don‚Äôt need super powers. Besides, the problem with LLMs is that you have no control over them at all. If an LLM doesn‚Äôt behave the way you want it to, what will you do? Prompt tinkering is ok but it assumes that the LLM is perfect. And it isn‚Äôt. There are other issues with prebuilt LLMs as well which makes it tough to use in an enterprise environment.

Message : github.com/shreyar/guardrails might be useful here, uses LLMs to give structured outputs including JSON, Python objects, XML and DSL like outputs should be possible too
Quoted Message : Did you try something improve controllability. We are also having issues, esp when you need executable or near executable like outputs. Think DSL like outputs etc.

Message : Something something PCA Nishant


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : @1267303xxxx
Quoted Message : Which LLM will you use ... I did benchmarking on all open source ones against GPT4.. all open source ones are bad üòû.. and really the only one commercially available is Dolly 2.. it can't compare to GPT4.

Message : LLM Components to decide and weigh memory in Langchain, from the Generative Agents paper. Implements 2 agents talking to each other as well. 
https://twitter.com/hwchase17/status/1647987713449263106

Message : i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?

Message : especially in this case related to generative AI

Message : Has any of you worked with LLMs for math problem solving, or used chain-of-reason prompting? We're delving into the problem solving use case and would love to discuss if you have.

Message : A good starting point:
1. https://www.youtube.com/watch?v=j1DvCavAmhE
2. https://www.froihofer.net/students/how-to-write-a-computer-science-paper/

Note that writing a paper is a different skillset from doing research or engineering, in the same way that interviewing for a job is a different skill from doing the job.

Would encourage others to directly DM the friend :)
Quoted Message : i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?

Message : Grab hold of a prof. Or.. Enterprise researchers can help if you intern with them.
Quoted Message : i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?

Message : Did you try something improve controllability. We are also having issues, esp when you need executable or near executable like outputs. Think DSL like outputs etc.
Quoted Message : We build some models and ensemble some others. Our use case is deliberately narrow- we don‚Äôt need super powers. Besides, the problem with LLMs is that you have no control over them at all. If an LLM doesn‚Äôt behave the way you want it to, what will you do? Prompt tinkering is ok but it assumes that the LLM is perfect. And it isn‚Äôt. There are other issues with prebuilt LLMs as well which makes it tough to use in an enterprise environment.

Message : github.com/shreyar/guardrails might be useful here, uses LLMs to give structured outputs including JSON, Python objects, XML and DSL like outputs should be possible too
Quoted Message : Did you try something improve controllability. We are also having issues, esp when you need executable or near executable like outputs. Think DSL like outputs etc.

Message : Something something PCA Nishant

Message : *Nirant

Message : We caught you using old dimensionality reduction techniques üëÄ

Message : @91773788xxxx : delt game moderate

Message : Adept.ai got copied as an in the OpenAI Plugin Store, called Multi-on

Adept.ai is best known for being started by the creators of Transformers (Vaswani, Parmar, who've left the co as well) and raising $415M till date.

https://twitter.com/DivGarg9/status/1648074780430696448

Message : ‚Äé<attached: 00000477-PHOTO-2023-04-18-10-11-54.jpg>

Message : We will need people who have the following experience:

1. CLIP and image analysis models - this will be used to tackle questions with diagrams
2. Opensource maintainers and contributors - to help in making this an accessible and reproducible project
3. Problem solving with GPT or LLMs - technical, analytical problems.

Message : Meeting invite?
Quoted Message : We will need people who have the following experience:\n\n1. CLIP and image analysis models - this will be used to tackle questions with diagrams\n2. Opensource maintainers and contributors - to help in making this an accessible and reproducible project\n3. Problem solving with GPT or LLMs - technical, analytical problems.

Message : 1. cc @91824021xxxx has worked with CLIP, BLIP-2 and VQA
2. You've @91991512xxxx sir, the creator of Vakyansh üôèüèº
3. OpenAI Evals has some clever examples: github.com/openai/evals
Quoted Message : We will need people who have the following experience:\n\n1. CLIP and image analysis models - this will be used to tackle questions with diagrams\n2. Opensource maintainers and contributors - to help in making this an accessible and reproducible project\n3. Problem solving with GPT or LLMs - technical, analytical problems.

Message : As mentioned in the screenshot ‚Äî Please find the group from Community in WhatsApp, Apply to Join, meeting link will be shared there :)
Quoted Message : Meeting invite?

Message : What are you trying to build?
Chat bot which can solve JEE questions? Or a Chatbot which can help students preparing for JEE?
Quoted Message : We will need people who have the following experience:\n\n1. CLIP and image analysis models - this will be used to tackle questions with diagrams\n2. Opensource maintainers and contributors - to help in making this an accessible and reproducible project\n3. Problem solving with GPT or LLMs - technical, analytical problems.

Message : @91824021xxxx ajao sir, sending you the whatsapp invite directly
Quoted Message : 1. cc @9182xxxxxxxx has worked with CLIP, BLIP-2 and VQA\n2. You've @9199xxxxxxxx sir, the creator of Vakyansh üôèüèº\n3. OpenAI Evals has some clever examples: github.com/openai/evals

Message : 4. Multimodal vector similarity search - we're going to index image and text embeddings of useful information. Will definitely need someone with solid experience here.
Quoted Message : We will need people who have the following experience:\n\n1. CLIP and image analysis models - this will be used to tackle questions with diagrams\n2. Opensource maintainers and contributors - to help in making this an accessible and reproducible project\n3. Problem solving with GPT or LLMs - technical, analytical problems.

Message : https://github.com/marqo-ai/marqo - probably can take a look at this db

Message : *vectordb

Message : I'm a bit oldschool here and prefer to stick with elasticsearch üòÇ
Quoted Message : https://github.com/marqo-ai/marqo - probably can take a look at this db

Message : Is it tough to setup and maintain? yes, but I have production level experience of doing that so it's fine i guess

Message : Should I bring an all-purpose AK47 to a knife fight and mention FAISS üòÖ

Message : Additionally, all kinds of financial help in terms of openAI credits, GPU credits are welcome with huge open arms. 

Heck, I'll even break-up with ES if someone can help with getting credits for a vectorDB üòÇ

Message : I'm in. I have curated a tagged dataset of a large number of JEE-styled questions that can be used for training.
Quoted Message : We will need people who have the following experience:\n\n1. CLIP and image analysis models - this will be used to tackle questions with diagrams\n2. Opensource maintainers and contributors - to help in making this an accessible and reproducible project\n3. Problem solving with GPT or LLMs - technical, analytical problems.

Message : Go ahead, I'll bite üôà
Quoted Message : Should I bring an all-purpose AK47 to a knife fight and mention FAISS üòÖ

Message : Lot of the modern DL infra is built around FAISS: Haystack (Deepset), Milvus, txtai. Even Langchain launched with FAISS.

FAISS is probably tested in more production systems than ES Vector/HNSW.
And ofc, it's a lib, you manage state in a file, so all CRD is quite straightforward ‚Äî  if you do not want frequent updates.

Message : makes complete sense

index would stay static after the first pass with final preprocessed data
Quoted Message : Lot of the modern DL infra is built around FAISS: Haystack (Deepset), Milvus, txtai. Even Langchain launched with FAISS.\n\nFAISS is probably tested in more production systems than ES Vector/HNSW. \nAnd ofc, it's a lib, you manage state in a file, so all CRD is quite straightforward ‚Äî  if you do not want frequent updates.

Message : Maybe we can just train a KNN model and save its artifact locally so people can run it locally too

Message : Karpathy baba's SVM approach also makes complete sense in this usecase

Message : Keep going down the path of Baba Karpathy, and soon you'll find yourself in a Random Forest with Boosted Trees. There my friend, I first saw wisdom.
Quoted Message : Karpathy baba's SVM approach also makes complete sense in this usecase

Message : Are you saying that Baba Karpathy is the Yoda of the machine learning world?
Quoted Message : Keep going down the path of Baba Karpathy, and soon you'll find yourself in a Random Forest with Boosted Trees. There my friend, I first saw wisdom.

Message : So Karpathy (w/ Fei Fei Li and others) was the one who demonstrated the LSTM+CNN Image Captioning Model in his PhD Thesis. He was also the one who introduced the idea of using model weights projected as an _attention_ map to debug models. This was a precursor to _Attention_ in the philosophical sense. 

He is a bit young to be Yoda, but sure he's Yoda given that a year in Deep Learning counts as 7 in Real world üòÖ
Quoted Message : Are you saying that Baba Karpathy is the Yoda of the machine learning world?

Message : Truly a pioneer

Message : found this in the eval PRs

https://github.com/openai/evals/pull/123
Quoted Message : 1. cc @9182xxxxxxxx has worked with CLIP, BLIP-2 and VQA\n2. You've @9199xxxxxxxx sir, the creator of Vakyansh üôèüèº\n3. OpenAI Evals has some clever examples: github.com/openai/evals

Message : https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1
Looks like there is a corelation between reasoning and code percentage in pretraining. Do you think finetuning a codgen model with jee data would work for problem solving?
Quoted Message : found this in the eval PRs\n\nhttps://github.com/openai/evals/pull/123

Message : ‚Äé<attached: 00000506-PHOTO-2023-04-18-13-10-52.jpg>

Message : Are there folks in this group interested in working on these problems? 

Happy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : Me - Problems I like

1) Long lived conversations: What would a good implementation of an AI therapist, teacher, or advisor look like who remembered what you did/said 1 day/week/month/year ago?

2) Mind uploading: How do you memorialize a loved one? How do you upload yourself to the everlasting ether?

3) Theory of Mind: e.g. Educational chatbot that knows what you don't know

Message : Interested 
Especially AI agents for conversations
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : 3) Is something I've bee thinking about for a few years - How do you reduce unknown unknowns

Message : Also - https://www.together.xyz/blog/redpajama

New group (MILA, eth zurich etc) working on a commercial LLaMA

Message : I‚Äôm interested as well. 
A problem I‚Äôm interested in AI agents for day to day conversation
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : what does the ‚Äúpersonal search‚Äù problem statement mean?
Quoted Message :  2023_04_18_3EB0BCCD7512F61B013388.jpeg

Message : Been working on personal search. Will keep you guys posted.
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : rewind.ai
Quoted Message : what does the ‚Äúpersonal search‚Äù problem statement mean?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00000506-PHOTO-2023-04-18-13-10-52.jpg>

Message : Are there folks in this group interested in working on these problems? 

Happy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : Me - Problems I like

1) Long lived conversations: What would a good implementation of an AI therapist, teacher, or advisor look like who remembered what you did/said 1 day/week/month/year ago?

2) Mind uploading: How do you memorialize a loved one? How do you upload yourself to the everlasting ether?

3) Theory of Mind: e.g. Educational chatbot that knows what you don't know

Message : Interested 
Especially AI agents for conversations
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : 3) Is something I've bee thinking about for a few years - How do you reduce unknown unknowns

Message : Also - https://www.together.xyz/blog/redpajama

New group (MILA, eth zurich etc) working on a commercial LLaMA

Message : I‚Äôm interested as well. 
A problem I‚Äôm interested in AI agents for day to day conversation
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : what does the ‚Äúpersonal search‚Äù problem statement mean?
Quoted Message :  2023_04_18_3EB0BCCD7512F61B013388.jpeg

Message : Been working on personal search. Will keep you guys posted.
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : rewind.ai
Quoted Message : what does the ‚Äúpersonal search‚Äù problem statement mean?

Message : I'm interested in the multimodal AI project.
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : ‚Äé<attached: 00000517-PHOTO-2023-04-18-13-31-58.jpg>

Message : DM me if you find mistakes.

Message : 2304.08448.pdf ‚Ä¢ ‚Äé26 pages ‚Äé<attached: 00000519-2304.08448.pdf>

Message : interesting‚Ä¶this must be really memory-heavy?
Quoted Message : rewind.ai

Message : The multi-modal AI project finds a direct correlation to what I work on currently. I would love to explore Generative AI to solve problems and build systems which are multi-modal.
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : My key takeaway from skimming this paper was the iterative prompting. 

A lot of jargon from medicine I'll decipher with a doctor friend and share a summary here in the future.
Quoted Message :  2023_04_18_43A4070560B61C191893CE2070685B6E.pdf

Message : Interested as well
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : Interested in how to do domain specific feedback loop and fine-tuning. 

A few friends in industry (security, appliances, medicine) are interested in learning more.
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : +1 Interested in this too @91773788xxxx
Quoted Message : Interested in how to do domain specific feedback loop and fine-tuning. \n\nA few friends in industry (security, appliances, medicine) are interested in learning more.

Message : +1 to domain specific feedback and fine-tuning
Quoted Message : Interested in how to do domain specific feedback loop and fine-tuning. \n\nA few friends in industry (security, appliances, medicine) are interested in learning more.

Message : What do you all mean by domain specific feedback? RLHF?

Message : ‚Äé<attached: 00000530-PHOTO-2023-04-18-13-46-30.jpg>

Message : Check out character.ai. They are doing something similar.
Quoted Message : Interested \nEspecially AI agents for conversations

Message : Nice! Any comparison for open source LLMs?
Quoted Message :  2023_04_18_0F9DAB592AA5268649017B16328A704F.jpeg

Message : Interested
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : Folks, please share ideas which you can contribute/implement to indicate interest. Or even better, share any relevant code/paper which you've seen on the topic :)

Message : Yes RLHF from the domain experts and internal team users. 

Say if there is an LLM answering questions from docs that are firewall installation manuals.

What sort of items should be shown in response? Sources, code snippets, correct nomenclature.

What are the issues with licencing, MIT licensed LLMs.

Annotation tools to collect feedback.

How to rewrite traditional PDF/Word manauls.

The questions are diverse and multi-dimensional and traditional industry leaders are savvy enough to bite the LLM bullet to improve their workflows, but have a ton of questions across paradigms I mentioned above.
Quoted Message : What do you all mean by domain specific feedback? RLHF?

Message : Helpful list of directions
Quoted Message : Yes RLHF from the domain experts and internal team users. \n\nSay if there is an LLM answering questions from docs that are firewall installation manuals. \n\nWhat sort of items should be shown in response? Sources, code snippets, correct nomenclature. \n\nWhat are the issues with licencing, MIT licensed LLMs. \n\nAnnotation tools to collect feedback. \n\nHow to rewrite traditional PDF/Word manauls. \n\nThe questions are diverse and multi-dimensional and traditional industry leaders are savvy enough to bite the LLM bullet to improve their workflows, but have a ton of questions across paradigms I mentioned above.

Message : are you planning to talk to Anton?
Quoted Message :  2023_04_18_3EB0BCCD7512F61B013388.jpeg

Message : Augmented reality Pokedex caught my eye.
Pardon my noob language but is there any way to convert images to 3D models?
Quoted Message :  2023_04_18_3EB0BCCD7512F61B013388.jpeg

Message : There is a openai model to convert image/text to 3D model I have seen: github.com/openai/point-e

Message : Yes there seems to be a project on this 

https://arxiv.org/abs/2301.08247
Quoted Message : Augmented reality Pokedex caught my eye.\nPardon my noob language but is there any way to convert images to 3D models?

Message : Segment Anything Model was used to create an object mask from image
Quoted Message : Yes there seems to be a project on this \n\nhttps://arxiv.org/abs/2301.08247

Message : Demo for anyone interested 
https://twitter.com/nikolauswest/status/1646093500478369792?s=46&t=icC0fizZK8E3ONsDVuGFWA

Message : https://t.co/sVSHuljpwe

This paper outlines the core of the technique used

Message : Might DM, but this program is US or US remote. Wbu?
Quoted Message : are you planning to talk to Anton?

Message : Anyone else facing issues with huggingface endpoints rn?

Message : Both Gh and hf are facing issues.

Message : personal search related: https://github.com/KnowledgeCanvas/knowledge

Message : interested. working on PKM adjacent problems (personal search etc), mostly solving for myself...building on top of my Readwise data.

more than the ML part (mostly solved IMO), I'm thinking about interfaces, better UX.
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : These are some really interesting directions.
I have been spending some time on these questions recently.
Quoted Message : Yes RLHF from the domain experts and internal team users. \n\nSay if there is an LLM answering questions from docs that are firewall installation manuals. \n\nWhat sort of items should be shown in response? Sources, code snippets, correct nomenclature. \n\nWhat are the issues with licencing, MIT licensed LLMs. \n\nAnnotation tools to collect feedback. \n\nHow to rewrite traditional PDF/Word manauls. \n\nThe questions are diverse and multi-dimensional and traditional industry leaders are savvy enough to bite the LLM bullet to improve their workflows, but have a ton of questions across paradigms I mentioned above.

Message : Clashes with this meetup

Message : Removing the previous message since we discourage self promotion and the person hasn't replied to a personal ping, has no name on WA, nor an active contributor here

Message : That is amazing! BLR should've more gatherings, hackathons for people to choose from!
Quoted Message : Clashes with this meetup

Message : Very good read

Message : https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/

Message : Title is a bit misleading though. The point is that models will become better, but not by adding more base training data

Message : Better chance of playing catchup for startups :)
Quoted Message : Title is a bit misleading though. The point is that models will become better, but not by adding more base training data

Message : Especially comes after together  said that their model will be 1.3 trillion params


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : interested. working on PKM adjacent problems (personal search etc), mostly solving for myself...building on top of my Readwise data.

more than the ML part (mostly solved IMO), I'm thinking about interfaces, better UX.
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : These are some really interesting directions.
I have been spending some time on these questions recently.
Quoted Message : Yes RLHF from the domain experts and internal team users. \n\nSay if there is an LLM answering questions from docs that are firewall installation manuals. \n\nWhat sort of items should be shown in response? Sources, code snippets, correct nomenclature. \n\nWhat are the issues with licencing, MIT licensed LLMs. \n\nAnnotation tools to collect feedback. \n\nHow to rewrite traditional PDF/Word manauls. \n\nThe questions are diverse and multi-dimensional and traditional industry leaders are savvy enough to bite the LLM bullet to improve their workflows, but have a ton of questions across paradigms I mentioned above.

Message : Clashes with this meetup

Message : Removing the previous message since we discourage self promotion and the person hasn't replied to a personal ping, has no name on WA, nor an active contributor here

Message : That is amazing! BLR should've more gatherings, hackathons for people to choose from!
Quoted Message : Clashes with this meetup

Message : Very good read

Message : https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/

Message : Title is a bit misleading though. The point is that models will become better, but not by adding more base training data

Message : Better chance of playing catchup for startups :)
Quoted Message : Title is a bit misleading though. The point is that models will become better, but not by adding more base training data

Message : Especially comes after together  said that their model will be 1.3 trillion params

Message : Quick question for folks who are using LLMs in production(guessing there would be many in the group)

Do you create different organisation for the development and production environments OR just separate keys?

I‚Äôm hearing companies are trying to keep the costs and usage metrics separate. Curious how are you folks doing this?

Message : ‚Äé<attached: 00000563-GIF-2023-04-18-17-26-33.mp4>
Quoted Message : Quick question for folks who are using LLMs in production(guessing there would be many in the group)\n\nDo you create different organisation for the development and production environments OR just separate keys?\n\nI‚Äôm hearing companies are trying to keep the costs and usage metrics separate. Curious how are you folks doing this?

Message : One account with multiple keys - easier to consolidate and have conversations with OpenAI team on priority access.

Message : we use AzureOpenAI, so tracking is pretty easy over there.
Quoted Message : Quick question for folks who are using LLMs in production(guessing there would be many in the group)\n\nDo you create different organisation for the development and production environments OR just separate keys?\n\nI‚Äôm hearing companies are trying to keep the costs and usage metrics separate. Curious how are you folks doing this?

Message : I'm also doing this fwiw
Quoted Message : we use AzureOpenAI, so tracking is pretty easy over there.

Message : btw do Azure Credits work for Azure OpenAI?

Message : cc Ankita @91882678xxxx works for Azure India, can you please folks and confirm here?
Quoted Message : btw do Azure Credits work for Azure OpenAI?

Message : Can you track dev and prod on the same keys though? I didn‚Äôt know that functionality was there
Quoted Message : we use AzureOpenAI, so tracking is pretty easy over there.

Message : Our OpenAI access   is on a subscription level , so if you have credits on that subscription, absolutely will work
Quoted Message : btw do Azure Credits work for Azure OpenAI?

Message : probably create different resources for prod and dev? haven't tried it though.
Quoted Message : Can you track dev and prod on the same keys though? I didn‚Äôt know that functionality was there

Message : Yea, building for this along with 2-3 more things now. Will use my 1 strike week to post the link of the product üòÖ
Quoted Message :  2023_04_18_3EB0D8481FCCD90E849CF3.mp4

Message : 1 strike next week*

Message : You can always ask someone else to post, including me sir! üôèüèº
Quoted Message : Yea, building for this along with 2-3 more things now. Will use my 1 strike week to post the link of the product üòÖ

Message : Haha yea! Have to book some time with you anyway
Quoted Message : You can always ask someone else to post, including me sir! üôèüèº

Message : count me in as an early user
Quoted Message : Yea, building for this along with 2-3 more things now. Will use my 1 strike week to post the link of the product üòÖ

Message : @91773788xxxx I heard there‚Äôs a meet up this sat. Where can I find details about this and how do I register?

Message : https://hasgeek.com/generativeAI/april-meetup/
Quoted Message : @9177xxxxxxxx I heard there‚Äôs a meet up this sat. Where can I find details about this and how do I register?

Message : has anyone worked with context based search with cohere embeddings and openai gpt3.5 for non-english languages? how good it is in terms of results?

Message : Has anyone worked here with map_rerank chain types in LangChain? Would like to know of there is away to return the document metadata for sources alongside the QA responses

Message : map_reduce and refine both have this already. map_rerank should too?
Quoted Message : Has anyone worked here with map_rerank chain types in LangChain? Would like to know of there is away to return the document metadata for sources alongside the QA responses

Message : Worked with OpenAI. Good for some languages (eg Spanish) not good for others (Czech) based on feedback from our users
Quoted Message : has anyone worked with context based search with cohere embeddings and openai gpt3.5 for non-english languages? how good it is in terms of results?

Message : Haven‚Äôt seen a good resource on what languages are good VS bad. Presume it‚Äôs based on amount of training data on the open web

Message : I am trying with Arabic but it just says hmm. I am not sure ü•≤
even though the context is in arabic. Do you think I have to write the whole prompt in that language?

Message : I think you're right, I need to explicitly define which keys I want in the chain response, let me give it a try
Quoted Message : map_reduce and refine both have this already. map_rerank should too?

Message : Assuming you're on 3.5, did you mention the response language in your system prompt? Something like: ÿØÿßÿ¶ŸÖÿß ÿßŸÑÿ±ÿØ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
Quoted Message : I am trying with Arabic but it just says hmm. I am not sure ü•≤\neven though the context is in arabic. Do you think I have to write the whole prompt in that language?

Message : ‚Äé<attached: 00000591-PHOTO-2023-04-18-18-13-06.jpg>
Quoted Message : Assuming you're on 3.5, did you mention the response language in your system prompt? Something like: ÿØÿßÿ¶ŸÖÿß ÿßŸÑÿ±ÿØ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©

Message : Hey everyone, please welcome @91889802xxxx. My old roommate. He's from CMI in case anyone from CMI is here. 15+ yrs in tech. 8+ yrs in fintech space , currently building AI solutions for real estate sector in India/Middle East/ North America/ Australia.

Message : ‚Äé<attached: 00000593-PHOTO-2023-04-18-18-13-57.jpg>
Quoted Message : I am trying with Arabic but it just says hmm. I am not sure ü•≤\neven though the context is in arabic. Do you think I have to write the whole prompt in that language?

Message : I just said, replay in context's language.. but let me be specific.

it works with a generic llm where there's no context with with context prompts it didn't

let me explore more on the prompt side
Quoted Message : Assuming you're on 3.5, did you mention the response language in your system prompt? Something like: ÿØÿßÿ¶ŸÖÿß ÿßŸÑÿ±ÿØ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©

Message : thanks!

Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.
Quoted Message : I just said, replay in context's language.. but let me be specific.\n\nit works with a generic llm where there's no context with with context prompts it didn't \n\nlet me explore more on the prompt side

Message : In the right place and product, this reply is worth hundreds of dollars!
Quoted Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.

Message : Is there any cheaper and lower latency way to detect language? Especially in audio
Quoted Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.

Message : Open-source knowledge sir üôèüèª
Quoted Message : In the right place and product, this reply is worth hundreds of dollars!

Message : In text we do this.https://github.com/Mimino666/langdetect
Quoted Message : Is there any cheaper and lower latency way to detect language? Especially in audio

Message : But audio is a bit more difficult
Quoted Message : In text we do this.https://github.com/Mimino666/langdetect

Message : Not worked in audio.
But for the text case also there are few libraries and API solutions (it is difficult to find the right one which works for you)
Quoted Message : Is there any cheaper and lower latency way to detect language? Especially in audio

Message : exactly what I started using.. by specifying the language it works for a generic question

now figuring out how to do with with some context

the context is in non-english but the whole system prompt is in english
Quoted Message : In text we do this.https://github.com/Mimino666/langdetect

Message : https://www.youtube.com/watch?v=30xueN12guw

Message : How easy/complex was this language detection/translation?
Quoted Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.
Quoted Message : I just said, replay in context's language.. but let me be specific.\n\nit works with a generic llm where there's no context with with context prompts it didn't \n\nlet me explore more on the prompt side

Message : In the right place and product, this reply is worth hundreds of dollars!
Quoted Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.

Message : Is there any cheaper and lower latency way to detect language? Especially in audio
Quoted Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.

Message : Open-source knowledge sir üôèüèª
Quoted Message : In the right place and product, this reply is worth hundreds of dollars!

Message : In text we do this.https://github.com/Mimino666/langdetect
Quoted Message : Is there any cheaper and lower latency way to detect language? Especially in audio

Message : But audio is a bit more difficult
Quoted Message : In text we do this.https://github.com/Mimino666/langdetect

Message : Not worked in audio.
But for the text case also there are few libraries and API solutions (it is difficult to find the right one which works for you)
Quoted Message : Is there any cheaper and lower latency way to detect language? Especially in audio

Message : exactly what I started using.. by specifying the language it works for a generic question

now figuring out how to do with with some context

the context is in non-english but the whole system prompt is in english
Quoted Message : In text we do this.https://github.com/Mimino666/langdetect

Message : https://www.youtube.com/watch?v=30xueN12guw

Message : How easy/complex was this language detection/translation?
Quoted Message : I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.

Message : And did it introduce some latency?

Message : @91876396xxxx check this. If API based solution then it will add latency for sure.
Quoted Message : Not worked in audio.\nBut for the text case also there are few libraries and API solutions (it is difficult to find the right one which works for you)

Message : Of the top of my head - Cut out a very short snippet of the audio, then use something like deepgram or whisper?
Quoted Message : Is there any cheaper and lower latency way to detect language? Especially in audio

Message : smaller the file, lower the latency is my guess.. but haven't tried it

Message : Best way to do this imo will be by sampling. Splice the audio into smaller chunks, hit parallelly, and give a best case score if your use case is language detection, else concatenate and map reduce for translation

Message : One issue is translation depends on context too, so chunks can‚Äôt be super small
Quoted Message : Best way to do this imo will be by sampling. Splice the audio into smaller chunks, hit parallelly, and give a best case score if your use case is language detection, else concatenate and map reduce for translation

Message : So you can split on gaps in amplitude. With a rule like 5 gaps in one chunk
Quoted Message : One issue is translation depends on context too, so chunks can‚Äôt be super small

Message : This might actually make for a good cost reduction (compromising latency though) use case as well. Read the amplitude and omit parts of the audio where no sound was detected and then translate/transcribe

Message : Yeah that's pretty common in audio pre processing.
Quoted Message : This might actually make for a good cost reduction (compromising latency though) use case as well. Read the amplitude and omit parts of the audio where no sound was detected and then translate/transcribe

Message : Interesting.. didn‚Äôt know that
Quoted Message : Yeah that's pretty common in audio pre processing.

Message : Same for text too. we remove white spaces and new lines to save for tokens in document chunks. 
Another way is to downscale the audio a bit, you don‚Äôt need high quality always, again, depends heavily on usecase
Quoted Message : Yeah that's pretty common in audio pre processing.

Message : Hey Everyone,
We were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:
1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.
2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad.
3. We found MidJourney has this option of blending two images which worked well but it distorted main object.
4. We tried segmentation using Segment-Anything and choose "best" mask - crop it and pass to diffusion model to generate background or blend. But choosing "best" mask is problematic, sometimes it choose background.

If anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : Props for asking a well-formed question! üëè
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : Can you please create a poll for this?
Quoted Message : Are there folks in this group interested in working on these problems? \n\nHappy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.

Message : I am building something similar to the spaced repetition app here - basically learning stuff from large corpuses 

Eg Learn lead gen from a popular podcast on marketing

sounds cool but I'm not sure what features to start with lol

would love to get some use cases from y'all
Quoted Message :  2023_04_18_3EB0BCCD7512F61B013388.jpeg

Message : Let me zoom out a bit: I'm personally convinced that there is sincere interest. For a working group to happen, the bottleneck isn't buyer, reader or user interest ‚Äî but builder/experimenter effort.

So what stops someone here from simply taking up an idea from the list and going ahead with it‚Äîwhat are the sources of friction? What can we do to remove those? This is highest RoI question worth answering.

My role then would be to remove as much friction as I can :)
Quoted Message : Can you please create a poll for this?

Message : I‚Äôm looking to slice audio too. What would folks recommend with Python? I know pydub is popular but I saw it requires an external package
Quoted Message : Best way to do this imo will be by sampling. Splice the audio into smaller chunks, hit parallelly, and give a best case score if your use case is language detection, else concatenate and map reduce for translation

Message : pydub is fine
Quoted Message : I‚Äôm looking to slice audio too. What would folks recommend with Python? I know pydub is popular but I saw it requires an external package

Message : hey, can you post an example input image? on which you're trying to do this task.
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : Nice! Share more? or DM
Quoted Message : I am building something similar to the spaced repetition app here - basically learning stuff from large corpuses \n\nEg Learn lead gen from a popular podcast on marketing \n\nsounds cool but I'm not sure what features to start with lol \n\nwould love to get some use cases from y'all

Message : Happy to chat. Have build/deployed something like this before but not with LLM.
Quoted Message : I am building something similar to the spaced repetition app here - basically learning stuff from large corpuses \n\nEg Learn lead gen from a popular podcast on marketing \n\nsounds cool but I'm not sure what features to start with lol \n\nwould love to get some use cases from y'all

Message : I think someone had asked on Text to Video, do check this
https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis

Message : quick thoughts

- Do simple background segmentation to separate foreground from bg
- generate background with SD separately (mask off area where subject is or block it somehow so SD generates around it)
- stitch foreground and background together

If you want to make sure lighting is correct - do very light img2img to fix stuff
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : @91997100xxxx might have some good ideas

Message : Just read your last point - have you thought of asking the user to select the best mask? Simple product problem vs complex AI pipeline

Message : could work depending on your product!

Message : Anyone aware about applications of generative AI in finance? Was excited about this and wanted to explore more

Message : Not GenerativeAI tbh, but pretty neat offering: https://www.causal.app/

And ofc, there is Bloomberg GPT, a 50B model for finance: https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/
Quoted Message : Anyone aware about applications of generative AI in finance? Was excited about this and wanted to explore more

Message : https://github.com/OpenBB-finance/OpenBBTerminal/releases/tag/v3.0.0rc2
Quoted Message : Anyone aware about applications of generative AI in finance? Was excited about this and wanted to explore more

Message : Open Source Bloomberg GPT

Message : OpenBB is pure terminal play, right?
Quoted Message : Open Source Bloomberg GPT

Message : I don't recall them doing a LLM, and if yes, what data and arch are they building on?

Message : Yup I‚Äôd thought the same based on their site 

But apparently there seems to be SDK/library
Someone integrated it with Auto-GPT for investment research agent

https://twitter.com/derekcheungsa/status/1647772023731494912?s=46&t=icC0fizZK8E3ONsDVuGFWA
Quoted Message : OpenBB is pure terminal play, right?

Message : Yeah, pure terminal play, i think they get direct market data, earnings calls, and reports
Quoted Message : OpenBB is pure terminal play, right?

Message : Making videos via SD. This guy's last couple of reels are very good : https://www.instagram.com/reel/Cq5eWq4rRQC/?utm_source=ig_web_copy_link

Message : Have you tried using the latest control net models for intruct pix2pix (https://github.com/lllyasviel/ControlNet-v1-1-nightly#controlnet-11-instruct-pix2pix) 

Given that you want to use text query, have to looked into grounded Segment anything ( https://github.com/IDEA-Research/Grounded-Segment-Anything) or even https://github.com/geekyutao/Inpaint-Anything

Also fine tuning a model look into this: https://github.com/mkshing/e4t-diffusion.

However I do not completely get why you would want to fine tune ? There are 100‚Äôs of modes already available in huggingface and third party sites which you can try to generate results with.

Control net works with automatic1111 with mikubil web extension (https://github.com/Mikubill/sd-webui-controlnet). It even supports the latest models.

Hope this helps.
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : ‚Äé<attached: 00000651-PHOTO-2023-04-18-22-48-08.jpg>

Message : Discovered by @91955016xxxx

Message : @91773788xxxx have you come across any img2img models where I can generate variations of UI elements. 

UI elements could be a button, a spinner, jackpot wheel (cred has some of these) and so on.

Basically, want to enable designers with a plethora of variations across shape, size, color and fonts

Message : a very limited version of this used to be logojoy.com

some inside sauce: I hear Figma is building a version of this with some partners
Quoted Message : @9177xxxxxxxx have you come across any img2img models where I can generate variations of UI elements. \n\nUI elements could be a button, a spinner, jackpot wheel (cred has some of these) and so on. \n\nBasically, want to enable designers with a plethora of variations across shape, size, color and fonts


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : OpenBB is pure terminal play, right?
Quoted Message : Open Source Bloomberg GPT

Message : I don't recall them doing a LLM, and if yes, what data and arch are they building on?

Message : Yup I‚Äôd thought the same based on their site 

But apparently there seems to be SDK/library
Someone integrated it with Auto-GPT for investment research agent

https://twitter.com/derekcheungsa/status/1647772023731494912?s=46&t=icC0fizZK8E3ONsDVuGFWA
Quoted Message : OpenBB is pure terminal play, right?

Message : Yeah, pure terminal play, i think they get direct market data, earnings calls, and reports
Quoted Message : OpenBB is pure terminal play, right?

Message : Making videos via SD. This guy's last couple of reels are very good : https://www.instagram.com/reel/Cq5eWq4rRQC/?utm_source=ig_web_copy_link

Message : Have you tried using the latest control net models for intruct pix2pix (https://github.com/lllyasviel/ControlNet-v1-1-nightly#controlnet-11-instruct-pix2pix) 

Given that you want to use text query, have to looked into grounded Segment anything ( https://github.com/IDEA-Research/Grounded-Segment-Anything) or even https://github.com/geekyutao/Inpaint-Anything

Also fine tuning a model look into this: https://github.com/mkshing/e4t-diffusion.

However I do not completely get why you would want to fine tune ? There are 100‚Äôs of modes already available in huggingface and third party sites which you can try to generate results with.

Control net works with automatic1111 with mikubil web extension (https://github.com/Mikubill/sd-webui-controlnet). It even supports the latest models.

Hope this helps.
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : ‚Äé<attached: 00000651-PHOTO-2023-04-18-22-48-08.jpg>

Message : Discovered by @91955016xxxx

Message : @91773788xxxx have you come across any img2img models where I can generate variations of UI elements. 

UI elements could be a button, a spinner, jackpot wheel (cred has some of these) and so on.

Basically, want to enable designers with a plethora of variations across shape, size, color and fonts

Message : a very limited version of this used to be logojoy.com

some inside sauce: I hear Figma is building a version of this with some partners
Quoted Message : @9177xxxxxxxx have you come across any img2img models where I can generate variations of UI elements. \n\nUI elements could be a button, a spinner, jackpot wheel (cred has some of these) and so on. \n\nBasically, want to enable designers with a plethora of variations across shape, size, color and fonts

Message : Pretty cool that its open https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0
Quoted Message :  2023_04_18_3EB0C460C5583BB18E36AD.jpeg

Message : This is nice. I've played with Midjourney for logo creation and it was pretty good. 

I have existing designs I want to try AI on and with SD I didn't get good results.

A model that can "segment" various attributes of a UI element and then replace with a guided text prompt would be killer.

I guess Figma stands a good chance to build this.
Quoted Message : a very limited version of this used to be logojoy.com\n\nsome inside sauce: I hear Figma is building a version of this with some partners

Message : Can you explain what you mean by you have existing designs? Is it some type of sketch? Also can you elaborate on ‚Äúsegment various attributes of UI elements ‚Äú 

My understanding is what you want exists. Can you tell what methods have you tried till now?
Quoted Message : This is nice. I've played with Midjourney for logo creation and it was pretty good. \n\nI have existing designs I want to try AI on and with SD I didn't get good results. \n\nA model that can \"segment\" various attributes of a UI element and then replace with a guided text prompt would be killer. \n\nI guess Figma stands a good chance to build this.

Message : Try this gradio space if you already have a sketch. https://huggingface.co/spaces/hysts/ControlNet

Message : My understanding is that the maximum amount of control right now comes from control net models. Given that multiple controllers can be clubbed together and img2img and inpainting is also supported, with even huggingface launching a control net sprint , we will get a lot of community controlnets which can be used. T2I adapters is another approach but controlnet has community momentum with it.

Message : Noob here, but would Controlnet (https://github.com/lllyasviel/ControlNet) be useful?

Used here:  https://github.com/Nutlope/roomGPT
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : Existing designs - I've used some UI elements from the Koo app and tried dreamstudio. 

The prompt was basic things like change color to make it more engaging, bright, sharp edges and so on.

Results were lacklustre.

I havent tried with pix2pix Or controlnet models, yet.
Quoted Message : Can you explain what you mean by you have existing designs? Is it some type of sketch? Also can you elaborate on ‚Äúsegment various attributes of UI elements ‚Äú \n\nMy understanding is what you want exists. Can you tell what methods have you tried till now?

Message : Cool. Use the gradio space I shared. It would be a good starting point. You can also try playgroundai.com and see if that can help you
Quoted Message : Existing designs - I've used some UI elements from the Koo app and tried dreamstudio. \n\nThe prompt was basic things like change color to make it more engaging, bright, sharp edges and so on. \n\nResults were lacklustre. \n\nI havent tried with pix2pix Or controlnet models, yet.

Message : Thanks a lot @91950019xxxx

Message : Hi,
An off topic question, not really related to generative models.
I have a regression problem, but the problem is that the training dataset I have is really confined. Will performing Shapiro Wilk test on the target variable demonstrate that the data I have is really bad, and cannot be worked with at all. I performed the test and got a p value in range 1e-18

Message : For readers, Shapiro Wilk is a measure of whether the data is normally distributed or not. https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test
Quoted Message : Hi,\nAn off topic question, not really related to generative models.\nI have a regression problem, but the problem is that the training dataset I have is really confined. Will performing Shapiro Wilk test on the target variable demonstrate that the data I have is really bad, and cannot be worked with at all. I performed the test and got a p value in range 1e-18

Message : In theory, that should convince your stakeholders. In practice, normality is not _necessary_ for you to regress on a dataset ‚Äî sure, it informs what methods you can or cannot use, but there are methods which don't make normal distribution assumption. 

Unless I'm missing something and you were my co-worker, that'd be my thought process with limited info here
Quoted Message : Hi,\nAn off topic question, not really related to generative models.\nI have a regression problem, but the problem is that the training dataset I have is really confined. Will performing Shapiro Wilk test on the target variable demonstrate that the data I have is really bad, and cannot be worked with at all. I performed the test and got a p value in range 1e-18

Message : Thanks for your input. Do you have any suggestions for methods I can use with a non normal dataset.
Quoted Message : In theory, that should convince your stakeholders. In practice, normality is not _necessary_ for you to regress on a dataset ‚Äî sure, it informs what methods you can or cannot use, but there are methods which don't make normal distribution assumption. \n\nUnless I'm missing something and you were my co-worker, that'd be my thought process with limited info here

Message : This was my thought too. This just violates some assumptions for linear regression variants, you can consider 1. other regression algorithms like tree based ones, or 2. See if the target can be transformed via a sensible function to close to normal distribution.
Quoted Message : In theory, that should convince your stakeholders. In practice, normality is not _necessary_ for you to regress on a dataset ‚Äî sure, it informs what methods you can or cannot use, but there are methods which don't make normal distribution assumption. \n\nUnless I'm missing something and you were my co-worker, that'd be my thought process with limited info here

Message : 2. *and then apply liner regression family

Message : Can you elaborate what you mean by confined? And really bad for what exactly?
Quoted Message : Hi,\nAn off topic question, not really related to generative models.\nI have a regression problem, but the problem is that the training dataset I have is really confined. Will performing Shapiro Wilk test on the target variable demonstrate that the data I have is really bad, and cannot be worked with at all. I performed the test and got a p value in range 1e-18

Message : Also, can you plot it somehow?

Message : I tried using support vector regression and experimented with non linear kernels, the results remained the same. Will try tree based methods as well.
Quoted Message : This was my thought too. This just violates some assumptions for linear regression variants, you can consider 1. other regression algorithms like tree based ones, or 2. See if the target can be transformed via a sensible function to close to normal distribution.

Message : ‚Äé<attached: 00000674-PHOTO-2023-04-19-00-38-45.jpg>
Quoted Message : Also, can you plot it somehow?

Message : Also, really sorry if I am making some stupid remarks/comments about the data. I have not worked a lot with tabular data, and I am just a beginner in Machine Learning.

Message : This is not some sort of time series data?

Message : No it‚Äôs not a time series data
Quoted Message : This is not some sort of time series data?

Message : ‚Äé<attached: 00000678-PHOTO-2023-04-19-01-14-51.jpg>

Message : It's not a function in the traditional sense. It could the case that y = some_prob_distribution(x). Ex. Y = normal_distributed(mean =x)

Message : Hey Guys, thanks a lot for suggestions on this. 
1. I am attaching a photo I just took, I wanted to extract the glass from the image and place it on a fancy dining table without distorting the structure of glass.

2. We have tried segmentation methods but the problem is to choose the highlighted object, sometimes mask quality of background is better than that of object.

3. Normal background removal algorithm works well to extract object but then the issue lies in stitching object to generated background. In all open source models I‚Äôve found - controlnet, pix2pix etc, these are bad at stitching. Probably they were trained to generate images and not blend.
The commercial ones like runway and midj are good but we can‚Äôt use them ;(
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : ‚Äé<attached: 00000681-PHOTO-2023-04-19-01-22-53.jpg>

Message : Try jadoosnap.com
Quoted Message : Hey Guys, thanks a lot for suggestions on this. \n1. I am attaching a photo I just took, I wanted to extract the glass from the image and place it on a fancy dining table without distorting the structure of glass. \n\n2. We have tried segmentation methods but the problem is to choose the highlighted object, sometimes mask quality of background is better than that of object. \n\n3. Normal background removal algorithm works well to extract object but then the issue lies in stitching object to generated background. In all open source models I‚Äôve found - controlnet, pix2pix etc, these are bad at stitching. Probably they were trained to generate images and not blend. \nThe commercial ones like runway and midj are good but we can‚Äôt use them ;(

Message : Wanted to give users of I‚Äôm feeling lucky option :) Though a nice suggestion if they want total control!
Quoted Message : Just read your last point - have you thought of asking the user to select the best mask? Simple product problem vs complex AI pipeline

Message : how did you blend the images? only if you want to share or is it a completely different approach?
Quoted Message : Try jadoosnap.com

Message : Yeah man curious to know! Results look quite nice!
Quoted Message : how did you blend the images? only if you want to share or is it a completely different approach?

Message : I actually did this exact approach.. researched online on how to blend.. saw adobe firefly results.. and dropped it ü•≤
Quoted Message : Hey Guys, thanks a lot for suggestions on this. \n1. I am attaching a photo I just took, I wanted to extract the glass from the image and place it on a fancy dining table without distorting the structure of glass. \n\n2. We have tried segmentation methods but the problem is to choose the highlighted object, sometimes mask quality of background is better than that of object. \n\n3. Normal background removal algorithm works well to extract object but then the issue lies in stitching object to generated background. In all open source models I‚Äôve found - controlnet, pix2pix etc, these are bad at stitching. Probably they were trained to generate images and not blend. \nThe commercial ones like runway and midj are good but we can‚Äôt use them ;(

Message : ‚Äé<attached: 00000688-PHOTO-2023-04-19-01-30-29.jpg>

Message : Two cents
1. Your target seems categorical, is this true?
2. Just eyeballing there does seems like there are (some) patterns. But will be very difficult to say what will make sense. It could be the case that you have mixture of distributions, it could be that there are other variables that should have been considered etc. You will need to look the process that generated the data and decide whether this makes sense. It could also just be that you have a bunch of outliers. If they are outliers, use a regularised regression. As you might have guessed, am a Bayesian.
3. Confined to a small range per se is not a problem, you could normalise etc. But the real issue whether your new data will be interpolatable from the models/do you know something about the process that informs you that.
4. To say you have bad data can be quite challenging. But incomplete may be so, as only part of the explanation might be provided by the current variable.
Quoted Message : No it‚Äôs not a time series data

Message : DM me brother
Quoted Message : how did you blend the images? only if you want to share or is it a completely different approach?

Message : For the first part no my data isn‚Äôt categorical. 
Will surely try Bayesian methods as well.
As for the better understanding of the data, can I dm you?
Quoted Message : Two cents\n1. Your target seems categorical, is this true?\n2. Just eyeballing there does seems like there are (some) patterns. But will be very difficult to say what will make sense. It could be the case that you have mixture of distributions, it could be that there are other variables that should have been considered etc. You will need to look the process that generated the data and decide whether this makes sense. It could also just be that you have a bunch of outliers. If they are outliers, use a regularised regression. As you might have guessed, am a Bayesian.\n3. Confined to a small range per se is not a problem, you could normalise etc. But the real issue whether your new data will be interpolatable from the models/do you know something about the process that informs you that. \n4. To say you have bad data can be quite challenging. But incomplete may be so, as only part of the explanation might be provided by the current variable.

Message : ‚Äé<attached: 00000692-PHOTO-2023-04-19-01-36-11.jpg>
Quoted Message :  2023_04_19_5E8F79A53E3448DCB9AF.jpeg

Message : Would be great if we could get prettier backgrounds! Thanks already!
Quoted Message :  2023_04_19_3A118EBD8521492DE8E7.jpeg

Message : ‚Äé<attached: 00000694-PHOTO-2023-04-19-01-58-08.jpg>
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : ‚Äé<attached: 00000695-PHOTO-2023-04-19-01-58-10.jpg>

Message : ‚Äé<attached: 00000696-PHOTO-2023-04-19-01-58-11.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I actually did this exact approach.. researched online on how to blend.. saw adobe firefly results.. and dropped it ü•≤
Quoted Message : Hey Guys, thanks a lot for suggestions on this. \n1. I am attaching a photo I just took, I wanted to extract the glass from the image and place it on a fancy dining table without distorting the structure of glass. \n\n2. We have tried segmentation methods but the problem is to choose the highlighted object, sometimes mask quality of background is better than that of object. \n\n3. Normal background removal algorithm works well to extract object but then the issue lies in stitching object to generated background. In all open source models I‚Äôve found - controlnet, pix2pix etc, these are bad at stitching. Probably they were trained to generate images and not blend. \nThe commercial ones like runway and midj are good but we can‚Äôt use them ;(

Message : ‚Äé<attached: 00000688-PHOTO-2023-04-19-01-30-29.jpg>

Message : Two cents
1. Your target seems categorical, is this true?
2. Just eyeballing there does seems like there are (some) patterns. But will be very difficult to say what will make sense. It could be the case that you have mixture of distributions, it could be that there are other variables that should have been considered etc. You will need to look the process that generated the data and decide whether this makes sense. It could also just be that you have a bunch of outliers. If they are outliers, use a regularised regression. As you might have guessed, am a Bayesian.
3. Confined to a small range per se is not a problem, you could normalise etc. But the real issue whether your new data will be interpolatable from the models/do you know something about the process that informs you that.
4. To say you have bad data can be quite challenging. But incomplete may be so, as only part of the explanation might be provided by the current variable.
Quoted Message : No it‚Äôs not a time series data

Message : DM me brother
Quoted Message : how did you blend the images? only if you want to share or is it a completely different approach?

Message : For the first part no my data isn‚Äôt categorical. 
Will surely try Bayesian methods as well.
As for the better understanding of the data, can I dm you?
Quoted Message : Two cents\n1. Your target seems categorical, is this true?\n2. Just eyeballing there does seems like there are (some) patterns. But will be very difficult to say what will make sense. It could be the case that you have mixture of distributions, it could be that there are other variables that should have been considered etc. You will need to look the process that generated the data and decide whether this makes sense. It could also just be that you have a bunch of outliers. If they are outliers, use a regularised regression. As you might have guessed, am a Bayesian.\n3. Confined to a small range per se is not a problem, you could normalise etc. But the real issue whether your new data will be interpolatable from the models/do you know something about the process that informs you that. \n4. To say you have bad data can be quite challenging. But incomplete may be so, as only part of the explanation might be provided by the current variable.

Message : ‚Äé<attached: 00000692-PHOTO-2023-04-19-01-36-11.jpg>
Quoted Message :  2023_04_19_5E8F79A53E3448DCB9AF.jpeg

Message : Would be great if we could get prettier backgrounds! Thanks already!
Quoted Message :  2023_04_19_3A118EBD8521492DE8E7.jpeg

Message : ‚Äé<attached: 00000694-PHOTO-2023-04-19-01-58-08.jpg>
Quoted Message : Hey Everyone,\nWe were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation:\n1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this.\n2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. \n3. We found MidJourney has this option of blending two images which worked well but it distorted main object.\n4. We tried segmentation using Segment-Anything and choose \"best\" mask - crop it and pass to diffusion model to generate background or blend. But choosing \"best\" mask is problematic, sometimes it choose background.\n\nIf anyone has tried anything in this space or could help, please DM! Thanks already :)

Message : ‚Äé<attached: 00000695-PHOTO-2023-04-19-01-58-10.jpg>

Message : ‚Äé<attached: 00000696-PHOTO-2023-04-19-01-58-11.jpg>

Message : ‚Äé<attached: 00000697-PHOTO-2023-04-19-01-58-13.jpg>

Message : ‚Äé<attached: 00000698-PHOTO-2023-04-19-01-58-15.jpg>

Message : Along with SD 1.5 inpainting ckpt
Quoted Message :  2023_04_19_3EB04346BE78288C61B581.jpeg

Message : And this was with minimal effort on the prompting end, so results may get better with better prompting.

Message : Have you tried to use any inpainting models? They are opensource by runwayml. The one shared above by Abhishek. 

Regarding image stitching, you said you controlnet was bad at it. Did you use the regular model? Or did you use inpainting checkpoint? What flaws did you see with them?
Quoted Message : Hey Guys, thanks a lot for suggestions on this. \n1. I am attaching a photo I just took, I wanted to extract the glass from the image and place it on a fancy dining table without distorting the structure of glass. \n\n2. We have tried segmentation methods but the problem is to choose the highlighted object, sometimes mask quality of background is better than that of object. \n\n3. Normal background removal algorithm works well to extract object but then the issue lies in stitching object to generated background. In all open source models I‚Äôve found - controlnet, pix2pix etc, these are bad at stitching. Probably they were trained to generate images and not blend. \nThe commercial ones like runway and midj are good but we can‚Äôt use them ;(

Message : ‚Äé<attached: 00000702-PHOTO-2023-04-19-02-23-16.jpg>

Message : Folks hoping all of you have seen launch of Open Assistant - https://open-assistant.io/ - opensourced alternative to ChatGPT by the LAION-AI initiative.

Message : I have seen this image somewhere. Is this a product of any startup?
Quoted Message :  2023_04_19_3A936DD175337E063577.jpeg

Message : The image is from my startups website. The ‚Äú product‚Äù is from a Instagram image of this company which sells candles. I just dropped out the hands, matchbox and light of the matchstick and incorporated into other image which I then used as base for controlnet inpainting.

Message : do you have a website to check it out more?

now I remember. I saw it here itself last month.
Quoted Message : The image is from my startups website. The ‚Äú product‚Äù is from a Instagram image of this company which sells candles. I just dropped out the hands, matchbox and light of the matchstick and incorporated into other image which I then used as base for controlnet inpainting.

Message : ‚Äé<attached: 00000707-PHOTO-2023-04-19-02-46-01.jpg>

Message : ‚Äé<attached: 00000708-PHOTO-2023-04-19-04-02-24.jpg>

Message : https://github.com/geekyutao/Inpaint-Anything maybe this can work for you
Quoted Message : Hey Guys, thanks a lot for suggestions on this. \n1. I am attaching a photo I just took, I wanted to extract the glass from the image and place it on a fancy dining table without distorting the structure of glass. \n\n2. We have tried segmentation methods but the problem is to choose the highlighted object, sometimes mask quality of background is better than that of object. \n\n3. Normal background removal algorithm works well to extract object but then the issue lies in stitching object to generated background. In all open source models I‚Äôve found - controlnet, pix2pix etc, these are bad at stitching. Probably they were trained to generate images and not blend. \nThe commercial ones like runway and midj are good but we can‚Äôt use them ;(

Message : Thanks for the suggestions. I did use normal checkpoints with a basic prompt to see if they are understanding physical structure. I‚Äôm attaching one of the result where I gave the prompt ‚Äúadd dining table in background‚Äù.  

I‚Äôll definitely try inpainting one as Abhishek told.
Quoted Message : Have you tried to use any inpainting models? They are opensource by runwayml. The one shared above by Abhishek. \n\nRegarding image stitching, you said you controlnet was bad at it. Did you use the regular model? Or did you use inpainting checkpoint? What flaws did you see with them?

Message : ‚Äé<attached: 00000711-PHOTO-2023-04-19-08-10-25.jpg>

Message : if your data is not normally distributed then you can use Extreme Value Theory tools. See Hill Estimator for instance, but there are others
Quoted Message : Hi,\nAn off topic question, not really related to generative models.\nI have a regression problem, but the problem is that the training dataset I have is really confined. Will performing Shapiro Wilk test on the target variable demonstrate that the data I have is really bad, and cannot be worked with at all. I performed the test and got a p value in range 1e-18

Message : Just curious to understand -

Have you introduced ChatGPT like LLM to younger kids (8-13 yrs age bracket)?

If yes then how are you making sure it is safe to use for them? (preventing hallucination, bias, etc)

Message : fwiw, in my experience trusting things which are made up is more common with my parent's age cohorts than urban, educated teenagers who seem to be skeptics by design
Quoted Message : Just curious to understand -\n\nHave you introduced ChatGPT like LLM to younger kids (8-13 yrs age bracket)?\n\nIf yes then how are you making sure it is safe to use for them? (preventing hallucination, bias, etc)

Message : Yeah, they are curious but how about keeping things age appropriate for them?
Quoted Message : fwiw, in my experience trusting things which are made up is more common with my parent's age cohorts than urban, educated teenagers who seem to be skeptics by design

Message : ‚Äé<attached: 00000717-PHOTO-2023-04-19-08-57-00.jpg>

Message : Thank you üôè
Really helpful
Quoted Message :  2023_04_19_3EB0B4B795ABB8EDC8B6BD.jpeg

Message : cc @1650224xxxx works on making the Google Play Store safe for kids and minors. Would love to hear more product design, generic principles from you üôèüèº

Message : Since these interfaces will have image (search, generation) soon, there has been academic interest in detecting _sexy_ images as well. These are suggestive, but not porn or nudity. The line gets blurred even more with comics/anime/hentai.

This is a neat project in that direction: https://github.com/GantMan/nsfw_model. I wish they'd share datasets and not just model weights

Message : Speaking purely in individual capacity 

More than companies, I think the governments in various countries are always actively working on rules and regulations around minors and are becoming better at it

Principles vary widely from age to age
Quoted Message : cc @165xxxxxxxx works on making the Google Play Store safe for kids and minors. Would love to hear more product design, generic principles from you üôèüèº

Message : We've been using this to ensure all questions are safe for works. Works decently well and is a requirement from companies
Quoted Message :  2023_04_19_3EB0B4B795ABB8EDC8B6BD.jpeg

Message : This will be super interesting as I do not know of any specific regulation yet....

A lot of big tech typically adds supervision by default for users <13 (Depends on country to country)


I would presume
- Chatgpt needs login : so if its something like a gmail account, the parent would know they used it

ChatGPT itself i dont kow if it has build parental controls. I suspect eventually they may....
Quoted Message : Just curious to understand -\n\nHave you introduced ChatGPT like LLM to younger kids (8-13 yrs age bracket)?\n\nIf yes then how are you making sure it is safe to use for them? (preventing hallucination, bias, etc)

Message : Sure, will look into that as well.
Quoted Message : if your data is not normally distributed then you can use Extreme Value Theory tools. See Hill Estimator for instance, but there are others

Message : ‚Äé<attached: 00000726-PHOTO-2023-04-19-09-17-56.jpg>
Quoted Message : This will be super interesting as I do not know of any specific regulation yet....\n\nA lot of big tech typically adds supervision by default for users <13 (Depends on country to country)\n\n\nI would presume \n- Chatgpt needs login : so if its something like a gmail account, the parent would know they used it\n\nChatGPT itself i dont kow if it has build parental controls. I suspect eventually they may....

Message : Kids in my daughter's (10yrs) class are already using it. And she is asking me questions like why can't I use it? I showed this to her but asked why others were able to access it? Why are parents allowing them to use it?

I am having a hard time answering these questions üòÖ
Quoted Message :  2023_04_19_3EB09FA5BDEC4DACF34468.jpeg

Message : ouch
Quoted Message : Kids in my daughter's (10yrs) class are already using it. And she is asking me questions like why can't I use it? I showed this to her but asked why others were able to access it? Why are parents allowing them to use it?\n\nI am having a hard time answering these questions üòÖ

Message : Hi! I need one help.
How to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me?
There is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : Fine tune vicuna on your WhatsApp chats
Quoted Message : Hi! I need one help.\nHow to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me? \nThere is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : index n retrive from vectorDB could be a easy quick start
Quoted Message : Hi! I need one help.\nHow to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me? \nThere is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : fine-tuning is not to save info . Its to teach a skill to the LLM
Quoted Message : Fine tune vicuna on your WhatsApp chats

Message : Do you think dependence on these for home work affect reasoning abilities in kids?
Quoted Message : Kids in my daughter's (10yrs) class are already using it. And she is asking me questions like why can't I use it? I showed this to her but asked why others were able to access it? Why are parents allowing them to use it?\n\nI am having a hard time answering these questions üòÖ

Message : I want to use it in ChatBot style. So I want to build it on something like GPT-4 or any other LLMs. 
Can we incorporate these embedding with existing LLMs as well?
Quoted Message : index n retrive from vectorDB could be a easy quick start

Message : Yes, in my view
Quoted Message : Do you think dependence on these for home work affect reasoning abilities in kids?

Message : yes. you just retrive the relavant context with cosine similarity , and simply feed it into the prompt. with character limit . it should work well . with some prompt engineering + if you using GPT4 put in the system message  to impersonate you based on the context provide. LLM chains
Quoted Message : I want to use it in ChatBot style. So I want to build it on something like GPT-4 or any other LLMs. \nCan we incorporate these embedding with existing LLMs as well?

Message : Do you think dependency on Google Search and Saved contacts affect our memory skills?
Quoted Message : Do you think dependence on these for home work affect reasoning abilities in kids?

Message : These are memory recall skills aren‚Äôt they ?
Quoted Message : Do you think dependency on Google Search and Saved contacts affect our memory skills?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Hi! I need one help.
How to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me?
There is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : Fine tune vicuna on your WhatsApp chats
Quoted Message : Hi! I need one help.\nHow to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me? \nThere is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : index n retrive from vectorDB could be a easy quick start
Quoted Message : Hi! I need one help.\nHow to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me? \nThere is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : fine-tuning is not to save info . Its to teach a skill to the LLM
Quoted Message : Fine tune vicuna on your WhatsApp chats

Message : Do you think dependence on these for home work affect reasoning abilities in kids?
Quoted Message : Kids in my daughter's (10yrs) class are already using it. And she is asking me questions like why can't I use it? I showed this to her but asked why others were able to access it? Why are parents allowing them to use it?\n\nI am having a hard time answering these questions üòÖ

Message : I want to use it in ChatBot style. So I want to build it on something like GPT-4 or any other LLMs. 
Can we incorporate these embedding with existing LLMs as well?
Quoted Message : index n retrive from vectorDB could be a easy quick start

Message : Yes, in my view
Quoted Message : Do you think dependence on these for home work affect reasoning abilities in kids?

Message : yes. you just retrive the relavant context with cosine similarity , and simply feed it into the prompt. with character limit . it should work well . with some prompt engineering + if you using GPT4 put in the system message  to impersonate you based on the context provide. LLM chains
Quoted Message : I want to use it in ChatBot style. So I want to build it on something like GPT-4 or any other LLMs. \nCan we incorporate these embedding with existing LLMs as well?

Message : Do you think dependency on Google Search and Saved contacts affect our memory skills?
Quoted Message : Do you think dependence on these for home work affect reasoning abilities in kids?

Message : These are memory recall skills aren‚Äôt they ?
Quoted Message : Do you think dependency on Google Search and Saved contacts affect our memory skills?

Message : hey guy quick intro i'm Akash , we are building a embedding engine specifically for code syntax.  also anyone here worked with Siamese search stuff ?

Message : Parents I guess would be more concerned with reasoning skills being affected coz of using GPT
Quoted Message : These are memory recall skills aren‚Äôt they ?

Message : Thank you Edgar and Akash! I will check these out!
Quoted Message : Fine tune vicuna on your WhatsApp chats

Message : Our parents were worried about memory and we seem to be doing okay without them üòõ
Quoted Message : Parents I guess would be more concerned with reasoning skills being affected coz of using GPT

Message : https://twitter.com/hwchase17/status/1648474409819340801?t=msztWX1rHzcmTfo3Zg2Uvw&s=19

webinar on evaluation by langchain.

OpenAI Evals maintainer will also be here in case anyone is interested in evaluation.

Message : cue the pessimists_archive twitter handle üòÇ
Quoted Message : Our parents were worried about memory and we seem to be doing okay without them üòõ

Message : ü§£ü§£ü§£
Step 1:Outsource memory
Step 2:Outsource reasoning
.
.
Infinite end:Outsource consciousness üòù
Quoted Message : Our parents were worried about memory and we seem to be doing okay without them üòõ

Message : Heard it from Altman in the Lex friedman interview that he repeatedly says in the company to treats it's users like adults
Quoted Message :  2023_04_19_3EB09FA5BDEC4DACF34468.jpeg

Message : cc @91955016xxxx for questions on QA evaluation and fact checking ‚Äî since you worked on that problem
cc @91997100xxxx since you are looking at ```openai/evals``` for JEE
Quoted Message : https://twitter.com/hwchase17/status/1648474409819340801?t=msztWX1rHzcmTfo3Zg2Uvw&s=19\n\nwebinar on evaluation by langchain.\n\nOpenAI Evals maintainer will also be here in case anyone is interested in evaluation.

Message : I did. Curious how you are thinking of applying it.
Quoted Message : hey guy quick intro i'm Akash , we are building a embedding engine specifically for code syntax.  also anyone here worked with Siamese search stuff ?

Message : GPT4 8k and 32k versions are now available on Azure Openai India as well.

Message : https://twitter.com/varunshenoy_/status/1648374949537775616?s=52

Connecting chatgpt with health data

Message : You could additionally change the object's position and use SD Inpainting, which gives more variation results. @91876402xxxx has mentioned those in details section of his product here - https://gooey.ai/product-photo-background-generator/
Quoted Message :  2023_04_19_3EB0778317446C63AC374E.jpeg

Message : anyone here using promptlayer or other tools for prompt versioning? 
https://promptlayer.com/

Message : Want to use a tool badly - is this good?
Quoted Message : anyone here using promptlayer or other tools for prompt versioning? \nhttps://promptlayer.com/

Message : Humanloop does A/B testing+versioning of prompts as well
Quoted Message : anyone here using promptlayer or other tools for prompt versioning? \nhttps://promptlayer.com/

Message : https://www.izzy.co/blogs/robo-boys.html

Has all the code - llama, and modal

Use whatsapp chats for creating a dataset
Quoted Message : Hi! I need one help.\nHow to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me? \nThere is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : haven't used it yet. but they integrate with langchain too.
Quoted Message : Want to use a tool badly - is this good?

Message : btw @91989995xxxx is also working on this!

portkey.ai
Quoted Message : anyone here using promptlayer or other tools for prompt versioning? \nhttps://promptlayer.com/

Message : thanks! Yes, I'm going to announce this soon.. we have a few companies in beta right now so happy to help if someone wants a tool that works out of the box
Quoted Message : btw @9198xxxxxxxx is also working on this!\n\nportkey.ai

Message : üëç joined the waitlist
Quoted Message : thanks! Yes, I'm going to announce this soon.. we have a few companies in beta right now so happy to help if someone wants a tool that works out of the box

Message : https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html

Message : interesting attempt at structuring prompts better. guardrail:XML, this:SQL
Quoted Message : https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html

Message : There should be some way to get nudged about cost incurred when running these via LLM calls lol
Reminiscent of orphaned resources that get spun up in cloud services

Message : https://python.langchain.com/en/latest/modules/models/llms/examples/token_usage_tracking.html
Quoted Message : There should be some way to get nudged about cost incurred when running these via LLM calls lol\nReminiscent of orphaned resources that get spun up in cloud services

Message : Appreciate the guardrails shoutout!
My understanding of AI functions from databricks was different -- essentially, it's an easy way to create a pipeline of applying LLMs to data in a SQL DB using a UDF. This would be an alternative to applying an LLM to data in a DB by creating a pipeline in python where connect to the DB via an ORM, calling the LLM, and then writing the results of the LLM back to the DB via ORM.
In comparison, guardrails would slot in around the single LLM call and make sure that the LLM output is correct/validated/structured/etc. Hope this helps!
Quoted Message : interesting attempt at structuring prompts better. guardrail:XML, this:SQL

Message : Folks, I have a request. 

I ran out of Midjourney prompts while running an experiment. Can someone here run the prompt and share results with me?

Message : */imagine* Indian politician Kamal Nath wearing white kurta, smiling , doing namaste, while meeting 4 tribal people in front of their hut on a hot summer day during an on-ground campaign ahead of elections.

Message : Friends, Nilesh @91953570xxxx is an engineer-turned-journalist covering Generative AI in India and it's impact on jobs and business
Quoted Message : Folks, I have a request. \n\nI ran out of Midjourney prompts while running an experiment. Can someone here run the prompt and share results with me?

Message : You can try openjourney if it's urgent
Quoted Message : Folks, I have a request. \n\nI ran out of Midjourney prompts while running an experiment. Can someone here run the prompt and share results with me?

Message : ‚Äé<attached: 00000773-PHOTO-2023-04-19-15-20-09.jpg>
Quoted Message : */imagine* Indian politician Kamal Nath wearing white kurta, smiling , doing namaste, while meeting 4 tribal people in front of their hut on a hot summer day during an on-ground campaign ahead of elections.

Message : https://cdn.discordapp.com/attachments/1059408411890028584/1098182375965478963/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png

Message : TIL Discord CDN has no auth!
Quoted Message : https://cdn.discordapp.com/attachments/1059408411890028584/1098182375965478963/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png

Message : trying out the chatgpt-retrieval plugin. 
Pinecone currently seems to have a waitlist for new users
Which is the next-best db to use?
supported dbs: pinecone, weaviate, zilliz, milvus, qdrant, redis, llamaindex (i know it heavily depends on the usecase‚Ä¶any pointers on how to decide? im just basically trying to create an experimental semantic search over certain documentations)

Message : It's an embedded image right?
Quoted Message : TIL Discord CDN has no auth!

Message : just do qdrant if you're running locally, lowest Memory footprint, the cloud has a decent free plan too
Quoted Message : trying out the chatgpt-retrieval plugin. \nPinecone currently seems to have a waitlist for new users\nWhich is the next-best db to use? \nsupported dbs: pinecone, weaviate, zilliz, milvus, qdrant, redis, llamaindex (i know it heavily depends on the usecase‚Ä¶any pointers on how to decide? im just basically trying to create an experimental semantic search over certain documentations)

Message : full disclosure: trying to sign qdrant as consulting client

Message : Yeah, using SQL lets me do embed ontology a little better, saves me a bit of time doing prompt engineering with vectordbs, but I have a theory about where all this is going to end up
Quoted Message : Appreciate the guardrails shoutout!\nMy understanding of AI functions from databricks was different -- essentially, it's an easy way to create a pipeline of applying LLMs to data in a SQL DB using a UDF. This would be an alternative to applying an LLM to data in a DB by creating a pipeline in python where connect to the DB via an ORM, calling the LLM, and then writing the results of the LLM back to the DB via ORM.\nIn comparison, guardrails would slot in around the single LLM call and make sure that the LLM output is correct/validated/structured/etc. Hope this helps!

Message : RDF2text2vector

Message : Literally no solution out there allows me to embed both taxonomy and ontology in my text right now, so my workflow is to put both of them in the text first before embedding.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00000773-PHOTO-2023-04-19-15-20-09.jpg>
Quoted Message : */imagine* Indian politician Kamal Nath wearing white kurta, smiling , doing namaste, while meeting 4 tribal people in front of their hut on a hot summer day during an on-ground campaign ahead of elections.

Message : https://cdn.discordapp.com/attachments/1059408411890028584/1098182375965478963/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png

Message : TIL Discord CDN has no auth!
Quoted Message : https://cdn.discordapp.com/attachments/1059408411890028584/1098182375965478963/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png

Message : trying out the chatgpt-retrieval plugin. 
Pinecone currently seems to have a waitlist for new users
Which is the next-best db to use?
supported dbs: pinecone, weaviate, zilliz, milvus, qdrant, redis, llamaindex (i know it heavily depends on the usecase‚Ä¶any pointers on how to decide? im just basically trying to create an experimental semantic search over certain documentations)

Message : It's an embedded image right?
Quoted Message : TIL Discord CDN has no auth!

Message : just do qdrant if you're running locally, lowest Memory footprint, the cloud has a decent free plan too
Quoted Message : trying out the chatgpt-retrieval plugin. \nPinecone currently seems to have a waitlist for new users\nWhich is the next-best db to use? \nsupported dbs: pinecone, weaviate, zilliz, milvus, qdrant, redis, llamaindex (i know it heavily depends on the usecase‚Ä¶any pointers on how to decide? im just basically trying to create an experimental semantic search over certain documentations)

Message : full disclosure: trying to sign qdrant as consulting client

Message : Yeah, using SQL lets me do embed ontology a little better, saves me a bit of time doing prompt engineering with vectordbs, but I have a theory about where all this is going to end up
Quoted Message : Appreciate the guardrails shoutout!\nMy understanding of AI functions from databricks was different -- essentially, it's an easy way to create a pipeline of applying LLMs to data in a SQL DB using a UDF. This would be an alternative to applying an LLM to data in a DB by creating a pipeline in python where connect to the DB via an ORM, calling the LLM, and then writing the results of the LLM back to the DB via ORM.\nIn comparison, guardrails would slot in around the single LLM call and make sure that the LLM output is correct/validated/structured/etc. Hope this helps!

Message : RDF2text2vector

Message : Literally no solution out there allows me to embed both taxonomy and ontology in my text right now, so my workflow is to put both of them in the text first before embedding.

Message : Hopefully someone comes up with RDF2vector directly

Message : my dataset has 7.5k rows‚Ä¶shouldn‚Äôt be a constraint right?
In general, how do people decide over dbs?
sorry if this was already discussed here earlier
Quoted Message : just do qdrant if you're running locally, lowest Memory footprint, the cloud has a decent free plan too

Message : Weaviate even had an issue in gh for RDF2vec, but it closed due to lack of interest

Message : Less than a million rows should be fine. qdrant CTO told me that they can do entire Wiki with inference usage of ~1.2G RAM üòß
Quoted Message : my dataset has 7.5k rows‚Ä¶shouldn‚Äôt be a constraint right?\nIn general, how do people decide over dbs?\nsorry if this was already discussed here earlier

Message : This sounds insane. Wiki text is around 80gb I think.
Quoted Message : Less than a million rows should be fine. qdrant CTO told me that they can do entire Wiki with inference usage of ~1.2G RAM üòß

Message : (not sure that's just English though)

Message : English Wikipedia is the claim
Quoted Message : (not sure that's just English though)

Message : Thank you, Shashank.
Quoted Message :  2023_04_19_3EB0F553808BD1390D2C30.jpeg

Message : what is the challenge with saving embeddings in a vector variable
Quoted Message : trying out the chatgpt-retrieval plugin. \nPinecone currently seems to have a waitlist for new users\nWhich is the next-best db to use? \nsupported dbs: pinecone, weaviate, zilliz, milvus, qdrant, redis, llamaindex (i know it heavily depends on the usecase‚Ä¶any pointers on how to decide? im just basically trying to create an experimental semantic search over certain documentations)

Message : In latency sense, for 7.5K rows, I don't think anything is going to beat np.array or torch.tensor on GPU ‚Äî or FAISS
Quoted Message : what is the challenge with saving embeddings in a vector variable

Message : @here getting really disappointing result when cloning my voice on elevenlabs, any other tool/saas suggestions?

Message : Checkout out VALL-E's unofficial PyTorch implementation  on GitHub. Facing similar issues with ElevenLabs

Message : Is there a way to use np.array for the chatgpt/retrieval-plugin? Didn‚Äôt find it in the documentation
Quoted Message : In latency sense, for 7.5K rows, I don't think anything is going to beat np.array or torch.tensor on GPU ‚Äî or FAISS

Message : azure tts has a neural voice cloning service i think. haven't used it tho. i only used their presets.
Quoted Message : @here getting really disappointing result when cloning my voice on elevenlabs, any other tool/saas suggestions?

Message : also Descript has cloning too

Message : is anyone working on AI financial advisors? change the incentive model. 

or is this a bad idea for a product due to some other reason?

https://twitter.com/ravihanda/status/1648596410953244672?t=7l8UC2grkzzutVDWuVBIOA&s=19

Message : Chroma has a decent local db support, could start with that as well
Quoted Message : In latency sense, for 7.5K rows, I don't think anything is going to beat np.array or torch.tensor on GPU ‚Äî or FAISS

Message : Simple local dev interface to get started with

Message : How to use these custom dbs in chatgpt/retrieval-plugin??
The official documentation says you have to set an ```export DATASTORE=<your_datastore>``` which currently allows only ```pinecone```, ```weaviate```, ```zilliz```, ```milvus```, ```dqrant```, ```redis``` and ```llamaindex``` it seems
Quoted Message : Chroma has a decent local db support, could start with that as well

Message : also, it‚Äôs entirely open source. I like knowing the hood, helps to extend, debug and hack around. They will come up with their hosted solution soon
Quoted Message : Chroma has a decent local db support, could start with that as well

Message : under the*

Message : Not sure, haven‚Äôt checked out the retrieval plugin repo in depth. It kinda looked like a mess when I saw it first lol
Quoted Message : How to use these custom dbs in chatgpt/retrieval-plugin??\nThe official documentation says you have to set an ```export DATASTORE=<your_datastore>``` which currently allows only ```pinecone```, ```weaviate```, ```zilliz```, ```milvus```, ```dqrant```, ```redis``` and ```llamaindex``` it seems

Message : Probably others could help here

Message : Has anyone retrained an open source transformer like llama? Mostly content creators are going gung ho around architectures like few shot learning/vector similarity

Message : okay, I checked it out. You could check out this PR branch https://github.com/openai/chatgpt-retrieval-plugin/pull/59 and get started with Chroma
Quoted Message : Not sure, haven‚Äôt checked out the retrieval plugin repo in depth. It kinda looked like a mess when I saw it first lol

Message : Did you use it ? Issue with eleven labs is it doesn‚Äôt have Indian accent, it works well on American accent
Quoted Message : Checkout out VALL-E's unofficial PyTorch implementation  on GitHub. Facing similar issues with ElevenLabs

Message : I mean does vall-e not have same issue

Message : I opened an issue: https://github.com/openai/chatgpt-retrieval-plugin/pull/59#issuecomment-1514694410
seems system-specific in the hindsight, but couldn‚Äôt get it to work
Anyone who has used ```chromadb``` with the retrieval plugin?
Quoted Message : okay, I checked it out. You could check out this PR branch https://github.com/openai/chatgpt-retrieval-plugin/pull/59 and get started with Chroma

Message : I haven't tried it myself, but will patch you in with some folks :)
Quoted Message : Did you use it ? Issue with eleven labs is it doesn‚Äôt have Indian accent, it works well on American accent

Message : Sharing what I wrote today - 
TLDR version
4 ways Generative AI can be used in Agriculture for farmers' benefit.  DPGs are gaining importance given rapid innovation around data sets. Agristack by Ministry of Agriculture becomes even more important.

Use Cases for Indian Agriculture
1.  Personalized Advisory to Farmer  - Answers to : What should I do today in field? Does my plant have a disease or pest ?
2.  Eligibility for Government Schemes - Answers to: What schemes can I benefit from? I have this need, is there anything government provides help with?
3.  Monitoring the problems faced by farmers in real time, and proactively managing those at state level.
Answers to - What are the top issues facing farmers today in state if Karnataka. Is availability of inputs a challenge today in a region.
4. Personalized training in agriculture - educational content in Agriculture
Answers to - I want to do crop diversification to grow Cotton from current Paddy. How do I make the transition?
For more details, read the article.
https://www.linkedin.com/pulse/4-ways-generative-ai-can-used-agriculture-ravi-trivedi/

Message : Has anyone evaluated - DeepSpeed - https://www.deepspeed.ai/ ?

Message : Deepspeed powers Bloom and LoRA from MSFT ‚Äî so many people might've tried it without knowing

Message : *tried the output model

Message : Microsoft has always had a history of the most powerful image models - their (Bing) image search capabilities are/were better than Google

Message : Has anyone felt/realized this anecdotally?
Quoted Message : Microsoft has always had a history of the most powerful image models - their (Bing) image search capabilities are/were better than Google

Message : thanks, that‚Äôd be v helpful
Quoted Message : I haven't tried it myself, but will patch you in with some folks :)

Message : qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now üòÖ
Quoted Message : full disclosure: trying to sign qdrant as consulting client

Message : If someone asks to choose b/w Redis and Qdrant, what would be your recommendation?
Quoted Message : qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now üòÖ

Message : Does a pod correspond to a pinecone index? 

Because 25$ / pod / month is steep. Specially for someone building a low touch / self serve SAAS on top.
Quoted Message : qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now üòÖ

Message : Redis for most things atm. qdrant is pointlessly long devX unless you care about low memory footprint in some way
Quoted Message : If someone asks to choose b/w Redis and Qdrant, what would be your recommendation?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Has anyone evaluated - DeepSpeed - https://www.deepspeed.ai/ ?

Message : Deepspeed powers Bloom and LoRA from MSFT ‚Äî so many people might've tried it without knowing

Message : *tried the output model

Message : Microsoft has always had a history of the most powerful image models - their (Bing) image search capabilities are/were better than Google

Message : Has anyone felt/realized this anecdotally?
Quoted Message : Microsoft has always had a history of the most powerful image models - their (Bing) image search capabilities are/were better than Google

Message : thanks, that‚Äôd be v helpful
Quoted Message : I haven't tried it myself, but will patch you in with some folks :)

Message : qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now üòÖ
Quoted Message : full disclosure: trying to sign qdrant as consulting client

Message : If someone asks to choose b/w Redis and Qdrant, what would be your recommendation?
Quoted Message : qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now üòÖ

Message : Does a pod correspond to a pinecone index? 

Because 25$ / pod / month is steep. Specially for someone building a low touch / self serve SAAS on top.
Quoted Message : qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now üòÖ

Message : Redis for most things atm. qdrant is pointlessly long devX unless you care about low memory footprint in some way
Quoted Message : If someone asks to choose b/w Redis and Qdrant, what would be your recommendation?

Message : DevEx is the key - long Redis

Somehow I've found it to be faster as well with lower consumption of memory/compute
Quoted Message : Redis for most things atm. qdrant is pointlessly long devX unless you care about low memory footprint in some way

Message : https://github.com/Stability-AI/StableLM

Unsure how/why the date on it is 20th April but quite a cool release

Message : Awesome !!! ü§©
Quoted Message : https://github.com/Stability-AI/StableLM\n\nUnsure how/why the date on it is 20th April but quite a cool release

Message : I wanted to know about how the different language models out there today are different.
Is it all about the training data, something else?

Message : It‚Äôs already 20th April in some parts of the world so‚Ä¶ üòÖ
Quoted Message : https://github.com/Stability-AI/StableLM\n\nUnsure how/why the date on it is 20th April but quite a cool release

Message : Any benchmark studies on how it's faring compared to existing models?
Quoted Message : https://github.com/Stability-AI/StableLM\n\nUnsure how/why the date on it is 20th April but quite a cool release

Message : ‚ÄúAs is typical for any pretrained Large Language Model without additional finetuning and reinforcement learning, the responses a user gets might be of varying quality and might potentially include offensive language and views. This is expected to be improved with scale, better data, community feedback, and optimisation.‚Äù

üòÜüòÇ
Quoted Message : Any benchmark studies on how it's faring compared to existing models?

Message : Have anyone used Weaviate? 
Been using it and found it pretty good for self hosting.
Quoted Message : If someone asks to choose b/w Redis and Qdrant, what would be your recommendation?

Message : Also, wrt to embedding models, has anyone here done considerable research on which model is better? Ada from openAI is good, but how different is it from sentence transformers from HuggingFace?

Message : Haha... I thought so but then the founding team mostly isn't based out of those areas
Quoted Message : It‚Äôs already 20th April in some parts of the world so‚Ä¶ üòÖ

Message : It‚Äôs always 4/20 somewhere üíÅ‚Äç‚ôÇÔ∏è
Quoted Message : It‚Äôs already 20th April in some parts of the world so‚Ä¶ üòÖ

Message : Haven't come across any benchmarks or anecdotal reviews

But param size is similar to LLaMa and (LLaMA is 1T tokens for its 7B model) considering Stability's track record, I'd expect similar results (?)

I'm sure better & smarter practitioners will tinker & let us know soonüôèüèª
Quoted Message : Any benchmark studies on how it's faring compared to existing models?

Message : i think Cohere cofounder did a comparison some time back. IIRC, it's a google sheet.
Quoted Message : Also, wrt to embedding models, has anyone here done considerable research on which model is better? Ada from openAI is good, but how different is it from sentence transformers from HuggingFace?

Message : Not sure how many folks have tried the new Bedrock product by AWS but curious if folks think some of it and the aspects of model benchmarks potentially move to AWS

Message : Any idea where I can find it?
Quoted Message : i think Cohere cofounder did a comparison some time back. IIRC, it's a google sheet.

Message : For indian languages cohere multilingual embeddings are having good discrimination based on my experiments.
Quoted Message : i think Cohere cofounder did a comparison some time back. IIRC, it's a google sheet.

Message : https://twitter.com/Nils_Reimers/status/1487014195568775173?t=qKHnPgJn4SvniSxT5SvXiw&s=19

idk if the medium article is updated or not. also correction: he isn't a cofounder at cohere.
Quoted Message : Any idea where I can find it?

Message : https://twitter.com/jerryjliu0/status/1648709029777252352?s=46&t=gjIVQMn9Hp7sUgYs_m23Ww

Message : @91955016xxxx - again contributing with Evalset generator

Message : Thank-you for the mention Arpan.

For the broader set of people, the idea here is to understand how well LLMs are good at doing QA on your documents.
The dataset generator and evaluation modules are built to answer this question.

You can check more details here -

Dataset generator module - https://twitter.com/jerryjliu0/status/1648709020382023683?s=20
Evaluation module - https://twitter.com/jerryjliu0/status/1645451894637367298?s=20

Albus (@91963283xxxx ) is currently using the module in their production. I will be speaking more on this in Saturday‚Äôs meet-up.
Quoted Message : @9195xxxxxxxx - again contributing with Evalset generator

Message : ‚Äé<attached: 00000852-PHOTO-2023-04-20-01-05-42.jpg>
Quoted Message : You could additionally change the object's position and use SD Inpainting, which gives more variation results. @9187xxxxxxxx has mentioned those in details section of his product here - https://gooey.ai/product-photo-background-generator/

Message : Thanks for the mention ravi! ‚ù§Ô∏è

Message : ‚Äé<attached: 00000854-PHOTO-2023-04-20-01-13-10.jpg>

Message : sorry I must have missed. Where is the meet-up ?
Quoted Message : Thank-you for the mention Arpan.\n\nFor the broader set of people, the idea here is to understand how well LLMs are good at doing QA on your documents. \nThe dataset generator and evaluation modules are built to answer this question.\n\nYou can check more details here - \n\nDataset generator module - https://twitter.com/jerryjliu0/status/1648709020382023683?s=20\nEvaluation module - https://twitter.com/jerryjliu0/status/1645451894637367298?s=20\n\nAlbus (@9196xxxxxxxx ) is currently using the module in their production. I will be speaking more on this in Saturday‚Äôs meet-up.

Message : BLR, Saturday evening: https://hasgeek.com/generativeAI/april-meetup/
Quoted Message : sorry I must have missed. Where is the meet-up ?

Message : https://blog.replit.com/llm-training A good blog post by Replit where they give us high-level description of how they train their own LLMs

Message : What's amazing is that the team is <5 people :)

Message : Replit is < 5 people???

Message : The ML team

Message : Wow ‚ù§Ô∏è

Message : The entire engineering team ~50 people

Message : Talent density >> head count ‚ù§Ô∏èüî•

Message : https://twitter.com/fabianstelzer/status/1648700767992180737?s=48

Message : EyeQuant founder talks about text2film
Quoted Message : https://twitter.com/fabianstelzer/status/1648700767992180737?s=48

Message : Proven again and again in the world of Foundational Models - almost all top companies have lean teams
Quoted Message : Talent density >> head count ‚ù§Ô∏èüî•

Message : Midjourney is 8 engineers, Replit is 5, OpenAI Whisper was 6 (and 3 of those were Greg Brockman, C. McLeavy and Ilya S.), _Attention is All You Need_ paper had 8 authors

Machine Learning is really riding the coattails of infrastructure folks slogging üòõ
Quoted Message : Proven again and again in the world of Foundational Models - almost all top companies have lean teams

Message : midjourney outsourced frontend to discord üòÇ
Quoted Message : Midjourney is 8 engineers, Replit is 5, OpenAI Whisper was 6 (and 3 of those were Greg Brockman, C. McLeavy and Ilya S.), _Attention is All You Need_ paper had 8 authors\n\nMachine Learning is really riding the coattails of infrastructure folks slogging üòõ

Message : https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/

Very interesting article about security and LLMs by one of my favourite programmers

Message : Cracked crazy adoption
Quoted Message : midjourney outsourced frontend to discord üòÇ

Message : Original song by Ariana Grande: https://www.youtube.com/watch?v=DOJremEQw88
Same song in the voice of Dua Lipa (AI-generated): https://www.youtube.com/watch?v=m38CJBHO2RI

This is just soooo good. ‚ú®


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : The entire engineering team ~50 people

Message : Talent density >> head count ‚ù§Ô∏èüî•

Message : https://twitter.com/fabianstelzer/status/1648700767992180737?s=48

Message : EyeQuant founder talks about text2film
Quoted Message : https://twitter.com/fabianstelzer/status/1648700767992180737?s=48

Message : Proven again and again in the world of Foundational Models - almost all top companies have lean teams
Quoted Message : Talent density >> head count ‚ù§Ô∏èüî•

Message : Midjourney is 8 engineers, Replit is 5, OpenAI Whisper was 6 (and 3 of those were Greg Brockman, C. McLeavy and Ilya S.), _Attention is All You Need_ paper had 8 authors

Machine Learning is really riding the coattails of infrastructure folks slogging üòõ
Quoted Message : Proven again and again in the world of Foundational Models - almost all top companies have lean teams

Message : midjourney outsourced frontend to discord üòÇ
Quoted Message : Midjourney is 8 engineers, Replit is 5, OpenAI Whisper was 6 (and 3 of those were Greg Brockman, C. McLeavy and Ilya S.), _Attention is All You Need_ paper had 8 authors\n\nMachine Learning is really riding the coattails of infrastructure folks slogging üòõ

Message : https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/

Very interesting article about security and LLMs by one of my favourite programmers

Message : Cracked crazy adoption
Quoted Message : midjourney outsourced frontend to discord üòÇ

Message : Original song by Ariana Grande: https://www.youtube.com/watch?v=DOJremEQw88
Same song in the voice of Dua Lipa (AI-generated): https://www.youtube.com/watch?v=m38CJBHO2RI

This is just soooo good. ‚ú®

Message : What tech is used for this?
Quoted Message : Original song by Ariana Grande: https://www.youtube.com/watch?v=DOJremEQw88\nSame song in the voice of Dua Lipa (AI-generated): https://www.youtube.com/watch?v=m38CJBHO2RI\n\nThis is just soooo good. ‚ú®

Message : Are you tracking usage on a per-api key basis? Is this even possible?
Quoted Message : One account with multiple keys - easier to consolidate and have conversations with OpenAI team on priority access.

Message : OpenAI tracks usage per organisation basis, one way to work through this might be setting up different teams for different keys
Quoted Message : Are you tracking usage on a per-api key basis? Is this even possible?

Message : I came across https://twitter.com/vboykis/status/1648756882679427072?t=JDfSjZx03Rlj9JHp1IbBpA&s=19

And i resonate with some of this.

Yesterday I tried ChatGPT to write code that could generate patterns for use as a background for quotes (a feature on Koo).

The code failed to run and i prompted ChatGPT with the error and while it kept rewriting the code, I wasn't able to get a version that worked.

Then good old Github search helped me find something useful.

Just wanted to share. Not dumping on ChatGPT.
The code that i got would have taken me many hours to piece together and the errors were minor and fixable with more context on the exact library if I spend time with the docs.

Message : Someone had a very good analogy on this :
It‚Äôs wrong to assume ChatGPT would replace programming jobs
ChatGPT is like co-pilot for devs
Which implies that you need an experienced pilot to go with it
It can‚Äôt work like a pilot on its own(yet)
Quoted Message : I came across https://twitter.com/vboykis/status/1648756882679427072?t=JDfSjZx03Rlj9JHp1IbBpA&s=19\n\nAnd i resonate with some of this. \n\nYesterday I tried ChatGPT to write code that could generate patterns for use as a background for quotes (a feature on Koo). \n\nThe code failed to run and i prompted ChatGPT with the error and while it kept rewriting the code, I wasn't able to get a version that worked. \n\nThen good old Github search helped me find something useful. \n\nJust wanted to share. Not dumping on ChatGPT. \nThe code that i got would have taken me many hours to piece together and the errors were minor and fixable with more context on the exact library if I spend time with the docs.

Message : just org / no tracking per key possible. 
IMO one org is important to develop relationship with OpenAI - lower retention period, support, access to better models, SLA, credits
Quoted Message : Are you tracking usage on a per-api key basis? Is this even possible?

Message : Well said
Quoted Message : Someone had a very good analogy on this :\nIt‚Äôs wrong to assume ChatGPT would replace programming jobs\nChatGPT is like co-pilot for devs\nWhich implies that you need an experienced pilot to go with it \nIt can‚Äôt work like a pilot on its own(yet)

Message : Tried this last night. Controlnet inpaint model isn‚Äôt much better than the regular sd inpaint. The advantage though is that you dont need a custom inpainting checkpoint, so you can inpaint with community models like analog diffusion, openjourney, protogen etc or maybe even a lora model?
Quoted Message : My understanding is that the maximum amount of control right now comes from control net models. Given that multiple controllers can be clubbed together and img2img and inpainting is also supported, with even huggingface launching a control net sprint , we will get a lot of community controlnets which can be used. T2I adapters is another approach but controlnet has community momentum with it.

Message : This is the comment by the author of the controlnet repo: "
OMG i find ControlNet inpaint and A1111 inpaint can work together to achieve perfect seamless and super robust inpaint and at the same time do not change unmasked area" : https://github.com/Mikubill/sd-webui-controlnet/issues/736#issuecomment-1510598350

Also if you tried directly from the controlnet v1.1 repo , he has added a disclaimer for his gradio file:

"This gradio demo does not include post-processing. Ideally, you need to post-process the latent image in each diffusion iteration and post-process the image after vae decoding, so that the unmasked area keeps unchanged. However, this is complicated to implement and perhaps a better idea is to make it in a1111. In this gradio example, the outputs are just the original outputs from diffusion, and the unmasked area in your image may change because of the vae or diffusion process."

I am using mikubil's controlnet extension which fits into automatic1111. I am still experimenting as well. This is less than 4 days of support overall. There are still some bugs which are getting resolved.
Quoted Message : Tried this last night. Controlnet inpaint model isn‚Äôt much better than the regular sd inpaint. The advantage though is that you dont need a custom inpainting checkpoint, so you can inpaint with community models like analog diffusion, openjourney, protogen etc or maybe even a lora model?

Message : Thanks. I used diffusers lib with the hugginface checkpoint so yes probably not as good as a1111. The inpainting code in general has always been super well done in a1111, really amazing stuff! What‚Äôs the status of a1111‚Äôs python api these days?
Quoted Message : This is the comment by the author of the controlnet repo: \"\nOMG i find ControlNet inpaint and A1111 inpaint can work together to achieve perfect seamless and super robust inpaint and at the same time do not change unmasked area\" : https://github.com/Mikubill/sd-webui-controlnet/issues/736#issuecomment-1510598350 \n\nAlso if you tried directly from the controlnet v1.1 repo , he has added a disclaimer for his gradio file:\n\n\"This gradio demo does not include post-processing. Ideally, you need to post-process the latent image in each diffusion iteration and post-process the image after vae decoding, so that the unmasked area keeps unchanged. However, this is complicated to implement and perhaps a better idea is to make it in a1111. In this gradio example, the outputs are just the original outputs from diffusion, and the unmasked area in your image may change because of the vae or diffusion process.\"\n\nI am using mikubil's controlnet extension which fits into automatic1111. I am still experimenting as well. This is less than 4 days of support overall. There are still some bugs which are getting resolved.

Message : ‚Äé<attached: 00000885-PHOTO-2023-04-20-13-52-42.jpg>

Message : I haven't worked with the API yet. So wouldn't know. Also the diffusers library isn't upToDate with the latest release. This is because the repo author is working on integrating it with automatic1111 first.
Quoted Message : Thanks. I used diffusers lib with the hugginface checkpoint so yes probably not as good as a1111. The inpainting code in general has always been super well done in a1111, really amazing stuff! What‚Äôs the status of a1111‚Äôs python api these days?

Message : What resolution is this?
Quoted Message :  2023_04_20_3EB080F9C8CD7612D165A3.jpeg

Message : 768x512

Message : The glass seems to have been modified a bit?

Message : yeah. I didn't mask correctly. I am testing other aspects of the controlnet.
Quoted Message : The glass seems to have been modified a bit?

Message : Keep us posted :-)
Quoted Message : yeah. I didn't mask correctly. I am testing other aspects of the controlnet.

Message : ‚Äé<attached: 00000892-PHOTO-2023-04-20-14-51-12.jpg>

Message : cc @91866009xxxx since you opened this thread
Quoted Message :  2023_04_20_3EB0B16C077B4B806F320B.jpeg

Message : The best way to insert an external object like a glass into another image is to just overlay it in another layer using photoshop or free web based photopea. Export as a single image (img1). Also export an image in the same dimensions but with only the glass and the rest of the background black (img2). Then inpaint over and around the glass in img1. Load img2 into controlnet. Use canny, depth, hed maps or a combo of these based on the kind of object. Adjust the controlnet weight appropriately. Also adjust the weight of the right word in the prompt like (glass:1.2).

Message : Another way to achieve the same thing is to load just the glass image with transparent bg into controlnet. and only use the canny / depth / hed preprocessor (not the model). Download the map. Position the map image according to your final image dimensions such that it is exactly where you want the generation to happen. Black the rest of the background and export as another image. Load this image into controlnet and this time leave the preprocessor blank. Only select the appropriate model. This works great because your object map is already perfectly positioned where you want it in the image.

Message : This is awesome @91961949xxxx Thanks a lot for this. I'll update once I have setup Automatic UI.

Message : How hard to push per key API results to Prometheus? From there use any UI tool like grafana to monitor per API usages.
https://github.com/prometheus/client_python
Quoted Message : Are you tracking usage on a per-api key basis? Is this even possible?

Message : Is anyone using GPT4 in prod? I'm sending gpt-4 as the model but its still using gpt-4-0314. Have heard gpt-4 is much more faster than the 0314

Message : Anyone have any clue if multimodal LLMs are good reading images of documents? Say for OCR.

Message : Which LLM‚Äôs? Pix2instruct? Or any other LLM?
Quoted Message : Anyone have any clue if multimodal LLMs are good reading images of documents? Say for OCR.

Message : say GPT-4? I know the multi-modal functionality is not rolled out yet but curious of  Visual Document Q&A is an application since you can ask it questions about images.

Message : I was just checking out this repo: https://github.com/clovaai/donut

Message : Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments
Quoted Message : Anyone have any clue if multimodal LLMs are good reading images of documents? Say for OCR.

Message : Doesn‚Äôt use OCR
Quoted Message : I was just checking out this repo: https://github.com/clovaai/donut

Message : I've tried it, hard to fine tune to your use case and get consistent results
Quoted Message : Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments

Message : Ya tesseract is great. I‚Äôm coming from the perspective of one model to rule them all. It‚Äôs clear that LLMs have absorbed a lot of vertical NLP usecases. Wondering if I can just use a multimodal LLM in the future for OCR also instead of using tesseract or a AWS/GCP API
Quoted Message : Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments

Message : In all likelihood, yes. Microsoft's LayoutLMv3 already does OCR: https://huggingface.co/microsoft/layoutlmv3-base
Quoted Message : Ya tesseract is great. I‚Äôm coming from the perspective of one model to rule them all. It‚Äôs clear that LLMs have absorbed a lot of vertical NLP usecases. Wondering if I can just use a multimodal LLM in the future for OCR also instead of using tesseract or a AWS/GCP API

Message : @91955016xxxx pointed out on DM, Donut also does OCR in a manner of speaking when it does Document Parsing
Quoted Message : I was just checking out this repo: https://github.com/clovaai/donut

Message : ‚Äé<attached: 00000911-PHOTO-2023-04-20-17-25-11.jpg>

Message : I see. Since they are taking in images, I was thinking there might be some ocr involved

Message : Would something like this be better and faster for resume parsing tasks, compared to feeding the resume text to an LLM and asking it to parse?
Quoted Message : In all likelihood, yes. Microsoft's LayoutLMv3 already does OCR: https://huggingface.co/microsoft/layoutlmv3-base

Message : Today, or in future? 

Today, this'd be faster perhaps because you'll only pass relevant sections to the text-LLM hopefully. Less clutter would make JSON-fixing easier I believe.
Quoted Message : Would something like this be better and faster for resume parsing tasks, compared to feeding the resume text to an LLM and asking it to parse?

Message : Got it, thanks.
I was referring for today i guess.

Message : Future changes everyday nowadays üòÖ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I've tried it, hard to fine tune to your use case and get consistent results
Quoted Message : Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments

Message : Ya tesseract is great. I‚Äôm coming from the perspective of one model to rule them all. It‚Äôs clear that LLMs have absorbed a lot of vertical NLP usecases. Wondering if I can just use a multimodal LLM in the future for OCR also instead of using tesseract or a AWS/GCP API
Quoted Message : Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments

Message : In all likelihood, yes. Microsoft's LayoutLMv3 already does OCR: https://huggingface.co/microsoft/layoutlmv3-base
Quoted Message : Ya tesseract is great. I‚Äôm coming from the perspective of one model to rule them all. It‚Äôs clear that LLMs have absorbed a lot of vertical NLP usecases. Wondering if I can just use a multimodal LLM in the future for OCR also instead of using tesseract or a AWS/GCP API

Message : @91955016xxxx pointed out on DM, Donut also does OCR in a manner of speaking when it does Document Parsing
Quoted Message : I was just checking out this repo: https://github.com/clovaai/donut

Message : ‚Äé<attached: 00000911-PHOTO-2023-04-20-17-25-11.jpg>

Message : I see. Since they are taking in images, I was thinking there might be some ocr involved

Message : Would something like this be better and faster for resume parsing tasks, compared to feeding the resume text to an LLM and asking it to parse?
Quoted Message : In all likelihood, yes. Microsoft's LayoutLMv3 already does OCR: https://huggingface.co/microsoft/layoutlmv3-base

Message : Today, or in future? 

Today, this'd be faster perhaps because you'll only pass relevant sections to the text-LLM hopefully. Less clutter would make JSON-fixing easier I believe.
Quoted Message : Would something like this be better and faster for resume parsing tasks, compared to feeding the resume text to an LLM and asking it to parse?

Message : Got it, thanks.
I was referring for today i guess.

Message : Future changes everyday nowadays üòÖ

Message : Sounds reasonable. Additionally, can I audit the requests made to each api key?
Quoted Message : How hard to push per key API results to Prometheus? From there use any UI tool like grafana to monitor per API usages.\nhttps://github.com/prometheus/client_python

Message : Labels can be used to pass API key hash or user friendly name (do not pass exact API key :))
https://github.com/prometheus/client_python#labels
Quoted Message : Sounds reasonable. Additionally, can I audit the requests made to each api key?

Message : I tried using MM-REACT using hugging face space provided by them. It works much better than Donut. The work uses Reasoning capabilities of LLMs to extract information from visually rich documents
Quoted Message : @9195xxxxxxxx pointed out on DM, Donut also does OCR in a manner of speaking when it does Document Parsing

Message : https://github.com/microsoft/MM-REACT

Message : https://github.com/Layout-Parser/layout-parser

Message : last time i checked, langchain had a layout-parser integration for pdfs
Quoted Message : https://github.com/Layout-Parser/layout-parser

Message : https://blog.eleuther.ai/transformer-math/?s=08

Message : Optimised implementation for Whisper, faster than real time üöÄ
https://twitter.com/sanchitgandhi99/status/1649046650793648128?s=20

Message : Sanchit is absolutely killing it

Message : Sahi! Anyone know the costs?
Quoted Message : Optimised implementation for Whisper, faster than real time üöÄ\nhttps://twitter.com/sanchitgandhi99/status/1649046650793648128?s=20

Message : Has anyone tried fine tuning dolly2 yet?

Message : It is open source 
https://github.com/sanchit-gandhi/whisper-jax
Quoted Message : Sahi! Anyone know the costs?

Message : @91709286xxxx This was so-vits-svc

https://github.com/voicepaw/so-vits-svc-fork
Quoted Message : Original song by Ariana Grande: https://www.youtube.com/watch?v=DOJremEQw88\nSame song in the voice of Dua Lipa (AI-generated): https://www.youtube.com/watch?v=m38CJBHO2RI\n\nThis is just soooo good. ‚ú®

Message : What tools or best practices you guys use for recording LLM experiments (for example, with what change of parameters, how much reasoning/relevancy of retrieved results increased along with tracking metrics like accuracy/precision improvements, finding difficulty in managing ways to look through various Jupyter notebooks etc? W&B is a familiar tool, but want to capture and know the Gist of all the experiments at one place. Looking forward to hearing your suggestions üôè

Message : https://twitter.com/CohereAI/status/1649097293201547264?t=UsFrQQNyNhdkoqPz8AgcrA&s=19


This is a smart move by cohere, releasing a Wikipedia paragraph embedding dataset, will invite hackers to make their prototypes using cohere model, get traction in this competitive market

Message : Given the model specificity for any operations, the more open and accessible you are, the more acceptance you will have by early adopters, more traction you will get

Message : Cmiiw, stability haven't made their latest stable diffusion model available to public and is only available on their dreamstudio ui, right?

Message : minigpt-4 is better
Quoted Message : I tried using MM-REACT using hugging face space provided by them. It works much better than Donut. The work uses Reasoning capabilities of LLMs to extract information from visually rich documents

Message : and https://llava-vl.github.io/ is very good too. Does well on gpt-4 samples

Message : https://twitter.com/marty_catboy/status/1649032460573745152

...

Message : Martin Shkreli's AI launch

Message : Btw very nice talks going on live at Weights & Biases LLMOps London event - https://www.youtube.com/watch?v=YfBtytGNEKE

Message : Current Best Practices for Training LLMs from Scratch - Final.pdf ‚Ä¢ ‚Äé23 pages ‚Äé<attached: 00000943-Current Best Practices for Training LLMs from Scratch - Final.pdf>

Message : This guy says he used langchain 
https://twitter.com/ankur_maker/status/1648349266006495237?s=20

to make this
https://www.producthunt.com/posts/autogpt-an-autonomous-gpt-4

How is this not a simple UI over the auto-GPT library? If not, then in what capacity could he have used LangChain here?

Message : WebGPT - run gpt models entirely on the browser. based on WebGPU. 

https://twitter.com/willdepue/status/1649147091573432321?t=JJxHljJSm46bWzjqoyr7ag&s=19

Message : damn. WebGPU seems to be a great ROI for folks building apps that concerns client privacy

Message : Absolutely love this resource! 
Google search for LLM Engineering returns junk results.

Folks, Are there other links  you recommend?

Message : https://kubiya.ai/

Unsure if this has been discussed before but found it to be a very nifty product

Message : Has anyone tried something similar?

Message : What caught your eye? Why is this interesting?
Quoted Message : https://kubiya.ai/\n\nUnsure if this has been discussed before but found it to be a very nifty product

Message : Can apply helm charts, debug, rollback on K8s clusters all via using a chat interface using natural language

I think it's a very good attempt at simplifying the end user experience
Quoted Message : What caught your eye? Why is this interesting?

Message : Well computer engineering goes in circles. It all started with command lines, then started becoming fancier, spent enormous efforts building GUIs and now after all the decades of innovation we are back to ‚Ä¶ command lines üòÜ(essentially)

Message : üòÜüòÜ

Message : https://blog.replit.com/llm-training this one
Quoted Message : Absolutely love this resource! \nGoogle search for LLM Engineering returns junk results.\n\nFolks, Are there other links  you recommend?

Message : I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask. 
https://www.twitch.tv/videos/1798833016?t=0h34m44s

Message : Like this technique
Quoted Message : Another way to achieve the same thing is to load just the glass image with transparent bg into controlnet. and only use the canny / depth / hed preprocessor (not the model). Download the map. Position the map image according to your final image dimensions such that it is exactly where you want the generation to happen. Black the rest of the background and export as another image. Load this image into controlnet and this time leave the preprocessor blank. Only select the appropriate model. This works great because your object map is already perfectly positioned where you want it in the image.

Message : I was hearing it live ! Pretty awesome talk Amogh !
Quoted Message : I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask. \nhttps://www.twitch.tv/videos/1798833016?t=0h34m44s

Message : Thanks!
Quoted Message : I was hearing it live ! Pretty awesome talk Amogh !

Message : You didn't pray to the demo Gods, they almost tested you there üòÇ
Quoted Message : I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask. \nhttps://www.twitch.tv/videos/1798833016?t=0h34m44s

Message : Good demo and techniques there üëè


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Can apply helm charts, debug, rollback on K8s clusters all via using a chat interface using natural language

I think it's a very good attempt at simplifying the end user experience
Quoted Message : What caught your eye? Why is this interesting?

Message : Well computer engineering goes in circles. It all started with command lines, then started becoming fancier, spent enormous efforts building GUIs and now after all the decades of innovation we are back to ‚Ä¶ command lines üòÜ(essentially)

Message : üòÜüòÜ

Message : https://blog.replit.com/llm-training this one
Quoted Message : Absolutely love this resource! \nGoogle search for LLM Engineering returns junk results.\n\nFolks, Are there other links  you recommend?

Message : I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask. 
https://www.twitch.tv/videos/1798833016?t=0h34m44s

Message : Like this technique
Quoted Message : Another way to achieve the same thing is to load just the glass image with transparent bg into controlnet. and only use the canny / depth / hed preprocessor (not the model). Download the map. Position the map image according to your final image dimensions such that it is exactly where you want the generation to happen. Black the rest of the background and export as another image. Load this image into controlnet and this time leave the preprocessor blank. Only select the appropriate model. This works great because your object map is already perfectly positioned where you want it in the image.

Message : I was hearing it live ! Pretty awesome talk Amogh !
Quoted Message : I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask. \nhttps://www.twitch.tv/videos/1798833016?t=0h34m44s

Message : Thanks!
Quoted Message : I was hearing it live ! Pretty awesome talk Amogh !

Message : You didn't pray to the demo Gods, they almost tested you there üòÇ
Quoted Message : I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask. \nhttps://www.twitch.tv/videos/1798833016?t=0h34m44s

Message : Good demo and techniques there üëè

Message : I was going to do pre recorded videos but @91740765xxxx keeps me so busy at Dashtoon that I had no time and had to wing it live üòõ
Quoted Message : You didn't pray to the demo Gods, they almost tested you there üòÇ

Message : Is there any good drawing to 3D tools out there

Message : cc @91800314xxxx is a 3d artist and has worked with NeRFs
Quoted Message : Is there any good drawing to 3D tools out there

Message : https://www.reddit.com/r/StableDiffusion/comments/12etqvx/tutorial_creating_a_consistent_character_as_a/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1

Message : Create consistent AI characters across images with SD

Message : Is there an AI art/ text to image group? @91773788xxxx @91961949xxxx

Message : This is the one for now ‚Äî hence the "DeepMedia" in the name!
Quoted Message : Is there an AI art/ text to image group? @9177xxxxxxxx @9196xxxxxxxx

Message : ‚ÄéPOLL:
Do you promise to share links and be generally helpful if we were to make a separate group for text to media (images, video, music)?
‚ÄéOPTION: Yes (51 votes)
‚ÄéOPTION: No (4 votes)

Message : I agree on separate image group too üòÖ

Message : Text is so much more popular but would want to have 100% coverage on images.

Message : I'd like that as well. There are about 300 odd folks who haven't muted this group (yet) ‚Äî so if more than 10% (>30)
folks say yes in the poll, let's do it!
Quoted Message : I agree on separate image group too üòÖ

Message : Can we join if we are noobs looking to start in deep media ?

Message : @91961949xxxx @91998208xxxx @91800314xxxx @91731882xxxx @91904921xxxx @91875456xxxx @3248663xxxx  please vote :P
Quoted Message : I'd like that as well. There are about 300 odd folks who haven't muted this group (yet) ‚Äî so if more than 10% (>30)\nfolks say yes in the poll, let's do it!

Message : I‚Äôve not muted

Message : It‚Äôs actually a really high quality group. I‚Äôve met some really smart people on here ü´°

Message : I agree.

Message : But from discussion standpoint, just want images/video specific place too üòÖ

Message : Hey, can we make a public xlxs doc where we can put all the links and a short description about the link. Because a lot of people are already sharing lots of links and it's hard to keep track of .

Message : Yessss. Beginners are welcome in the community! This is why I personally take the pain to dig up everything from UI components to VectorDB benchmarks for questions asked here!
Quoted Message : Can we join if we are noobs looking to start in deep media ?

Message : Working on this. Releasing next Friday.
Quoted Message : Hey, can we make a public xlxs doc where we can put all the links and a short description about the link. Because a lot of people are already sharing lots of links and it's hard to keep track of .

Message : Hero we deserve
Quoted Message : Yessss. Beginners are welcome in the community! This is why I personally take the pain to dig up everything from UI components to VectorDB benchmarks for questions asked here!

Message : Thanks, man. I recently got into LLMs stuff, so I'm missing the text to image and basically all the new recently released techniques on the image generation. This will really be helpful.
Quoted Message : Working on this. Releasing next Friday.

Message : There should be an option for Not Applicable

Message : Agree!
Quoted Message : Text is so much more popular but would want to have 100% coverage on images.

Message : Yeah, that's "No"
Quoted Message : There should be an option for Not Applicable

Message : there are already like 5 groups in this community, it's becoming like the slack channel hell üòÇ

Message : Yes please. Separate image group please
Quoted Message : I agree on separate image group too üòÖ

Message : Ah! Have a lot of controlnet, SD and text to video stuff I‚Äôd love to share and have deeper discussions. Have felt this group is more towards LLMs and NLP and image stuff doesn‚Äôt get discussed as much.
Quoted Message : This is the one for now ‚Äî hence the \"DeepMedia\" in the name!

Message : Haha ‚ÄúNO‚Äù can be rude
Quoted Message : Yeah, that's \"No\"

Message : üòÇ

Message : And much like Slack, the expectation is that you've 1-2 core channels where you contribute actively, sporadically in 2 more and lurk in the rest :)
Quoted Message : there are already like 5 groups in this community, it's becoming like the slack channel hell üòÇ

Message : Dont follow all is the secret to all slack groups :D
Quoted Message : there are already like 5 groups in this community, it's becoming like the slack channel hell üòÇ

Message : You can just choose to not vote üòÖ
Quoted Message : There should be an option for Not Applicable

Message : I promise to contribute more actively to the resultant text-only group :)

Message : Guess I tipped the balance. Can us commoners get a new group? üò¨
Quoted Message : I'd like that as well. There are about 300 odd folks who haven't muted this group (yet) ‚Äî so if more than 10% (>30)\nfolks say yes in the poll, let's do it!

Message : DeepMedia: Generative Art (Text to Images, Video, Music)

https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J
Quoted Message : Guess I tipped the balance. Can us commoners get a new group? üò¨

Message : ‚Äé<attached: 00001007-GIF-2023-04-21-12-42-18.mp4>

Message : Haha @91773788xxxx  we need a Text to Action group as well for the next revolution in AI ..

Message : New poll please
Quoted Message : Haha @9177xxxxxxxx  we need a Text to Action group as well for the next revolution in AI ..

Message : Early joiners beer on me üç∫


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : And much like Slack, the expectation is that you've 1-2 core channels where you contribute actively, sporadically in 2 more and lurk in the rest :)
Quoted Message : there are already like 5 groups in this community, it's becoming like the slack channel hell üòÇ

Message : Dont follow all is the secret to all slack groups :D
Quoted Message : there are already like 5 groups in this community, it's becoming like the slack channel hell üòÇ

Message : You can just choose to not vote üòÖ
Quoted Message : There should be an option for Not Applicable

Message : I promise to contribute more actively to the resultant text-only group :)

Message : Guess I tipped the balance. Can us commoners get a new group? üò¨
Quoted Message : I'd like that as well. There are about 300 odd folks who haven't muted this group (yet) ‚Äî so if more than 10% (>30)\nfolks say yes in the poll, let's do it!

Message : DeepMedia: Generative Art (Text to Images, Video, Music)

https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J
Quoted Message : Guess I tipped the balance. Can us commoners get a new group? üò¨

Message : ‚Äé<attached: 00001007-GIF-2023-04-21-12-42-18.mp4>

Message : Haha @91773788xxxx  we need a Text to Action group as well for the next revolution in AI ..

Message : New poll please
Quoted Message : Haha @9177xxxxxxxx  we need a Text to Action group as well for the next revolution in AI ..

Message : Early joiners beer on me üç∫

Message : Yes sir, in couple of weeks when we've more people interested in actions :)
Quoted Message : Haha @9177xxxxxxxx  we need a Text to Action group as well for the next revolution in AI ..

Message : Haha üòÇ  I know an expert in building AI community..

Message : folks, noob request here.

I've built plug and play GPT wrappers, but I want to understand the basics of how LLMs work in detail, any resources for a deeper dive into understanding it from scratch?

Thank you :D

Message : Illustrated Transformers: https://jalammar.github.io/illustrated-transformer/

Transformer Family: https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/
Quoted Message : folks, noob request here.\n\nI've built plug and play GPT wrappers, but I want to understand the basics of how LLMs work in detail, any resources for a deeper dive into understanding it from scratch?\n\nThank you :D

Message : Thanks a ton Nirant!
Quoted Message : Illustrated Transformers: https://jalammar.github.io/illustrated-transformer/\n\nTransformer Family: https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/

Message : https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ

Neural Networks: Zero to Hero
- Andrej Karpathy
Quoted Message : Illustrated Transformers: https://jalammar.github.io/illustrated-transformer/\n\nTransformer Family: https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/

Message : https://docs.google.com/spreadsheets/d/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4/edit?usp=sharing quick and dirty effort on this
Quoted Message : Hey, can we make a public xlxs doc where we can put all the links and a short description about the link. Because a lot of people are already sharing lots of links and it's hard to keep track of .

Message : üôá‚Äç‚ôÇÔ∏è thanks, my weekend will go well
Quoted Message : https://docs.google.com/spreadsheets/d/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4/edit?usp=sharing quick and dirty effort on this

Message : Really nice. Did you write a script for whatsapp web?
Quoted Message : https://docs.google.com/spreadsheets/d/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4/edit?usp=sharing quick and dirty effort on this

Message : Can export chat to plain text and regex on it :)
Quoted Message : Really nice. Did you write a script for whatsapp web?

Message : yeah this. now tweaking to get context. almost done
Quoted Message : Can export chat to plain text and regex on it :)

Message : Langchain it! Release code to Github. I'll add the features I'm working on as well.
Quoted Message : yeah this. now tweaking to get context. almost done

Message : My Ola's ex-colleague built this. See if this is helpful 

https://supergroup.ai/
Quoted Message : https://docs.google.com/spreadsheets/d/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4/edit?usp=sharing quick and dirty effort on this

Message : "Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples" (from https://news.mit.edu/2023/large-language-models-in-context-learning-0207 ) 

So this an emergent property and we don't know how it happened! wtf!
Anyone knows how few-shot / in-context learning works?

Message : https://arxiv.org/abs/2303.12712 in this paper Microsoft researchers who had early access describes to an extent how they think it works. Finally they also conclude they don't know how it works üôÅ
Quoted Message : \"Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples\" (from https://news.mit.edu/2023/large-language-models-in-context-learning-0207 ) \n\nSo this an emergent property and we don't know how it happened! wtf!\nAnyone knows how few-shot / in-context learning works?

Message : ‚Äé<attached: 00001033-PHOTO-2023-04-21-15-44-36.jpg>
Quoted Message : \"Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples\" (from https://news.mit.edu/2023/large-language-models-in-context-learning-0207 ) \n\nSo this an emergent property and we don't know how it happened! wtf!\nAnyone knows how few-shot / in-context learning works?

Message : How did you do this so quickly
Quoted Message : https://docs.google.com/spreadsheets/d/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4/edit?usp=sharing quick and dirty effort on this

Message : export chat+pandas

Message : +github copilot ofc

Message : Love how "Langchain it" is becoming a verb here
Quoted Message : Langchain it! Release code to Github. I'll add the features I'm working on as well.

Message : Am sorry if I'm missing something here. What's new in this? Isn't this what we have been doing in most LLM apps? Just feed the context. Model won't "learn" anything.
Quoted Message : \"Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples\" (from https://news.mit.edu/2023/large-language-models-in-context-learning-0207 ) \n\nSo this an emergent property and we don't know how it happened! wtf!\nAnyone knows how few-shot / in-context learning works?

Message : In context learning examples include input/output pairs, not just stuffing data into the prompt
Quoted Message : Am sorry if I'm missing something here. What's new in this? Isn't this what we have been doing in most LLM apps? Just feed the context. Model won't \"learn\" anything.

Message : There is an interesting Microsoft paper that checks the values at various layers of the transformer when giving examples in the prompt vs fine tuning the models with the same examples for 1 epoch. They find similar values in both and have a theory that prompting with examples causes implicit gradient descent which helps the model perform on the unseen example.
Quoted Message : \"Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples\" (from https://news.mit.edu/2023/large-language-models-in-context-learning-0207 ) \n\nSo this an emergent property and we don't know how it happened! wtf!\nAnyone knows how few-shot / in-context learning works?

Message : Question for the embeddings experts in this group: say I have a hybrid index on Pinecone. Then during my query, I *only* input dense (semantic) embeddings, what happens? Does this mean it will query only using the dense embeddings or am I likely to get bad results?

Message : With Pinecone, we don't know. We'll have to read their docs
Quoted Message : Question for the embeddings experts in this group: say I have a hybrid index on Pinecone. Then during my query, I *only* input dense (semantic) embeddings, what happens? Does this mean it will query only using the dense embeddings or am I likely to get bad results?

Message : okay cool, i will do some digging and report back here as Im sure its useful to others. FWIW I'm migrating from dense only -> sparse + dense and a lot of these little questions come up

Message : Same story here, would be interested in hearing more about your experience (will share mine once I have gone through it)

Message : Text to (relatively) high res video is here:
https://research.nvidia.com/labs/toronto-ai/VideoLDM
Code not released yet, but someone may be able to reverse engineer the method from the details in the paper one way or another.

Message : Hi, I am bit new with using GPU. I want to train/run few models. 
Which GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.
Also, is it worth to buy the hardware itself rather than renting on the cloud?

Message : You can try this if it works for you https://colab.research.google.com/drive/1YORPWx4okIHXnjW7MSAidXN29mPVNT7F?usp=sharing
Quoted Message : Hi, I am bit new with using GPU. I want to train/run few models. \nWhich GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.  \nAlso, is it worth to buy the hardware itself rather than renting on the cloud?

Message : You can get a free tesla T4 from google
Quoted Message : Hi, I am bit new with using GPU. I want to train/run few models. \nWhich GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.  \nAlso, is it worth to buy the hardware itself rather than renting on the cloud?

Message : You mean Google Colab? Actually I need to download lots of data and do it on a recurring basis, so colab notebook won't fit. I will try this anyway :(

Message : https://fullstackdeeplearning.com/cloud-gpus/ This comparison table might be useful.

Message : Thank you Sachin and The Last Samurai. I will go through these links!

Message : Industry's best kept secret: Kaggle Notebooks! You can have the data uploaded to Kaggle even. You often get better GPUs than Colab and lot more storage.
Quoted Message : You mean Google Colab? Actually I need to download lots of data and do it on a recurring basis, so colab notebook won't fit. I will try this anyway :(

Message : Wow! I think this will solve my problem! Thank you Nirant!!
Quoted Message : Industry's best kept secret: Kaggle Notebooks! You can have the data uploaded to Kaggle even. You often get better GPUs than Colab and lot more storage.

Message : also there are ways to use ngrok and vscode with these hosted notebooks so that you can code with scripts and still use these GPU resources for free. It's like you have your own GPU system. In colab it used to work, you can try it with kaggle notebook too
Quoted Message : Wow! I think this will solve my problem! Thank you Nirant!!

Message : https://www.freecodecamp.org/news/how-to-use-google-colab-with-vs-code/
You are talking about this? Let me try!
Quoted Message : also there are ways to use ngrok and vscode with these hosted notebooks so that you can code with scripts and still use these GPU resources for free. It's like you have your own GPU system. In colab it used to work, you can try it with kaggle notebook too

Message : Seems like they have banned it 
https://github.com/abhishekkrthakur/colabcode/issues/110

But this is a really great hack!!

Message : Cheapest for model fine tuning i found is rtx5000, runpod.io have reserved and on demand
Quoted Message : Hi, I am bit new with using GPU. I want to train/run few models. \nWhich GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.  \nAlso, is it worth to buy the hardware itself rather than renting on the cloud?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You can get a free tesla T4 from google
Quoted Message : Hi, I am bit new with using GPU. I want to train/run few models. \nWhich GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.  \nAlso, is it worth to buy the hardware itself rather than renting on the cloud?

Message : You mean Google Colab? Actually I need to download lots of data and do it on a recurring basis, so colab notebook won't fit. I will try this anyway :(

Message : https://fullstackdeeplearning.com/cloud-gpus/ This comparison table might be useful.

Message : Thank you Sachin and The Last Samurai. I will go through these links!

Message : Industry's best kept secret: Kaggle Notebooks! You can have the data uploaded to Kaggle even. You often get better GPUs than Colab and lot more storage.
Quoted Message : You mean Google Colab? Actually I need to download lots of data and do it on a recurring basis, so colab notebook won't fit. I will try this anyway :(

Message : Wow! I think this will solve my problem! Thank you Nirant!!
Quoted Message : Industry's best kept secret: Kaggle Notebooks! You can have the data uploaded to Kaggle even. You often get better GPUs than Colab and lot more storage.

Message : also there are ways to use ngrok and vscode with these hosted notebooks so that you can code with scripts and still use these GPU resources for free. It's like you have your own GPU system. In colab it used to work, you can try it with kaggle notebook too
Quoted Message : Wow! I think this will solve my problem! Thank you Nirant!!

Message : https://www.freecodecamp.org/news/how-to-use-google-colab-with-vs-code/
You are talking about this? Let me try!
Quoted Message : also there are ways to use ngrok and vscode with these hosted notebooks so that you can code with scripts and still use these GPU resources for free. It's like you have your own GPU system. In colab it used to work, you can try it with kaggle notebook too

Message : Seems like they have banned it 
https://github.com/abhishekkrthakur/colabcode/issues/110

But this is a really great hack!!

Message : Cheapest for model fine tuning i found is rtx5000, runpod.io have reserved and on demand
Quoted Message : Hi, I am bit new with using GPU. I want to train/run few models. \nWhich GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.  \nAlso, is it worth to buy the hardware itself rather than renting on the cloud?

Message : Thank you!!
Quoted Message : Cheapest for model fine tuning i found is rtx5000, runpod.io have reserved and on demand

Message : I am actually failing to understand the pricing of cloud gpus.
Rtx 5000 gpu cost 1.5L
While on cloud, even with the cheapest you will pay Rs 11k everymonth. So if I buy the GPU permanently and host it - I can get my returns just in 13 months. That‚Äôs a great business model.
Even if it is on-demand - assuming AI is here to stay (ofcourse), I should be able to get returns in 2 years.
What part am I missing here? Are there any cloud gpu providers in India?

Message : You need economies of scale, not considering maintenance and over head
Quoted Message : I am actually failing to understand the pricing of cloud gpus.\nRtx 5000 gpu cost 1.5L\nWhile on cloud, even with the cheapest you will pay Rs 11k everymonth. So if I buy the GPU permanently and host it - I can get my returns just in 13 months. That‚Äôs a great business model. \nEven if it is on-demand - assuming AI is here to stay (ofcourse), I should be able to get returns in 2 years. \nWhat part am I missing here? Are there any cloud gpu providers in India?

Message : Also interests rate on capital investment

Message : e2e networks give some GPUs. 

But most GPUs get outdated within 12-18 months due change in RAM expectations or new models. Also datacenter GPUs are wayyy faster than retail ones for high volume data transfer.
Quoted Message : I am actually failing to understand the pricing of cloud gpus.\nRtx 5000 gpu cost 1.5L\nWhile on cloud, even with the cheapest you will pay Rs 11k everymonth. So if I buy the GPU permanently and host it - I can get my returns just in 13 months. That‚Äôs a great business model. \nEven if it is on-demand - assuming AI is here to stay (ofcourse), I should be able to get returns in 2 years. \nWhat part am I missing here? Are there any cloud gpu providers in India?

Message : Also the current price point is similar across many providers, so we already have an optimum price discovery for this asset

Message : Got it guys! Thanks. This makes sense.

Message : I have one. 
Add 50k for cooling and 40-60k for a good cpu.
After that you need a constant power supply of at least 700w.
I had 1200w psu , got damaged due to voltage /power fluctuations in blr.
Quoted Message : I am actually failing to understand the pricing of cloud gpus.\nRtx 5000 gpu cost 1.5L\nWhile on cloud, even with the cheapest you will pay Rs 11k everymonth. So if I buy the GPU permanently and host it - I can get my returns just in 13 months. That‚Äôs a great business model. \nEven if it is on-demand - assuming AI is here to stay (ofcourse), I should be able to get returns in 2 years. \nWhat part am I missing here? Are there any cloud gpu providers in India?

Message : https://vast.ai/

Message : Any reviews on this cloud GPU rental
Quoted Message : https://vast.ai/

Message : 16Gb memory is not enough.
Quoted Message : I have one. \nAdd 50k for cooling and 40-60k for a good cpu.\nAfter that you need a constant power supply of at least 700w. \nI had 1200w psu , got damaged due to voltage /power fluctuations in blr.

Message : Last weekend I had  posted a question on how if I used Sentence Transformers  for word embeddings the container image size was huge. The reason it was using Torch GPU image. You can reduce the size drastically  if use the Torch CPU image. This is common sense , but for those who may be struggling like me this might be useful

Message : The Docker file will have this RUN pip3 install torch --index-url https://download.pytorch.org/whl/cpu for my Linux machine

Message : Hope this is useful

Message : Hi, How can you enable multiple checkpoints in automatic1111?

Message : While fine tuning the model using dreambooth?
Quoted Message : Hi, How can you enable multiple checkpoints in automatic1111?

Message : Yeah

Message : Awesome. If you have any public images/code, please share. Thanks
Quoted Message : Last weekend I had  posted a question on how if I used Sentence Transformers  for word embeddings the container image size was huge. The reason it was using Torch GPU image. You can reduce the size drastically  if use the Torch CPU image. This is common sense , but for those who may be struggling like me this might be useful

Message : Folks will we get the recording or decks of today's talks ?

Message : Decks yes. I'll email them to the email on the registration one. 

Recordings, Hasgeek will need some time to edit up
Quoted Message : Folks will we get the recording or decks of today's talks ?

Message : Hey guys, what‚Äôs the solution to privacy while using chatGPT? Most enterprises don‚Äôt want to risk sharing their sensitive information to chatGPT?

If not chatGPT, What‚Äôs the cost/ROI analysis on which model to use etc?

Message : We are getting into the realm of fine-tuned domain specific language models that can run on consumer grade GPUs and even CPUs.

Message : What are the usecases where privacy is of utmost importance+you can't go lower in size than chatGPT to achieve expected results?
Quoted Message : Hey guys, what‚Äôs the solution to privacy while using chatGPT? Most enterprises don‚Äôt want to risk sharing their sensitive information to chatGPT?\n\nIf not chatGPT, What‚Äôs the cost/ROI analysis on which model to use etc?

Message : Thanks for organising the event! @91773788xxxx and others (whose names I didn‚Äôt catch üòÖ)

Message : IIRC, GPT-4 launched with McKinsey as a client. Maybe they can use that to assuage any privacy concerns

Message : Then lightning rounds were good. Would like to hear more of what others have been building..
Quoted Message : Thanks for organising the event! @9177xxxxxxxx and others (whose names I didn‚Äôt catch üòÖ)

Message : FROM python:3.8-slim-buster
COPY . /app
WORKDIR /app
RUN pip3 install torch --index-url https://download.pytorch.org/whl/cpu
RUN pip install -r requirements.txt
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
Quoted Message : Awesome. If you have any public images/code, please share. Thanks

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ~‚ÄØAakash Kumar - aacash.eth

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ‚Ä™+44¬†7880¬†564836‚Ä¨ and ‚Ä™+91¬†96405¬†90294‚Ä¨

Message : was added to chat

Message : https://www.qblocks.cloud/ is run by a friend. You can try it out and if needed I can put you in touch with the founder. I‚Äôve used it frequently and it worked great for my use case
Quoted Message : Hi, I am bit new with using GPU. I want to train/run few models. \nWhich GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.  \nAlso, is it worth to buy the hardware itself rather than renting on the cloud?

Message : Will DM you!
Quoted Message : We are getting into the realm of fine-tuned domain specific language models that can run on consumer grade GPUs and even CPUs.

Message : Privacy is important as a principle for enterprises. What‚Äôs the best way to figure out which model will work for a particular use case? Any blog/advice on that?
Quoted Message : What are the usecases where privacy is of utmost importance+you can't go lower in size than chatGPT to achieve expected results?

Message : Have y‚Äôall seen this: 
https://www.essence-ai.io/

You input the song name, lyrics and singer names and it will tell you what the underlying meaning of the song lyrics are.

I tried it on Doobey, from that Gehraiyan movie and it gave a scary good answer. Obviously shits on other songs, but for my use case of 1, it was pretty amazing.

Message : Looks interesting. 

In case you follow such work, any chance you remember the little GitHub repo which created generative models for sample libraries?

I think it was trained using for techno drum loops. You could drop a sample library and run his script to randomly generate a new sample in the same style.

Audio to audio model.
Quoted Message : Have y‚Äôall seen this: \nhttps://www.essence-ai.io/\n\nYou input the song name, lyrics and singer names and it will tell you what the underlying meaning of the song lyrics are. \n\nI tried it on Doobey, from that Gehraiyan movie and it gave a scary good answer. Obviously shits on other songs, but for my use case of 1, it was pretty amazing.

Message : I can look around, but nothing comes top of mind.
Quoted Message : Looks interesting. \n\nIn case you follow such work, any chance you remember the little GitHub repo which created generative models for sample libraries?\n\nI think it was trained using for techno drum loops. You could drop a sample library and run his script to randomly generate a new sample in the same style.\n\nAudio to audio model.

Message : Thank you!! I will reach out :D
Quoted Message : https://www.qblocks.cloud/ is run by a friend. You can try it out and if needed I can put you in touch with the founder. I‚Äôve used it frequently and it worked great for my use case

Message : Thanks!
Quoted Message : I can look around, but nothing comes top of mind.

Message : Does anyone have access to Anthropics pitch deck? 
https://techcrunch.com/2023/04/06/anthropics-5b-4-year-plan-to-take-on-openai/

Message : OpenAI's John Schulman gave an interesting talk at Berkeley last week on why RLHF was needed to get the instruct models to behave nicely. 

Yoav Goldberg interprets the talk and makes a convincing argument about the signals in the RLHF training regime as opposed to pure supervision based fine-tuning.

https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://www.qblocks.cloud/ is run by a friend. You can try it out and if needed I can put you in touch with the founder. I‚Äôve used it frequently and it worked great for my use case
Quoted Message : Hi, I am bit new with using GPU. I want to train/run few models. \nWhich GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now.  \nAlso, is it worth to buy the hardware itself rather than renting on the cloud?

Message : Will DM you!
Quoted Message : We are getting into the realm of fine-tuned domain specific language models that can run on consumer grade GPUs and even CPUs.

Message : Privacy is important as a principle for enterprises. What‚Äôs the best way to figure out which model will work for a particular use case? Any blog/advice on that?
Quoted Message : What are the usecases where privacy is of utmost importance+you can't go lower in size than chatGPT to achieve expected results?

Message : Have y‚Äôall seen this: 
https://www.essence-ai.io/

You input the song name, lyrics and singer names and it will tell you what the underlying meaning of the song lyrics are.

I tried it on Doobey, from that Gehraiyan movie and it gave a scary good answer. Obviously shits on other songs, but for my use case of 1, it was pretty amazing.

Message : Looks interesting. 

In case you follow such work, any chance you remember the little GitHub repo which created generative models for sample libraries?

I think it was trained using for techno drum loops. You could drop a sample library and run his script to randomly generate a new sample in the same style.

Audio to audio model.
Quoted Message : Have y‚Äôall seen this: \nhttps://www.essence-ai.io/\n\nYou input the song name, lyrics and singer names and it will tell you what the underlying meaning of the song lyrics are. \n\nI tried it on Doobey, from that Gehraiyan movie and it gave a scary good answer. Obviously shits on other songs, but for my use case of 1, it was pretty amazing.

Message : I can look around, but nothing comes top of mind.
Quoted Message : Looks interesting. \n\nIn case you follow such work, any chance you remember the little GitHub repo which created generative models for sample libraries?\n\nI think it was trained using for techno drum loops. You could drop a sample library and run his script to randomly generate a new sample in the same style.\n\nAudio to audio model.

Message : Thank you!! I will reach out :D
Quoted Message : https://www.qblocks.cloud/ is run by a friend. You can try it out and if needed I can put you in touch with the founder. I‚Äôve used it frequently and it worked great for my use case

Message : Thanks!
Quoted Message : I can look around, but nothing comes top of mind.

Message : Does anyone have access to Anthropics pitch deck? 
https://techcrunch.com/2023/04/06/anthropics-5b-4-year-plan-to-take-on-openai/

Message : OpenAI's John Schulman gave an interesting talk at Berkeley last week on why RLHF was needed to get the instruct models to behave nicely. 

Yoav Goldberg interprets the talk and makes a convincing argument about the signals in the RLHF training regime as opposed to pure supervision based fine-tuning.

https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81

Message : First instance of an Indian politician referring to deepfakes / audio synthesis?

https://twitter.com/ptrmadurai/status/1649792158902173697?s=46&t=oCZGQA9ou-MHG2nmvsr-CA

Message : Hi all,
I've just joined this group. Can anyone please share the links to the slides for yesterday's talks??

Message : ‚Äé<attached: 00001151-PHOTO-2023-04-23-09-30-31.jpg>

Message : course.fast.ai for being able to make sense of all of this ‚Äî even as it changes in 2-3 months and we add VQA (Vision) to mainstream OpenAI APIs
Quoted Message :  2023_04_23_3EB0DEB19548D339AF7C33.jpeg

Message : Lot of new work should come from STT and TTS side, including performance improvements like Whisper-JAX in the coming 4-6 month and more important, voice cloning, avatars and the like. They should have their own "Lensa moment" as such if someone markets it well.

Message : Stable Diffusion/Generative video?

Message : Not for beginners I think... but I should say Stable Diffusion does get people hooked ... I got hooked like that üôÇ
Quoted Message : Stable Diffusion/Generative video?

Message : Depends if your friend would like to get more into theory or hands on applications
Quoted Message :  2023_04_23_3EB0DEB19548D339AF7C33.jpeg

Message : most devs want hands on first i think
Quoted Message : Depends if your friend would like to get more into theory or hands on applications

Message : This is good learning path, only it skips all the LLM theory
Quoted Message :  2023_04_23_3EB0DEB19548D339AF7C33.jpeg

Message : if i had to recommend a course to cover the NLP hands-on with theory - https://www.udemy.com/course/nlp-with-transformers/

if you like his teaching style, all the future videos on advance topics are available here for free -
https://www.youtube.com/@jamesbriggs/playlists
https://www.pinecone.io/learn/nlp/

Message : This used to be super helpful when heroku was free and we could deploy our applications on heroku. Last I remember, Torch CPU and other packages took less than 500mb to deploy

Message : Was talking about this
Quoted Message : Last weekend I had  posted a question on how if I used Sentence Transformers  for word embeddings the container image size was huge. The reason it was using Torch GPU image. You can reduce the size drastically  if use the Torch CPU image. This is common sense , but for those who may be struggling like me this might be useful

Message : You can still pretty affordable (about $2/mo) instances on Fly.io
Quoted Message : This used to be super helpful when heroku was free and we could deploy our applications on heroku. Last I remember, Torch CPU and other packages took less than 500mb to deploy

Message : If there's anyone interested, Mckay Wrigley is starting a course on Replit on AI dev. The advanced stuff is coming soon but here's the day 0 course. https://twitter.com/mckaywrigley/status/1649492404943323136

You can signup here - https://www.takeoff.school/

Message : Thanks
Quoted Message : You can still pretty affordable (about $2/mo) instances on Fly.io

Message : controlnet Inpaint guidelines for A1111. https://github.com/Mikubill/sd-webui-controlnet/issues/968 @91876402xxxx you can try out with this and let me know how it is working for you. 

Also @91961949xxxx, saw your twitch where you mentioned segment anything. You can integrate it with A1111 with https://github.com/continue-revolution/sd-webui-segment-anything.

Message : From the author of controlnet repo: 

Now the ControlNet Inpaint can directly use the A1111 inpaint path to support perfect seamless inpaint experience. It supports arbitary base model without merging and works perfectly with LoRAs and every other addons.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØShreyas Gupta

Message : Hi everyone! Shreyas here, I‚Äôm a product designer at Clari working on revGPT, a chat interface to get on top of everything happening with sales in an organisation ( and a few personal projects:) ). 

Also, yesterday‚Äôs meetup was amazing!

Message : I saw this tweet by the guy who made BabyAGI, with a new approach to vector search & embeddings: https://twitter.com/yoheinakajima/status/1650049673770725378?s=46&t=WT1iAtjftW-5_e62F8FZTg

Message : He then goes on to say that the ‚Äúpaper‚Äù, the code, and the twitter thread as well, were all created with ChatGPT

Message : Can the experts here explain if this is all fluff or has actual basis?

Message : https://yoheinakajima.com/asymmetrix-asymmetric-vector-embeddings-for-directional-similarity-search/
Quoted Message : He then goes on to say that the ‚Äúpaper‚Äù, the code, and the twitter thread as well, were all created with ChatGPT

Message : Not fluff. Nakajima has been tinkering with AGI for long
Quoted Message : Can the experts here explain if this is all fluff or has actual basis?

Message : Yep. I was referring to this new technique for vector search which he came up with, or chatgpt came up with
Quoted Message : Not fluff. Nakajima has been tinkering with AGI for long

Message : Lol. He literally said he has idea what it does.

https://twitter.com/yoheinakajima/status/1650054082852438017
Quoted Message : Not fluff. Nakajima has been tinkering with AGI for long

Message : Well I didn‚Äôt say he didn‚Äôt knew what he‚Äôs talking about or that what he‚Äôs speaking is fluff.
I was wondering if the method and the code outlined is actually something new and works as proposed

Message : Yep. Still assimilating. Atleast from a reco system lens can comment : in theory, this can potentially be a good approach

Message : what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing

Message : This WhatsApp group üôà
Quoted Message : what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing

Message : I hear OpenAI has some decent folks
Quoted Message : what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing

Message : should have a job board :)
Quoted Message : This WhatsApp group üôà

Message : This would be helpful - looking for an AD/Director of ML for my team too üôåüèº
Quoted Message : should have a job board :)

Message : How about a board that takes natural language input from job seekers and start-ups and matches them? Does something like this exist? Shouldn't be hard to build one.
Quoted Message : should have a job board :)

Message : Looking to hire folks as well - full time or part time! Job board would be ideal
Quoted Message : what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing

Message : I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?

Message : Oh it‚Äôs ridiculous. 

Woman (in English) is 1 token.
‡∞∏‡±ç‡∞§‡±ç‡∞∞‡±Ä (woman in Telugu) is 18 tokens.

Ramsri had a nice thread.
https://twitter.com/ramsri_goutham/status/1615217407378984960
Quoted Message : I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?

Message : I haven‚Äôt come across a lang2lang comparison. But openAi has a tokenizer you can use to estimate tokens and build a comparison set.

https://platform.openai.com/tokenizer
Quoted Message : Oh it‚Äôs ridiculous. \n\nWoman (in English) is 1 token.\n‡∞∏‡±ç‡∞§‡±ç‡∞∞‡±Ä (woman in Telugu) is 18 tokens. \n\nRamsri had a nice thread. \nhttps://twitter.com/ramsri_goutham/status/1615217407378984960

Message : For tokenization and word embeddings to reduce cost, you may like to use Sentence Transformers / [ something like that ] and pass the Embeddings to OpenAI for completion
Quoted Message : I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This WhatsApp group üôà
Quoted Message : what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing

Message : I hear OpenAI has some decent folks
Quoted Message : what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing

Message : should have a job board :)
Quoted Message : This WhatsApp group üôà

Message : This would be helpful - looking for an AD/Director of ML for my team too üôåüèº
Quoted Message : should have a job board :)

Message : How about a board that takes natural language input from job seekers and start-ups and matches them? Does something like this exist? Shouldn't be hard to build one.
Quoted Message : should have a job board :)

Message : Looking to hire folks as well - full time or part time! Job board would be ideal
Quoted Message : what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing

Message : I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?

Message : Oh it‚Äôs ridiculous. 

Woman (in English) is 1 token.
‡∞∏‡±ç‡∞§‡±ç‡∞∞‡±Ä (woman in Telugu) is 18 tokens.

Ramsri had a nice thread.
https://twitter.com/ramsri_goutham/status/1615217407378984960
Quoted Message : I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?

Message : I haven‚Äôt come across a lang2lang comparison. But openAi has a tokenizer you can use to estimate tokens and build a comparison set.

https://platform.openai.com/tokenizer
Quoted Message : Oh it‚Äôs ridiculous. \n\nWoman (in English) is 1 token.\n‡∞∏‡±ç‡∞§‡±ç‡∞∞‡±Ä (woman in Telugu) is 18 tokens. \n\nRamsri had a nice thread. \nhttps://twitter.com/ramsri_goutham/status/1615217407378984960

Message : For tokenization and word embeddings to reduce cost, you may like to use Sentence Transformers / [ something like that ] and pass the Embeddings to OpenAI for completion
Quoted Message : I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?

Message : They‚Äôre also building foundation models 
https://helloentrepreneurs.com/technology/iit-madras-will-soon-develop-an-alternative-to-chatgpt-17857/

Message : Hence, ^
Quoted Message : Oh it‚Äôs ridiculous. \n\nWoman (in English) is 1 token.\n‡∞∏‡±ç‡∞§‡±ç‡∞∞‡±Ä (woman in Telugu) is 18 tokens. \n\nRamsri had a nice thread. \nhttps://twitter.com/ramsri_goutham/status/1615217407378984960

Message : Don't know if this helps, thought of putting this

Message : @91731882xxxx has built a wrapper around openai tiktoken to count tokens in a file or text -
https://github.com/felvin-search/token-count - might be helpful for you.
Quoted Message : I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?

Message : I think we can put one google doc in the group description. Should be good enough to solve the purpose. :)
Quoted Message : should have a job board :)

Message : Or another group in the community for sole job seekers and employers!

Message : I was trying to generate an image of "a key ring with the OpenAI logo on it"

Couldn't get DallE, PlaygroundAI to generate even a half-decent image. Can anyone help/point out the right directions?

Message : u can use ControlNet canny model https://huggingface.co/spaces/hysts/ControlNet, just start with the openai logo, select the canny model and give the promptt

Message : ‚Äé<attached: 00001202-PHOTO-2023-04-23-22-42-27.jpg>
Quoted Message : I was trying to generate an image of \"a key ring with the OpenAI logo on it\"\n\nCouldn't get DallE, PlaygroundAI to generate even a half-decent image. Can anyone help/point out the right directions?

Message : If it had the keyring chain-thing, that'd be pretty cool, trying out the ControlNet model
Quoted Message :  2023_04_23_3A428575EE45DEAD9C8A.jpeg

Message : ‚Äé<attached: 00001204-PHOTO-2023-04-23-22-46-12.jpg>

Message : As someone who did hire from this group in some way and trying more. 

It is far more exciting for an engineer to read what you‚Äôre building and some glimpses of problems you are solving and then reaching out to you out of interest/curiosity than applying  on yet another job board.
Quoted Message : should have a job board :)

Message : ‚Äé<attached: 00001206-PHOTO-2023-04-23-22-48-18.jpg>

Message : pardon my bad drawing

Message : Thx, this is something very close! will finish the remaining using gooey
Quoted Message :  2023_04_23_3A30EF50CBDD1DA8AFB4.jpeg

Message : This was controlnet only btw, both canny and hed boundary worked well (you can change that in settings)
Quoted Message : u can use ControlNet canny model https://huggingface.co/spaces/hysts/ControlNet, just start with the openai logo, select the canny model and give the promptt

Message : Anyone working on open domain Q&A type problems or ones which make use of retreievers/dense embeddings?

Message : Yes I am. My product helps businesses set this up for internal function (esp. customer service and customer success).
Quoted Message : Anyone working on open domain Q&A type problems or ones which make use of retreievers/dense embeddings?

Message : Oh cool, can you share what kind of models and retrieval algorithms you are using?
Quoted Message : Yes I am. My product helps businesses set this up for internal function (esp. customer service and customer success).

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ~‚ÄØAmrit Kochar

Message : Yup we use OpenAI at the moment and dense embeddings only (OpenAI again)
Quoted Message : Oh cool, can you share what kind of models and retrieval algorithms you are using?

Message : Going to move to hybrid soon

Message : Oh cool, are you doing similarity search on a flat embedding space to retrieve context?
Quoted Message : Yup we use OpenAI at the moment and dense embeddings only (OpenAI again)

Message : At the moment, yes. Might change depending on what we focus on / feedback from customer s

Message : Came across this GitHub where someone used PEFT to fine tune a LLM based on their iMessage chats to impersonate so that you can create a bot which talks like you 
https://github.com/1rgs/MeGPT/blob/main/fine_tune.py



Reminded me of this discussion we had earlier
Quoted Message : Hi! I need one help.\nHow to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me? \nThere is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?

Message : Son of Anton üòú
Quoted Message : Came across this GitHub where someone used PEFT to fine tune a LLM based on their iMessage chats to impersonate so that you can create a bot which talks like you \nhttps://github.com/1rgs/MeGPT/blob/main/fine_tune.py\n\n\n\nReminded me of this discussion we had earlier

Message : ‚Äé<attached: 00001222-PHOTO-2023-04-24-09-26-26.jpg>

Message : cc @91846007xxxx who runs a similar community, @91991113xxxx who is in a Marketing role at Slice, and tech savvy generally
Quoted Message :  2023_04_24_3A431CA84E5ABA501B28.jpeg

Message : Hi rohan happy to connext
Quoted Message :  2023_04_24_3A431CA84E5ABA501B28.jpeg

Message : Any supabase user is there? 

Whenever I am making the query to the function via the python sdk - getting timeout read operation error.

I checked CPU usage too- thats around 4% and memory usage 63% ( I don't know why this is so much, I am hardly making any api call)

Message : You'll probably get a faster response here: https://github.com/orgs/supabase/discussions ?
Quoted Message : Any supabase user is there? \n\nWhenever I am making the query to the function via the python sdk - getting timeout read operation error. \n\nI checked CPU usage too- thats around 4% and memory usage 63% ( I don't know why this is so much, I am hardly making any api call)

Message : If it's an rpc call, can you explain analyze the sql?

Message : Or check your RLS policies

Message : RLS polies are public. 

Yeah, I thought some issue with RPC function but then I tried to creating index via the SQL editor but same issue.
Quoted Message : If it's an rpc call, can you explain analyze the sql?

Message : https://explain.dalibo.com/

Message : posted their too- but no response yet
Quoted Message : You'll probably get a faster response here: https://github.com/orgs/supabase/discussions ?

Message : Use this to visualize your query to understand where it's slow
Quoted Message : https://explain.dalibo.com/

Message : Add indexes for parts of the query where there's a mismatch between planned rows and returned rows

Message : Unoptimized reads on RLS policies won't show up here. So do check for that separately
Quoted Message : RLS polies are public. \n\nYeah, I thought some issue with RPC function but then I tried to creating index via the SQL editor but same issue.

Message : ahh okay..
Quoted Message : Unoptimized reads on RLS policies won't show up here. So do check for that separately


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You'll probably get a faster response here: https://github.com/orgs/supabase/discussions ?
Quoted Message : Any supabase user is there? \n\nWhenever I am making the query to the function via the python sdk - getting timeout read operation error. \n\nI checked CPU usage too- thats around 4% and memory usage 63% ( I don't know why this is so much, I am hardly making any api call)

Message : If it's an rpc call, can you explain analyze the sql?

Message : Or check your RLS policies

Message : RLS polies are public. 

Yeah, I thought some issue with RPC function but then I tried to creating index via the SQL editor but same issue.
Quoted Message : If it's an rpc call, can you explain analyze the sql?

Message : https://explain.dalibo.com/

Message : posted their too- but no response yet
Quoted Message : You'll probably get a faster response here: https://github.com/orgs/supabase/discussions ?

Message : Use this to visualize your query to understand where it's slow
Quoted Message : https://explain.dalibo.com/

Message : Add indexes for parts of the query where there's a mismatch between planned rows and returned rows

Message : Unoptimized reads on RLS policies won't show up here. So do check for that separately
Quoted Message : RLS polies are public. \n\nYeah, I thought some issue with RPC function but then I tried to creating index via the SQL editor but same issue.

Message : ahh okay..
Quoted Message : Unoptimized reads on RLS policies won't show up here. So do check for that separately

Message : Send the specific link on the Github or discord forum with more details

Message : Can help

Message : Folks @brkirch ... Automatic1111 guy is doing a new branch for Mac release of Automatic1111 - I tried it much faster than the stock Automatic1111 ... but it is still experimental

Message : https://github.com/brkirch/stable-diffusion-webui/releases

Message : https://github.com/orgs/supabase/discussions/13923
Quoted Message : Send the specific link on the Github or discord forum with more details

Message : cc @91740765xxxx @91961949xxxx @91961193xxxx @91966317xxxx Thought this might be interesting to you
Quoted Message : https://github.com/brkirch/stable-diffusion-webui/releases

Message : Woah this is great
Quoted Message : Folks @brkirch ... Automatic1111 guy is doing a new branch for Mac release of Automatic1111 - I tried it much faster than the stock Automatic1111 ... but it is still experimental

Message : hahah was just tagging you and @91997100xxxx
Quoted Message : Woah this is great

Message : It's failing because the query us timing out. Two options :

1. ALTER DATABASE postgres SET statement_timeout = '15m'

Please remember to remove it from the session once done

2. Add a new column. Set the index on that column, and then copy the data into it.
Quoted Message : https://github.com/orgs/supabase/discussions/13923

Message : Need to get a 64 gb mac like @91997100xxxx now
Quoted Message : hahah was just tagging you and @9199xxxxxxxx

Message : ‚Äé<attached: 00001251-GIF-2023-04-24-12-20-50.mp4>
Quoted Message : Need to get a 64 gb mac like @9199xxxxxxxx now

Message : ahh okay. let me try
Quoted Message : It's failing because the query us timing out. Two options :\n\n1. ALTER DATABASE postgres SET statement_timeout = '15m'\n\nPlease remember to remove it from the session once done\n\n2. Add a new column. Set the index on that column, and then copy the data into it.

Message : Are school kids in India using chatGPT ? 
Is there a way to check the demographic analysis of age group using ChatGPT ?

Message : If I remember correctly, but I might be wrong, OpenAI requires you to be 18 years old to use ChatGPT in particular. OpenAI doesn't release any demographic data around it. That aside, pretty sure students are using it. @91974101xxxx mentioned how his daughter's friends are using it.
Quoted Message : Are school kids in India using chatGPT ? \nIs there a way to check the demographic analysis of age group using ChatGPT ?

Message : https://e2eml.school/transformers.html

Message : Yeah the demographic data isn't available but the percentage of users in India is just going up month on month
Quoted Message : If I remember correctly, but I might be wrong, OpenAI requires you to be 18 years old to use ChatGPT in particular. OpenAI doesn't release any demographic data around it. That aside, pretty sure students are using it. @9197xxxxxxxx mentioned how his daughter's friends are using it.

Message : Same here. Hear anecdotal evidence of kids going majorly into it. My 12 yo son using it to rephrase stuff from Wikipedia for school essays ü§£üòÖ
Quoted Message : If I remember correctly, but I might be wrong, OpenAI requires you to be 18 years old to use ChatGPT in particular. OpenAI doesn't release any demographic data around it. That aside, pretty sure students are using it. @9197xxxxxxxx mentioned how his daughter's friends are using it.

Message : What is memory usage before hitting a query? Also what is data size?
Conversations from raw data to objects might be taking time. Faced with a similar issue while using ORM. https://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly
Quoted Message : Any supabase user is there? \n\nWhenever I am making the query to the function via the python sdk - getting timeout read operation error. \n\nI checked CPU usage too- thats around 4% and memory usage 63% ( I don't know why this is so much, I am hardly making any api call)

Message : on the second step , while copying the data from one column to another

still getting the error -

"An error has occurred: Failed to fetch"
Quoted Message : It's failing because the query us timing out. Two options :\n\n1. ALTER DATABASE postgres SET statement_timeout = '15m'\n\nPlease remember to remove it from the session once done\n\n2. Add a new column. Set the index on that column, and then copy the data into it.

Message : Memory Usage is around 63% before and after... 

CPU Usage increase to 21%

Data size (if you mean data records ) that is around 500K
Quoted Message : What is memory usage before hitting a query? Also what is data size?\nConversations from raw data to objects might be taking time. Faced with a similar issue while using ORM. https://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly

Message : However you guard. Kids are smart and they know how to navigate around restrictions. üòÖ
Quoted Message : If I remember correctly, but I might be wrong, OpenAI requires you to be 18 years old to use ChatGPT in particular. OpenAI doesn't release any demographic data around it. That aside, pretty sure students are using it. @9197xxxxxxxx mentioned how his daughter's friends are using it.

Message : Friends, how long do I've to wait before I can say "off-topic" for Supabase/Postgres performance queries? Asking for a friend üòÖ

Message : Nice! 

@91773788xxxx if we could have a transformers deep dive like this for a workshop it would be great. High quality Sesh like Amod‚Äôd
Quoted Message : https://e2eml.school/transformers.html

Message : okay. sorry.. I didn't knew that..
Quoted Message : Friends, how long do I've to wait before I can say \"off-topic\" for Supabase/Postgres performance queries? Asking for a friend üòÖ

Message : No sweat, just want to be cognisant that we've 600+ folks here and they're here mainly for keeping up with GenerativeAI. Supabase is quite likely not relevant for them :)
Quoted Message : okay. sorry.. I didn't knew that..

Message : make sense
Quoted Message : No sweat, just want to be cognisant that we've 600+ folks here and they're here mainly for keeping up with GenerativeAI. Supabase is quite likely not relevant for them :)

Message : Would ‚ù§Ô∏è to have more Amod-esque speakers. The rarity is a challenge for any meetup curator. Have suggestions? 

@91740765xxxx can reach out
Quoted Message : Nice! \n\n@9177xxxxxxxx if we could have a transformers deep dive like this for a workshop it would be great. High quality Sesh like Amod‚Äôd

Message : https://www.reddit.com/r/selfhosted/comments/12w4p2f/localai_openai_compatible_api_to_run_llm_models/

LocalAI supports multiple models backends (such as Alpaca, Cerebras, GPT4ALL-J and StableLM) and works seamlessly with OpenAI API

Unsure of performance but this is pretty cool

Message : Yourself? :)
Quoted Message : Would ‚ù§Ô∏è to have more Amod-esque speakers. The rarity is a challenge for any meetup curator. Have suggestions? \n\n@9174xxxxxxxx can reach out

Message : @91942037xxxx

Message : The intent is to have mid-speakers (we're all mid compared to Amod) as backup incase we've speaker cancellations. 

And use this forum to give chance to someone perhaps lesser known but equally good
Quoted Message : Yourself? :)

Message : Would people in the group be interested in sessions from AI21 Labs, Cohere and Anthorpic ?

Message : Cohere (Nils Reimers) for sure ‚Äî I've a half a page of questions also!
Quoted Message : Would people in the group be interested in sessions from AI21 Labs, Cohere and Anthorpic ?

Message : Is there any event/session link to register for the same?
Quoted Message : Cohere (Nils Reimers) for sure ‚Äî I've a half a page of questions also!

Message : I will try to get it setup. Will share with the community
Quoted Message : Is there any event/session link to register for the same?

Message : Yes please would love transformers or diffusion models in the May one. Any takers here?
Quoted Message : Would ‚ù§Ô∏è to have more Amod-esque speakers. The rarity is a challenge for any meetup curator. Have suggestions? \n\n@9174xxxxxxxx can reach out

Message : For May, would prefer tasks like VQA, Stable/Latent Diffusion, image captioning. @91740765xxxx and I'll help you deliver a kickass talk. We've both spoken at different technical venues, ranging from Hasgeek events to Pycon.
Quoted Message : Yes please would love transformers or diffusion models in the May one. Any takers here?

Message : https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting

A not-so-technical guide to proper prompt engineering

Message : Addendum: The April theme was Question Answering (hence a QA demo + QA internals) aka "How to make your own ChatGPT for internal docs" 

And Deep Dive on Quantization

Message : The May theme is yet to be decided but we're looking for work around image generation, video and sound. The curator will be Soumyadeep @91740765xxxx (https://www.linkedin.com/in/soumyadeepmukherjee/?originalSubdomain=in) ‚Äî previously Infra at Udaan and now runs a Generative AI company in Bengaluru.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : The intent is to have mid-speakers (we're all mid compared to Amod) as backup incase we've speaker cancellations. 

And use this forum to give chance to someone perhaps lesser known but equally good
Quoted Message : Yourself? :)

Message : Would people in the group be interested in sessions from AI21 Labs, Cohere and Anthorpic ?

Message : Cohere (Nils Reimers) for sure ‚Äî I've a half a page of questions also!
Quoted Message : Would people in the group be interested in sessions from AI21 Labs, Cohere and Anthorpic ?

Message : Is there any event/session link to register for the same?
Quoted Message : Cohere (Nils Reimers) for sure ‚Äî I've a half a page of questions also!

Message : I will try to get it setup. Will share with the community
Quoted Message : Is there any event/session link to register for the same?

Message : Yes please would love transformers or diffusion models in the May one. Any takers here?
Quoted Message : Would ‚ù§Ô∏è to have more Amod-esque speakers. The rarity is a challenge for any meetup curator. Have suggestions? \n\n@9174xxxxxxxx can reach out

Message : For May, would prefer tasks like VQA, Stable/Latent Diffusion, image captioning. @91740765xxxx and I'll help you deliver a kickass talk. We've both spoken at different technical venues, ranging from Hasgeek events to Pycon.
Quoted Message : Yes please would love transformers or diffusion models in the May one. Any takers here?

Message : https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting

A not-so-technical guide to proper prompt engineering

Message : Addendum: The April theme was Question Answering (hence a QA demo + QA internals) aka "How to make your own ChatGPT for internal docs" 

And Deep Dive on Quantization

Message : The May theme is yet to be decided but we're looking for work around image generation, video and sound. The curator will be Soumyadeep @91740765xxxx (https://www.linkedin.com/in/soumyadeepmukherjee/?originalSubdomain=in) ‚Äî previously Infra at Udaan and now runs a Generative AI company in Bengaluru.

Message : üíØ 
Small suggestion,if some these talks can also be accompanied by a walkthrough workshop on basics of each use case


It could look like this

Basics of VQA-Creating your own chat your docs

Basics of using Stable Diffusion-Generate your own images/Cartoonify yourself use case
Quoted Message : For May, would prefer tasks like VQA, Stable/Latent Diffusion, image captioning. @9174xxxxxxxx and I'll help you deliver a kickass talk. We've both spoken at different technical venues, ranging from Hasgeek events to Pycon.

Message : @91961193xxxx taught a Stable Diffusion workshop in Feb, and there wasn't enough interest at that time. We'll consider this going foward.
Quoted Message : üíØ \nSmall suggestion,if some these talks can also be accompanied by a walkthrough workshop on basics of each use case \n\n\nIt could look like this \n\nBasics of VQA-Creating your own chat your docs \n\nBasics of using Stable Diffusion-Generate your own images/Cartoonify yourself use case

Message : Happy to do a session covering dreambooth, Lora, controlnet, creating realistic images, civitai and customisation and more. 

Can gauge interest for this from the group first
Quoted Message : For May, would prefer tasks like VQA, Stable/Latent Diffusion, image captioning. @9174xxxxxxxx and I'll help you deliver a kickass talk. We've both spoken at different technical venues, ranging from Hasgeek events to Pycon.

Message : Idk about others, but I believe that workshops should be paid. If someone's creating course material + examples for me to follow, they should be compensated for their time. 

Maybe we can send bookings with payment links in the future to gauge interest, and set up workshops after we confirm participation.

What say @91994047xxxx , @91773788xxxx ?
Quoted Message : Happy to do a session covering dreambooth, Lora, controlnet, creating realistic images, civitai and customisation and more. \n\nCan gauge interest for this from the group first

Message : Yeah, by default, workshops will be paid. Upto the educator to price them. Can set this up early May and ask here :)
Quoted Message : Idk about others, but I believe that workshops should be paid. If someone's creating course material + examples for me to follow, they should be compensated for their time. \n\nMaybe we can send bookings with payment links in the future to gauge interest, and set up workshops after we confirm participation. \n\nWhat say @9199xxxxxxxx , @9177xxxxxxxx ?

Message : So the way me and Nirant have been thinking to structure like 1 product/usage/use-case talk, 1 deep dive into some engg optimisations/libraries/use-cases and 1 deep dive into fundamentals.

Would like it more if you can do something like just controlnet from basics to demo rather than a little of many things.

Hope it makes sense?
Quoted Message : Happy to do a session covering dreambooth, Lora, controlnet, creating realistic images, civitai and customisation and more. \n\nCan gauge interest for this from the group first

Message : PSA - we had a stable diffusion workshop in March has.gy/1CNF

If folks here are interested, they can register their interest here - https://hasgeek.com/generativeAI/stable-diffusion-workshop2/

With enough interest going, will have organizers setup next one

Message : Hey @91994047xxxx can you explain a bit on "creating realistic images" specifically what would be the topics on this. Is it prompt oriented or model oriented or something else?
Quoted Message : Happy to do a session covering dreambooth, Lora, controlnet, creating realistic images, civitai and customisation and more. \n\nCan gauge interest for this from the group first

Message : Sure works - was thinking this would be similar to Amod‚Äôs talk but can do a paid workshop too
Quoted Message : Idk about others, but I believe that workshops should be paid. If someone's creating course material + examples for me to follow, they should be compensated for their time. \n\nMaybe we can send bookings with payment links in the future to gauge interest, and set up workshops after we confirm participation. \n\nWhat say @9199xxxxxxxx , @9177xxxxxxxx ?

Message : Makes sense
Quoted Message : So the way me and Nirant have been thinking to structure like 1 product/usage/use-case talk, 1 deep dive into some engg optimisations/libraries/use-cases and 1 deep dive into fundamentals.\n\nWould like it more if you can do something like just controlnet from basics to demo rather than a little of many things.\n\nHope it makes sense?

Message : Both - but mostly model oriented and more complex dreambooth methods
Quoted Message : Hey @9199xxxxxxxx can you explain a bit on \"creating realistic images\" specifically what would be the topics on this. Is it prompt oriented or model oriented or something else?

Message : Or rather less known

Message : Sounds good
Quoted Message : The May theme is yet to be decided but we're looking for work around image generation, video and sound. The curator will be Soumyadeep @9174xxxxxxxx (https://www.linkedin.com/in/soumyadeepmukherjee/?originalSubdomain=in) ‚Äî previously Infra at Udaan and now runs a Generative AI company in Bengaluru.

Message : Excellent criticism of _safetyism_ and discusses the loudest detractors and their main arguments (excellent if you want to catch up!) 

Direct quote from author elsewhere:
If we‚Äôd decided that Transistor Safety was a key issue in the 1960s, we‚Äôd probably still think of transistors as a tool mostly used for steering rockets and for lightweight combat radios‚Äîjust like fears of nuclear war had a bigger impact on nuclear power than on the nuclear weapons themselves.

https://www.piratewires.com/p/against-safetyism

Message : https://warpspeed2023.devfolio.co/

Message : Piratewires is always great, one of my favourite substacks
Quoted Message : Excellent criticism of _safetyism_ and discusses the loudest detractors and their main arguments (excellent if you want to catch up!) \n\nDirect quote from author elsewhere: \nIf we‚Äôd decided that Transistor Safety was a key issue in the 1960s, we‚Äôd probably still think of transistors as a tool mostly used for steering rockets and for lightweight combat radios‚Äîjust like fears of nuclear war had a bigger impact on nuclear power than on the nuclear weapons themselves.\n\nhttps://www.piratewires.com/p/against-safetyism

Message : This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.

Message : @91800314xxxx ? ü§î
Quoted Message : This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.

Message : I work in these areas, happy to chat!
Quoted Message : This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.

Message : Did some work few months back with mediapipe along with integration in blender. Though not updated with recent developments
Quoted Message : This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.

Message : I've worked on a few projects where we did live performance capture, yes. Happy to chat about it!
Quoted Message : This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.

Message : https://twitter.com/Uncanny_Harry/status/1650462479237931008?s=2

Holy smokes! This gen2 video is stunning

Message : ‚Äé<attached: 00001322-PHOTO-2023-04-24-19-21-36.jpg>

Message : Text is easier to read on a phone than a text inside an image :) Type the text ;)
Quoted Message :  2023_04_24_3A367CBE823CC95A5EBB.jpeg

Message : If it's a marketing plug, please refrain.
Quoted Message : Text is easier to read on a phone than a text inside an image :) Type the text ;)

Message : It is not. But happy to remove it if you think so. Sorry, I happen to be a marketer üôèüèΩ
Quoted Message : If it's a marketing plug, please refrain.

Message : Anyone here has experience working with Interoperable Master Format? Would love to connect.

Message : Has anyone noticed differences between using newlines/replacing them when using openai's embedding api?

Message : While you're at it, @91989227xxxx and I'd love to know why Langchain does a newline replacement too üòÖ
https://github.com/hwchase17/langchain/blame/d2520a5f1e78f8e7a2f5c888feda62bafd3ab963/langchain/embeddings/huggingface.py#L65
Quoted Message : Has anyone noticed differences between using newlines/replacing them when using openai's embedding api?

Message : \n is probably not a token in the vocabulary
Quoted Message : Has anyone noticed differences between using newlines/replacing them when using openai's embedding api?

Message : ‚Äé<attached: 00001332-PHOTO-2023-04-24-21-39-10.jpg>
Quoted Message : \n is probably not a token in the vocabulary

Message : Creating a token from an unknown world and having it in the vocabulary is different. The model‚Äôs vocabulary are words that it understands to encode into something meaningful in the encoder.
Quoted Message :  2023_04_24_3EB05F2B31B16BEC47AB35.jpeg

Message : Can you elaborate or rephrase a bit? I didn't understand
Quoted Message : Creating a token from an unknown world and having it in the vocabulary is different. The model‚Äôs vocabulary are words that it understands to encode into something meaningful in the encoder.

Message : https://www.livemint.com/companies/start-ups/indian-engineering-colleges-lead-generative-ai-research-projects-in-indic-languages-facing-challenges-in-data-sourcing-and-computing-power-11681663553393.html

Message : Let‚Äôs take a NLP model from huggingface which follows the transformer library specification. It will have a vocab file in it, you will see the vocabulary of the model, words  it was trained to encode. New line, tabs are not part of vocabulary.
Quoted Message : Can you elaborate or rephrase a bit? I didn't understand

Message : So while a newline could be a token it doesn‚Äôt have any semantic meaning when it‚Äôs encoded.

Message : Aaah, that'd make sense. Thanks for explaining!

Message : So to rephrase the original question ‚Äî  if we have the original vocab file for GPT3.5 and that has a newline, adding/removing it makes a semantic difference and vice versa?

Message : If the vocabulary has new lines, you could keep them. But for all practical purposes I haven‚Äôt seen models contain any space, tab or new lines in models
Quoted Message : So to rephrase the original question ‚Äî  if we have the original vocab file for GPT3.5 and that has a newline, adding/removing it makes a semantic difference and vice versa?

Message : You will use up tokens and not get any advantage in terms of results


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00001332-PHOTO-2023-04-24-21-39-10.jpg>
Quoted Message : \n is probably not a token in the vocabulary

Message : Creating a token from an unknown world and having it in the vocabulary is different. The model‚Äôs vocabulary are words that it understands to encode into something meaningful in the encoder.
Quoted Message :  2023_04_24_3EB05F2B31B16BEC47AB35.jpeg

Message : Can you elaborate or rephrase a bit? I didn't understand
Quoted Message : Creating a token from an unknown world and having it in the vocabulary is different. The model‚Äôs vocabulary are words that it understands to encode into something meaningful in the encoder.

Message : https://www.livemint.com/companies/start-ups/indian-engineering-colleges-lead-generative-ai-research-projects-in-indic-languages-facing-challenges-in-data-sourcing-and-computing-power-11681663553393.html

Message : Let‚Äôs take a NLP model from huggingface which follows the transformer library specification. It will have a vocab file in it, you will see the vocabulary of the model, words  it was trained to encode. New line, tabs are not part of vocabulary.
Quoted Message : Can you elaborate or rephrase a bit? I didn't understand

Message : So while a newline could be a token it doesn‚Äôt have any semantic meaning when it‚Äôs encoded.

Message : Aaah, that'd make sense. Thanks for explaining!

Message : So to rephrase the original question ‚Äî  if we have the original vocab file for GPT3.5 and that has a newline, adding/removing it makes a semantic difference and vice versa?

Message : If the vocabulary has new lines, you could keep them. But for all practical purposes I haven‚Äôt seen models contain any space, tab or new lines in models
Quoted Message : So to rephrase the original question ‚Äî  if we have the original vocab file for GPT3.5 and that has a newline, adding/removing it makes a semantic difference and vice versa?

Message : You will use up tokens and not get any advantage in terms of results

Message : Sometimes, new line matters for text splitting/ chunking. (Such as splitting by para). Then the /n has meaning, correct?
Quoted Message : Let‚Äôs take a NLP model from huggingface which follows the transformer library specification. It will have a vocab file in it, you will see the vocabulary of the model, words  it was trained to encode. New line, tabs are not part of vocabulary.

Message : I'm referring to text splitting pre-embedding
Quoted Message : Sometimes, new line matters for text splitting/ chunking. (Such as splitting by para). Then the /n has meaning, correct?

Message : Those are character splitters. Yeah they look into these control characters.
Quoted Message : Sometimes, new line matters for text splitting/ chunking. (Such as splitting by para). Then the /n has meaning, correct?

Message : The assumption from the model author is that you would split texts the way you see fit and then remove unknown vocabulary, tokenize and then feed the texts into the model.

Message : *text splitters
Quoted Message : Those are character splitters. Yeah they look into these control characters.

Message : ‚Äé<attached: 00001347-PHOTO-2023-04-24-22-01-04.jpg>

Message : ‚Äé<attached: 00001348-PHOTO-2023-04-24-22-01-05.jpg>

Message : My approach for choosing splitting and sanitizing texts would be to run some experiments and see what preserves or improved the performance of the model with the least number of tokens.

Message : Context length obviously plays a role also. Can‚Äôt go longer than ctx supported.

Message : might be the reason for the extra tokens too? As the new line + word is not recognised as a common enough token
Quoted Message : Let‚Äôs take a NLP model from huggingface which follows the transformer library specification. It will have a vocab file in it, you will see the vocabulary of the model, words  it was trained to encode. New line, tabs are not part of vocabulary.

Message : You could look into the source code of the tiktoken library on GitHub to see how they are doing it. It‚Äôs purely heuristics.
Quoted Message : might be the reason for the extra tokens too? As the new line + word is not recognised as a common enough token

Message : The tokenizer is called C100k or something

Message : gpt-4 uses a different tokenizer but they haven't updated the url you linked with that.

https://news.ycombinator.com/item?id=35453400
Quoted Message :  2023_04_24_3EB05F2B31B16BEC47AB35.jpeg

Message : yes
Quoted Message : The tokenizer is called C100k or something

Message : ‚Äé<attached: 00001356-PHOTO-2023-04-24-22-09-04.jpg>
Quoted Message : gpt-4 uses a different tokenizer but they haven't updated the url you linked with that.\n\nhttps://news.ycombinator.com/item?id=35453400

Message : Nice, love pirate wires - good source of truth with lesswrong and scott alexander
Quoted Message : Excellent criticism of _safetyism_ and discusses the loudest detractors and their main arguments (excellent if you want to catch up!) \n\nDirect quote from author elsewhere: \nIf we‚Äôd decided that Transistor Safety was a key issue in the 1960s, we‚Äôd probably still think of transistors as a tool mostly used for steering rockets and for lightweight combat radios‚Äîjust like fears of nuclear war had a bigger impact on nuclear power than on the nuclear weapons themselves.\n\nhttps://www.piratewires.com/p/against-safetyism

Message : Can help - explored and published on these topics
Quoted Message : This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.

Message : https://twitter.com/aribk24/status/1650372832524926977?s=20

Grimes responsed

Our hackathon project

We should launch and deploy lol @91981970xxxx

Message : responded*

Message : Worked in pose estimation (egomotion/SLAM etc) and deployed in few places. Dabbled in human pose at some point but not up to date with lit. You can DM. Not much in mocap/face-body reconstruction.
Quoted Message : This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.

Message : How did you do this?
Quoted Message : https://twitter.com/aribk24/status/1650372832524926977?s=20\n\nGrimes responsed \n\nOur hackathon project \n\nWe should launch and deploy lol @9198xxxxxxxx

Message : We did something very similar for the hackathon - there are some good voice models out there

Arib launched it and grimes responded
Quoted Message : How did you do this?

Message : Holy shit! Let‚Äôs go Arib. Arib hooked me up with a free ticket to a Sam Altman session. What a great dude
Quoted Message : https://twitter.com/aribk24/status/1650372832524926977?s=20\n\nGrimes responsed \n\nOur hackathon project \n\nWe should launch and deploy lol @9198xxxxxxxx

Message : This thing is going to take over the world.
Quoted Message : https://twitter.com/aribk24/status/1650372832524926977?s=20\n\nGrimes responsed \n\nOur hackathon project \n\nWe should launch and deploy lol @9198xxxxxxxx

Message : Sounds legit ! Can you repost your hackathon link? 

Is it using so-vits-svc or a different library?
Quoted Message : https://twitter.com/aribk24/status/1650372832524926977?s=20\n\nGrimes responsed \n\nOur hackathon project \n\nWe should launch and deploy lol @9198xxxxxxxx

Message : what are some cool chatgpt related chrome extensions y'all have come across?

Message : V. interesting read on potential to use RL without human feedback: https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81

Message : Not entirely sure if this belongs here, but which are most interesting OSS projects in the space? I finally have some free time and would love to contribute more.

Message : ShareGPT!
Quoted Message : what are some cool chatgpt related chrome extensions y'all have come across?

Message : One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI üòù and not be bothered to text-back during the week. And just be presented with a date on the weekend.
Quoted Message : what are some cool chatgpt related chrome extensions y'all have come across?

Message : For that I had to make a chrome extension that can read all my chats

Message : she: you're so fun, so when do we go out?
Ojasvi: as an AI language model, I can't go out as I've been ...
Quoted Message : One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI üòù and not be bothered to text-back during the week. And just be presented with a date on the weekend.

Message : ü§£ü§£ü§£ü§£ü§£

Message : No it's trained exclusively to type like me with a super low temperature

Message : I don't want to come across as someone I'm not

Message : Just wanted my own two extra hands, not an AI "dating expert"

Message : time to recreate: hang the DJ

Message : beware of prompt injection attacks üòÇ
Quoted Message : No it's trained exclusively to type like me with a super low temperature

Message : Next feature is a vector search on all the girls I've swiped right in the past and autoswiping on girls that cross a certain similarity threshold. Will apply to their images and also their textual information like bios.

Message : It's still in POC stage üòù


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : For that I had to make a chrome extension that can read all my chats

Message : she: you're so fun, so when do we go out?
Ojasvi: as an AI language model, I can't go out as I've been ...
Quoted Message : One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI üòù and not be bothered to text-back during the week. And just be presented with a date on the weekend.

Message : ü§£ü§£ü§£ü§£ü§£

Message : No it's trained exclusively to type like me with a super low temperature

Message : I don't want to come across as someone I'm not

Message : Just wanted my own two extra hands, not an AI "dating expert"

Message : time to recreate: hang the DJ

Message : beware of prompt injection attacks üòÇ
Quoted Message : No it's trained exclusively to type like me with a super low temperature

Message : Next feature is a vector search on all the girls I've swiped right in the past and autoswiping on girls that cross a certain similarity threshold. Will apply to their images and also their textual information like bios.

Message : It's still in POC stage üòù

Message : can those occur in my context?
Quoted Message : beware of prompt injection attacks üòÇ

Message : Damn exactly what I was looking for
Quoted Message : ShareGPT!

Message : idk honestly. yours is also low temp. so maybe more difficult than usual? my understanding is that most prompt injection out there is tested on the default temperature 0.7
Quoted Message : can those occur in my context?

Message : If anyone wants/needs help on prompt injection, please send me your model. I enjoy interacting with LLMs to trick them into breaking things.
Quoted Message : beware of prompt injection attacks üòÇ

Message : Will do once I'm out of POC stage
Quoted Message : If anyone wants/needs help on prompt injection, please send me your model. I enjoy interacting with LLMs to trick them into breaking things.

Message : Yeah plus the training dataset is made from my chats
Not sure if I've been sent a prompt injection by anyone so far
Quoted Message : idk honestly. yours is also low temp. so maybe more difficult than usual? my understanding is that most prompt injection out there is tested on the default temperature 0.7

Message : **creates fake profile to send ojasvi a prompt injection attack**
Quoted Message : Yeah plus the training dataset is made from my chats\nNot sure if I've been sent a prompt injection by anyone so far

Message : Feels like a dialogue straight outta ‚ÄòIndian Matchmaking‚Äô

How about you also get a summary of the conversation before you go on that date?
Quoted Message : One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI üòù and not be bothered to text-back during the week. And just be presented with a date on the weekend.

Message : https://openai.com/brand
I don't understand how OpenAI can claim the word GPT - is it not a generic term?

Message : +1 on this 
I was thinking if it‚Äôs a case where adding word GPT is misleading users that it‚Äôs an OpenAI model/something sold by OpenAI as a service

Rather than something built on top of OpenAI
Quoted Message : https://openai.com/brand\nI don't understand how OpenAI can claim the word GPT - is it not a generic term?

Message : Transformers is the generic term, GPT was their branding from the beginning
Quoted Message : https://openai.com/brand\nI don't understand how OpenAI can claim the word GPT - is it not a generic term?

Message : This is for Branding if you want to mention OpenAI. Just don‚Äôt mentioned them and you can name anything.

Message : ‚Äé<attached: 00001400-PHOTO-2023-04-25-09-38-55.jpg>

Message : ah so do they have a trademark on GPT?
Quoted Message : Transformers is the generic term, GPT was their branding from the beginning

Message : https://techcrunch.com/2023/04/24/gpt-may-be-trademarked-soon-if-openai-has-its-way/
Quoted Message : ah so do they have a trademark on GPT?

Message : The fact that ChatGPT, as being associated with OpenAI is widely known - they‚Äôre only trying to prevent any use of [insertword]GPT that may suggest an association/affiliation/partnership with OpenAI when there may be none. 
Their guidelines are just a polite way of saying - we may bring a TM infringement suit against you (whether or not they succeed is a different question altogether).
Note: that you don‚Äôt necessarily need to have a registered TM to bring a suit if it is otherwise widely known.
Quoted Message : https://techcrunch.com/2023/04/24/gpt-may-be-trademarked-soon-if-openai-has-its-way/

Message : Any of you use qdrant for vector search? It looks really cool and easy to use as well.

Message : The difference between pinecone, Milvus and Qdrant is so small!

Message : Redis and Qdrant. Have tried Chroma too. 

Disclosure: I'm a ML Consultant and Qdrant is a client
Quoted Message : Any of you use qdrant for vector search? It looks really cool and easy to use as well.

Message : Developer Experience?
Quoted Message : The difference between pinecone, Milvus and Qdrant is so small!

Message : off-topic - anyone wants to complete a Bounty for Yohei Nakajima? https://replit.com/bounties/@YoheiNakajima/scrape-an-api-and-se

Message : Too little money for trivial work?
Quoted Message : off-topic - anyone wants to complete a Bounty for Yohei Nakajima? https://replit.com/bounties/@YoheiNakajima/scrape-an-api-and-se

Message : Has anybody tried training any of the openai models on code?

What I am trying to do: Razorpay has open sourced their design system (just like Bootstrap). I want to be able to describe to the model one or more components that I want to create in natural language and the model spits out these components as described using the  design system.

https://github.com/razorpay/blade

Message : Embeddings plus GPT-3.5 should be able to do it
Quoted Message : Has anybody tried training any of the openai models on code?\n\nWhat I am trying to do: Razorpay has open sourced their design system (just like Bootstrap). I want to be able to describe to the model one or more components that I want to create in natural language and the model spits out these components as described using the  design system.\n\nhttps://github.com/razorpay/blade

Message : While I read through the fine tuning section of openai docs, just wondering if there are any do/donts/tips that I should keep in mind

Message : Not perfectly though
Quoted Message : Embeddings plus GPT-3.5 should be able to do it

Message : Is fine tuning necessary?
Quoted Message : Has anybody tried training any of the openai models on code?\n\nWhat I am trying to do: Razorpay has open sourced their design system (just like Bootstrap). I want to be able to describe to the model one or more components that I want to create in natural language and the model spits out these components as described using the  design system.\n\nhttps://github.com/razorpay/blade

Message : I did kind of a similar approach to create diagrams using MermaidJS. Created embeddings from the docs and added gpt-3.5. Worked well for the most part

Message : Most of these components have several parameters that they accept that define the behaviour of the UI component.

I feel that fine tuning will help with getting better results overall.

I tried generating Bootstrap components since it is widely used and available. It does a decent job overall of creating components. However, takes a lot of prompting to get certain attributes to be set based on the behaviour described
Quoted Message : Is fine tuning necessary?

Message : Plan of action that I have in mind:
1. Version 1 > Feed it the documents and code and see if the results are similar to what I get for generating Bootstrap components.
2. Version 2 > Check if any finetuning is necessary. Will play around with it and see if it generates better results.

Message : Afaik, fine tuning is only available for base models not for RLHF'ed/SFT models. So you may see degradation in performance.
Quoted Message : While I read through the fine tuning section of openai docs, just wondering if there are any do/donts/tips that I should keep in mind

Message : ‚Äé<attached: 00001427-PHOTO-2023-04-25-13-37-24.jpg>
Quoted Message : Afaik, fine tuning is only available for base models not for RLHF'ed/SFT models. So you may see degradation in performance.

Message : Thanks
Quoted Message :  2023_04_25_2BB2AFA6E8A4878352127C1DD06F8BC3.jpeg

Message : I couldn‚Äôt setup Qdrant and Chroma with the chatgpt-retrieval plugin üò¢
Quoted Message : Redis and Qdrant. Have tried Chroma too. \n\nDisclosure: I'm a ML Consultant and Qdrant is a client

Message : https://github.com/openai/chatgpt-retrieval-plugin/pull/59#issuecomment-1514694410

Message : Is there a consensus yet on the best affordable spot GPU / cloud providers?

Any recommendations pls üôè

Message : Haha great idea - how did you train it?
Quoted Message : One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI üòù and not be bothered to text-back during the week. And just be presented with a date on the weekend.

Message : Haven't done it yet. Still trying to improve the chrome extension to make it smoother to use.

Also a little apprehensive about scraping my chats. Companies don't like that to happen on their webpages generally.
Quoted Message : Haha great idea - how did you train it?

Message : download (1).mp3 ‚Äé<attached: 00001435-download (1).mp3>

Message : download (3).mp3 ‚Äé<attached: 00001436-download (3).mp3>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Afaik, fine tuning is only available for base models not for RLHF'ed/SFT models. So you may see degradation in performance.
Quoted Message : While I read through the fine tuning section of openai docs, just wondering if there are any do/donts/tips that I should keep in mind

Message : ‚Äé<attached: 00001427-PHOTO-2023-04-25-13-37-24.jpg>
Quoted Message : Afaik, fine tuning is only available for base models not for RLHF'ed/SFT models. So you may see degradation in performance.

Message : Thanks
Quoted Message :  2023_04_25_2BB2AFA6E8A4878352127C1DD06F8BC3.jpeg

Message : I couldn‚Äôt setup Qdrant and Chroma with the chatgpt-retrieval plugin üò¢
Quoted Message : Redis and Qdrant. Have tried Chroma too. \n\nDisclosure: I'm a ML Consultant and Qdrant is a client

Message : https://github.com/openai/chatgpt-retrieval-plugin/pull/59#issuecomment-1514694410

Message : Is there a consensus yet on the best affordable spot GPU / cloud providers?

Any recommendations pls üôè

Message : Haha great idea - how did you train it?
Quoted Message : One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI üòù and not be bothered to text-back during the week. And just be presented with a date on the weekend.

Message : Haven't done it yet. Still trying to improve the chrome extension to make it smoother to use.

Also a little apprehensive about scraping my chats. Companies don't like that to happen on their webpages generally.
Quoted Message : Haha great idea - how did you train it?

Message : download (1).mp3 ‚Äé<attached: 00001435-download (1).mp3>

Message : download (3).mp3 ‚Äé<attached: 00001436-download (3).mp3>

Message : I got access to this. Haven‚Äôt installed yet 

https://www.cupidbot.ai

Thinking this can be done with llama trained on my chats and run locally
Quoted Message : Haven't done it yet. Still trying to improve the chrome extension to make it smoother to use.\n\nAlso a little apprehensive about scraping my chats. Companies don't like that to happen on their webpages generally.

Message : Nice! Which model? 

@91750785xxxx
Quoted Message :  2023_04_25_3EB01E528004B804EC1BBA.mp3

Message : so-vits-svc fork

Message : This is how world will end
Quoted Message : I got access to this. Haven‚Äôt installed yet \n\nhttps://www.cupidbot.ai\n\nThinking this can be done with llama trained on my chats and run locally

Message : I like the disclaimer : " Havent installed it yet " . : )
Quoted Message : I got access to this. Haven‚Äôt installed yet \n\nhttps://www.cupidbot.ai\n\nThinking this can be done with llama trained on my chats and run locally

Message : apna-bana-le-ariana.mp3 ‚Äé<attached: 00001442-apna-bana-le-ariana.mp3>

Message : Try out Weaviate if it fits your needs. We're using Weaviate with 15 million+ vectors. Good performance with normal index-wide vector search as well as pre-filtered vector search. 

They have a blog post on using with chatgpt-retrieval that might be relevant to you: https://weaviate.io/blog/weaviate-retrieval-plugin
Quoted Message : I couldn‚Äôt setup Qdrant and Chroma with the chatgpt-retrieval plugin üò¢

Message : Haha
Quoted Message : I like the disclaimer : \" Havent installed it yet \" . : )

Message : This was not a scam? Had strong scam vibes
Quoted Message : I got access to this. Haven‚Äôt installed yet \n\nhttps://www.cupidbot.ai\n\nThinking this can be done with llama trained on my chats and run locally

Message : Can you tell us which parts require training vs which parts are zero shot / one shot inference?
Quoted Message : so-vits-svc fork

Message : https://arize.com/observe-2023/

Message : I haven't trained these models myself because of data prep requirements.

But afaik it doesn't need lyrics/text for training or inference. It's trained on voice samples (.mp3/.wav files). Even at the time of training, just feed it a .mp3 file (sing yourself or use an existing song). So after training, it's all 0 zero-shot inference.
Quoted Message : Can you tell us which parts require training vs which parts are zero shot / one shot inference?

Message : Is someone kind enough to share their gpt4 access for a day and half please? ü•π

Message : For GPT4 access, you can try https://github.com/xtekky/gpt4free

Message : In case you do not have a paid subscription

Message : I want to clone Arijit Singh's voice. Will have to collect and clean the data.
Quoted Message : I haven't trained these models myself because of data prep requirements.\n\nBut afaik it doesn't need lyrics/text for training or inference. It's trained on voice samples (.mp3/.wav files). Even at the time of training, just feed it a .mp3 file (sing yourself or use an existing song). So after training, it's all 0 zero-shot inference.

Message : Ah, so its like style transfer for speech, nice
Quoted Message : I haven't trained these models myself because of data prep requirements.\n\nBut afaik it doesn't need lyrics/text for training or inference. It's trained on voice samples (.mp3/.wav files). Even at the time of training, just feed it a .mp3 file (sing yourself or use an existing song). So after training, it's all 0 zero-shot inference.

Message : Yup.
Quoted Message : Ah, so its like style transfer for speech, nice

Message : Hire someone on upwork/fiver? Costs <50 USD for this
Quoted Message : I want to clone Arijit Singh's voice. Will have to collect and clean the data.

Message : And 2 dats

Message : days*

Message : Are you using https://beta.elevenlabs.io/ for this?
Quoted Message : I want to clone Arijit Singh's voice. Will have to collect and clean the data.

Message : Nope. https://github.com/voicepaw/so-vits-svc-fork
Quoted Message : Are you using https://beta.elevenlabs.io/ for this?

Message : Someone leaked pretrained models of many popular singers a week back. Was that for this project?
Quoted Message : Nope. https://github.com/voicepaw/so-vits-svc-fork

Message : Probably. Wait I'll share.
Quoted Message : Someone leaked pretrained models of many popular singers a week back. Was that for this project?

Message : https://docs.google.com/spreadsheets/d/1qzeFdpUPr7E0jOFwWSXd8LF30ZLjz1CSVEBiG8gPHTU/edit#gid=1792554832 this one?

Message : They even got Freddy

Message : https://twitter.com/tivadardanka/status/1649721970886594561?s=21&t=r3oag1xERfq9yMvHrl3kqA

Message : https://aiagent.app/

Very cool product in case people haven't tried it

Message : This is pretty cool! Know who's built this?
Quoted Message : https://aiagent.app/\n\nVery cool product in case people haven't tried it

Message : The toolkit says coming soon
Quoted Message : https://aiagent.app/\n\nVery cool product in case people haven't tried it

Message : something that‚Äôs already here - fixie.ai

Message : doesnt this look like godmode.space (or just AutoGPT in general)?
Quoted Message : https://aiagent.app/\n\nVery cool product in case people haven't tried it

Message : Fixie's SDK is pretty powerful
Quoted Message : something that‚Äôs already here - fixie.ai

Message : has anyone used AutoGPT (or its derivatives) for anything useful so far? Let me know if there are some projects that do this.

Message : have you used this?
Quoted Message : something that‚Äôs already here - fixie.ai

Message : I have, a bit
Quoted Message : have you used this?

Message : Worked for the 30 mins i played with it
Quoted Message : have you used this?

Message : How are you running it on prod? Docker? Is it a cluster?
Quoted Message : Try out Weaviate if it fits your needs. We're using Weaviate with 15 million+ vectors. Good performance with normal index-wide vector search as well as pre-filtered vector search. \n\nThey have a blog post on using with chatgpt-retrieval that might be relevant to you: https://weaviate.io/blog/weaviate-retrieval-plugin

Message : The concept is fun, but I haven‚Äôt really found it useful.
Quoted Message : has anyone used AutoGPT (or its derivatives) for anything useful so far? Let me know if there are some projects that do this.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : The toolkit says coming soon
Quoted Message : https://aiagent.app/\n\nVery cool product in case people haven't tried it

Message : something that‚Äôs already here - fixie.ai

Message : doesnt this look like godmode.space (or just AutoGPT in general)?
Quoted Message : https://aiagent.app/\n\nVery cool product in case people haven't tried it

Message : Fixie's SDK is pretty powerful
Quoted Message : something that‚Äôs already here - fixie.ai

Message : has anyone used AutoGPT (or its derivatives) for anything useful so far? Let me know if there are some projects that do this.

Message : have you used this?
Quoted Message : something that‚Äôs already here - fixie.ai

Message : I have, a bit
Quoted Message : have you used this?

Message : Worked for the 30 mins i played with it
Quoted Message : have you used this?

Message : How are you running it on prod? Docker? Is it a cluster?
Quoted Message : Try out Weaviate if it fits your needs. We're using Weaviate with 15 million+ vectors. Good performance with normal index-wide vector search as well as pre-filtered vector search. \n\nThey have a blog post on using with chatgpt-retrieval that might be relevant to you: https://weaviate.io/blog/weaviate-retrieval-plugin

Message : The concept is fun, but I haven‚Äôt really found it useful.
Quoted Message : has anyone used AutoGPT (or its derivatives) for anything useful so far? Let me know if there are some projects that do this.

Message : It's a cluster, but we're using their managed SaaS service WCS, https://weaviate.io/developers/weaviate/installation/weaviate-cloud-services
Quoted Message : How are you running it on prod? Docker? Is it a cluster?

Message : Just out of curiosity, why not?
Quoted Message : The concept is fun, but I haven‚Äôt really found it useful.

Message : depends on the application I guess? I generally use it for paraphrasing (for which chatgpt suffices) and coding (where none of these models work very well - haven't tried GPT4 which some people claim is much better, but more expensive too)
Quoted Message : Just out of curiosity, why not?

Message : ‚Äé<attached: 00001489-PHOTO-2023-04-25-19-06-09.jpg>
Quoted Message : https://aiagent.app/\n\nVery cool product in case people haven't tried it

Message : why not? at least thats the idea wit medical AI, as of now humans by nature will not trust AI diagnosis any more than a human doctor's diagnosis. AI assisted healthcare makes sense from both effort minimization and improving patient outcome
Quoted Message :  2023_04_25_3A6FDF3554FD5DA00E96.jpeg

Message : an example: https://whiterabbit.ai/

Message : Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines.
Anyone here has some suggestions for good place to host?

Message : Have it forever - https://gooey.ai/compare-large-language-models/?example_id=7ihhyv3l
Quoted Message : Is someone kind enough to share their gpt4 access for a day and half please? ü•π

Message : Serverless? Modal and Banana type services?
Quoted Message : Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines.\nAnyone here has some suggestions for good place to host?

Message : Okay, I am not sure if serverless would be right for us. So I have a normal python script with multiple diffusion models and hosted via flask/streamlit. Sorry, little noob in hosting :p
Quoted Message : Serverless? Modal and Banana type services?

Message : wow - this should help my case, if they offer what they claim.
Thanks Dev!
Quoted Message : Have it forever - https://gooey.ai/compare-large-language-models/?example_id=7ihhyv3l

Message : Hey Shivansh ,

I am Nilesh, we are building a platform specially for GPU based workload  https://inferless.com/
Quoted Message : Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines.\nAnyone here has some suggestions for good place to host?

Message : happy to connect and understand how we can help you

Message : Arey this is mine only :) DM for bugs and feedback
Quoted Message : wow - this should help my case, if they offer what they claim.\nThanks Dev!

Message : https://arize.com/observe-2023/
The third annual Arize:Observe is the first conference dedicated solely to ML observability in the year of generative AI.
This (free to attend) event is starting in an hour.  Seemed to be a good one atleast few of the sessions. Check it out.

Message : We‚Äôve spent a lot of time trying diff GPU hosting platforms. 

Top picks for IaaS / PaaS type hosting:

Fastest:

(1) Banana.dev for fast scalable hosting / prototyping (‚Çπ150 per hour for 40GB)

Cheapest:

(2) Jarvis (~60-70 per hour for similar GPU as Banana)
Quoted Message : Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines.\nAnyone here has some suggestions for good place to host?

Message : Check Modal Labs perhaps? It's beginner friendly and they've Python-friendly web endpoints: https://modal.com/docs/guide/webhooks
Quoted Message : Okay, I am not sure if serverless would be right for us. So I have a normal python script with multiple diffusion models and hosted via flask/streamlit. Sorry, little noob in hosting :p

Message : ‚Äé<attached: 00001509-PHOTO-2023-04-25-20-42-39.jpg>
Quoted Message : We‚Äôve spent a lot of time trying diff GPU hosting platforms. \n\nTop picks for IaaS / PaaS type hosting:\n\nFastest:\n\n(1) Banana.dev for fast scalable hosting / prototyping (‚Çπ150 per hour for 40GB)\n\nCheapest:\n\n(2) Jarvis (~60-70 per hour for similar GPU as Banana)

Message : e73ef8fe-7ddb-465b-8d54-a170f52ab287%2FGPU_Price_Comparison_Jan_22.pdf ‚Ä¢ ‚Äé26 pages ‚Äé<attached: 00001510-e73ef8fe-7ddb-465b-8d54-a170f52ab287%2FGPU_Price_Comparison_Jan_22.pdf>

Message : Ongoing webinar on Dolly right now. Still on for another 30 mins. 

https://event.on24.com/wcc/r/4187692/F74E3C2FB135A1C3CDC5302CCDED7772

Message : Q&A so far. In case it's helpful for anyone.

Is loading and testing LLM different depending on type of training? ie. categorization vs q&a

Loading LLMs is generally about the same for most models. You will use Hugging Face, usually. Testing a classifier is straightforward because the right answers are clear. Testing QA is harder; is the answer accurate? how accurate? is the tone OK? because it's natural language.

After finetuning, how can you test/ensure new dataset is trained in new model? ie recent events such as covid, 2023 beijing hospital fire, etc.

You would hold out some fine-tuning data for test and evaluation, as with any other model. How you evaluate the model on that data depends a lot on the data!

At the public rate for GPU time at Databricks, how much did it cost to train/tune Dolly?

The largest 12B model cost several thousand dollars to fine tune. That is not cheap, but a lot less than training from scratch. You don't have to fine tune in many cases, or can tune less or tune a smaller model.

Do you think the large 12b%2B models will end up with different flavours and organisations will have to pick the LLM specialism to build on top or will there be a base model to rule them all?

I think the idea here is specialized models (single billions of params) could keep up with SOTA models (hundreds of billions) if fine-tuned for a specific task. Maybe.

are we bound to use data ingestion service like databricks for fine tune dolly 2.0

No, you can use or fine-tune Dolly anywhere. It's not tied to Databricks.

What is the optimal length for fine-tuning the model, or how many training samples are needed for effective fine-tuning?

No one answer to that. Depends on the data, model and problem. You can see that a couple epochs at 15K data points were roughly enough to turn Pythia into an instruction-following model. I'd aim for tens of thousands of examples, but, no hard rule here.

Is Dolly only pre-trained for english language or could you fine tune the model for other languages?

It is based on Pythia, which mostly saw English text. The fine-tuning set is also English. You could fine-tune on other languages instruction sets, but that doesn't mean the base model learned the language. It would work to a limited degree.

What the size of GPU Ram is required for hosting/fine-tuning Dolly 2.0?

A100 is nice, but A10/V100 and even T4 can work: https://github.com/databrickslabs/dolly#generating-on-other-instances

do you have a good tutorial to get started with Dolly

Sure, simplest thing is to run the couple lines of code you see on the model page: https://huggingface.co/databricks/dolly-v2-3b

Will there be a recording of this available?

We will send out the webinar recording after the event via email!

I'd like a LLM that simulates me, and how I think and answer questions. Is it possible to augment an existing LLM or do I need to build my own? I want it to learn based on all the content/collateral I create or have created.

You can create prompts like "Here is some text I wrote: ... Now write X in the same style" That can work with LLMs. You can also fine-tune on your text of course

will this session be recorded ?

The webinar will be recorded and sent out via email post event

what would be the token limit for an LLM made by our selfs , or we can decide that

It depends on your model's architecture. Pythia, thus Dolly, use a 2048 token context window. Others are larger or smaller.

Do you have any example costs of fine tuning? I nearly had a go but was nervous what cost I might incur!

It entirely depends on what you are tuning, on what hardware, and for how long. As a reference point, the 12B fine-tuned Dolly model cost several thousand dollars. Smaller models would be less. I wouldn't fine-tune unless you have a specific reason.

does LLM use reinforcement learning?

LLM training can use human-in-the-loop feedback. See "RLHF" https://huggingface.co/blog/rlhf

What was the GPU requirements to load the 12B Dolly model for inference & training?

See the repo: https://github.com/databrickslabs/dolly#generating-on-other-instances

I have a large amount of unlabeled, domain specific text data, as well as a much smaller set of labeled data. I would like to leverage both to fine tune a language model for a specific task. How would you recommend fine-tuning the model in a way that let's me use both the unlabeled and labeled data I have access to?

Hard to answer right here, but in the end the input to training are just chunks of text. You can feed it text, and text of data + label. You're asking it to learn to write the text you feed it, so there's some art to constructing the input. For labeled data you want to construct the text so that the desired output follows the type of question you'll ask.

What if you have domain specific corpus? How do you integrate that into Dolly

1) you can fine-tune on that data, 2) you can use langchain to feed related text from your corpus alongside your question to an off-the-shelf LLM. The latter is what we show at https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot

Is it viable to use opensource generative models for instruction following data? Since generating a dataset is time consuming. This is regarding fine tuning dolly 2.0

You mean, can you generate fine-tuning data from another LLM? sure that's what Alpaca did, by scraping OpenAI. However the resulting model was not for unrestricted commercial use because the data was scraped from OpenAI.

I have an unstructured text corpus, think like wikipedia pages. Can we fine tune LLM by adding this data? Is there any notebook explaining this.

Yes, if you want to. Hard to explain the detail here, but see Dolly's training repo: https://github.com/databrickslabs/dolly We also have an example of Dolly + StackExchange data that does not need fine-tuning: https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot

Can Dolly 2.0 be used as an agent for something like Langchain?

Absolutely. We have a whole demo on that https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot

When does it make sense to start fine tuning your data vs sending lengthy, detailed prompts?

Good question. Fine-tuning takes more upfront work but indeed makes generation faster b/c you dont' stuff context into the prompt. Fine-tuning also means you have to re-fine-tune to have it learn new information, versus just stuffing the latest info into a prompt.

What use cases / applications are you seeing that companies / startups are doing using Dolly? What is your POV on the risk for technology being redundant due to the fast pace of development in Gen AI?

Most people are interested in question-answering over private text collections. Translation and summarization were already well understood use cases, but QA is 'new'. Chat not so much. This space is changing really fast, and what we use now will be obsolete next year, but, thankfully it all remains fairly accessible.

How can i train a locally hosted dolly 2 instance with my own datasets? I currently have data in a CSV format.

See https://github.com/databrickslabs/dolly though I don't know that CSV is natural language text, not really what LLMs have learned to process. CSV doesn't need LLMs to understand! however you can see in tools like langchain some patterns for querying databases with natural language and describing the results, so that is possible.

Why does Dolly 2.0 use pythia eleutherai instead of LlaMA as a base model?

LLaMa is not for commercial use, while Pythia is. We wanted to make something that was commercially usable like typical OSS code is.

Can I use LLM to classify a set of texts? Whether they are "good" or "threat"?

Yes. You can present it a few examples of "good" and "threat" in the prompt and ask about a new example. This is few-shot learning. You could even fine-tune it to do that. However, for simple classification, far simpler off-the-shelf models would be easier to use.

Is fine-tuning required for us to use Dolly in generating insights and answering certain questions about dataframes or other data that we might have on Databricks?

No. See the example at https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot which answers questions over a domain corpus without fine tuning

How do you manage for picking the right hugging face model(s) for commerical use cases so that companies don't get stuck in litigating later?

Most of the models in Hugging Face have license information. You should look at the license specifics

Message : ‚Äé<attached: 00001513-PHOTO-2023-04-25-21-03-38.jpg>

Message : Open Source (Llama 30B-based) rival to ChatGPT from Huggingface:
hf.co/chat

Message : Must be WA blue ü§£
Quoted Message :  2023_04_25_3A62D59226AD3DF7E67B.jpeg

Message : ‚Äé<attached: 00001516-PHOTO-2023-04-25-21-05-21.jpg>

Message : You're welcome :P Did this via apple app on mac in case there's an actual constraint on other devices :P
Quoted Message :  2023_04_25_3A62D59226AD3DF7E67B.jpeg

Message : Fine tuning vs sending long, detailed prompts is a very interesting topic/Product design requirement

Fine tuning is more upfront work and also requires constant re-training/re-fine tuning to keep it relevant

On the other hand, sending long, detailed prompts has its own set of pros/cons

Does anyone here have inputs on economics b/w the two?

My sense + anecdotal conversations have told me that fine-tuning often has a higher marginal cost. Eager to hear from others
Quoted Message : Q&A so far. In case it's helpful for anyone.\n\nIs loading and testing LLM different depending on type of training? ie. categorization vs q&a\n\nLoading LLMs is generally about the same for most models. You will use Hugging Face, usually. Testing a classifier is straightforward because the right answers are clear. Testing QA is harder; is the answer accurate? how accurate? is the tone OK? because it's natural language.\n\nAfter finetuning, how can you test/ensure new dataset is trained in new model? ie recent events such as covid, 2023 beijing hospital fire, etc.\n\nYou would hold out some fine-tuning data for test and evaluation, as with any other model. How you evaluate the model on that data depends a lot on the data!\n\nAt the public rate for GPU time at Databricks, how much did it cost to train/tune Dolly?\n\nThe largest 12B model cost several thousand dollars to fine tune. That is not cheap, but a lot less than training from scratch. You don't have to fine tune in many cases, or can tune less or tune a smaller model.\n\nDo you think the large 12b%2B models will end up with different flavours and organisations will have to pick the LLM specialism to build on top or will there be a base model to rule them all?\n\nI think the idea here is specialized models (single billions of params) could keep up with SOTA models (hundreds of billions) if fine-tuned for a specific task. Maybe.\n\nare we bound to use data ingestion service like databricks for fine tune dolly 2.0\n\nNo, you can use or fine-tune Dolly anywhere. It's not tied to Databricks.\n\nWhat is the optimal length for fine-tuning the model, or how many training samples are needed for effective fine-tuning?\n\nNo one answer to that. Depends on the data, model and problem. You can see that a couple epochs at 15K data points were roughly enough to turn Pythia into an instruction-following model. I'd aim for tens of thousands of examples, but, no hard rule here.\n\nIs Dolly only pre-trained for english language or could you fine tune the model for other languages?\n\nIt is based on Pythia, which mostly saw English text. The fine-tuning set is also English. You could fine-tune on other languages instruction sets, but that doesn't mean the base model learned the language. It would work to a limited degree.\n\nWhat the size of GPU Ram is required for hosting/fine-tuning Dolly 2.0?\n\nA100 is nice, but A10/V100 and even T4 can work: https://github.com/databrickslabs/dolly#generating-on-other-instances\n\ndo you have a good tutorial to get started with Dolly\n\nSure, simplest thing is to run the couple lines of code you see on the model page: https://huggingface.co/databricks/dolly-v2-3b\n\nWill there be a recording of this available?\n\nWe will send out the webinar recording after the event via email!\n\nI'd like a LLM that simulates me, and how I think and answer questions. Is it possible to augment an existing LLM or do I need to build my own? I want it to learn based on all the content/collateral I create or have created.\n\nYou can create prompts like \"Here is some text I wrote: ... Now write X in the same style\" That can work with LLMs. You can also fine-tune on your text of course\n\nwill this session be recorded ?\n\nThe webinar will be recorded and sent out via email post event\n\nwhat would be the token limit for an LLM made by our selfs , or we can decide that\n\nIt depends on your model's architecture. Pythia, thus Dolly, use a 2048 token context window. Others are larger or smaller.\n\nDo you have any example costs of fine tuning? I nearly had a go but was nervous what cost I might incur!\n\nIt entirely depends on what you are tuning, on what hardware, and for how long. As a reference point, the 12B fine-tuned Dolly model cost several thousand dollars. Smaller models would be less. I wouldn't fine-tune unless you have a specific reason.\n\ndoes LLM use reinforcement learning?\n\nLLM training can use human-in-the-loop feedback. See \"RLHF\" https://huggingface.co/blog/rlhf\n\nWhat was the GPU requirements to load the 12B Dolly model for inference & training?\n\nSee the repo: https://github.com/databrickslabs/dolly#generating-on-other-instances\n\nI have a large amount of unlabeled, domain specific text data, as well as a much smaller set of labeled data. I would like to leverage both to fine tune a language model for a specific task. How would you recommend fine-tuning the model in a way that let's me use both the unlabeled and labeled data I have access to?\n\nHard to answer right here, but in the end the input to training are just chunks of text. You can feed it text, and text of data + label. You're asking it to learn to write the text you feed it, so there's some art to constructing the input. For labeled data you want to construct the text so that the desired output follows the type of question you'll ask.\n\nWhat if you have domain specific corpus? How do you integrate that into Dolly\n\n1) you can fine-tune on that data, 2) you can use langchain to feed related text from your corpus alongside your question to an off-the-shelf LLM. The latter is what we show at https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot\n\nIs it viable to use opensource generative models for instruction following data? Since generating a dataset is time consuming. This is regarding fine tuning dolly 2.0\n\nYou mean, can you generate fine-tuning data from another LLM? sure that's what Alpaca did, by scraping OpenAI. However the resulting model was not for unrestricted commercial use because the data was scraped from OpenAI.\n\nI have an unstructured text corpus, think like wikipedia pages. Can we fine tune LLM by adding this data? Is there any notebook explaining this.\n\nYes, if you want to. Hard to explain the detail here, but see Dolly's training repo: https://github.com/databrickslabs/dolly We also have an example of Dolly + StackExchange data that does not need fine-tuning: https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot\n\nCan Dolly 2.0 be used as an agent for something like Langchain?\n\nAbsolutely. We have a whole demo on that https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot\n\nWhen does it make sense to start fine tuning your data vs sending lengthy, detailed prompts?\n\nGood question. Fine-tuning takes more upfront work but indeed makes generation faster b/c you dont' stuff context into the prompt. Fine-tuning also means you have to re-fine-tune to have it learn new information, versus just stuffing the latest info into a prompt.\n\nWhat use cases / applications are you seeing that companies / startups are doing using Dolly? What is your POV on the risk for technology being redundant due to the fast pace of development in Gen AI?\n\nMost people are interested in question-answering over private text collections. Translation and summarization were already well understood use cases, but QA is 'new'. Chat not so much. This space is changing really fast, and what we use now will be obsolete next year, but, thankfully it all remains fairly accessible.\n\nHow can i train a locally hosted dolly 2 instance with my own datasets? I currently have data in a CSV format.\n\nSee https://github.com/databrickslabs/dolly though I don't know that CSV is natural language text, not really what LLMs have learned to process. CSV doesn't need LLMs to understand! however you can see in tools like langchain some patterns for querying databases with natural language and describing the results, so that is possible.\n\nWhy does Dolly 2.0 use pythia eleutherai instead of LlaMA as a base model?\n\nLLaMa is not for commercial use, while Pythia is. We wanted to make something that was commercially usable like typical OSS code is.\n\nCan I use LLM to classify a set of texts? Whether they are \"good\" or \"threat\"?\n\nYes. You can present it a few examples of \"good\" and \"threat\" in the prompt and ask about a new example. This is few-shot learning. You could even fine-tune it to do that. However, for simple classification, far simpler off-the-shelf models would be easier to use.\n\nIs fine-tuning required for us to use Dolly in generating insights and answering certain questions about dataframes or other data that we might have on Databricks?\n\nNo. See the example at https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot which answers questions over a domain corpus without fine tuning\n\nHow do you manage for picking the right hugging face model(s) for commerical use cases so that companies don't get stuck in litigating later?\n\nMost of the models in Hugging Face have license information. You should look at the license specifics

Message : My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction. 

But interested to hear others perspectives.
Quoted Message : Fine tuning vs sending long, detailed prompts is a very interesting topic/Product design requirement\n\nFine tuning is more upfront work and also requires constant re-training/re-fine tuning to keep it relevant\n\nOn the other hand, sending long, detailed prompts has its own set of pros/cons\n\nDoes anyone here have inputs on economics b/w the two?\n\nMy sense + anecdotal conversations have told me that fine-tuning often has a higher marginal cost. Eager to hear from others

Message : Added Q to above:

When context windows are super large (32K for GPT4 and someone tested 1M recently) will we still need fine tuning when almost all context will fit inside 1M tokens?

Message : *satisfactory output
Quoted Message : My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction. \n\nBut interested to hear others perspectives.

Message : https://manifold.markets/IsaacKing/will-any-llm-have-a-context-window

Message : Related discussion here https://news.ycombinator.com/item?id=35682424

Message : Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?

As opposed to an ensemble of smaller fine-tuned models?
Quoted Message : My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction. \n\nBut interested to hear others perspectives.

Message : Noob question: I work at an education company. We finetuned chatgpt's davinci model on some of our content to see if it can create good new content. Results so far are fairly poor, and I'm wondering if this should be expected since gpt-3.5 and gpt-4 significantly raised the bar from previous versions? Has anyone else seen sub-par quality output from finetuned models? Are there other options (such as Huggingface transformers) that might work better?

Message : Particularly when the context window will support 32K or 100K+ tokens which can fit all fine tuning data ?
Quoted Message : Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?\n\nAs opposed to an ensemble of smaller fine-tuned models?

Message : How do we think of expenses?
Quoted Message : Particularly when the context window will support 32K or 100K+ tokens which can fit all fine tuning data ?

Message : More input tokens would mostly mean more expensive API calls?

Message : Expenses is ~ # of context window tokens to and fro on OpenAI atleast
Quoted Message : How do we think of expenses?

Message : My understanding so far is that GPT 4 especially is very capable for most use cases with few shot in-context learning. So would be easier to test and learn like this, figure the nuances of the use case and then evaluate smaller fine tuned models.
Quoted Message : Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?\n\nAs opposed to an ensemble of smaller fine-tuned models?

Message : Makes sense. With that in mind 1M tokens of context will be much worse on $ than fine tuning maybe.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://manifold.markets/IsaacKing/will-any-llm-have-a-context-window

Message : Related discussion here https://news.ycombinator.com/item?id=35682424

Message : Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?

As opposed to an ensemble of smaller fine-tuned models?
Quoted Message : My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction. \n\nBut interested to hear others perspectives.

Message : Noob question: I work at an education company. We finetuned chatgpt's davinci model on some of our content to see if it can create good new content. Results so far are fairly poor, and I'm wondering if this should be expected since gpt-3.5 and gpt-4 significantly raised the bar from previous versions? Has anyone else seen sub-par quality output from finetuned models? Are there other options (such as Huggingface transformers) that might work better?

Message : Particularly when the context window will support 32K or 100K+ tokens which can fit all fine tuning data ?
Quoted Message : Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?\n\nAs opposed to an ensemble of smaller fine-tuned models?

Message : How do we think of expenses?
Quoted Message : Particularly when the context window will support 32K or 100K+ tokens which can fit all fine tuning data ?

Message : More input tokens would mostly mean more expensive API calls?

Message : Expenses is ~ # of context window tokens to and fro on OpenAI atleast
Quoted Message : How do we think of expenses?

Message : My understanding so far is that GPT 4 especially is very capable for most use cases with few shot in-context learning. So would be easier to test and learn like this, figure the nuances of the use case and then evaluate smaller fine tuned models.
Quoted Message : Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?\n\nAs opposed to an ensemble of smaller fine-tuned models?

Message : Makes sense. With that in mind 1M tokens of context will be much worse on $ than fine tuning maybe.

Message : But say we were using an open source model (Llama? alpaca? Of the future) where pricing isn‚Äôt a factor of token count. The large context window approach will work better with more flexibility?

Message : Open question still - anyone tried both approaches?
Quoted Message : But say we were using an open source model (Llama? alpaca? Of the future) where pricing isn‚Äôt a factor of token count. The large context window approach will work better with more flexibility?

Message : (Adding to what Karan said)

My experience with this- still iterating on this though... In rare usecases where LLM might not have seen that kind of data, fine-tuning might add value otherwise using few-shot prompting or coming up with even more complex chains for the usecase under consideration is sufficient
Quoted Message : My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction. \n\nBut interested to hear others perspectives.

Message : I think it's a function of Product maturity

Thinking out loud,

If I were experimenting the impact of GPT for my use-case/workflow, I'd almost always want to begin with few shot prompting to begin with and put the product in the hands of users, collect sufficient data and then experiment if fine-tuning with the collected data gives me better results

Anecdotally, it's also a function of the design requirement from a business perspective - if I support a multi-tenant architecture, every tenant might require a separate fine-tuned version of the same base model for various requirements

Message : If it's a multi tenant setup, I think it's better to finetune on the combined data for all tenants and then use few-shot prompting to refine for every customer.

(Atleast that's what I am hoping to work üòÇ)

Message : Umm, if I'm a chatbot/conversational AI company and have competing customers (say Axis and HDFC) as my clientele, I'd likely have a base model and fine-tuned (forked) versions of the same running inside the environments of Axis and HDFC

Either of them wouldn't be comfortable with me using their data to train my base model which can be offered to their competitor

I've seen the same concept in a different video analytics use-case - where CCTV camera feeds are analyzed to study multitude of things when deployed in a retail outlet
Quoted Message : If it's a multi tenant setup, I think it's better to finetune on the combined data for all tenants and then use few-shot prompting to refine for every customer.\n\n(Atleast that's what I am hoping to work üòÇ)

Message : The former use-case was via anecdotal research

The later was from my personal experience as a Solutioning Exercise
Quoted Message : Umm, if I'm a chatbot/conversational AI company and have competing customers (say Axis and HDFC) as my clientele, I'd likely have a base model and fine-tuned (forked) versions of the same running inside the environments of Axis and HDFC\n\nEither of them wouldn't be comfortable with me using their data to train my base model which can be offered to their competitor\n\nI've seen the same concept in a different video analytics use-case - where CCTV camera feeds are analyzed to study multitude of things when deployed in a retail outlet

Message : How much are we seeing Indian clients caring about their data being used for model training? Is it just regulatory heavy industries like banking or are non-reg industries saying the same? (Eg Ed-tech)

Message : https://www.researchgate.net/publication/370213628_Scaling_Transformer_to_1M_tokens_and_beyond_with_RMT

Message : Personal experience from a limited sample set - more about the use-case than regulations

Also, the more mature the company, the more concerns they raise

Happy to chat/share more 1:1
Quoted Message : How much are we seeing Indian clients caring about their data being used for model training? Is it just regulatory heavy industries like banking or are non-reg industries saying the same? (Eg Ed-tech)

Message : I think no ML product company can exist if *none* of their customers are ready to share their data for training purposes. So let's say big banks like Axis and HDFC are not ready, then the base model can't be trained on their data. But smaller banks might be ready to share their data for a lower price of implementation etc. (assuming this). So base model can be trained on the banks using the lower pricing tier and few shot prompting etc can be used for the Axis and HDFCs of the world, on-premise to make it work for their data. 

If no one is sharing data, then you have to fine tune for everyone and the offering becomes closer to a service rather than a product in my opinion. Thoughts?

Message : Also important to build a differentiated solution. Else anyone can create the wrapper without fine tuning
Quoted Message : I think no ML product company can exist if *none* of their customers are ready to share their data for training purposes. So let's say big banks like Axis and HDFC are not ready, then the base model can't be trained on their data. But smaller banks might be ready to share their data for a lower price of implementation etc. (assuming this). So base model can be trained on the banks using the lower pricing tier and few shot prompting etc can be used for the Axis and HDFCs of the world, on-premise to make it work for their data. \n\nIf no one is sharing data, then you have to fine tune for everyone and the offering becomes closer to a service rather than a product in my opinion. Thoughts?

Message : Well said. We have a similar vision - start with embeddings and then at some point fine tune per client (maybe per team)
Quoted Message : I think it's a function of Product maturity\n\nThinking out loud, \n\nIf I were experimenting the impact of GPT for my use-case/workflow, I'd almost always want to begin with few shot prompting to begin with and put the product in the hands of users, collect sufficient data and then experiment if fine-tuning with the collected data gives me better results\n\nAnecdotally, it's also a function of the design requirement from a business perspective - if I support a multi-tenant architecture, every tenant might require a separate fine-tuned version of the same base model for various requirements

Message : Precisely why AI has higher marginal costs (and poorer GMs) than traditional cloud software

This is my biggest question to/for folks calling AI as the next biggest platform shift

Typical ways to bypass this though is to compensate those you're using the data from - either through partnerships or direct commercial agreements
Quoted Message : I think no ML product company can exist if *none* of their customers are ready to share their data for training purposes. So let's say big banks like Axis and HDFC are not ready, then the base model can't be trained on their data. But smaller banks might be ready to share their data for a lower price of implementation etc. (assuming this). So base model can be trained on the banks using the lower pricing tier and few shot prompting etc can be used for the Axis and HDFCs of the world, on-premise to make it work for their data. \n\nIf no one is sharing data, then you have to fine tune for everyone and the offering becomes closer to a service rather than a product in my opinion. Thoughts?

Message : You can get away with embeddings right? So there‚Äôs no training?
Quoted Message : I think no ML product company can exist if *none* of their customers are ready to share their data for training purposes. So let's say big banks like Axis and HDFC are not ready, then the base model can't be trained on their data. But smaller banks might be ready to share their data for a lower price of implementation etc. (assuming this). So base model can be trained on the banks using the lower pricing tier and few shot prompting etc can be used for the Axis and HDFCs of the world, on-premise to make it work for their data. \n\nIf no one is sharing data, then you have to fine tune for everyone and the offering becomes closer to a service rather than a product in my opinion. Thoughts?

Message : discussing this for a complicated usecase where finetuning is required in some capacity. So pureplay embeddings and few shot prompting won't work is the assumption here.
Quoted Message : You can get away with embeddings right? So there‚Äôs no training?

Message : Those models doesn't not have RLHF etc, not just smaller models. So you will be seeing perf similar to GPT3 and some more: your fine tuning. You will need other models and then train RLHF or use one of the RLHF trained models and try. Haven't done the last part. You will most likely need to fine tune RLHF as well, as the new models might have drifted in the output space.
Quoted Message : Noob question: I work at an education company. We finetuned chatgpt's davinci model on some of our content to see if it can create good new content. Results so far are fairly poor, and I'm wondering if this should be expected since gpt-3.5 and gpt-4 significantly raised the bar from previous versions? Has anyone else seen sub-par quality output from finetuned models? Are there other options (such as Huggingface transformers) that might work better?

Message : Very true. But at the same time all these companies are trusting MS, Goog and AWS with their data. One of our customers, large multinational, had absolute 'no' few weeks ago to if you can provide guarantee, nothing will be leaked, you can use OpenAI. Unfortunately, OpenAI fine print isn't that black and white.
Quoted Message : Personal experience from a limited sample set - more about the use-case than regulations\n\nAlso, the more mature the company, the more concerns they raise\n\nHappy to chat/share more 1:1

Message : What's the exact fine print that is difficult to decipher?
Quoted Message : Very true. But at the same time all these companies are trusting MS, Goog and AWS with their data. One of our customers, large multinational, had absolute 'no' few weeks ago to if you can provide guarantee, nothing will be leaked, you can use OpenAI. Unfortunately, OpenAI fine print isn't that black and white.

Message : From what I understand, context is the application's and not Open AIs but want to understand this further.

Message : Tell them they‚Äôll loose everything when their competition uses chatgpt to outperform them üòóüòù
Quoted Message : Very true. But at the same time all these companies are trusting MS, Goog and AWS with their data. One of our customers, large multinational, had absolute 'no' few weeks ago to if you can provide guarantee, nothing will be leaked, you can use OpenAI. Unfortunately, OpenAI fine print isn't that black and white.

Message : Scare is definitely one approach haha :D
Quoted Message : Tell them they‚Äôll loose everything when their competition uses chatgpt to outperform them üòóüòù

Message : And it took the big 3 15 odd years to instil this trust

Which is why I really like AWS's push with Bedrock
Quoted Message : Very true. But at the same time all these companies are trusting MS, Goog and AWS with their data. One of our customers, large multinational, had absolute 'no' few weeks ago to if you can provide guarantee, nothing will be leaked, you can use OpenAI. Unfortunately, OpenAI fine print isn't that black and white.

Message : Or tell them you‚Äôre using azure, azure has like a direct passthrough of gpt
Quoted Message : Tell them they‚Äôll loose everything when their competition uses chatgpt to outperform them üòóüòù

Message : Used replicate and runpod.io, would recommend both for serverless and stateful use cases
Quoted Message : Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines.\nAnyone here has some suggestions for good place to host?

Message : In typical Amazon fashion, better selection inside a VPC that customers trust with Anthropic which is possibly the biggest competitor to OAI today
Quoted Message : And it took the big 3 15 odd years to instil this trust\n\nWhich is why I really like AWS's push with Bedrock

Message : It feels like a good tool for scaffolding, but also a bit blind. The way the repo is also feels limiting. 

It‚Äôs can also be a giant token consumption monster.
Quoted Message : Just out of curiosity, why not?

Message : Their wordings are something like "OpenAI may use content to provide and maintain services". What he heard from an OpenAI engineer was won't be used for training* (*to be verified by the engineer). Don't know if Nirant or others heard an update from their team.
Quoted Message : From what I understand, context is the application's and not Open AIs but want to understand this further.

Message : https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy

The azure openai service is very clear on this.

‚ÄúMicrosoft hosts the OpenAI models within our Azure infrastructure, and all customer data sent to Azure OpenAI remains within the Azure OpenAI service‚Äù

‚ÄúNo prompts or completions are stored in the model during these operations, and prompts and completions are not used to train, retrain or improve the models.‚Äù

Message : Open AI engineer Boris Power - "Prompting leads to faster results, with fine tuning it's painful to edit with changing data. Use fine tuning for exact format of input and output and if you have lots of historical high quality data. New use cases - fine tuning acts a lot of cost. Fine tuning doesn't do well when you need to understand facts and then provide the output"

Message : ‚Äé<attached: 00001565-PHOTO-2023-04-25-22-32-00.jpg>

Message : Thanks for this. Could be helpful for us.
Quoted Message :  2023_04_25_3ACA6C8026AF96321496.jpeg

Message : They did say in an email that all data is deleted within 30 days and it‚Äôs not used for training

Message : https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt - turnoff chat history on chatgpt

Message : Already did this. Like how this is fine print on the website since Sam said the purpose of releasing chatgpt to the world was (high frequency / diverse) user feedback.
Quoted Message : https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt - turnoff chat history on chatgpt

Message : *this was

Message : Openai doesn't need customer data to improve models at this stage.    No data sent over api by platform customers has ever been used.  When asked about it, they said they are just keeping the data around for 30 days for trust and safety.

As regards fine tuning, apart from it often not doing as well as prompt engineering, the other risk is that when a new model upgrade comes, it usually does better than the fine tuned model just out of the box.  We saw that with gpt4 and that trend is likely to continue.  As such, fine tuning is unlikely to be a reasonable moat for most players.

Message : OpenAI not needing data: Highly doubt that claim, they like everyone else would happily take more data. Esp when they are out of training data for GPT (they have exhausted text data). But also as feedback for fine-tuning layers like RLHF. The key there is they don't use API day, chatting on website probably will be used as is (which they say as well, in the free version). Ideally if they really don't need data, they should give a zero knowledge guarantee. They don't use input or output. But could they use intermediate layer info, can their folks eyeball it to improve the system. All those are probably open questions.
Quoted Message : Openai doesn't need customer data to improve models at this stage.    No data sent over api by platform customers has ever been used.  When asked about it, they said they are just keeping the data around for 30 days for trust and safety.\n\nAs regards fine tuning, apart from it often not doing as well as prompt engineering, the other risk is that when a new model upgrade comes, it usually does better than the fine tuned model just out of the box.  We saw that with gpt4 and that trend is likely to continue.  As such, fine tuning is unlikely to be a reasonable moat for most players.

Message : I think multinationals too will move to start using them. Their models are quite good and it is just a matter of time.

Message : They do need more data, just not api platform customer data.

They have sufficient data partnerships, etc.  This was their response to a very direct question when I was in their office.
Quoted Message : OpenAI not needing data: Highly doubt that claim, they like everyone else would happily take more data. Esp when they are out of training data for GPT (they have exhausted text data). But also as feedback for fine-tuning layers like RLHF. The key there is they don't use API day, chatting on website probably will be used as is (which they say as well, in the free version). Ideally if they really don't need data, they should give a zero knowledge guarantee. They don't use input or output. But could they use intermediate layer info, can their folks eyeball it to improve the system. All those are probably open questions.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00001565-PHOTO-2023-04-25-22-32-00.jpg>

Message : Thanks for this. Could be helpful for us.
Quoted Message :  2023_04_25_3ACA6C8026AF96321496.jpeg

Message : They did say in an email that all data is deleted within 30 days and it‚Äôs not used for training

Message : https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt - turnoff chat history on chatgpt

Message : Already did this. Like how this is fine print on the website since Sam said the purpose of releasing chatgpt to the world was (high frequency / diverse) user feedback.
Quoted Message : https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt - turnoff chat history on chatgpt

Message : *this was

Message : Openai doesn't need customer data to improve models at this stage.    No data sent over api by platform customers has ever been used.  When asked about it, they said they are just keeping the data around for 30 days for trust and safety.

As regards fine tuning, apart from it often not doing as well as prompt engineering, the other risk is that when a new model upgrade comes, it usually does better than the fine tuned model just out of the box.  We saw that with gpt4 and that trend is likely to continue.  As such, fine tuning is unlikely to be a reasonable moat for most players.

Message : OpenAI not needing data: Highly doubt that claim, they like everyone else would happily take more data. Esp when they are out of training data for GPT (they have exhausted text data). But also as feedback for fine-tuning layers like RLHF. The key there is they don't use API day, chatting on website probably will be used as is (which they say as well, in the free version). Ideally if they really don't need data, they should give a zero knowledge guarantee. They don't use input or output. But could they use intermediate layer info, can their folks eyeball it to improve the system. All those are probably open questions.
Quoted Message : Openai doesn't need customer data to improve models at this stage.    No data sent over api by platform customers has ever been used.  When asked about it, they said they are just keeping the data around for 30 days for trust and safety.\n\nAs regards fine tuning, apart from it often not doing as well as prompt engineering, the other risk is that when a new model upgrade comes, it usually does better than the fine tuned model just out of the box.  We saw that with gpt4 and that trend is likely to continue.  As such, fine tuning is unlikely to be a reasonable moat for most players.

Message : I think multinationals too will move to start using them. Their models are quite good and it is just a matter of time.

Message : They do need more data, just not api platform customer data.

They have sufficient data partnerships, etc.  This was their response to a very direct question when I was in their office.
Quoted Message : OpenAI not needing data: Highly doubt that claim, they like everyone else would happily take more data. Esp when they are out of training data for GPT (they have exhausted text data). But also as feedback for fine-tuning layers like RLHF. The key there is they don't use API day, chatting on website probably will be used as is (which they say as well, in the free version). Ideally if they really don't need data, they should give a zero knowledge guarantee. They don't use input or output. But could they use intermediate layer info, can their folks eyeball it to improve the system. All those are probably open questions.

Message : Data Partnership: Interesting.
Quoted Message : They do need more data, just not api platform customer data.\n\nThey have sufficient data partnerships, etc.  This was their response to a very direct question when I was in their office.

Message : Anyone have a list of data partners for Open AI?

Message : Nah... They don't talk about how they train their new models either in terms of data or architecture...  Their platform api  data policy is public info though...
Quoted Message : Anyone have a list of data partners for Open AI?

Message : I spent a day in march at openai office when they have invited some startups. They are very much looking to get more data to train their models from the industry because they have exhausted internet and academic datasets. However their organization is so small that they are able to cater to partnership proposals only from the biggest tech companies right now, all of which are lining up at their door. Over time they may get to your request.

Message : ‚Äé<attached: 00001584-PHOTO-2023-04-26-09-50-55.jpg>

Message : Woah, it would have easily made 90%'ile in my undergrad randomized algo course at IIT.
Quoted Message :  2023_04_26_3EB0334088892FC322B779.jpeg

Message : If it helps, BITS Pilani did not have a randomized algo course ‚Äî we had a design and analysis of algorithms, which was more analysis than design: And even Turbo does better than on those questions (specially speed!) than I do even today üòÖ
Quoted Message : Woah, it would have easily made 90%'ile in my undergrad randomized algo course at IIT.

Message : Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics

Built by former head of Google AI, less than 10-15 days of training perhaps üòÖ
https://twitter.com/amasad/status/1651019556423598081

Message : Apparently they built this under 2 weeks
Quoted Message : Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics\n\nBuilt by former head of Google AI, less than 10-15 days of training perhaps üòÖ\nhttps://twitter.com/amasad/status/1651019556423598081

Message : https://twitter.com/Mascobot/status/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19

Code + text datasets improves LLM performance at non-code tasks

Don't think this is discussed much
Quoted Message : Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics\n\nBuilt by former head of Google AI, less than 10-15 days of training perhaps üòÖ\nhttps://twitter.com/amasad/status/1651019556423598081

Message : Widely known no? Even GPT3.5-turbo and GPT4 are a Codex iteration, not vanilla LLM?
Quoted Message : https://twitter.com/Mascobot/status/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19\n\nCode + text datasets improves LLM performance at non-code tasks\n\nDon't think this is discussed much

Message : Widely known to maybe scientists, not discussed much I feel

Someone was telling me that the probable reason for the same is the fact that most consumers of the tech this time around are outside of core ML

Message : Fair, I might be suffering some form of inside-track groupthink here üòÖ

Also, _how_ the models are made isn't widely useful, is it?
Quoted Message : Widely known to maybe scientists, not discussed much I feel\n\nSomeone was telling me that the probable reason for the same is the fact that most consumers of the tech this time around are outside of core ML

Message : To many, I wouldn't think it does

And the economics enthusiast in me likes it as it could be early signs of this tech becoming a utility (?)

Message : Aligned, it's a utility like ec2 in 3 years or sooner
Quoted Message : To many, I wouldn't think it does\n\nAnd the economics enthusiast in me likes it as it could be early signs of this tech becoming a utility (?)

Message : 100% - this is the difference between AI now and 5 years back.
Quoted Message : Widely known to maybe scientists, not discussed much I feel\n\nSomeone was telling me that the probable reason for the same is the fact that most consumers of the tech this time around are outside of core ML

Message : The UX of consuming models was not great up until openai came into the picture.

Message : Still kinda sad that HF hasn't learned this well enough tbh
Quoted Message : The UX of consuming models was not great up until openai came into the picture.

Message : Once we have a well supported IR which works across all platforms, serving and consuming models from source would become a lot easier too.

Message : They were born at a different time. Compared to their competition at that time(2017-18) they have done well.
Quoted Message : Still kinda sad that HF hasn't learned this well enough tbh

Message : Almost everyone who does NLP now makes their models work their transformer library.

Message : In 2018 we spent half a day finding out how to use a model someone trained lol

Message : UX bhi and ML application development pipeline bhi üòÖ

Feature engineering et al was too complex for most companies to get going with AI
Quoted Message : The UX of consuming models was not great up until openai came into the picture.

Message : Stanford NLP ü§åüèº
Quoted Message : In 2018 we spent half a day finding out how to use a model someone trained lol

Message : https://www.reddit.com/r/StableDiffusion/comments/12yzd2a/google_researchers_achieve_performance/

Message : Anyone working on ML on edge here?

Message : This looks big

Message : Some of this stuff like flash attention is generally applicable even on servers
Quoted Message : Anyone working on ML on edge here?

Message : Wow!
Quoted Message : https://www.reddit.com/r/StableDiffusion/comments/12yzd2a/google_researchers_achieve_performance/

Message : https://www.qualcomm.com/news/onq/2023/02/worlds-first-on-device-demonstration-of-stable-diffusion-on-android

Message : Some earlier work from Qualcomm

Message : Pretty cool. Quite interesting that there is a huge jump from chatGPT. Will try this on the JEE ones we all were trying.
Quoted Message :  2023_04_26_3EB0334088892FC322B779.jpeg

Message : Palantir launches ChatGPT for war 
https://twitter.com/KennethCassel/status/1650958033034309633

Message : Damn expect anduril to come up with something too

Message : The full video link for those who are interested in involvement of tech in defence and future wars

https://youtu.be/XEM5qz__HOU
Quoted Message : Palantir launches ChatGPT for war \nhttps://twitter.com/KennethCassel/status/1650958033034309633

Message : this makes me sad

Message : I hate that their tech usecases go from disaster relief efforts straight to drone warfare

Message : ‚Äé<attached: 00001626-PHOTO-2023-04-26-13-41-07.jpg>

Message : Well for one, this is clear proof that programmers are god living among us ‚ò∫Ô∏è
Quoted Message : https://twitter.com/Mascobot/status/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19\n\nCode + text datasets improves LLM performance at non-code tasks\n\nDon't think this is discussed much

Message : Only 2 ML engineers that too :)
Quoted Message : Well for one, this is clear proof that programmers are god living among us ‚ò∫Ô∏è


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Some earlier work from Qualcomm

Message : Pretty cool. Quite interesting that there is a huge jump from chatGPT. Will try this on the JEE ones we all were trying.
Quoted Message :  2023_04_26_3EB0334088892FC322B779.jpeg

Message : Palantir launches ChatGPT for war 
https://twitter.com/KennethCassel/status/1650958033034309633

Message : Damn expect anduril to come up with something too

Message : The full video link for those who are interested in involvement of tech in defence and future wars

https://youtu.be/XEM5qz__HOU
Quoted Message : Palantir launches ChatGPT for war \nhttps://twitter.com/KennethCassel/status/1650958033034309633

Message : this makes me sad

Message : I hate that their tech usecases go from disaster relief efforts straight to drone warfare

Message : ‚Äé<attached: 00001626-PHOTO-2023-04-26-13-41-07.jpg>

Message : Well for one, this is clear proof that programmers are god living among us ‚ò∫Ô∏è
Quoted Message : https://twitter.com/Mascobot/status/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19\n\nCode + text datasets improves LLM performance at non-code tasks\n\nDon't think this is discussed much

Message : Only 2 ML engineers that too :)
Quoted Message : Well for one, this is clear proof that programmers are god living among us ‚ò∫Ô∏è

Message : Any idea how 10 days of traning time translates to total gpu time spent, i.e. including experiments?
Quoted Message : Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics\n\nBuilt by former head of Google AI, less than 10-15 days of training perhaps üòÖ\nhttps://twitter.com/amasad/status/1651019556423598081

Message : I‚Äôve worked with Pete Warden and the tinyml folks at Google, used to be with the company that owns the accelerators for their voice wake, happy to chat !
Quoted Message : Anyone working on ML on edge here?

Message : Wonderful!
Quoted Message : I‚Äôve worked with Pete Warden and the tinyml folks at Google, used to be with the company that owns the accelerators for their voice wake, happy to chat !

Message : Will DM

Message : ‚Äé~‚ÄØNirant changed the group description

Message : ‚Äé~‚ÄØNirant changed the group description

Message : Anyone knows how they did it with 1/10th the parameter count?

More training data?
More training cycles?
Better quality of data from their platform?
Quoted Message : Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics\n\nBuilt by former head of Google AI, less than 10-15 days of training perhaps üòÖ\nhttps://twitter.com/amasad/status/1651019556423598081

Message : Keeping it coming pls. Beginner insights most welcome Some of us still noobs in the group. 3 month old industry for us üòÇ
Quoted Message : Fair, I might be suffering some form of inside-track groupthink here üòÖ\n\nAlso, _how_ the models are made isn't widely useful, is it?

Message : Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM üôè üéº

Message : Doesn't look like they've some unfair data (qty or quality advantage) ‚Äî they just decided to test Chinchilla limits and that worked. They trained for a lot more tokens than most people have tried for similarly sized models. 

There was some research in Feb from the same guy who now works with Replit that existing LLMs might be overparameterized!
Quoted Message : Anyone knows how they did it with 1/10th the parameter count?\n\nMore training data?\nMore training cycles?\nBetter quality of data from their platform?

Message : PSA: Dedicated group for music, images, video: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J
Quoted Message : Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM üôè üéº

Message : If anyone remotely knows this person. An expert talk by then would be helpful ++
Quoted Message : Doesn't look like they've some unfair data (qty or quality advantage) ‚Äî they just decided to test Chinchilla limits and that worked. They trained for a lot more tokens than most people have tried for similarly sized models. \n\nThere was some research in Feb from the same guy who now works with Replit that existing LLMs might be overparameterized!

Message : them *

Message : Replit Demo Day videos are soon going to be on Youtube from what I hear
Quoted Message : If anyone remotely knows this person. An expert talk by then would be helpful ++

Message : To all the silent VCs in this group feeding this chat thread to an LLM, pls help üôè üòÇ

Message : Slide Deck from Accel's @91994530xxxx on opportunities in Generative AI, finetuning vs prompting and so on. Worth your 5 minutes. 

https://bit.ly/ai-webinar-ps

(Note: This is how it's supposed to be shared, have someone else e.g. one of the mods share your content)

Message : yeah will be up tomorrow - and the model should be released soon as well
Quoted Message : Replit Demo Day videos are soon going to be on Youtube from what I hear

Message : Thanks!
Quoted Message : Slide Deck from Accel's @9199xxxxxxxx on opportunities in Generative AI, finetuning vs prompting and so on. Worth your 5 minutes. \n\nhttps://bit.ly/ai-webinar-ps \n\n(Note: This is how it's supposed to be shared, have someone else e.g. one of the mods share your content)

Message : Thanks Anshul sir! Anshul sir @91997020xxxx leads Replit India
Quoted Message : yeah will be up tomorrow - and the model should be released soon as well

Message : ‚Äé<attached: 00001666-PHOTO-2023-04-26-16-33-16.jpg>

Message : Thanks! Was this a closed session?
Quoted Message : Slide Deck from Accel's @9199xxxxxxxx on opportunities in Generative AI, finetuning vs prompting and so on. Worth your 5 minutes. \n\nhttps://bit.ly/ai-webinar-ps \n\n(Note: This is how it's supposed to be shared, have someone else e.g. one of the mods share your content)

Message : Yes Sudharshan .. i did this for Accel funded startups - founders and tech teams
Quoted Message : Thanks! Was this a closed session?

Message : Alright thanks, was going to ask for invites to future sessions - this is really good

Message : https://twitter.com/matthieurouif/status/1650904940036890626

Smart - Suggests backgrounds for objects automatically

1) I think they use a multimodal model to understand the object
2) Ask GPT-4 to suggest backgrounds for the object
3) Generate appropriate backgrounds for the object

Message : The gpt-4 multimodal model has an api yet? I thought it was chatgpt only
Quoted Message : https://twitter.com/matthieurouif/status/1650904940036890626\n\nSmart - Suggests backgrounds for objects automatically\n\n1) I think they use a multimodal model to understand the object\n2) Ask GPT-4 to suggest backgrounds for the object\n3) Generate appropriate backgrounds for the object

Message : GPT4 takes text in and can generate prompt for a SD/Midjourney landscape
Quoted Message : The gpt-4 multimodal model has an api yet? I thought it was chatgpt only

Message : They use photoroom 
https://www.photoroom.com/api
Quoted Message : https://twitter.com/matthieurouif/status/1650904940036890626\n\nSmart - Suggests backgrounds for objects automatically\n\n1) I think they use a multimodal model to understand the object\n2) Ask GPT-4 to suggest backgrounds for the object\n3) Generate appropriate backgrounds for the object

Message : ‚Äé<attached: 00001677-PHOTO-2023-04-26-17-10-46.jpg>

Message : Not out, you can use https://minigpt-4.github.io/ or https://llava-vl.github.io/

Quite good
Quoted Message : The gpt-4 multimodal model has an api yet? I thought it was chatgpt only

Message : Doesn't have image understanding
Quoted Message : They use photoroom \nhttps://www.photoroom.com/api

Message : https://dust.tt is awesome!

Message : It's internal for now

Message : better than modal or runpod?
Quoted Message : https://dust.tt is awesome!

Message : Shared interest, please keep me posted on your connects !
Quoted Message : Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM üôè üéº

Message : It has an interesting ui for chaining prompts. I prefer python f-strings ofcourse, but the concept is interesting in its own
Quoted Message : better than modal or runpod?

Message : Dust.tt is amazing!
Quoted Message : https://dust.tt is awesome!

Message : Nice looking at the docs
Quoted Message : It has an interesting ui for chaining prompts. I prefer python f-strings ofcourse, but the concept is interesting in its own

Message : i don't get it. what's novel about this? segment, get image caption using any model blip, sam etc. then prompt gpt-4 to create background for photoshoot. then inpaint. right?

i only have doubt regarding how the shadow of the knight is added, does inpainting take care of that?

does one really need photoroom models specifically to achieve similar results?
Quoted Message : https://twitter.com/matthieurouif/status/1650904940036890626\n\nSmart - Suggests backgrounds for objects automatically\n\n1) I think they use a multimodal model to understand the object\n2) Ask GPT-4 to suggest backgrounds for the object\n3) Generate appropriate backgrounds for the object

Message : https://www.linkedin.com/posts/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios

AI-Generated Pizza Commercial

Tools used:

- Script: GPT4
- Images: Midjourney
- Video Clips: Runway Gen2
- VO: Eleven Labs
- Music: SOUNDRAW AI Music
- Graphics and editing: Adobe After Effects

Message : @91705412xxxx is playing with music gen these days
Quoted Message : Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM üôè üéº


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://dust.tt is awesome!

Message : It's internal for now

Message : better than modal or runpod?
Quoted Message : https://dust.tt is awesome!

Message : Shared interest, please keep me posted on your connects !
Quoted Message : Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM üôè üéº

Message : It has an interesting ui for chaining prompts. I prefer python f-strings ofcourse, but the concept is interesting in its own
Quoted Message : better than modal or runpod?

Message : Dust.tt is amazing!
Quoted Message : https://dust.tt is awesome!

Message : Nice looking at the docs
Quoted Message : It has an interesting ui for chaining prompts. I prefer python f-strings ofcourse, but the concept is interesting in its own

Message : i don't get it. what's novel about this? segment, get image caption using any model blip, sam etc. then prompt gpt-4 to create background for photoshoot. then inpaint. right?

i only have doubt regarding how the shadow of the knight is added, does inpainting take care of that?

does one really need photoroom models specifically to achieve similar results?
Quoted Message : https://twitter.com/matthieurouif/status/1650904940036890626\n\nSmart - Suggests backgrounds for objects automatically\n\n1) I think they use a multimodal model to understand the object\n2) Ask GPT-4 to suggest backgrounds for the object\n3) Generate appropriate backgrounds for the object

Message : https://www.linkedin.com/posts/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios

AI-Generated Pizza Commercial

Tools used:

- Script: GPT4
- Images: Midjourney
- Video Clips: Runway Gen2
- VO: Eleven Labs
- Music: SOUNDRAW AI Music
- Graphics and editing: Adobe After Effects

Message : @91705412xxxx is playing with music gen these days
Quoted Message : Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM üôè üéº

Message : Novelty isn't the only dimension. Ease of use is greatly improved and tons of Shopify stores which sell everything from soaps and other trinkets would love this. 

Not to mention IG influencers, and their teams :)
Quoted Message : i don't get it. what's novel about this? segment, get image caption using any model blip, sam etc. then prompt gpt-4 to create background for photoshoot. then inpaint. right?\n\ni only have doubt regarding how the shadow of the knight is added, does inpainting take care of that?\n\ndoes one really need photoroom models specifically to achieve similar results?

Message : oh totally agreed! my initial impression from the post here was that there's something new... technically speaking (as a lot of folks here are technical). 

hence the question :)
Quoted Message : Novelty isn't the only dimension. Ease of use is greatly improved and tons of Shopify stores which sell everything from soaps and other trinkets would love this. \n\nNot to mention IG influencers, and their teams :)

Message : The application.
Quoted Message : i don't get it. what's novel about this? segment, get image caption using any model blip, sam etc. then prompt gpt-4 to create background for photoshoot. then inpaint. right?\n\ni only have doubt regarding how the shadow of the knight is added, does inpainting take care of that?\n\ndoes one really need photoroom models specifically to achieve similar results?

Message : Went through this, this is very useful

Do count me in as well for the next in person or online sessions üôÇ
Quoted Message : Slide Deck from Accel's @9199xxxxxxxx on opportunities in Generative AI, finetuning vs prompting and so on. Worth your 5 minutes. \n\nhttps://bit.ly/ai-webinar-ps \n\n(Note: This is how it's supposed to be shared, have someone else e.g. one of the mods share your content)

Message : Resharing the link, as someone has recently joined and is curious about the deck DM'ed 

https://bit.ly/ai-webinar-ps

Message : Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling

Message : How's the availability on Amazon Sagemaker?

Should be good for hobby use-cases I'd guess
Quoted Message : Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling

Message : Might not be applicable for everyone, but I think by far the fastest and best experience would be to apply for google cloud startup credits, and use a dedicated A100 for colab.

https://cloud.google.com/startup

https://research.google.com/colaboratory/marketplace.html
Quoted Message : Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling

Message : Jupiter on VS Code with Banana on backend will cost ‚Çπ150/hour. 

Deepnote offers a hosted service with a great free tier for this too but not on best GPUs.
Quoted Message : Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling

Message : ^ banana.dev also has a great free tier for 1 hour of use

Message : Should still be good for tinkering use-cases I'd guess?
Quoted Message : Jupiter on VS Code with Banana on backend will cost ‚Çπ150/hour. \n\nDeepnote offers a hosted service with a great free tier for this too but not on best GPUs.

Message : Really nice for notebooks / automation / scripting 
https://deepnote.com/

Message : Yes. Community model templates allow one click deployment. For 50+ models. Simple docs.
Quoted Message : Should still be good for tinkering use-cases I'd guess?

Message : Kaggle
Quoted Message : Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling

Message : I want to experiment with deploying StableDiffusion and running Gradio/Automatic1111 ... will also want to keep some of the models like Lyriel / Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase

Message : You can try paperspace, they are undercutting big tech on GPUs. https://www.paperspace.com
Quoted Message : Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling

Message : they have 5GB space on the Gradient .. üôÅ
Quoted Message : You can try paperspace, they are undercutting big tech on GPUs. https://www.paperspace.com

Message : ‚Äé<attached: 00001719-PHOTO-2023-04-26-18-47-49.jpg>

Message : Google Colab is $12 - and 50GB

Message : I have been using my Mac Pro as a server at home + socket + multiple LMs. Works like a charm :)
Quoted Message : I want to experiment with deploying StableDiffusion and running Gradio/Automatic1111 ... will also want to keep some of the models like Lyriel / Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase

Message : You can keep the model storage on hugging face and then use any serverless gpu player to import your model from there directly.
Quoted Message : I want to experiment with deploying StableDiffusion and running Gradio/Automatic1111 ... will also want to keep some of the models like Lyriel / Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase

Message : Will try this !
Quoted Message : You can keep the model storage on hugging face and then use any serverless gpu player to import your model from there directly.

Message : ‚Äé<attached: 00001724-PHOTO-2023-04-26-18-53-11.jpg>

Message : ‚Äé~‚ÄØNirant changed the group description

Message : ‚Äé<attached: 00001732-PHOTO-2023-04-26-19-40-23.jpg>

Message : This doesn't work, start up credits cannot be used for colab, they have separate billing
Quoted Message : Might not be applicable for everyone, but I think by far the fastest and best experience would be to apply for google cloud startup credits, and use a dedicated A100 for colab.\n\nhttps://cloud.google.com/startup\n\nhttps://research.google.com/colaboratory/marketplace.html

Message : Yes, but now you can connect a gce vm to colab, giving you persistent sessions and dedicated compute
Quoted Message : This doesn't work, start up credits cannot be used for colab, they have separate billing

Message : https://research.google.com/colaboratory/marketplace.html

Message : Can recommend runpod, stop the instance when not using, will only be charged for storage

Similar options for jarvislabs, paperspace

At one point we using paperspace but then they kept running out of affordable GPUs like rtx5000, so switched, but things might have changed now
Quoted Message : I want to experiment with deploying StableDiffusion and running Gradio/Automatic1111 ... will also want to keep some of the models like Lyriel / Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase

Message : Buy a 3080 machine. Looks like we are moving back to a world where we all have a desktop at home üòÖ
Quoted Message : I want to experiment with deploying StableDiffusion and running Gradio/Automatic1111 ... will also want to keep some of the models like Lyriel / Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase

Message : On a more serious note, runpod, lambdalabs, fluidstack. Keep moving around üòÖ

Message : Finally buckled to Google Colab - 100 compute units for 12$ - 2 units per hour for StableDiffusion stuff that I'm doing - so 50 hours of stable diffusion for 1000 rs or 20rs / hour FYI.

Message : Does anyone know what compute units mean?

Message : ‚Äé<attached: 00001741-PHOTO-2023-04-26-20-55-21.jpg>

Message : I asked gpt. this maybe helpful

For example, a Tesla K80 GPU, which is one of the most commonly used GPUs on Google Colab, provides approximately 12 compute units per hour. This means that if you use a Tesla K80 GPU for an hour, you will be charged for 12 compute units
Quoted Message : Does anyone know what compute units mean?

Message : Back to On Prime? üòÇ
Quoted Message : Buy a 3080 machine. Looks like we are moving back to a world where we all have a desktop at home üòÖ

Message : What GPU do they offer at this price? How much RAM for SD?
Quoted Message : Finally buckled to Google Colab - 100 compute units for 12$ - 2 units per hour for StableDiffusion stuff that I'm doing - so 50 hours of stable diffusion for 1000 rs or 20rs / hour FYI.

Message : T4 24GB think for this rate

Message : "No One Knows What It Means But It's Provocative, It Gets The People Going" ü§£
Quoted Message : Does anyone know what compute units mean?

Message : Are these instances persistent? Or do yoh still have to do the google drive hack
Quoted Message :  2023_04_26_3EB0A76DA53C2C69F69E5D.jpeg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : On a more serious note, runpod, lambdalabs, fluidstack. Keep moving around üòÖ

Message : Finally buckled to Google Colab - 100 compute units for 12$ - 2 units per hour for StableDiffusion stuff that I'm doing - so 50 hours of stable diffusion for 1000 rs or 20rs / hour FYI.

Message : Does anyone know what compute units mean?

Message : ‚Äé<attached: 00001741-PHOTO-2023-04-26-20-55-21.jpg>

Message : I asked gpt. this maybe helpful

For example, a Tesla K80 GPU, which is one of the most commonly used GPUs on Google Colab, provides approximately 12 compute units per hour. This means that if you use a Tesla K80 GPU for an hour, you will be charged for 12 compute units
Quoted Message : Does anyone know what compute units mean?

Message : Back to On Prime? üòÇ
Quoted Message : Buy a 3080 machine. Looks like we are moving back to a world where we all have a desktop at home üòÖ

Message : What GPU do they offer at this price? How much RAM for SD?
Quoted Message : Finally buckled to Google Colab - 100 compute units for 12$ - 2 units per hour for StableDiffusion stuff that I'm doing - so 50 hours of stable diffusion for 1000 rs or 20rs / hour FYI.

Message : T4 24GB think for this rate

Message : "No One Knows What It Means But It's Provocative, It Gets The People Going" ü§£
Quoted Message : Does anyone know what compute units mean?

Message : Are these instances persistent? Or do yoh still have to do the google drive hack
Quoted Message :  2023_04_26_3EB0A76DA53C2C69F69E5D.jpeg

Message : ‚Äé<attached: 00001748-PHOTO-2023-04-26-20-59-23.jpg>

Message : not persistent
Quoted Message : Are these instances persistent? Or do yoh still have to do the google drive hack

Message : Which platform is this?
Quoted Message :  2023_04_26_3A160FE850F5D3307FE6.jpeg

Message : Google cloud
Quoted Message : Which platform is this?

Message : For non persistent / spot instances of GPUs GOOG was always in under supply while we were testing. 

Hence spot prices there are always cheaper than reserved prices; but you don‚Äôt get them on time in real time inference at various times.
Quoted Message : Are these instances persistent? Or do yoh still have to do the google drive hack

Message : https://www.chartgpt.dev/

Very nifty product this, loved it

Message : https://news.ycombinator.com/item?id=35697627

Some very interesting discussions/comments in the thread

Message : For anyone using Weaviate, do you store all of your metadata in Weaviate or in a different DB?

Message : Context: I'm using Pinecone and I'm saving most of my content in a different db (pinecone has a limit on size of meta data). Want to know if that is required / recommended for other Vector DBs like Weaviate

Message : whats the major difference between storing it in vector dbs and something like a numpy array? is retrieval super fast for say 1000s of vectors
Quoted Message : For anyone using Weaviate, do you store all of your metadata in Weaviate or in a different DB?

Message : Yep, our app allows users embed content so we need containerization + expect this to increase significantly (ü§û). If you are building a vertical app (only embedding content yourself), numpy is probably ok - others probably have a better view tho

Message : https://www.youtube.com/watch?v=7TCqGslll-4

Message : https://github.com/ai-forever/Kandinsky-2

Came across a cool looking text2img model

Message : https://twitter.com/rasbt/status/1651226178353614854?s=48&t=ACPHEfclkXmi9Z92RTsh9g

Message : @91748395xxxx
Quoted Message : https://twitter.com/rasbt/status/1651226178353614854?s=48&t=ACPHEfclkXmi9Z92RTsh9g

Message : In Weaviate itself. It also allows to do pre filtered vector search based on the metadata, it internally builds separate indices for the metadata as well.
Quoted Message : For anyone using Weaviate, do you store all of your metadata in Weaviate or in a different DB?

Message : Oh cool, so you could store everything in weviate? Is the cost prohibitive? For example, if metadata is chunks of text
Quoted Message : In Weaviate itself. It also allows to do pre filtered vector search based on the metadata, it internally builds separate indices for the metadata as well.

Message : Their managed SaaS  right now actually charges only based on the number of vectors and the dimensions of the vectors, irrespective of the extra metadata stored

https://weaviate.io/pricing
Quoted Message : Oh cool, so you could store everything in weviate? Is the cost prohibitive? For example, if metadata is chunks of text

Message : Replit's latest announcement is interesting: https://twitter.com/swyx/status/1650989632413401089?s=20

Message : Anyone started learning LLMs/Transformers/ML in the last 3 months?
I‚Äôd like to discuss and exchange notes üòÅ

Message : Let‚Äôs do a zoom session to discuss?
Quoted Message : Anyone started learning LLMs/Transformers/ML in the last 3 months?\nI‚Äôd like to discuss and exchange notes üòÅ

Message : How are people here dealing with rate limits, 5xx with OpenAI? Exponential backoff is what we have but its such poor UX

Message : bumping - has anyone been able to solve?
Quoted Message : Is anyone using GPT4 in prod? I'm sending gpt-4 as the model but its still using gpt-4-0314. Have heard gpt-4 is much more faster than the 0314

Message : I faced this problem before. We used some form of leaky bucket to smoothen the API calling rate.
Quoted Message : How are people here dealing with rate limits, 5xx with OpenAI? Exponential backoff is what we have but its such poor UX

Message : Not particularly for OpenAI but for a general solution for limiting API calling rates.

Message : 429s, use the retry-after. Are you getting rate limited for requests or tokenS?

500s - random jitter back off with fallbacks to 3.5 is the better experience
Quoted Message : How are people here dealing with rate limits, 5xx with OpenAI? Exponential backoff is what we have but its such poor UX

Message : all types of errors now. I wish there was a middle layer to solve this
Quoted Message : 429s, use the retry-after. Are you getting rate limited for requests or tokenS?\n\n500s - random jitter back off with fallbacks to 3.5 is the better experience

Message : :)
Quoted Message : all types of errors now. I wish there was a middle layer to solve this

Message : Any proxies like Nginx with Lua JIT or Envoy with WASM/Lua can be used for production setup without adding any much latency and performance overhead.
Quoted Message : all types of errors now. I wish there was a middle layer to solve this

Message : Can you elaborate and/or share links? Hearing about Lua JIT and WASM in this context for the first time üòÖ
Quoted Message : Any proxies like Nginx with Lua JIT or Envoy with WASM/Lua can be used for production setup without adding any much latency and performance overhead.

Message : https://openresty.org/en/
Quoted Message : Can you elaborate and/or share links? Hearing about Lua JIT and WASM in this context for the first time üòÖ

Message : https://tetrate.io/blog/wasm-modules-and-envoy-extensibility-explained-part-1/

Message : These enovy, istio, nginx are API proxy and they have a customised layer where we can add multiple filters. These filters can extend functionality. Which you can write in Lua, Wasm etc. Lua interpreters bring less overhead and way faster than python interpreter.

Message : Things like if you are testing multiple models on production one is main other are tests. And you like to send prod requests to all and then like to monitor outcomes. For this generally you need to write code. But in the case of these proxies you simply need to write small Lua or even yaml. And this proxy itself sends requests to all these services (which host models) and passes the response of the main service to the caller/client. 
Actually there are multiple ways to achieve the same thing, this one is from DevOps/SRE perspective üòÖ

Message : Thanks to those who reached out. 
Thinking of proceeding this way:
- Resources are being compiled here - https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240
- To participate (AKA edit the sheet ; discus on what else we can do) ping me
Quoted Message : Anyone started learning LLMs/Transformers/ML in the last 3 months?\nI‚Äôd like to discuss and exchange notes üòÅ

Message : Hey, I have been trying to train Indic-BloomLM (bloom finetuned on Indian language dataset via LoRA). I am stuck with this weird bug that everytime the forward pass happens it keeps occupying more and more gpu memory and then runs out of it. (Have tried all batch + gradient accumulation + gradient checkpoint combos). 
This is the closest issue I have seen to my problem - https://github.com/huggingface/peft/issues/161

Anyone has any idea/has previously solved this. It would be great to connect. I have been banging my head on this for a few days now.

Message : Guys quick question. 

What does the model suffix stand for?
Eg.
gpt-3.5-turbo
gpt-3.5-turbo-0301

Message : ‚Äé<attached: 00001790-PHOTO-2023-04-27-10-52-37.jpg>
Quoted Message : Guys quick question. \n\nWhat does the model suffix stand for? \nEg. \ngpt-3.5-turbo\ngpt-3.5-turbo-0301

Message : https://twitter.com/raj_raj88/status/1631018786492157954
Quoted Message : Guys quick question. \n\nWhat does the model suffix stand for? \nEg. \ngpt-3.5-turbo\ngpt-3.5-turbo-0301

Message : i guess 302, 303 etc. are later versions


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://openresty.org/en/
Quoted Message : Can you elaborate and/or share links? Hearing about Lua JIT and WASM in this context for the first time üòÖ

Message : https://tetrate.io/blog/wasm-modules-and-envoy-extensibility-explained-part-1/

Message : These enovy, istio, nginx are API proxy and they have a customised layer where we can add multiple filters. These filters can extend functionality. Which you can write in Lua, Wasm etc. Lua interpreters bring less overhead and way faster than python interpreter.

Message : Things like if you are testing multiple models on production one is main other are tests. And you like to send prod requests to all and then like to monitor outcomes. For this generally you need to write code. But in the case of these proxies you simply need to write small Lua or even yaml. And this proxy itself sends requests to all these services (which host models) and passes the response of the main service to the caller/client. 
Actually there are multiple ways to achieve the same thing, this one is from DevOps/SRE perspective üòÖ

Message : Thanks to those who reached out. 
Thinking of proceeding this way:
- Resources are being compiled here - https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240
- To participate (AKA edit the sheet ; discus on what else we can do) ping me
Quoted Message : Anyone started learning LLMs/Transformers/ML in the last 3 months?\nI‚Äôd like to discuss and exchange notes üòÅ

Message : Hey, I have been trying to train Indic-BloomLM (bloom finetuned on Indian language dataset via LoRA). I am stuck with this weird bug that everytime the forward pass happens it keeps occupying more and more gpu memory and then runs out of it. (Have tried all batch + gradient accumulation + gradient checkpoint combos). 
This is the closest issue I have seen to my problem - https://github.com/huggingface/peft/issues/161

Anyone has any idea/has previously solved this. It would be great to connect. I have been banging my head on this for a few days now.

Message : Guys quick question. 

What does the model suffix stand for?
Eg.
gpt-3.5-turbo
gpt-3.5-turbo-0301

Message : ‚Äé<attached: 00001790-PHOTO-2023-04-27-10-52-37.jpg>
Quoted Message : Guys quick question. \n\nWhat does the model suffix stand for? \nEg. \ngpt-3.5-turbo\ngpt-3.5-turbo-0301

Message : https://twitter.com/raj_raj88/status/1631018786492157954
Quoted Message : Guys quick question. \n\nWhat does the model suffix stand for? \nEg. \ngpt-3.5-turbo\ngpt-3.5-turbo-0301

Message : i guess 302, 303 etc. are later versions

Message : Not clear to me what does snapshop mean here. If this model is to be deprecated in 3 months, what's the need in the forst place. Is there a specific reason of not following conventional versioning. Would appreciate if someone can eli5
Quoted Message :  2023_04_27_3A2E64D953B53853F9DC.jpeg

Message : Think of a continuous model training process with multiple forks, each "named" or versioned model is a actually a checkpoint in that. 

So if you want to build on the latest model, the underlying behaviour might keep changing ‚Äî so they're giving a named version for that, but it'll be deprecated. This ensures that the _behaviour_ change is explicit instead of implicit.
Quoted Message : Not clear to me what does snapshop mean here. If this model is to be deprecated in 3 months, what's the need in the forst place. Is there a specific reason of not following conventional versioning. Would appreciate if someone can eli5

Message : Workflow wise: Say you build on 0314 or any other 3 month model, when it gets deprecated, you have to explicitly upgrade and you'll be prepared to run your entire battery of tests again. This is better than a silent upgrade where the behaviour of underlying model changes silently.

Message : Does this help?

Message : Yes but basis this tweet https://twitter.com/raj_raj88/status/1631018786492157954 my understanding is 3.5-turbo refers to the latest model 3.5-turbo-x 

If both model refer to the latest checkpoint then what's the need of retaining the snapshot explicitly - got me confused.

Message : Let me move this to DM, need to understand your query better üòÖ
Quoted Message : Yes but basis this tweet https://twitter.com/raj_raj88/status/1631018786492157954 my understanding is 3.5-turbo refers to the latest model 3.5-turbo-x \n\nIf both model refer to the latest checkpoint then what's the need of retaining the snapshot explicitly - got me confused.

Message : Might be useful for you,i was trying to train a Bloom model  and i was running out of GPU memory..and this gradient notebook helped me https://github.com/rasbt/gradient-accumulation-blog/blob/main/src/1_batchsize-1.py where if we want to use a batch size of 256 but can only fit a batch size of 64 into GPU memory, we can perform gradient accumulation over four batches of size 64. (After processing all four batches, we will have the accumulated gradients equivalent to a single batch of size 256.) This allows us to effectively emulate a larger batch size without requiring larger GPU memory or tensor sharding across different devices.
Quoted Message : Hey, I have been trying to train Indic-BloomLM (bloom finetuned on Indian language dataset via LoRA). I am stuck with this weird bug that everytime the forward pass happens it keeps occupying more and more gpu memory and then runs out of it. (Have tried all batch + gradient accumulation + gradient checkpoint combos). \nThis is the closest issue I have seen to my problem - https://github.com/huggingface/peft/issues/161\n\nAnyone has any idea/has previously solved this. It would be great to connect. I have been banging my head on this for a few days now.

Message : As I have mentioned, tried all possible combinations with gradient accumulation as well. Problem is of memory leak
Quoted Message : Might be useful for you,i was trying to train a Bloom model  and i was running out of GPU memory..and this gradient notebook helped me https://github.com/rasbt/gradient-accumulation-blog/blob/main/src/1_batchsize-1.py where if we want to use a batch size of 256 but can only fit a batch size of 64 into GPU memory, we can perform gradient accumulation over four batches of size 64. (After processing all four batches, we will have the accumulated gradients equivalent to a single batch of size 256.) This allows us to effectively emulate a larger batch size without requiring larger GPU memory or tensor sharding across different devices.

Message : If you are facing GPU constraints you can try using the quantized version and fine tuning using lora+ bits and bytes
Quoted Message : Hey, I have been trying to train Indic-BloomLM (bloom finetuned on Indian language dataset via LoRA). I am stuck with this weird bug that everytime the forward pass happens it keeps occupying more and more gpu memory and then runs out of it. (Have tried all batch + gradient accumulation + gradient checkpoint combos). \nThis is the closest issue I have seen to my problem - https://github.com/huggingface/peft/issues/161\n\nAnyone has any idea/has previously solved this. It would be great to connect. I have been banging my head on this for a few days now.

Message : Okay my bad I see you are already using peft
Quoted Message : If you are facing GPU constraints you can try using the quantized version and fine tuning using lora+ bits and bytes

Message : Based on cursory research, rundiffusion seems like a good hosted solution for automatic SD UI. 

If anyone has any gotchas using this please do tell üôè

I want to give my design team the UI to play with for a day or two.

Message : It's pretty good, just not that well known
Quoted Message : Based on cursory research, rundiffusion seems like a good hosted solution for automatic SD UI. \n\nIf anyone has any gotchas using this please do tell üôè\n\nI want to give my design team the UI to play with for a day or two.

Message : ‚Äé<attached: 00001806-PHOTO-2023-04-27-13-08-25.jpg>

Message : Hey Guys
I need some advice

I have a few deep learning projects which I have to run on GPU - can you tell me any service or firm name which I can consider ?
I am looking for a decent GPU - like V100 or A100 not very high end over cloud
I have used Colab pro - its useless - no use when the computing credits are over

Message : https://twitter.com/Replit/status/1651344182425051136?t=246tp7Zj7ABXzT7FXB936g&s=19

At the risk of sparking a debate on Smaller Models vs Larger Models for production workloads

What do people here think?

This is a surprising result by a team of 2 people and 10 days of training

Message : You can try qblocks.cloud
Quoted Message : Hey Guys\nI need some advice\n\nI have a few deep learning projects which I have to run on GPU - can you tell me any service or firm name which I can consider ?\nI am looking for a decent GPU - like V100 or A100 not very high end over cloud\nI have used Colab pro - its useless - no use when the computing credits are over

Message : Tried serverless GPUs like bananadev?
Quoted Message : Hey Guys\nI need some advice\n\nI have a few deep learning projects which I have to run on GPU - can you tell me any service or firm name which I can consider ?\nI am looking for a decent GPU - like V100 or A100 not very high end over cloud\nI have used Colab pro - its useless - no use when the computing credits are over

Message : I am using this. Comes to around 1 dollar for 24gb GPU
Quoted Message : You can try qblocks.cloud

Message : This is some kind of membership. Optional I think
Quoted Message :  2023_04_27_3EB0EECAE3DAE86CB05169.jpeg

Message : any devrels here ?

Message : This has some nice comparison of serverless platforms

https://www.inferless.com/serverless-gpu-market
Quoted Message : Hey Guys\nI need some advice\n\nI have a few deep learning projects which I have to run on GPU - can you tell me any service or firm name which I can consider ?\nI am looking for a decent GPU - like V100 or A100 not very high end over cloud\nI have used Colab pro - its useless - no use when the computing credits are over

Message : You‚Äôre welcome to try it out for yourself next week when it drops :)
Quoted Message : https://twitter.com/Replit/status/1651344182425051136?t=246tp7Zj7ABXzT7FXB936g&s=19\n\nAt the risk of sparking a debate on Smaller Models vs Larger Models for production workloads\n\nWhat do people here think?\n\nThis is a surprising result by a team of 2 people and 10 days of training

Message : Also the LLM relevant stuff is 46:00 onwards
Quoted Message : https://www.youtube.com/watch?v=7TCqGslll-4

Message : Already signed up & looking forward :)
Quoted Message : You‚Äôre welcome to try it out for yourself next week when it drops :)

Message : This is optional but might turn out to be cheaper if you are using it for high-velocity use cases. I have tried the Automatic1111 on SD V1.5 and is pretty decent for playing around.
Quoted Message : This is some kind of membership. Optional I think

Message : Has anyone gotten higher rate limits from OpenAI?

Message : cc @91981853xxxx has among the largest OpenAI bills in India, @91989995xxxx used to work with the same team

Message : Names please? üòÖ (I see Rohit‚Äôs)
Quoted Message : cc @9198xxxxxxxx has among the largest OpenAI bills in India, @9198xxxxxxxx used to work with the same team

Message : Can this be used to solve marketing problems?
Quoted Message : https://twitter.com/Replit/status/1651344182425051136?t=246tp7Zj7ABXzT7FXB936g&s=19\n\nAt the risk of sparking a debate on Smaller Models vs Larger Models for production workloads\n\nWhat do people here think?\n\nThis is a surprising result by a team of 2 people and 10 days of training

Message : Anirudh Singla of Pepper Content and Rohit (now of Portkey), earlier at Pepper Content
Quoted Message : Names please? üòÖ (I see Rohit‚Äôs)

Message : yes, we got it upgraded multiple times at Pepper. (This is Rohit)
Quoted Message : Has anyone gotten higher rate limits from OpenAI?

Message : was it for GPT4? or GPT3.5?
Quoted Message : yes, we got it upgraded multiple times at Pepper. (This is Rohit)

Message : Yes. Take usually 2-3 days. Applies for all incl gpt4
Quoted Message : Has anyone gotten higher rate limits from OpenAI?

Message : Applied via the google forms or something else. I tried it but never got reply from them. also they have not increased rate-limit too
Quoted Message : Yes. Take usually 2-3 days. Applies for all incl gpt4

Message : Stand corrected.. i misread it as quota increase.
We had applied for rate limit increase a few months back (in 3.5) - took 2/3 days based on what I recall
Quoted Message : Applied via the google forms or something else. I tried it but never got reply from them. also they have not increased rate-limit too

Message : Hi. I'm hosting a talk by two leading US researchers in AI at 7:30 PM in Indiranagar today. Here is a link for the same: https://lu.ma/StateofAI 
Sorry for the last minute invite. It is an ad-hoc event (got it all together in the last hour).

Message : We are limited¬†to¬†20¬†seats so pardon me if we're unable to accommodate all

Message : Just in the spirit of full disclosure: Please consider this a community event as well. Pranjal @91994014xxxx isn't doing self promotion here :).
Quoted Message : Hi. I'm hosting a talk by two leading US researchers in AI at 7:30 PM in Indiranagar today. Here is a link for the same: https://lu.ma/StateofAI \nSorry for the last minute invite. It is an ad-hoc event (got it all together in the last hour).

Message : Oh yes thanks. It's free and there are no affiliations. Just shared passion for AI
Quoted Message : Just in the spirit of full disclosure: Please consider this a community event as well. Pranjal @9199xxxxxxxx isn't doing self promotion here :).

Message : 20 seats is a venue constraint


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : yes, we got it upgraded multiple times at Pepper. (This is Rohit)
Quoted Message : Has anyone gotten higher rate limits from OpenAI?

Message : was it for GPT4? or GPT3.5?
Quoted Message : yes, we got it upgraded multiple times at Pepper. (This is Rohit)

Message : Yes. Take usually 2-3 days. Applies for all incl gpt4
Quoted Message : Has anyone gotten higher rate limits from OpenAI?

Message : Applied via the google forms or something else. I tried it but never got reply from them. also they have not increased rate-limit too
Quoted Message : Yes. Take usually 2-3 days. Applies for all incl gpt4

Message : Stand corrected.. i misread it as quota increase.
We had applied for rate limit increase a few months back (in 3.5) - took 2/3 days based on what I recall
Quoted Message : Applied via the google forms or something else. I tried it but never got reply from them. also they have not increased rate-limit too

Message : Hi. I'm hosting a talk by two leading US researchers in AI at 7:30 PM in Indiranagar today. Here is a link for the same: https://lu.ma/StateofAI 
Sorry for the last minute invite. It is an ad-hoc event (got it all together in the last hour).

Message : We are limited¬†to¬†20¬†seats so pardon me if we're unable to accommodate all

Message : Just in the spirit of full disclosure: Please consider this a community event as well. Pranjal @91994014xxxx isn't doing self promotion here :).
Quoted Message : Hi. I'm hosting a talk by two leading US researchers in AI at 7:30 PM in Indiranagar today. Here is a link for the same: https://lu.ma/StateofAI \nSorry for the last minute invite. It is an ad-hoc event (got it all together in the last hour).

Message : Oh yes thanks. It's free and there are no affiliations. Just shared passion for AI
Quoted Message : Just in the spirit of full disclosure: Please consider this a community event as well. Pranjal @9199xxxxxxxx isn't doing self promotion here :).

Message : 20 seats is a venue constraint

Message : @91773788xxxx truly missing your organising skills and energy today üòÖ

Message : Nirant is a one man army
Quoted Message : @9177xxxxxxxx truly missing your organising skills and energy today üòÖ

Message : We've hit capacity. Optimising for maximum participation by limiting it to one VC per firm. Please pardon üôè

Message : Any chance of a live stream/recording?

Message : It appears that way, but in practice, I'm simply the face for the work done by multiple folks e.g. @91740765xxxx, @91955016xxxx, @91903012xxxx, Hasgeek crew: @91994547xxxx and co
Quoted Message : Nirant is a one man army

Message : Don't have the infra/team. Sorry
Quoted Message : Any chance of a live stream/recording?

Message : ‚Äé<attached: 00001842-PHOTO-2023-04-27-17-43-55.jpg>

Message : Is this happening? üôÇ
Quoted Message : Let‚Äôs do a zoom session to discuss?

Message : Any recommended resources?
Quoted Message : Anyone started learning LLMs/Transformers/ML in the last 3 months?\nI‚Äôd like to discuss and exchange notes üòÅ

Message : Try training your own via huggingface. I did that and learnt a lot more (had to beat my head around a lot)
Quoted Message : Any recommended resources?

Message : 1. https://course.fast.ai ‚Äî probably the best there is 
2. CS25 on Transformers: https://web.stanford.edu/class/cs25/
3. HF Transformers Course: https://huggingface.co/learn/nlp-course/chapter1/1
Quoted Message : Any recommended resources?

Message : 3 is more NLP focussed, 2 is broader ranging from Vision to Speech and what not

Message : Thanks Aashay and Nirant.

Have added these to the earlier shared sheet.
Quoted Message : Thanks to those who reached out. \nThinking of proceeding this way:\n- Resources are being compiled here - https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240 \n- To participate (AKA edit the sheet ; discus on what else we can do) ping me

Message : could you pls reshare or perhaps link it in group desc

Message : https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240
Quoted Message : Thanks to those who reached out. \nThinking of proceeding this way:\n- Resources are being compiled here - https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240 \n- To participate (AKA edit the sheet ; discus on what else we can do) ping me

Message : It starts from scratch. Not sure if useful to many here. Anyway Admin‚Äôs call if they want to add it group  desc

Message : https://twitter.com/andrewyng/status/1651605660382134274?s=46&t=wdMpftHBI367157ViAY2Gg

Message : Pinecone raised 100m

Message : https://twitter.com/pinecone/status/1651602704647553028?t=4BEHwzuba9-bvJ_ocusDQQ&s=19

Message : It's having the nvidia moment in age of langchain , good to raise when you have the buzz
Quoted Message : https://twitter.com/pinecone/status/1651602704647553028?t=4BEHwzuba9-bvJ_ocusDQQ&s=19

Message : Yeah, also serendipity is a beautiful thing. Started in W15 cohort 8 years ago, to build for the vector search market. Raised series A after 7 years

And then Gen AI comes along and floods your TAM like a tsunami

Message : Took 8 years to be in the right place at right time. More power to them

Message : Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution!
Quoted Message : It's having the nvidia moment in age of langchain , good to raise when you have the buzz

Message : This.
Quoted Message : Took 8 years to be in the right place at right time. More power to them

Message : ‚Äé<attached: 00001860-PHOTO-2023-04-27-21-21-01.jpg>

Message : ‚Äé<attached: 00001861-PHOTO-2023-04-27-21-21-24.jpg>

Message : Woah! Have to say they‚Äôre good - literally 0 issues since we launched with them
Quoted Message : Pinecone raised 100m

Message : agreed, love his videos
Quoted Message : Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution!

Message : For anyone looking for them:

https://youtube.com/@jamesbriggs
Quoted Message : agreed, love his videos

Message : Oh absolutely,

This is true for any developer product and especially with emerging platform shifts

As new workflows emerge, there's new opportunity for tooling

Redis and Pinecone are very, very good with DevEx and DevRel around that
Quoted Message : Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution!

Message : I have a friend there and he was telling me about their production traction from India - it's significant

Message : any idea if these individuals devs using it or more startups / small companies?
Quoted Message : I have a friend there and he was telling me about their production traction from India - it's significant

Message : Startups/companies

We were talking about how to separate the control and data plane to adhere to data residency rules in India

And almost all of this traction is on AWS for the time being
Quoted Message : any idea if these individuals devs using it or more startups / small companies?

Message : yes / would love to know who all so can share learnings. We are at 20K vectors
Quoted Message : I have a friend there and he was telling me about their production traction from India - it's significant

Message : Their content game is also great. In most AI keywords they are within 5.
Quoted Message : Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution!

Message : https://www.databricks.com/blog/contributing-spark-loader-for-hugging-face-datasets

Message : Haan we can plan one on weekend. @91988071xxxx  would you want to take a lead on this?  cc @91773788xxxx
Quoted Message : Is this happening? üôÇ

Message : Sure
Quoted Message : Haan we can plan one on weekend. @9198xxxxxxxx  would you want to take a lead on this?  cc @9177xxxxxxxx

Message : ‚ÄéPOLL:
What time do you prefer for the Zoom discussion on ‚ÄúLearning Transformers / NLP / ML‚Äù
‚ÄéOPTION: Sat, 29th evening (5-6pm) (3 votes)
‚ÄéOPTION: Sat, 29th night (8-9pm) (4 votes)
‚ÄéOPTION: Sun, 30th morning (11-12pm) (2 votes)
‚ÄéOPTION: Sun, 30th evening (4-5pm) (39 votes)
‚ÄéOPTION: Sun, 30th night (8-9pm) (4 votes)
‚ÄéOPTION: Next weekend - Saturday (0 votes)
‚ÄéOPTION: Next weekend - Sunday (0 votes)

Message : (There is a Nvidia-HF event on Saturday morning, hence kept slots after that)


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I have a friend there and he was telling me about their production traction from India - it's significant

Message : any idea if these individuals devs using it or more startups / small companies?
Quoted Message : I have a friend there and he was telling me about their production traction from India - it's significant

Message : Startups/companies

We were talking about how to separate the control and data plane to adhere to data residency rules in India

And almost all of this traction is on AWS for the time being
Quoted Message : any idea if these individuals devs using it or more startups / small companies?

Message : yes / would love to know who all so can share learnings. We are at 20K vectors
Quoted Message : I have a friend there and he was telling me about their production traction from India - it's significant

Message : Their content game is also great. In most AI keywords they are within 5.
Quoted Message : Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution!

Message : https://www.databricks.com/blog/contributing-spark-loader-for-hugging-face-datasets

Message : Haan we can plan one on weekend. @91988071xxxx  would you want to take a lead on this?  cc @91773788xxxx
Quoted Message : Is this happening? üôÇ

Message : Sure
Quoted Message : Haan we can plan one on weekend. @9198xxxxxxxx  would you want to take a lead on this?  cc @9177xxxxxxxx

Message : ‚ÄéPOLL:
What time do you prefer for the Zoom discussion on ‚ÄúLearning Transformers / NLP / ML‚Äù
‚ÄéOPTION: Sat, 29th evening (5-6pm) (3 votes)
‚ÄéOPTION: Sat, 29th night (8-9pm) (4 votes)
‚ÄéOPTION: Sun, 30th morning (11-12pm) (2 votes)
‚ÄéOPTION: Sun, 30th evening (4-5pm) (39 votes)
‚ÄéOPTION: Sun, 30th night (8-9pm) (4 votes)
‚ÄéOPTION: Next weekend - Saturday (0 votes)
‚ÄéOPTION: Next weekend - Sunday (0 votes)

Message : (There is a Nvidia-HF event on Saturday morning, hence kept slots after that)

Message : Online ? URL ?
Quoted Message : (There is a Nvidia-HF event on Saturday morning, hence kept slots after that)

Message : https://sites.google.com/huggingface.co/generative-ai-meetup

The registrations are closed though, I'm looking for invites too
Quoted Message : Online ? URL ?

Message : Need an experienced person to guide and answer queries.. volunteer please

Message : https://twitter.com/thesephist/status/1651677221797371904?t=UAtNw7WFH00_AS5oGpirUw&s=19

Didn't know that Notion uses Anthropic LLMs

Message : https://www.euractiv.com/section/artificial-intelligence/news/meps-seal-the-deal-on-artificial-intelligence-act/

Message : ‚Äé<attached: 00001883-PHOTO-2023-04-28-02-34-58.jpg>

Message : same
Quoted Message : https://sites.google.com/huggingface.co/generative-ai-meetup\n\nThe registrations are closed though, I'm looking for invites too

Message : haha, whose place is this party going down at
Quoted Message :  2023_04_28_3AE56A39E380122B1292.jpeg

Message : Has anyone heard of using diffusion for detection / recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar.

Message : Or, more generally, using diffusion in a generic neural network or for some other application outside of generating content

Message : They use transformers for lane detection- https://youtu.be/aVjDX5XshYo

Diffusion pipelines are used to create healthcare datasets - https://hai.stanford.edu/news/could-stable-diffusion-solve-gap-medical-imaging-data
Quoted Message : Has anyone heard of using diffusion for detection / recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar.

Message : https://arxiv.org/abs/2112.00390

Diffusion for image segmentation
Quoted Message : Has anyone heard of using diffusion for detection / recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar.

Message : text2motion 
https://mingyuan-zhang.github.io/projects/MotionDiffuse.html

more on this topic: https://deepsense.ai/data-generation-with-diffusion-models-part-1/
Quoted Message : Or, more generally, using diffusion in a generic neural network or for some other application outside of generating content

Message : @91788006xxxx might know a thing or two
Quoted Message : Has anyone heard of using diffusion for detection / recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar.

Message : I got a call from someone inviting me here. Seems a lot like a marketing campaign. If someone is interested in  their data lake services then they should definitely attend it.

Message : If not, then I don't see much why anyone would attend

Message : Diffusion is a noise removal process at its core
It's kind of like an IMG to IMG process, but that doesn't happen in the image domain. It happens in the image embedding domain.
Quoted Message : Has anyone heard of using diffusion for detection / recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar.

Message : You can use it to generate content, but you can also use diffusion to process content.

Example of former - midjourney
Example of latter - image restoration or enhancement
Quoted Message : Diffusion is a noise removal process at its core\nIt's kind of like an IMG to IMG process, but that doesn't happen in the image domain. It happens in the image embedding domain.

Message : @91942037xxxx‚Äôs place

@91990072xxxx covered
- google page rank and its simplicity
- linear algebra, embeddings and how they all come together
- topology 101
- His MS, PhD stories and why he loves research
- Lot of other good discussions
Quoted Message : haha, whose place is this party going down at

Message : @91990072xxxx is an incredible teacher - should do a talk for the group

Message : Has anyone used promptlayer? or anything similar?

Message : Anyone who has resources for Data Exploration and Feature Engineering?

Message : We can point you in a million directions, but perhaps the most value-for-time is this:
Feature Engineering: https://www.kaggle.com/learn/feature-engineering
DataViz: https://www.kaggle.com/learn/data-visualization

For feature engineering in particular, you can learn more from reading a single Kaggle Winner blog and code than you would from 10 papers ‚Äî I say this as someone who has done both
Quoted Message : Anyone who has resources for Data Exploration and Feature Engineering?

Message : What are the best projects around these areas of interest:

1. Fine tuning Frozen embeddings in-domain
2. Serving embedding with guarantees on latency
3. Ranking/search embedding from QA-pairs e.g. bi-encoder?

Across Modality? But can look at text2text for now

Message : Is the intention to get more familiar with these problems? Like a project to assist coursework?
Quoted Message : What are the best projects around these areas of interest:\n\n1. Fine tuning Frozen embeddings in-domain\n2. Serving embedding with guarantees on latency\n3. Ranking/search embedding from QA-pairs e.g. bi-encoder?\n\nAcross Modality? But can look at text2text for now

Message : Hmm, that's part of the problem. Too many teams re-invent these pieces internally.
Quoted Message : Is the intention to get more familiar with these problems? Like a project to assist coursework?

Message : Why do you've to touch a GPU for doing custom embedding in 2023? That's a very 2016 thing to do

Message : https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/

Message : Such a late stage hype cycle thing to do: Copy paste the docstrings and prompts from a FOSS project to a blog and people find that valuable ü§î
Quoted Message : https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/

Message : I totally agree! But in their defence, this space has been moving too fast for most people to catch up on. I'm surprised that most people have not heard of ReAct, but then know about AutoGPT :P
Quoted Message : Such a late stage hype cycle thing to do: Copy paste the docstrings and prompts from a FOSS project to a blog and people find that valuable ü§î

Message : Yes. I was not criticising the writer, but the audience (i.e. us) for having poor taste. Artists have always been constrained by the times we work in.
Quoted Message : I totally agree! But in their defence, this space has been moving too fast for most people to catch up on. I'm surprised that most people have not heard of ReAct, but then know about AutoGPT :P

Message : Umm, almost all kinds of arts have an audience as well
Quoted Message : Yes. I was not criticising the writer, but the audience (i.e. us) for having poor taste. Artists have always been constrained by the times we work in.

Message : Also, AutoGPT has fantastic marketing. Credit due where it is due.

Message : Did it actually do anything useful yet? Haven't seen any impressive results so far.
Quoted Message : Also, AutoGPT has fantastic marketing. Credit due where it is due.

Message : AutoGPT has been major disappointment from the hype prospective

Message : it is only aboe to do small things/tasks with bounded scopes and well-defined goals 

i was able to create python scripts for minor task automation and then some creative writing assignments. but give it anything a little broad, and it spirals out
Quoted Message : Did it actually do anything useful yet? Haven't seen any impressive results so far.

Message : Can do basic financial analysis of companies. Somehow gets the easiest thing (getting the right current price from google) wrong. But was able to so SWOT + competitive analysis + DCF
Quoted Message : AutoGPT has been major disappointment from the hype prospective

Message : This could be a stupid question but beyond customisability (and maybe power), what's the difference between bing (powered by GPT) and AutoGPT for basic questions? Both have access to the latest information through search.

Message : Have done market sizing and memo writing using AutoGPT, but takes alot of time and gets into loops too often

Message : Oh my,  I see that link has led to a mini furore in this group üòü I actually had a specific question but got a call.
Quoted Message : Such a late stage hype cycle thing to do: Copy paste the docstrings and prompts from a FOSS project to a blog and people find that valuable ü§î


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Yes. I was not criticising the writer, but the audience (i.e. us) for having poor taste. Artists have always been constrained by the times we work in.
Quoted Message : I totally agree! But in their defence, this space has been moving too fast for most people to catch up on. I'm surprised that most people have not heard of ReAct, but then know about AutoGPT :P

Message : Umm, almost all kinds of arts have an audience as well
Quoted Message : Yes. I was not criticising the writer, but the audience (i.e. us) for having poor taste. Artists have always been constrained by the times we work in.

Message : Also, AutoGPT has fantastic marketing. Credit due where it is due.

Message : Did it actually do anything useful yet? Haven't seen any impressive results so far.
Quoted Message : Also, AutoGPT has fantastic marketing. Credit due where it is due.

Message : AutoGPT has been major disappointment from the hype prospective

Message : it is only aboe to do small things/tasks with bounded scopes and well-defined goals 

i was able to create python scripts for minor task automation and then some creative writing assignments. but give it anything a little broad, and it spirals out
Quoted Message : Did it actually do anything useful yet? Haven't seen any impressive results so far.

Message : Can do basic financial analysis of companies. Somehow gets the easiest thing (getting the right current price from google) wrong. But was able to so SWOT + competitive analysis + DCF
Quoted Message : AutoGPT has been major disappointment from the hype prospective

Message : This could be a stupid question but beyond customisability (and maybe power), what's the difference between bing (powered by GPT) and AutoGPT for basic questions? Both have access to the latest information through search.

Message : Have done market sizing and memo writing using AutoGPT, but takes alot of time and gets into loops too often

Message : Oh my,  I see that link has led to a mini furore in this group üòü I actually had a specific question but got a call.
Quoted Message : Such a late stage hype cycle thing to do: Copy paste the docstrings and prompts from a FOSS project to a blog and people find that valuable ü§î

Message : Hahha, no furore. Just banter.
Quoted Message : Oh my,  I see that link has led to a mini furore in this group üòü I actually had a specific question but got a call.

Message : Bing has a lot longer context window ‚Äî so can reason over more search results, is basically free for most people, easier to use.
Quoted Message : This could be a stupid question but beyond customisability (and maybe power), what's the difference between bing (powered by GPT) and AutoGPT for basic questions? Both have access to the latest information through search.

Message : AutoGPT took all the learnings developed by langchain, vectors DBs etc etc and made it available for the wider non-developer audience to use in the format they understand better. 

The limelight always goes to what is easy to use üò¨
Quoted Message : Also, AutoGPT has fantastic marketing. Credit due where it is due.

Message : Bing is also not powered 100% by GPT but uses an internal MSFT model quite often

Message : *Anyone here who has used such sequential prompting on a custom dataset to run a controlled conversation, say a roleplay?* We‚Äôre building a sales roleplay product that mimics conversations of a specific team, and I would like to know such available best practices to optimise the output if someone has dived deeper into something like this.
Quoted Message : https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/

Message : This is perhaps the best tooling for guided-chat with some roleplay.

https://github.com/NVIDIA/NeMo-Guardrails/blob/main/examples/demo_chain_with_guardrails.py

Addendum: I used to run the ML team at Verloop.io ‚Äî a chat automation company powering Nykaa, Rentomojo etc. a long time ago.  Have some interest and exposure to challenges in chat systems in particular.
Quoted Message : *Anyone here who has used such sequential prompting on a custom dataset to run a controlled conversation, say a roleplay?* We‚Äôre building a sales roleplay product that mimics conversations of a specific team, and I would like to know such available best practices to optimise the output if someone has dived deeper into something like this.

Message : It‚Äôs for B2B enterprises, so the idea is that it better get as precise yet flair-ful as it can get (based on a team‚Äôs dynamics).

Message : AlignmentAI

Message : PMGPT

Message : ```Here are a few suggestions for a name for an AI assistant/co-pilot for product managers/product teams:

1. ProdigyAI
2. PMate (Product Manager's Mate)
3. CoPilotAI
4. ProductIQ
5. ProdigiAI
6. BrainstormAI
7. LaunchpadAI
8. ProductWave
9. VisionaryAI
10. ProductGenius```

welcome to generativeai group üòÇ

Message : No offence to any PM, you all are loved üòõ

Message : Tx. Deleted since it borders self promotion
Quoted Message : ```Here are a few suggestions for a name for an AI assistant/co-pilot for product managers/product teams:\n\n1. ProdigyAI\n2. PMate (Product Manager's Mate)\n3. CoPilotAI\n4. ProductIQ\n5. ProdigiAI\n6. BrainstormAI\n7. LaunchpadAI\n8. ProductWave\n9. VisionaryAI\n10. ProductGenius```\n\nwelcome to generativeai group üòÇ

Message : Still waiting for someone to name their product bhAI. Names like samurAI and ikigAI are already gone.
Quoted Message : ```Here are a few suggestions for a name for an AI assistant/co-pilot for product managers/product teams:\n\n1. ProdigyAI\n2. PMate (Product Manager's Mate)\n3. CoPilotAI\n4. ProductIQ\n5. ProdigiAI\n6. BrainstormAI\n7. LaunchpadAI\n8. ProductWave\n9. VisionaryAI\n10. ProductGenius```\n\nwelcome to generativeai group üòÇ

Message : Used this only https://www.namefinder.ai
Quoted Message : ```Here are a few suggestions for a name for an AI assistant/co-pilot for product managers/product teams:\n\n1. ProdigyAI\n2. PMate (Product Manager's Mate)\n3. CoPilotAI\n4. ProductIQ\n5. ProdigiAI\n6. BrainstormAI\n7. LaunchpadAI\n8. ProductWave\n9. VisionaryAI\n10. ProductGenius```\n\nwelcome to generativeai group üòÇ

Message : A dairy founder wanted g.ai but had to resort to mal.ai
Quoted Message : Still waiting for someone to name their product bhAI. Names like samurAI and ikigAI are already gone.

Message : AIshwarIA
Quoted Message : Still waiting for someone to name their product bhAI. Names like samurAI and ikigAI are already gone.

Message : I think something like autogpt becomes useful when human closed loop feedback cycles are involved at a large scale. Something that incorporates large scale human feedback and nudges into its reasoning, that's where I see real potential
Quoted Message : AutoGPT has been major disappointment from the hype prospective

Message : Eg for trading bots this might be a community of 1000s of traders constantly giving it nudges and guidance on its thoughts and actions

Message : ‚ÄéPOLL:
While i was thinking about my pending gpt-4 request.. quick poll about your status
‚ÄéOPTION: Has gpt-4 api access (24 votes)
‚ÄéOPTION: Requested and awaiting (34 votes)
‚ÄéOPTION: Didn't request yet (6 votes)

Message : For the technical folks that are waiting on GPT4 API Access for more than 30 days, with any meaningful open source presence ‚Äî please DM me. 

Can share a tip which has helped @91876402xxxx get access as well recently :)

Message : I got the access in 5 days. Had requested it last weekend and got it this week.

Message : Works like a charm. We had been pusing internal teams at Microsoft for a month, with no end in sight, but nirant's tip worked in 2 hours :)
Quoted Message : For the technical folks that are waiting on GPT4 API Access for more than 30 days, with any meaningful open source presence ‚Äî please DM me. \n\nCan share a tip which has helped @9187xxxxxxxx get access as well recently :)

Message : Does anyone have access to GPT plugins?

Message : did you get through Azure OpenAI service?

Message : Yes, thanks to nirant as well
Quoted Message : Does anyone have access to GPT plugins?

Message : I haven't checked that yet. Is it available through that?
Quoted Message : did you get through Azure OpenAI service?

Message : Are awesome. How did you get it?
Quoted Message : Yes, thanks to nirant as well

Message : I just want to play with the plugins and explore their capabilities.

Message : Interesting bit: the Microsoft folks pushed us to shift all our code to azure openai service, and something called semantic-kernel in order to get gpt-4 access, but none of it has materialised yet

https://github.com/microsoft/semantic-kernel
Quoted Message : did you get through Azure OpenAI service?

Message : I feel guilty open sourcing nirant's tips üòÇ
Quoted Message : Are awesome. How did you get it?

Message : More important: We also shouldn't abuse OpenAI's goodwill :)
Quoted Message : I feel guilty open sourcing nirant's tips üòÇ

Message : Haha. No worries. I have gpt-4 api access.
I am just looking for Plugin access.

Message : Anyone in Ben Tossel's AI maker group?

Message : I am
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : Pray tell üôÇ
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : And also the joining linküòÖ
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : Gotta apply

Message : maker club?
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : Where?
Quoted Message : Gotta apply

Message : let me find the link


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : More important: We also shouldn't abuse OpenAI's goodwill :)
Quoted Message : I feel guilty open sourcing nirant's tips üòÇ

Message : Haha. No worries. I have gpt-4 api access.
I am just looking for Plugin access.

Message : Anyone in Ben Tossel's AI maker group?

Message : I am
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : Pray tell üôÇ
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : And also the joining linküòÖ
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : Gotta apply

Message : maker club?
Quoted Message : Anyone in Ben Tossel's AI maker group?

Message : Where?
Quoted Message : Gotta apply

Message : let me find the link

Message : ‚Äé<attached: 00001963-PHOTO-2023-04-28-17-02-42.jpg>

Message : For folks wondering how is FP8 working? This is based on NVIDIA's Transformer Engine: https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/index.html

Message : What impact you foresee? Large Model, Faster Model, or new model arch?
Quoted Message :  2023_04_28_3EB075C7BE51C233666A79.jpeg

Message : Coreweave talks about tier 3 datacenters in north america. What does that mean? Do we have any in India as well?
Quoted Message :  2023_04_28_3EB075C7BE51C233666A79.jpeg

Message : Mostly faster inference in the 3-6 month horizon as compute providers figure this out, and perhaps more Fp16, Fp8/int8 proliferation for task-specific models
Quoted Message : What impact you foresee? Large Model, Faster Model, or new model arch?

Message : Faster inference means lesser costs because you can handle higher concurrent users per gpu
Quoted Message : What impact you foresee? Large Model, Faster Model, or new model arch?

Message : If I was running a serverless GPU company with mixed-GPUs e.g. A100, H100, P100 and what not ‚Äî I'd resist the temptation to pass on these cost savings to customers. Mainly because I'm not quite sure how many customers will pay for 3x faster use cases
Quoted Message : Faster inference means lesser costs because you can handle higher concurrent users per gpu

Message : Also at times you can‚Äôt guarantee to spawn up some of the higher end GPUs on demand, leading to slower spawn up time for users
Quoted Message : If I was running a serverless GPU company with mixed-GPUs e.g. A100, H100, P100 and what not ‚Äî I'd resist the temptation to pass on these cost savings to customers. Mainly because I'm not quite sure how many customers will pay for 3x faster use cases

Message : I doubt you'll have this luxury for long, imo serverless gpus are a perfect competition model with market competition dictating  the pricing instead of arbitrary end user value
Quoted Message : If I was running a serverless GPU company with mixed-GPUs e.g. A100, H100, P100 and what not ‚Äî I'd resist the temptation to pass on these cost savings to customers. Mainly because I'm not quite sure how many customers will pay for 3x faster use cases

Message : https://twitter.com/bentossell/status/1636394074101153792

Message : fyi

Message : Hey, this is nice, thanks for sharing
Quoted Message : https://twitter.com/bentossell/status/1636394074101153792

Message : Looks too good to be true, what do you think is the catch here?

Message : No catch, it's Ben

Message : anyone  , building with langchain here ?  just deployed a private V2 for collectiv langchainX. would be happy to share access , if you building with langchain would help your process

Message : Hi! Does anyone know of any tools that can summarize custom code repos/documentation? Something like https://github.com/mtenenholtz/chat-twitter but where you can maybe enter in any Github repo link and it'll summarize it for you.

Message : https://github.com/peterw/Chat-with-Github-Repo
Quoted Message : Hi! Does anyone know of any tools that can summarize custom code repos/documentation? Something like https://github.com/mtenenholtz/chat-twitter but where you can maybe enter in any Github repo link and it'll summarize it for you.

Message : https://stability.ai/blog/deepfloyd-if-text-to-image-model

Message : Thanks
Quoted Message : https://github.com/peterw/Chat-with-Github-Repo

Message : Research license only
Quoted Message : https://stability.ai/blog/deepfloyd-if-text-to-image-model

Message : interesting approach, will be interesting to see if it will be able to displace the stable diffusion model given the eco-system that has already grown around it
Quoted Message : https://stability.ai/blog/deepfloyd-if-text-to-image-model

Message : Very lame question: Does LlamaIndex or Langchain support VectorDB with Sources with GPT4 or GPT3.5-Turbo? 

For LLM libs, both of them have such embarrassingly bad doc search üôà

Message : If yes, can you please point me to the right docs üòÖ

Message : what does vectordb with sources with gpt mean?

Message : Say the Vector DB replies with Doc1, 3, 5, 7 and only 5, 7 are actually used by the LLM to answer the question ‚Äî I want the response to include 5, 7
Quoted Message : what does vectordb with sources with gpt mean?

Message : https://github.com/jerryjliu/llama_index/blob/main/examples/vector_indices/PineconeIndexDemo.ipynb

Message : response.source_nodes should give you the sources.
Quoted Message : https://github.com/jerryjliu/llama_index/blob/main/examples/vector_indices/PineconeIndexDemo.ipynb

Message : That gives 1, 3, 5, 7 ‚Äî all top k
Quoted Message : response.source_nodes should give you the sources.

Message : ohh okay. Sorry, I misunderstood then. One way is to use evaluation module on top these to get only 5, 7 are being used.
Quoted Message : That gives 1, 3, 5, 7 ‚Äî all top k

Message : I have a hack for this
Quoted Message : Say the Vector DB replies with Doc1, 3, 5, 7 and only 5, 7 are actually used by the LLM to answer the question ‚Äî I want the response to include 5, 7

Message : Use this prompt - 

Cite the Search Results using [${number}] notation in your answer.

Message : Then simply parse the citations returned using regex

Message : I've tried variants of this. Not consistent enough unfortunately across questions. Do you change the system prompt in some way?
Quoted Message : Use this prompt - \n\nCite the Search Results using [${number}] notation in your answer.

Message : ‚Äé<attached: 00001996-PHOTO-2023-04-29-00-59-24.jpg>

Message : ‚Äé<attached: 00001997-PHOTO-2023-04-29-00-59-47.jpg>

Message : Works very consistently

Message : (Haven't experimented with gpt-4 though yet)

Message : Including instructions and search results in system prompt made it forget the instructions sometimes
Quoted Message : I've tried variants of this. Not consistent enough unfortunately across questions. Do you change the system prompt in some way?

Message : So moved them to user prompt

Message : ‚Äé<attached: 00002002-PHOTO-2023-04-29-01-03-03.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Use this prompt - 

Cite the Search Results using [${number}] notation in your answer.

Message : Then simply parse the citations returned using regex

Message : I've tried variants of this. Not consistent enough unfortunately across questions. Do you change the system prompt in some way?
Quoted Message : Use this prompt - \n\nCite the Search Results using [${number}] notation in your answer.

Message : ‚Äé<attached: 00001996-PHOTO-2023-04-29-00-59-24.jpg>

Message : ‚Äé<attached: 00001997-PHOTO-2023-04-29-00-59-47.jpg>

Message : Works very consistently

Message : (Haven't experimented with gpt-4 though yet)

Message : Including instructions and search results in system prompt made it forget the instructions sometimes
Quoted Message : I've tried variants of this. Not consistent enough unfortunately across questions. Do you change the system prompt in some way?

Message : So moved them to user prompt

Message : ‚Äé<attached: 00002002-PHOTO-2023-04-29-01-03-03.jpg>

Message : This technique also in my experience has the added benefit of producing more grounded results, because you are kinda forcing it to cite sources. (Not sure why it works at all though)

Message : OpenAI models don‚Äôt do this. What you want is basically the LLMs to cite references.
Quoted Message : Say the Vector DB replies with Doc1, 3, 5, 7 and only 5, 7 are actually used by the LLM to answer the question ‚Äî I want the response to include 5, 7

Message : *The reader model

Message : Interesting.
Quoted Message :  2023_04_29_3AF5E4DF0C964519ACF5.jpeg

Message : @91773788xxxx something like this - https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html ?

Message : Yes, but this uses text-davinci-003 ‚Äî which leads to couple of trade offs:  

1. Slower and more expensive than gpt3.5-turbo
2. Confabulates more than Turbo, so have to keep answers really small and sentence-length often
3. Worse at reasoning than GPT4
Quoted Message : @9177xxxxxxxx something like this - https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html ?

Message : what could be reasons that the methodology can‚Äôt be ported to GPT-4? (I haven‚Äôt looked at the code yet, only did a cursory read on this today)

Message : Do you mean LLM or code reasons? There are no LLM reasons
Quoted Message : what could be reasons that the methodology can‚Äôt be ported to GPT-4? (I haven‚Äôt looked at the code yet, only did a cursory read on this today)

Message : Replacing the OpenAI() classes in the example with ChatOpenAI() doesn't work?
Quoted Message : Yes, but this uses text-davinci-003 ‚Äî which leads to couple of trade offs:  \n\n1. Slower and more expensive than gpt3.5-turbo\n2. Confabulates more than Turbo, so have to keep answers really small and sentence-length often\n3. Worse at reasoning than GPT4

Message : Code reasons - is the ‚Äúreturn_only_outputs‚Äù prop not available for ChatCompletions

Message : Code Reasons: Langchain is structured around separation of LLMs and Vector Indices ‚Äî the Chat LLMs (e.g. ```ChatOpenAI```) prompts aren't compatible with these other operands like qa_with_sources

Message : You‚Äôll have to extend the chain functions I guess..
Quoted Message : Code Reasons: Langchain is structured around separation of LLMs and Vector Indices ‚Äî the Chat LLMs (e.g. ```ChatOpenAI```) prompts aren't compatible with these other operands like qa_with_sources

Message : Llama Index: @91955016xxxx can share more context, but I think they've just gotten around to it. From what I can tell, they have no such limitations

Message : *just not gotten around to it

Message : Aah, that makes sense. Will make for a great PR!

Message : That was a quick delete üòÇüòÇüòÇ

Message : Yeah, sometimes I've to enforce that "stay on topic" policy to myself ü§£

Message : Langchain is very complex though. Tried doing some very simple modifications today and I just gave up and went back to good old OpenAI libs

Message : My eyes can‚Äôt believe this, what error does it throw?
Quoted Message : Code Reasons: Langchain is structured around separation of LLMs and Vector Indices ‚Äî the Chat LLMs (e.g. ```ChatOpenAI```) prompts aren't compatible with these other operands like qa_with_sources

Message : It's definitely not meant for simple things
Quoted Message : Langchain is very complex though. Tried doing some very simple modifications today and I just gave up and went back to good old OpenAI libs

Message : OpenAI has a function in one of their libs to convert chat prompts to text ones and vice versa - that‚Äôs needed here I guess üòÖ

Message : Wait, what. I've not seen this. Is this part of their default Python SDK? If not, can you link it here?
Quoted Message : OpenAI has a function in one of their libs to convert chat prompts to text ones and vice versa - that‚Äôs needed here I guess üòÖ

Message : https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/prompt/base.py#L22
Quoted Message : Wait, what. I've not seen this. Is this part of their default Python SDK? If not, can you link it here?

Message : Okay, I see the code. Now I feel sad that I didn't think of this. Probably should've asked this question at 9 AM instead of 2 AM üòÖ
Quoted Message : https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/prompt/base.py#L22

Message : while we are in this repo - these prompts are gold 

https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/registry/modelgraded/fact.yaml

https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/registry/modelgraded/closedqa.yaml

Message : These kinda gems are what make this group worthwhile ü´∞üèª

Message : Yes! Writing a blog on how good the library is. We aren‚Äôt using so much of what became available here!

Message : anyone knows a model that can give aesthetic score for an image?

Message : FID against LAION-A?
Quoted Message : anyone knows a model that can give aesthetic score for an image?

Message : Please share after ur done
Quoted Message : Yes! Writing a blog on how good the library is. We aren‚Äôt using so much of what became available here!

Message : Adding context here: 

Part 1: **FID**

FID (Frechlet Inception Distance) is a score which is primarily used for evaluating quality of generated images against a source dataset. It first came to notice when GANs were used to generate novel faces (circa 2019). FID is a distance score between features or vectors ‚Äî so lower FID score means your images are closer to what you are comparing against.

Here is an example blog from that era: https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/

Message : ‚Äé<attached: 00002035-PHOTO-2023-04-29-03-21-05.jpg>

Message : Pretty cool approach.
Quoted Message :  2023_04_29_3EB02FCFEAB3D1040ACEE1.jpeg

Message : That said, if you've user-scored images, you can go very far with just a ResNet and a classification model. AirBnB Staff ML Engineers with a PhD were still doing that and getting promoted in Dec 2022: https://medium.com/airbnb-engineering/when-a-picture-is-worth-more-than-words-17718860dcc2

Message : Basically, Big Data beats Big Brains any day, all day long

Message : Before anyone asks, Airbnb uses AWS OpenSearch with HNSW for their VectorStore

Message : Thinking along similar lines, I'm eagerly waiting for a model that takes in any photo and gives out professional level DSLR photos. Perfect lighting, colors, focus, contrast, etc :)

Message : For folks looking to fine-tune LLMs to their custom domains, the first step is to build a good quality dataset of ~50k data points. LAMINI AI launched a library today to make this process easier. You'll have to make a dataset of around 100 data points and the library will expand it to a nice 70k+ data points dataset that you own(CC-BY license).
https://github.com/lamini-ai/lamini/

They also provide tools to quickly fine-tune some of the open trendy camel like creatures.

Message : ‚Äé~‚ÄØMahesh was added

Message : Folks, this is a super exciting community and I love the sheer amount of activity here. Everytime I open Whatsapp and there‚Äôs 300+ new messages, and I do like the buzz of it (quite similar to the speed of AI development üòõ). 

But my non-AI brain just can‚Äôt keep up with all that‚Äôs happening in this group.

I must excuse myself for now.

Will probably be back once AI takes over my day job and I have more time to be present here.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Adding context here: 

Part 1: **FID**

FID (Frechlet Inception Distance) is a score which is primarily used for evaluating quality of generated images against a source dataset. It first came to notice when GANs were used to generate novel faces (circa 2019). FID is a distance score between features or vectors ‚Äî so lower FID score means your images are closer to what you are comparing against.

Here is an example blog from that era: https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/

Message : ‚Äé<attached: 00002035-PHOTO-2023-04-29-03-21-05.jpg>

Message : Pretty cool approach.
Quoted Message :  2023_04_29_3EB02FCFEAB3D1040ACEE1.jpeg

Message : That said, if you've user-scored images, you can go very far with just a ResNet and a classification model. AirBnB Staff ML Engineers with a PhD were still doing that and getting promoted in Dec 2022: https://medium.com/airbnb-engineering/when-a-picture-is-worth-more-than-words-17718860dcc2

Message : Basically, Big Data beats Big Brains any day, all day long

Message : Before anyone asks, Airbnb uses AWS OpenSearch with HNSW for their VectorStore

Message : Thinking along similar lines, I'm eagerly waiting for a model that takes in any photo and gives out professional level DSLR photos. Perfect lighting, colors, focus, contrast, etc :)

Message : For folks looking to fine-tune LLMs to their custom domains, the first step is to build a good quality dataset of ~50k data points. LAMINI AI launched a library today to make this process easier. You'll have to make a dataset of around 100 data points and the library will expand it to a nice 70k+ data points dataset that you own(CC-BY license).
https://github.com/lamini-ai/lamini/

They also provide tools to quickly fine-tune some of the open trendy camel like creatures.

Message : ‚Äé~‚ÄØMahesh was added

Message : Folks, this is a super exciting community and I love the sheer amount of activity here. Everytime I open Whatsapp and there‚Äôs 300+ new messages, and I do like the buzz of it (quite similar to the speed of AI development üòõ). 

But my non-AI brain just can‚Äôt keep up with all that‚Äôs happening in this group.

I must excuse myself for now.

Will probably be back once AI takes over my day job and I have more time to be present here.

Message : Working on a summary web version and hopefully a weekly/monthly newsletter ü§û
Quoted Message : Folks, this is a super exciting community and I love the sheer amount of activity here. Everytime I open Whatsapp and there‚Äôs 300+ new messages, and I do like the buzz of it (quite similar to the speed of AI development üòõ). \n\nBut my non-AI brain just can‚Äôt keep up with all that‚Äôs happening in this group. \n\nI must excuse myself for now. \n\nWill probably be back once AI takes over my day job and I have more time to be present here.

Message : Cool che. Will sign up for that.

Until then cheers to Nirant and all the future AI millionaires / billionaires here ‚úåüèª
Quoted Message : Working on a summary web version and hopefully a weekly/monthly newsletter ü§û

Message : I prefer never using them... Just picking the prompts from their source code
Quoted Message : Langchain is very complex though. Tried doing some very simple modifications today and I just gave up and went back to good old OpenAI libs

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØApurva Bhatt

Message : Who here is using langchain in prod?

Message : How? Manually üòØ
Quoted Message : Working on a summary web version and hopefully a weekly/monthly newsletter ü§û

Message : No way. Shouldn't expect that from Nirant. Automate. üòÅ
Quoted Message : How? Manually üòØ

Message : This is a nice read

https://a16z.com/2023/04/27/navigating-the-high-cost-of-ai-compute/

Message : Mainly my point about finding any good way to extract WhatsApp group data  automatically. I don't find any official APIs. There might be few unofficial ways but that may cause a number ban.
Quoted Message : No way. Shouldn't expect that from Nirant. Automate. üòÅ

Message : Hey folks, 

Any leads/info on the best text to video (paid and free/open source tech) available in the market.

Something with a wow factor.

thanks for the inputs.

Message : My understanding is currently runwayml gen 2.
Quoted Message : Hey folks, \n\nAny leads/info on the best text to video (paid and free/open source tech) available in the market. \n\nSomething with a wow factor. \n\nthanks for the inputs.

Message : This isn't available yet I thought.

Message : Don‚Äôt know about access. I have seen multiple videos of it on twitter lately.

Message : Few days old üòú: 
https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/
(done in collab with openAPI - so has the best prompting tips)

Message : https://replicate.com/cjwbw/damo-text-to-video

https://replicate.com/deforum/deforum_stable_diffusion

Are the two I have found.

Message : https://github.com/Picsart-AI-Research/Text2Video-Zero

Is quite good...

Message : Folks, so we are doing the "Learning Transformers/NLP/ML" discussion on Sunday 4-5pm.

Agenda:
1. Learners talk about what they'd like to learn about (So come prepared!)
2. If someone knows learning resources they share it  (We are trying to get an experienced person for this!)
3. The topics will be compiled and shared (So that experienced folks can add more learning resources to it after the event)

Calendar link: https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=NDBidDlwcXBzczRocjV0YTRndjBxbGMyN2Mgc2hhc2hhbmsuY2RvQG0&tmsrc=shashank.cdo%40gmail.com

Message : Anyone at the nvidia event?

Message : Using openai APIs to expand?
Quoted Message : For folks looking to fine-tune LLMs to their custom domains, the first step is to build a good quality dataset of ~50k data points. LAMINI AI launched a library today to make this process easier. You'll have to make a dataset of around 100 data points and the library will expand it to a nice 70k+ data points dataset that you own(CC-BY license).\nhttps://github.com/lamini-ai/lamini/\n\nThey also provide tools to quickly fine-tune some of the open trendy camel like creatures.

Message : Fyi that calendar link doesn't do anything for me, using Android here
Quoted Message : Folks, so we are doing the \"Learning Transformers/NLP/ML\" discussion on Sunday 4-5pm.\n\nAgenda:\n1. Learners talk about what they'd like to learn about (So come prepared!)\n2. If someone knows learning resources they share it  (We are trying to get an experienced person for this!)\n3. The topics will be compiled and shared (So that experienced folks can add more learning resources to it after the event)\n\nCalendar link: https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=NDBidDlwcXBzczRocjV0YTRndjBxbGMyN2Mgc2hhc2hhbmsuY2RvQG0&tmsrc=shashank.cdo%40gmail.com

Message : I can make a list of great solutions for it if there's interest :)
Quoted Message : We can point you in a million directions, but perhaps the most value-for-time is this:\nFeature Engineering: https://www.kaggle.com/learn/feature-engineering\nDataViz: https://www.kaggle.com/learn/data-visualization\n\nFor feature engineering in particular, you can learn more from reading a single Kaggle Winner blog and code than you would from 10 papers ‚Äî I say this as someone who has done both

Message : Tuned in for Gen AI, listening to GPU talks üíÄ
Quoted Message : Anyone at the nvidia event?

Message : Thanks for flagging it Amir.

Fixed the calendar link to "Learning Transformers/NLP/ML" discussion on Sunday 4-5pm:
(You need to be logged in to google for it to work. Google calendar doesn't handle it well otherwise)
https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=MXJxbm4xZDVlZmc3MGRpcDJna3NsODM3ZG4gMWNkNjI0MzA3ODkwN2JhN2M3YzhjNjg1NGVkNGVjMWUzZDhiMjc4MjU5NmMyZmRhNWI0MDFlZTI5ZDM3OTYzZUBn&tmsrc=1cd6243078907ba7c7c8c6854ed4ec1e3d8b2782596c2fda5b401ee29d37963e%40group.calendar.google.com

Alternatively, video link to join directly : https://meet.google.com/jag-jjny-owf
Quoted Message : Folks, so we are doing the \"Learning Transformers/NLP/ML\" discussion on Sunday 4-5pm.\n\nAgenda:\n1. Learners talk about what they'd like to learn about (So come prepared!)\n2. If someone knows learning resources they share it  (We are trying to get an experienced person for this!)\n3. The topics will be compiled and shared (So that experienced folks can add more learning resources to it after the event)\n\nCalendar link: https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=NDBidDlwcXBzczRocjV0YTRndjBxbGMyN2Mgc2hhc2hhbmsuY2RvQG0&tmsrc=shashank.cdo%40gmail.com

Message : https://twitter.com/bhutanisanyam1/status/1412933178411536384

Please see the replies to this^

Compilation of the most epic FE competitions^
Quoted Message : I can make a list of great solutions for it if there's interest :)

Message : https://postgresml.org/blog/tuning-vector-recall-while-generating-query-embeddings-in-the-database

Message : Haha - I'm here
Quoted Message : Tuned in for Gen AI, listening to GPU talks üíÄ

Message : It's high quality

Message : Will share insights

Message : https://teams.microsoft.com/l/meetup-join/19%3ameeting_OGM2NDU4N2QtYjdmOS00YzJmLThmZTctYTkxYWEyNWQ0OGNj%40thread.v2/0?context=%7B%22Tid%22%3A%2243083d15-7273-40c1-b7db-39efd9ccc17a%22%2C%22Oid%22%3A%222e1cc663-be56-46e0-ab3b-b7a9f58868e7%22%2C%22IsBroadcastMeeting%22%3Atrue%2C%22role%22%3A%22a%22%7D&btype=a&role=a 
link to the same .

Message : Hey @91740765xxxx @91997100xxxx : For tomorrow's zoom meet-up, can you drive 15 minute of the session on 101 of Generative AI? @91988071xxxx is looking for a tech expert in the session.

Message : Nirant is busy tomorrow.

Message : Hey guys. I am trying to build something with Generative AI in the advertisement space. I don‚Äôt have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss.

Message : My name is Srinath btw. And I am a final year BTech student.

Message : Would love to help @91807502xxxx . Dm me whenever free
Quoted Message : Hey guys. I am trying to build something with Generative AI in the advertisement space. I don‚Äôt have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss.

Message : Folks, please reach out to our friend directly :)
Quoted Message : Hey guys. I am trying to build something with Generative AI in the advertisement space. I don‚Äôt have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss.

Message : Thanks Nitish. DMing you.
Quoted Message : Would love to help @9180xxxxxxxx . Dm me whenever free

Message : Hello everyone, I am Apurva. I am building a product to make content viral on social media using generative AI. 
I am still exploring the way to build a product. Feel free to connect and exchange ideas.
I am currently working at BertLabs and before that, I worked at sharechat.

Message : Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically).

I see this being useful in intelligent document processing and ocr, where data collection is a very difficult task due to privacy and all.

If anyone has already done this, then please let me know. Else, if interested we can form a small group and build this as an open source lib.

Message : Looks like all the Mohits are looking for same use case. üòÇ

I'm also looking for a solution for this specific use case
Quoted Message : Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically).\n\nI see this being useful in intelligent document processing and ocr, where data collection is a very difficult task due to privacy and all.\n\nIf anyone has already done this, then please let me know. Else, if interested we can form a small group and build this as an open source lib.

Message : Brilliant. We can call our library mohit then!


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Nirant is busy tomorrow.

Message : Hey guys. I am trying to build something with Generative AI in the advertisement space. I don‚Äôt have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss.

Message : My name is Srinath btw. And I am a final year BTech student.

Message : Would love to help @91807502xxxx . Dm me whenever free
Quoted Message : Hey guys. I am trying to build something with Generative AI in the advertisement space. I don‚Äôt have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss.

Message : Folks, please reach out to our friend directly :)
Quoted Message : Hey guys. I am trying to build something with Generative AI in the advertisement space. I don‚Äôt have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss.

Message : Thanks Nitish. DMing you.
Quoted Message : Would love to help @9180xxxxxxxx . Dm me whenever free

Message : Hello everyone, I am Apurva. I am building a product to make content viral on social media using generative AI. 
I am still exploring the way to build a product. Feel free to connect and exchange ideas.
I am currently working at BertLabs and before that, I worked at sharechat.

Message : Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically).

I see this being useful in intelligent document processing and ocr, where data collection is a very difficult task due to privacy and all.

If anyone has already done this, then please let me know. Else, if interested we can form a small group and build this as an open source lib.

Message : Looks like all the Mohits are looking for same use case. üòÇ

I'm also looking for a solution for this specific use case
Quoted Message : Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically).\n\nI see this being useful in intelligent document processing and ocr, where data collection is a very difficult task due to privacy and all.\n\nIf anyone has already done this, then please let me know. Else, if interested we can form a small group and build this as an open source lib.

Message : Brilliant. We can call our library mohit then!

Message : Definitely üíØ
Quoted Message : Brilliant. We can call our library mohit then!

Message : Would anyone know a transcription open source or paid API that can handle hindi/english as well as indian regional languages

Message : OpenAI Whisper does this off the bat
Quoted Message : Would anyone know a transcription open source or paid API that can handle hindi/english as well as indian regional languages

Message : I tried assemblyAI as well but they are expensive, are there any other that I may have missed?

Message : @1937708xxxx should definitely be able to help!

Message : thanks will dm him

Message : Building this but for CSVs at the moment, would love to chat!
Quoted Message : Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically).\n\nI see this being useful in intelligent document processing and ocr, where data collection is a very difficult task due to privacy and all.\n\nIf anyone has already done this, then please let me know. Else, if interested we can form a small group and build this as an open source lib.

Message : For Hindi there are whisper models trained for Hindi from IITM.

Do check here - https://huggingface.co/vasista22
Quoted Message : Would anyone know a transcription open source or paid API that can handle hindi/english as well as indian regional languages

Message : Deepgram built using whisper works good as well. They give $200 credit to try it out.

Message : You can try monster api as well
Quoted Message : Would anyone know a transcription open source or paid API that can handle hindi/english as well as indian regional languages

Message : If somebody is trying out deepgram nova vs Whisper - would love to hear results from both
Quoted Message : Deepgram built using whisper works good as well. They give $200 credit to try it out.

Message : You don't need generative models for this. Converting raw text to PDFs/images and then applying simple distortions is a very common and effective way to get synthetic data for OCR.
Quoted Message : Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically).\n\nI see this being useful in intelligent document processing and ocr, where data collection is a very difficult task due to privacy and all.\n\nIf anyone has already done this, then please let me know. Else, if interested we can form a small group and build this as an open source lib.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØAkshat Khare

Message : ‚Äé<attached: 00002101-PHOTO-2023-04-29-17-54-18.jpg>

Message : https://playbook.samaltman.com

For all the fellow founders out here - a very grounded article by sam altman on building great products and companies

Message : Hey

Sorry. So am I. ü•∫
Quoted Message : Hey @9174xxxxxxxx @9199xxxxxxxx : For tomorrow's zoom meet-up, can you drive 15 minute of the session on 101 of Generative AI? @9198xxxxxxxx is looking for a tech expert in the session.

Message : Will not be able to make it.

Message : Will you be recording this?
Quoted Message : Thanks for flagging it Amir.\n\nFixed the calendar link to \"Learning Transformers/NLP/ML\" discussion on Sunday 4-5pm:\n(You need to be logged in to google for it to work. Google calendar doesn't handle it well otherwise) \nhttps://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=MXJxbm4xZDVlZmc3MGRpcDJna3NsODM3ZG4gMWNkNjI0MzA3ODkwN2JhN2M3YzhjNjg1NGVkNGVjMWUzZDhiMjc4MjU5NmMyZmRhNWI0MDFlZTI5ZDM3OTYzZUBn&tmsrc=1cd6243078907ba7c7c8c6854ed4ec1e3d8b2782596c2fda5b401ee29d37963e%40group.calendar.google.com\n\nAlternatively, video link to join directly : https://meet.google.com/jag-jjny-owf

Message : ‚Äé<attached: 00002106-VIDEO-2023-04-29-19-21-18.mp4>

Message : Weekend fun!

Message : D-ID is crazy good. Any ideas on the underlying architecture?
Quoted Message :  2023_04_29_3EB0D433ECF42BDEDA77CB.mp4

Message : SadTalker is open and it getting there. Some friends are working on a project and they moved on from D-ID for SadTalker. You will need a good GPU though.

Message : Not so sure but this tech is around since a while.
Quoted Message : D-ID is crazy good. Any ideas on the underlying architecture?

Message : Not zero shot lipsync / animation - that's hard and has limited work
Quoted Message : Not so sure but this tech is around since a while.

Message : Sad talker is arguably better...
Quoted Message : SadTalker is open and it getting there. Some friends are working on a project and they moved on from D-ID for SadTalker. You will need a good GPU though.

Message : D-ID is very expensive if you‚Äôre building a project with a pipeline to generate content on an enormous amount.

Message : How expensive?
Quoted Message : D-ID is very expensive if you‚Äôre building a project with a pipeline to generate content on an enormous amount.

Message : As mentioned on their Pricing page. ü§£

Message : Have you deployed and tested at scale?
Quoted Message : As mentioned on their Pricing page. ü§£

Message : Unreasonably expensive for an api product
Quoted Message : How expensive?

Message : We used multiple D-ID accounts to get this done :p
Quoted Message : As mentioned on their Pricing page. ü§£

Message : They have a full fledged web studio as well.
So I don't think they are trying to build only API product.
Quoted Message : Unreasonably expensive for an api product

Message : Yup exactly - I feel like the pricing is aligned for the dashboard only
Quoted Message : They have a full fledged web studio as well.\nSo I don't think they are trying to build only API product.

Message : Right now SadTalker can generate 10min video per hour that‚Äôs 2$ GPU time

Message : D-ID is charging 6$ per 10 mins. If you can have 3090 or 4090 at home, that would be like 300-400h gpu time to get your money back.

Message : May be get one with nvlinks for larger runs and still it‚Äôs a lot better return time for investment

Message : And yet has a lot of traction - good product to build.
Quoted Message : D-ID is charging 6$ per 10 mins. If you can have 3090 or 4090 at home, that would be like 300-400h gpu time to get your money back.

Message : Any idea on what models they use?

Message : ü§∑‚Äç‚ôÇÔ∏è their own. SadTalker is new and evolving. From tencent I think.

Message : So many things to build, so many industries to disrupt. 
I see this group producing pioneers for next India decade.
Quoted Message : And yet has a lot of traction - good product to build.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : We used multiple D-ID accounts to get this done :p
Quoted Message : As mentioned on their Pricing page. ü§£

Message : They have a full fledged web studio as well.
So I don't think they are trying to build only API product.
Quoted Message : Unreasonably expensive for an api product

Message : Yup exactly - I feel like the pricing is aligned for the dashboard only
Quoted Message : They have a full fledged web studio as well.\nSo I don't think they are trying to build only API product.

Message : Right now SadTalker can generate 10min video per hour that‚Äôs 2$ GPU time

Message : D-ID is charging 6$ per 10 mins. If you can have 3090 or 4090 at home, that would be like 300-400h gpu time to get your money back.

Message : May be get one with nvlinks for larger runs and still it‚Äôs a lot better return time for investment

Message : And yet has a lot of traction - good product to build.
Quoted Message : D-ID is charging 6$ per 10 mins. If you can have 3090 or 4090 at home, that would be like 300-400h gpu time to get your money back.

Message : Any idea on what models they use?

Message : ü§∑‚Äç‚ôÇÔ∏è their own. SadTalker is new and evolving. From tencent I think.

Message : So many things to build, so many industries to disrupt. 
I see this group producing pioneers for next India decade.
Quoted Message : And yet has a lot of traction - good product to build.

Message : Just ran it - seeing that its running gfpgan at the end too - so this time can definitely be reduced
Quoted Message : Right now SadTalker can generate 10min video per hour that‚Äôs 2$ GPU time

Message : üëç 
I have offloaded that project to someone else to lead as my hands are full. I‚Äôll pass on this info to them.
Quoted Message : Just ran it - seeing that its running gfpgan at the end too - so this time can definitely be reduced

Message : Only notes (as of now)

Message : Yes and 2$ can be brought down if doing at scale (Assuming A100)
Quoted Message : Just ran it - seeing that its running gfpgan at the end too - so this time can definitely be reduced

Message : Margins are great for this - and competition is less. (text to talking head avatars vs rephrase ai etc). Good product to build.

Message : I'll take a stab at building an mvp soon

Message : Tried doing this back in 2019 and almost raised funding, but didn't work out

Message : Not sure how big is the market for this though.

Message : It's an evolving market. Also look at leading indicators

Message : ‚Äé<attached: 00002137-PHOTO-2023-04-29-20-38-14.jpg>

Message : Wow this is very real
Quoted Message :  2023_04_29_3EB0D433ECF42BDEDA77CB.mp4

Message : I've built this product as both an API, and also earlier (2020) as a charcater.ai type offering, and even tried to sell as nfts. 

Hard sell unless you know how to gain traction on social media.
Quoted Message : Tried doing this back in 2019 and almost raised funding, but didn't work out

Message : Hillarious stuff man
Quoted Message :  2023_04_29_3EB0D433ECF42BDEDA77CB.mp4

Message : I know how to do that :)
Quoted Message : I've built this product as both an API, and also earlier (2020) as a charcater.ai type offering, and even tried to sell as nfts. \n\nHard sell unless you know how to gain traction on social media.

Message : That's the easy bit

Message : Don‚Äôt you want 8 AI avatars on Arnab‚Äôs show with different personalities?
Quoted Message : Not sure how big is the market for this though.

Message : *Shakes hands*
Quoted Message : I know how to do that :)

Message : Thank you! @91878003xxxx spent lot of time in generating the voices!
Quoted Message : Wow this is very real

Message : Haha. We should jam.
Quoted Message : *Shakes hands*

Message : If human can generate similar kind of content, I don‚Äôt think pureplay AI will sell. Human generated content is already limitless.
Only when AI gives way higher quality production or heavily personalized content - then people might start liking it.
Quoted Message : Don‚Äôt you want 8 AI avatars on Arnab‚Äôs show with different personalities?

Message : It was just a joke. But AI fact checking anchor in every debate can be a nice start.

Message : Thinking XYZ movie in Nolan style. Or personalized standup making references about my own personal life - that might really work.

Message : Also if anyone else wants to jam with @91876402xxxx and me, and even potentially collaborate on building this - hit me up. 

I can sell and market. We just need to build a good product.
Quoted Message : Margins are great for this - and competition is less. (text to talking head avatars vs rephrase ai etc). Good product to build.

Message : There will be a popup after every statement then üòÖüòÖ
Quoted Message : It was just a joke. But AI fact checking anchor in every debate can be a nice start.

Message : Interested. Would like to offer something like this to creators on Koo.
Quoted Message : Also if anyone else wants to jam with @9187xxxxxxxx and me, and even potentially collaborate on building this - hit me up. \n\nI can sell and market. We just need to build a good product.

Message : Also interested. Particularly interested in the AI Vocalist use case.
Quoted Message : Interested. Would like to offer something like this to creators on Koo.

Message : Please do keep me posted on the jam

Message : Also interested in the jam in a literal sense, as I‚Äôd be happy to beta test to create viral content

Message : Sure will make a group

Message : Any opensource alternative to elevenlabs?

Message : bark

Message : Anyone came across any examples/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries?

Message : Text to sql kind of thing ? And then sql can be run on data or direct qna on csv data?
Quoted Message : Anyone came across any examples/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries?

Message : Thanks! Checking.
Quoted Message : bark

Message : Except for their officially released cloned voices, it hallucinates a lot.

Message : Yes correct
Quoted Message : Text to sql kind of thing ? And then sql can be run on data or direct qna on csv data?

Message : guardrails released this recently

Message : https://twitter.com/ShreyaR/status/1650883072324419587

Message : cc @1217305xxxx

Message : Looks very interesting. DMing for further help.
Quoted Message : Except for their officially released cloned voices, it hallucinates a lot.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : bark

Message : Anyone came across any examples/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries?

Message : Text to sql kind of thing ? And then sql can be run on data or direct qna on csv data?
Quoted Message : Anyone came across any examples/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries?

Message : Thanks! Checking.
Quoted Message : bark

Message : Except for their officially released cloned voices, it hallucinates a lot.

Message : Yes correct
Quoted Message : Text to sql kind of thing ? And then sql can be run on data or direct qna on csv data?

Message : guardrails released this recently

Message : https://twitter.com/ShreyaR/status/1650883072324419587

Message : cc @1217305xxxx

Message : Looks very interesting. DMing for further help.
Quoted Message : Except for their officially released cloned voices, it hallucinates a lot.

Message : Hey

What you guys are using for telemetry- scoring as per like/dislike, analysing feedback of the users.

Message : Couldn't find anything. Trying to build it in house with eventual plans to expose as API & dashboard
Quoted Message : Hey\n\nWhat you guys are using for telemetry- scoring as per like/dislike, analysing feedback of the users.

Message : @91903012xxxx please build this for us! ü´£

Message : The analysis part might be outsource-able to thoughtspot
Quoted Message : Hey\n\nWhat you guys are using for telemetry- scoring as per like/dislike, analysing feedback of the users.

Message : ‚Äé<attached: 00002172-PHOTO-2023-04-29-23-33-31.jpg>

Message : ‚Äé<attached: 00002173-PHOTO-2023-04-29-23-33-47.jpg>

Message : This is what they're currently offering:

Message : ‚Äé<attached: 00002175-PHOTO-2023-04-29-23-35-12.jpg>

Message : Their responses have to be REALLY good to have people leave chatGPT and other LLMs and use these features.

Message : download (2).wav ‚Äé<attached: 00002177-download (2).wav>

Message : Bark is lit too üî•

Message : Lyrics by gpt, vocals and music by bark!

Message : This is the way!

Message : https://github.com/gventuri/pandas-ai
Quoted Message : Anyone came across any examples/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries?

Message : Anyone has found any solution to ChatOpenAI giving "Could not parse LLM output:" errors?

Message : https://github.com/jerryjliu/llama_index/blob/590639a14dd7346b7f5cc00a21dd24ce0d35ae30/gpt_index/langchain_helpers/text_splitter.py#L240

Baffled by the sheer genius of the SentenceSplitter in llama index

Message : https://github.com/openai/openai-python/blob/c556584eff3b36c92278e6af62cfe02ebb68fb65/openai/embeddings_utils.py#L21

just saw this too
Quoted Message : While you're at it, @9198xxxxxxxx and I'd love to know why Langchain does a newline replacement too üòÖ\nhttps://github.com/hwchase17/langchain/blame/d2520a5f1e78f8e7a2f5c888feda62bafd3ab963/langchain/embeddings/huggingface.py#L65

Message : This is what openai used in their rlhf paper - https://scale.com/content-language
Quoted Message : Hey\n\nWhat you guys are using for telemetry- scoring as per like/dislike, analysing feedback of the users.

Message : https://twitter.com/MisbahSy/status/1652479189747130368?t=l_GaFpmX5tP50AfqEut_Dw&s=09

Multi-lingual document search with a no-code interface

Message : I'm excited to try cohere's multilingual model somewhere.. Maybe benchmark it to NLLB :)

Message : basic project idea:
train a chatbot on this : https://support.apple.com/en-in/guide/shortcuts/welcome/ios

Message : shortcuts are super useful if you know what you're doing

Message : Most people don't use them to their full potential since the documentation is so messy

Message : Can be a vague, small step towards AGI for the common-man.

Message : Would love to get a functionality like : "Create shortcuts to automatically change my wallpaper based on 7 images, 1 for each day of the week"

Message : One of my friends set up something like that and it took him 2 full hours to get his head around it

Message : And even generating a step by step guide to make a shortcut should be plenty for people like me

Message : Any best resources for creating charts/graphs from data, open-source "Chart-GPT" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : Got it. Any open source solution which you know?
Quoted Message : This is what openai used in their rlhf paper - https://scale.com/content-language

Message : are you looking to fine-tune or perform RLHF?
Quoted Message : Got it. Any open source solution which you know?

Message : RLHF on an open-source model*

Message : Majorly for RLHF.
Firstly, want to visualise the data in a nice format, so that can improve the prompt manually.
With this, want to have analyse metrics like - per user usage, etc.
Quoted Message : are you looking to fine-tune or perform RLHF?

Message : So, for the first case, let‚Äôs say
If a user gets a false response from the assistant and gives a bad review, how should we go about analysing it - by the storing that particular message or by getting the complete chat as the message can be contextual with the other messages in the chat.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØSaurab Paruthi

Message : Hey , 

I am using one of the sentence transformers models  for embedding.

I used to use the Replit but figured out the api stops working after some time and need to restart the function.

Is there any better solution?

Message : Contextual is the way to go. Tracing will allow for this. Working on it now
Quoted Message : So, for the first case, let‚Äôs say\nIf a user gets a false response from the assistant and gives a bad review, how should we go about analysing it - by the storing that particular message or by getting the complete chat as the message can be contextual with the other messages in the chat.

Message : Alright
Quoted Message : Contextual is the way to go. Tracing will allow for this. Working on it now

Message : Add more RAM to your REPL with a boost. Repl on Replit might've very limited RAM, they're like 2007 PCs in terms of specs.
Quoted Message : Hey , \n\nI am using one of the sentence transformers models  for embedding.  \n\nI used to use the Replit but figured out the api stops working after some time and need to restart the function. \n\nIs there any better solution?

Message : ‚Äé<attached: 00002206-PHOTO-2023-04-30-14-31-18.jpg>

Message : Any other alternative you suggest?  Let me try to increase the ram and see?
Quoted Message : Add more RAM to your REPL with a boost. Repl on Replit might've very limited RAM, they're like 2007 PCs in terms of specs.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : RLHF on an open-source model*

Message : Majorly for RLHF.
Firstly, want to visualise the data in a nice format, so that can improve the prompt manually.
With this, want to have analyse metrics like - per user usage, etc.
Quoted Message : are you looking to fine-tune or perform RLHF?

Message : So, for the first case, let‚Äôs say
If a user gets a false response from the assistant and gives a bad review, how should we go about analysing it - by the storing that particular message or by getting the complete chat as the message can be contextual with the other messages in the chat.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØSaurab Paruthi

Message : Hey , 

I am using one of the sentence transformers models  for embedding.

I used to use the Replit but figured out the api stops working after some time and need to restart the function.

Is there any better solution?

Message : Contextual is the way to go. Tracing will allow for this. Working on it now
Quoted Message : So, for the first case, let‚Äôs say\nIf a user gets a false response from the assistant and gives a bad review, how should we go about analysing it - by the storing that particular message or by getting the complete chat as the message can be contextual with the other messages in the chat.

Message : Alright
Quoted Message : Contextual is the way to go. Tracing will allow for this. Working on it now

Message : Add more RAM to your REPL with a boost. Repl on Replit might've very limited RAM, they're like 2007 PCs in terms of specs.
Quoted Message : Hey , \n\nI am using one of the sentence transformers models  for embedding.  \n\nI used to use the Replit but figured out the api stops working after some time and need to restart the function. \n\nIs there any better solution?

Message : ‚Äé<attached: 00002206-PHOTO-2023-04-30-14-31-18.jpg>

Message : Any other alternative you suggest?  Let me try to increase the ram and see?
Quoted Message : Add more RAM to your REPL with a boost. Repl on Replit might've very limited RAM, they're like 2007 PCs in terms of specs.

Message : How do I read this - how‚Äôs the recall measured?
Quoted Message :  2023_04_30_3EB08416A509BE3FF857AA.jpeg

Message : Those details are the same as here: https://ann-benchmarks.com
Quoted Message : How do I read this - how‚Äôs the recall measured?

Message : What would be the best way to implement a file search? If I have a ton of documents and I want a semantic search on top of it to solve the discovery problem, how should I go about it? One use case could be for google drive.

I was thinking, get all documents' metadata + content, make embeddings, search on top of it. Not sure of the efficiency given I'm not looking for answers from the doc, just want to make relevant search... Thoughts?

Message : Langchain has a drive connector fwik. You could use that to then do search with it's helper functions
Quoted Message : What would be the best way to implement a file search? If I have a ton of documents and I want a semantic search on top of it to solve the discovery problem, how should I go about it? One use case could be for google drive.\n\nI was thinking, get all documents' metadata + content, make embeddings, search on top of it. Not sure of the efficiency given I'm not looking for answers from the doc, just want to make relevant search... Thoughts?

Message : okay, I'll check that.. thanks.
Quoted Message : Langchain has a drive connector fwik. You could use that to then do search with it's helper functions

Message : Nice, performance gains attributed to rust vs golang? Assuming both are using the same algo (hnsw) ?
Quoted Message :  2023_04_30_3EB08416A509BE3FF857AA.jpeg

Message : is the tuning of recall/speed done by building a new index for each point on this plot, or is it tunable per query?

Message : This is the code outline we used: 
https://github.com/erikbern/ann-benchmarks/blob/main/ann_benchmarks/algorithms/qdrant.py

See the runner for answer to your question (and other specifics on how indexing, single vs batch) are executed:
https://github.com/erikbern/ann-benchmarks/blob/main/ann_benchmarks/runner.py

It's all FOSS, qdrant folks want Weaviate to get a chance to respond
Quoted Message : is the tuning of recall/speed done by building a new index for each point on this plot, or is it tunable per query?

Message : Folks we are starting the Learners' discussion at 4pm - Join here : meet.google.com/jag-jjny-owf

cc'ing those who voted for this slot : @91990072xxxx @91824763xxxx @91789933xxxx @91943220xxxx @91991692xxxx @91637926xxxx @91787042xxxx @91992063xxxx @91775505xxxx @91896919xxxx @81802388xxxx @91987102xxxx @91801866xxxx @91994446xxxx @91788006xxxx @1650963xxxx @91959744xxxx @91962021xxxx @91875456xxxx @91809262xxxx @91961193xxxx @91789543xxxx @91773832xxxx @91819753xxxx @1510493xxxx @491515183xxxx @91886154xxxx @91997032xxxx @91762015xxxx @91917924xxxx @91858501xxxx @91702215xxxx @91772808xxxx @91931036xxxx @91953785xxxx
Quoted Message : https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240

Message : Thanks @91961193xxxx  @91942037xxxx @91990072xxxx for joining in and sharing pointers and notes üôè

Message : I found this tool that shows a nice dashboard of costs incurred while using OpenAI api‚Äôs : https://llm.report
The demo looks good, can find out usage costs per model

Message : Thanks @91988071xxxx for hosting

Message : Looking for feedback on a new product that I'm working on that generates design from prompts using a design system, would love to get some feedback. DM me or upvote and I will send a message üß∞ Thanks :D

Message : Are there any graphic designers in this group who are interested in learning more about using stable diffusion in their work? I'd love to talk and understand where generative AI can make the most impact in your work. And then hopefully show you how you can apply it

Message : This is nice. Do you know any other tool which also has per user usage tables?
Quoted Message : I found this tool that shows a nice dashboard of costs incurred while using OpenAI api‚Äôs : https://llm.report\nThe demo looks good, can find out usage costs per model

Message : Would also love to interview product designers ‚ù§Ô∏è

Message : On that note, would like to connect to folks in marketing, specially graphic designers in marketing agencies, or if you know anyone in such agency, kindly connect üôè

Message : https://twitter.com/bohanhou1998/status/1652151502012837890?s=20

Message : Haven‚Äôt found any other yet
Quoted Message : This is nice. Do you know any other tool which also has per user usage tables?

Message : ‚Äé<attached: 00002228-PHOTO-2023-05-01-00-53-21.jpg>

Message : It's quite public, OpenAI demos it everywhere?

Message : MUST get access to this tool
Quoted Message : It's quite public, OpenAI demos it everywhere?

Message : The fastest way to get GPT Plugins access is perhaps to make a Twitter viral demo ü•≤
Quoted Message : MUST get access to this tool

Message : I have GPT plugins access, but I don't this tool anywhere in the ui
Quoted Message : The fastest way to get GPT Plugins access is perhaps to make a Twitter viral demo ü•≤

Message : https://github.com/georgia-tech-db/eva

AI enabled queries on top of unstructured data (videos, images) ü´°

Message : Any  *** flask / python web stack devs here for freelance? Thx!

Message : Dm ing.

I've been working with flask + django + k8s for the past 3 years while working for the World Health Organization.
Quoted Message : Any  *** flask / python web stack devs here for freelance? Thx!

Message : AutoGPT is now emerging as a catch all for any automation it seems. Jason Calacanis has posted a bounty worth $270 on Replit for outbound sales emails

RIP high-volume, low-quality SDR:

https://replit.com/bounties/@JasonCalacanis/aichrome-extension-t?t=applications

Message : I was able to deploy something locally ( followed line by line advice of chatgpt) to generate personalised DM, email + coffee conversation points for a linkedin profile as a non coder. Jason's requirement should be easy stuff for someone better.
Quoted Message : AutoGPT is now emerging as a catch all for any automation it seems. Jason Calacanis has posted a bounty worth $270 on Replit for outbound sales emails\n\nRIP high-volume, low-quality SDR:\n\nhttps://replit.com/bounties/@JasonCalacanis/aichrome-extension-t?t=applications

Message : Link to this group? Want to add a friend

Message : @91773788xxxx can I post an GenAI internship opportunity at Koo here?

Message : Posting it without really posting it üòé
Quoted Message : @9177xxxxxxxx can I post an GenAI internship opportunity at Koo here?

Message : I just pinged @91961949xxxx ki please delete this too üòÖ

I've seen too many communities die once we allow hiring and fundraising news to be allowed

Message : We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there
Quoted Message : I just pinged @9196xxxxxxxx ki please delete this too üòÖ\n\nI've seen too many communities die once we allow hiring and fundraising news to be allowed

Message : Agree
Quoted Message : We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there

Message : Lots of good talent here and opportunities

Message : A subgroup for hiring could be a great idea, keeping this group for ideas/discussions
Quoted Message : We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there

Message : How about a subreddit with flairs for hiring, news, discussion etc?

Message : Perhaps a weekly post with all open roles can work better instead of a separate WA group? That makes it easier for all seekers to discover open roles also. 

I'll be happy to collate and do it myself. Maybe leave üëç here if that works?

Message : The challenge is that posting on LinkedIn has been ineffective for specific areas and GenAI has very few communities.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : @91773788xxxx can I post an GenAI internship opportunity at Koo here?

Message : Posting it without really posting it üòé
Quoted Message : @9177xxxxxxxx can I post an GenAI internship opportunity at Koo here?

Message : I just pinged @91961949xxxx ki please delete this too üòÖ

I've seen too many communities die once we allow hiring and fundraising news to be allowed

Message : We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there
Quoted Message : I just pinged @9196xxxxxxxx ki please delete this too üòÖ\n\nI've seen too many communities die once we allow hiring and fundraising news to be allowed

Message : Agree
Quoted Message : We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there

Message : Lots of good talent here and opportunities

Message : A subgroup for hiring could be a great idea, keeping this group for ideas/discussions
Quoted Message : We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there

Message : How about a subreddit with flairs for hiring, news, discussion etc?

Message : Perhaps a weekly post with all open roles can work better instead of a separate WA group? That makes it easier for all seekers to discover open roles also. 

I'll be happy to collate and do it myself. Maybe leave üëç here if that works?

Message : The challenge is that posting on LinkedIn has been ineffective for specific areas and GenAI has very few communities.

Message : Sent you something similar
Quoted Message : Perhaps a weekly post with all open roles can work better instead of a separate WA group? That makes it easier for all seekers to discover open roles also. \n\nI'll be happy to collate and do it myself. Maybe leave üëç here if that works?

Message : ‚Äé~‚ÄØNirant changed the group description

Message : For folks interested in hiring from the community, added a Google Form here: https://nirantk.com/community
Quoted Message : Perhaps a weekly post with all open roles can work better instead of a separate WA group? That makes it easier for all seekers to discover open roles also. \n\nI'll be happy to collate and do it myself. Maybe leave üëç here if that works?

Message : Why not have a diff announcement group? ü§î
Quoted Message : For folks interested in hiring from the community, added a Google Form here: https://nirantk.com/community

Message : +1
Quoted Message : Why not have a diff announcement group? ü§î

Message : Splintering off is a terrible idea ‚Äî that is partially why of the last 3 groups which we've split off: Generative AI + {Art, Philosophy, Startups} ‚Äî 2 are dead and one is comatose
Quoted Message : Why not have a diff announcement group? ü§î

Message : Why is no one discussing AI philosophy üòÇüôà

Message : Stems from my bias since I seeded this community from my friends. I've generally been a believer that the best philosophy is action, not discussion. That is why we care about OpenAI and not say, so many other brilliant teams
Quoted Message : Why is no one discussing AI philosophy üòÇüôà

Message : I would be interested in something that covers hiring freelancers too.
Quoted Message : For folks interested in hiring from the community, added a Google Form here: https://nirantk.com/community

Message : Yeah, please add there! You can mention in the questions that what kinda freelancing role is this e.g. contractual, but recurring, project based. That is why the questions are free form :)
Quoted Message : I would be interested in something that covers hiring freelancers too.

Message : https://www.youtube.com/watch?v=FE88OOUBonQ

Damn, andrew ng is building a generic few shot computer vision platform

Message : ‚Äé<attached: 00002265-PHOTO-2023-05-01-17-26-01.jpg>

Message : Send link?

Message : Anyone interested in teaming up for Warpspeed?

Message : Looking forward to participate, hopefully this one is online
Quoted Message :  2023_05_01_1B965CB2AD3DBA1CCF14690DAA499BCB.jpeg

Message : It is mentioned that it is an offline event
Quoted Message : Looking forward to participate, hopefully this one is online

Message : ‚Äé<attached: 00002270-PHOTO-2023-05-01-18-14-46.jpg>

Message : Offline, only selected candidates will be allowed
Quoted Message : Looking forward to participate, hopefully this one is online

Message : Meta's SAM under the hood?
Quoted Message : https://www.youtube.com/watch?v=FE88OOUBonQ\n\nDamn, andrew ng is building a generic few shot computer vision platform

Message : Yes it's offline, please do apply :)
Quoted Message : Offline, only selected candidates will be allowed

Message : Will there be selections for attending the hackathon?
Quoted Message : Yes it's offline, please do apply :)

Message : Nope, this is a custom model, haven‚Äôt seen anything quite like it anywhere else
Quoted Message : Meta's SAM under the hood?

Message : + 1. Need more teams from this group. And winners! I‚Äôm up as well to jam with anyone looking.
Quoted Message : Anyone interested in teaming up for Warpspeed?

Message : ‚Äé<attached: 00002278-PHOTO-2023-05-01-23-37-19.jpg>

Message : Have you tried if it works when you call it from outside those notebooks?
Quoted Message :  2023_05_01_3EB0B73B944469D88AAD08.jpeg

Message : Ok yeah doesn't work. Interesting.

Message : AuthenticationError: Your authentication token is not from a valid issuer.

Message : Wireshark it and find if you can get the headers?
Quoted Message : AuthenticationError: Your authentication token is not from a valid issuer.

Message : I mean, this is just nerd-sniping @91876402xxxx, I feel ambushed üòÇ

Message : I also want this magic api key though that I can just publish in my code lol

Message : playwright might be easier than reverse engineering the jupyter notebook api üëÄ
Quoted Message : Wireshark it and find if you can get the headers?

Message : Sal Khan just gave another Ted, the vision reimagined with AI. As good and powerful as the first one. 

https://youtu.be/hJP5GqnTrNo

Message : Hinton is leaving google

Message : https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html

Message : Article is biased

Message : His tweets are better

Message : https://twitter.com/zoink/status/1653052807950536706

lol

Message : How are you folks using ChatGPT to learn?

https://twitter.com/Suhail/status/1651091438367809537

This has been surprisingly good for a lot of topics

Message : Yudbot.com
If someone wants to test their AI safety knowledge in a frustrating way.

Message : I'm starting work on a llm vault manager to bring API level caps ($ &/or tokens)

right now I'm planning with:
- configure_limits
- record_input
- record_output

any better abstraction here and ideas? not directly building inside langchain to keep it open for all LLMs.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : playwright might be easier than reverse engineering the jupyter notebook api üëÄ
Quoted Message : Wireshark it and find if you can get the headers?

Message : Sal Khan just gave another Ted, the vision reimagined with AI. As good and powerful as the first one. 

https://youtu.be/hJP5GqnTrNo

Message : Hinton is leaving google

Message : https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html

Message : Article is biased

Message : His tweets are better

Message : https://twitter.com/zoink/status/1653052807950536706

lol

Message : How are you folks using ChatGPT to learn?

https://twitter.com/Suhail/status/1651091438367809537

This has been surprisingly good for a lot of topics

Message : Yudbot.com
If someone wants to test their AI safety knowledge in a frustrating way.

Message : I'm starting work on a llm vault manager to bring API level caps ($ &/or tokens)

right now I'm planning with:
- configure_limits
- record_input
- record_output

any better abstraction here and ideas? not directly building inside langchain to keep it open for all LLMs.

Message : @91870951xxxx @91933437xxxx
Quoted Message : I'm starting work on a llm vault manager to bring API level caps ($ &/or tokens)\n\nright now I'm planning with: \n- configure_limits\n- record_input\n- record_output\n\nany better abstraction here and ideas? not directly building inside langchain to keep it open for all LLMs.

Message : also is API level cap, something that you generally try to keep? got some responses on twitter - wanted to check here too if people would find it useful

Message : @91989995xxxx might be interesting for you
Quoted Message : I'm starting work on a llm vault manager to bring API level caps ($ &/or tokens)\n\nright now I'm planning with: \n- configure_limits\n- record_input\n- record_output\n\nany better abstraction here and ideas? not directly building inside langchain to keep it open for all LLMs.

Message : https://www.yudbot.com/

Message : If something can cause the world harm, shouldn‚Äôt  the news article be open to all and not behind a paywall ü§∑üèª‚Äç‚ôÇÔ∏èüòú
Quoted Message : https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html

Message : If this was a political group, I'd say that this is an example of capitalism at its prime. But hey, I don't want to get banned üòû
Quoted Message : If something can cause the world harm, shouldn‚Äôt  the news article be open to all and not behind a paywall ü§∑üèª‚Äç‚ôÇÔ∏èüòú

Message : ‚Äé<attached: 00002303-PHOTO-2023-05-02-07-09-43.jpg>

Message : How are you folks adding conversational memory to gpt-3.5-turbo?

Building a chat app and need it to remember previous chat history for context.

Message : Might help :)
https://python.langchain.com/en/latest/modules/memory.html

Message : I would have loved to plug Langchain here if they had absolutely anything which worked
Quoted Message : How are you folks adding conversational memory to gpt-3.5-turbo?\n\nBuilding a chat app and need it to remember previous chat history for context.

Message : Could you please elaborate? Trying this out. Any shortcomings that we need to be aware of?
Quoted Message : I would have loved to plug Langchain here if they had absolutely anything which worked

Message : https://augmented-reality-knowledge.github.io/

Anyone here working on 3D generation problem statements ? Would love to jam

Message : Is this not working for you?
https://platform.openai.com/docs/api-reference/chat/create

You can specify previous history as part of `messages` that you send to the model.
Quoted Message : How are you folks adding conversational memory to gpt-3.5-turbo?\n\nBuilding a chat app and need it to remember previous chat history for context.

Message : Random shortcoming from the last 24 hours alone which I've seen:
1. Adding any form of Retriever to this chat leads to tokenisation and other forms of errors, which require fixes in the lib itself
2. Because Langchain keeps the message history in memory as a Python object, we've to manually wire it back to some store e.g. I used Redis
Quoted Message : Could you please elaborate? Trying this out. Any shortcomings that we need to be aware of?

Message : For a lot of _common_ use cases (outside of agents), it's perhaps better to roll your own then to use Langchain ‚Äî and I say this as the resident Langchain fanboi of this group

Message : What if there are a lot of messages? Exceed 4096 tokens.
Quoted Message : Is this not working for you?\nhttps://platform.openai.com/docs/api-reference/chat/create\n\nYou can specify previous history as part of `messages` that you send to the model.

Message : Make an extra API call and ask the model which messages are worth keeping up
Quoted Message : What if there are a lot of messages? Exceed 4096 tokens.

Message : Give an Example?
Quoted Message : Make an extra API call and ask the model which messages are worth keeping up

Message : Code flow example: https://github.com/hwchase17/langchain/blob/master/langchain/memory/summary.py

tl;dr: keep moving the conversation to a `history` object and summarize it. With each message, you unfurl the `history` back to the user-AI dialogue format which chat models expect

Message : thanks!

Message : 1) Does it make sense to use something else like llamaindex now. Anyone who has experience using both of them?

2) When not using langchain and rolling on your own, using document loaders and indexes becomes a pain. Do you recommend to look at their source code directly and copy paste the implementation in your own code or is there a better third party library for this?
Quoted Message : For a lot of _common_ use cases (outside of agents), it's perhaps better to roll your own then to use Langchain ‚Äî and I say this as the resident Langchain fanboi of this group

Message : There was a person from luma labs here no? ü§î
Quoted Message : https://augmented-reality-knowledge.github.io/\n\nAnyone here working on 3D generation problem statements ? Would love to jam

Message : A friend has used llamaindex for chat conversations and was satisfied
Quoted Message : 1) Does it make sense to use something else like llamaindex now. Anyone who has experience using both of them?\n\n2) When not using langchain and rolling on your own, using document loaders and indexes becomes a pain. Do you recommend to look at their source code directly and copy paste the implementation in your own code or is there a better third party library for this?

Message : He is in the other group created  by Nirant.
Quoted Message : A friend has used llamaindex for chat conversations and was satisfied

Message : DMing you
Quoted Message : A friend has used llamaindex for chat conversations and was satisfied

Message : @91959137xxxx for chat convos how has your experience been with llamaindex?

Message : I know you use both langchain and llama

Message : Yeah I started of with gpt index but moved to langchain

Message : Actually I wanted to create custom tools

Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : For these use cases, Langchain is still very good
Quoted Message : 1) Does it make sense to use something else like llamaindex now. Anyone who has experience using both of them?\n\n2) When not using langchain and rolling on your own, using document loaders and indexes becomes a pain. Do you recommend to look at their source code directly and copy paste the implementation in your own code or is there a better third party library for this?

Message : Why Lucene/OpenSearch? Have a requirement which prevents you from using a decent VectorDB or Elastic itself?
Quoted Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : For storing chat history isn't llama better? Thought you had some points on this
Quoted Message : Yeah I started of with gpt index but moved to langchain

Message : I have
Quoted Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : It gets the job done

Message : Those are also options being evaluated but there are company level constraints on them.
Quoted Message : Why Lucene/OpenSearch? Have a requirement which prevents you from using a decent VectorDB or Elastic itself?

Message : @91773788xxxx any input on the 2nd question?
Quoted Message : For these use cases, Langchain is still very good

Message : Thanks, I will DM you.
Quoted Message : I have

Message : This is my biggest worry of using LangChain in production env. This is a very active repo lot of PRs being merged but still don't see much quality checks around it (unit and integration tests). Like Haystack and even some part of Transformers repo has which I feel should be required for any production quality codebase.
Quoted Message : Random shortcoming from the last 24 hours alone which I've seen:\n1. Adding any form of Retriever to this chat leads to tokenisation and other forms of errors, which require fixes in the lib itself\n2. Because Langchain keeps the message history in memory as a Python object, we've to manually wire it back to some store e.g. I used Redis

Message : It's not just about backward compatibility. It's also about clarity on what they want to do ‚Äî Langchain seems to be prioritising agents, tools and toolchain around that over everything else
Quoted Message : This is my biggest worry of using LangChain in production env. This is a very active repo lot of PRs being merged but still don't see much quality checks around it (unit and integration tests). Like Haystack and even some part of Transformers repo has which I feel should be required for any production quality codebase.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : For these use cases, Langchain is still very good
Quoted Message : 1) Does it make sense to use something else like llamaindex now. Anyone who has experience using both of them?\n\n2) When not using langchain and rolling on your own, using document loaders and indexes becomes a pain. Do you recommend to look at their source code directly and copy paste the implementation in your own code or is there a better third party library for this?

Message : Why Lucene/OpenSearch? Have a requirement which prevents you from using a decent VectorDB or Elastic itself?
Quoted Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : For storing chat history isn't llama better? Thought you had some points on this
Quoted Message : Yeah I started of with gpt index but moved to langchain

Message : I have
Quoted Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : It gets the job done

Message : Those are also options being evaluated but there are company level constraints on them.
Quoted Message : Why Lucene/OpenSearch? Have a requirement which prevents you from using a decent VectorDB or Elastic itself?

Message : @91773788xxxx any input on the 2nd question?
Quoted Message : For these use cases, Langchain is still very good

Message : Thanks, I will DM you.
Quoted Message : I have

Message : This is my biggest worry of using LangChain in production env. This is a very active repo lot of PRs being merged but still don't see much quality checks around it (unit and integration tests). Like Haystack and even some part of Transformers repo has which I feel should be required for any production quality codebase.
Quoted Message : Random shortcoming from the last 24 hours alone which I've seen:\n1. Adding any form of Retriever to this chat leads to tokenisation and other forms of errors, which require fixes in the lib itself\n2. Because Langchain keeps the message history in memory as a Python object, we've to manually wire it back to some store e.g. I used Redis

Message : It's not just about backward compatibility. It's also about clarity on what they want to do ‚Äî Langchain seems to be prioritising agents, tools and toolchain around that over everything else
Quoted Message : This is my biggest worry of using LangChain in production env. This is a very active repo lot of PRs being merged but still don't see much quality checks around it (unit and integration tests). Like Haystack and even some part of Transformers repo has which I feel should be required for any production quality codebase.

Message : True we wrote own in js stuff moved away from langchain , will open source soon once we have most basic func
Quoted Message : It's not just about backward compatibility. It's also about clarity on what they want to do ‚Äî Langchain seems to be prioritising agents, tools and toolchain around that over everything else

Message : Question was around data connectors and indexing: 

My 2 cents: I wouldn't be rolling that on my own now. You're better off using Langchain, Llama Index anything. Rolling your own Transform in ELT as a Python lib is too much overhead, and will often break in ways that you've not thought of.
Quoted Message : @9177xxxxxxxx any input on the 2nd question?

Message : Does deforum have a commercial license?

Message : interesting - I've been using https://deeplearn.org/ for this

Message : Has anybody tried Semantic Kernel? Do you see this as langchain alternative? 
https://github.com/microsoft/semantic-kernel/blob/main/python/README.md (Seems cleaner to me)

Message : I don't see it as a Langchain alternative yet (doesn't care about agents, data indexing, tools at all) ‚Äî but for the few things it does, it does have a cleaner API. I am planning to try it out if a project comes along
Quoted Message : Has anybody tried Semantic Kernel? Do you see this as langchain alternative? \nhttps://github.com/microsoft/semantic-kernel/blob/main/python/README.md (Seems cleaner to me)

Message : Hmm, you're right. I could see Semantic Kernel adding tools, agents as capabilities with a clean-ish API in the short term.

Message : But it'd be quite ironical if $MSFT has better API design than a well-funded, immensely popular FOSS project to be honest ü•≤
Quoted Message : Hmm, you're right. I could see Semantic Kernel adding tools, agents as capabilities with a clean-ish API in the short term.

Message : yea! heard they raised another round already (not sure about the source though)

MSFT has been doing some really good stuff lately though in OSS
Quoted Message : But it'd be quite ironical if $MSFT has better API design than a well-funded, immensely popular FOSS project to be honest ü•≤

Message : Why though?
Quoted Message : But it'd be quite ironical if $MSFT has better API design than a well-funded, immensely popular FOSS project to be honest ü•≤

Message : I frankly don‚Äôt see any llm abstraction library really working out in the near term. Its like writing a C compiler for a changing chip design and Instruction set before x86
Quoted Message : Hmm, you're right. I could see Semantic Kernel adding tools, agents as capabilities with a clean-ish API in the short term.

Message : API design has little to do with community traction I'd believe
Quoted Message : Why though?

Message : Say more, I don't understand you
Quoted Message : API design has little to do with community traction I'd believe

Message : Fun analogy, but the x86 is GPT4 no?
Quoted Message : I frankly don‚Äôt see any llm abstraction library really working out in the near term. Its like writing a C compiler for a changing chip design and Instruction set before x86

Message : Gpt is the processor, instruction set is the prompts
Quoted Message : Fun analogy, but the x86 is GPT4 no?

Message : MSFT is the fastest moving startup in his new world IMO
Quoted Message : yea! heard they raised another round already (not sure about the source though)\n\nMSFT has been doing some really good stuff lately though in OSS

Message : Reminds of the SaaS joke I've made since 2019: All B2B salesfolk work for Microsoft, only some know it
Quoted Message : MSFT is the fastest moving startup in his new world IMO

Message : I love how one man Satya Nadella has changed that perception over a few years, completely
Quoted Message : MSFT is the fastest moving startup in his new world IMO

Message : Don't use langchain, absolute shit show at scale. Memory is essentially a list of chat messages, In our system, we save it in redis as a single serialised string, retrieved and constructed at run time. I've also implemented a moving window approach to summarise chat history to save on tokens. Happy to discuss more.
Quoted Message : How are you folks adding conversational memory to gpt-3.5-turbo?\n\nBuilding a chat app and need it to remember previous chat history for context.

Message : https://github.com/jerryjliu/llama_index/blob/main/gpt_index/prompts/default_prompts.py

https://sourcegraph.com/search?q=context:global+repo:%5Egithub%5C.com/hwchase17/langchain%24+file:/prompt.py%24&patternType=standard&sm=1&groupBy=path

The most useful parts of langchain and llamaindex by far - but if you take 5 minutes to go through these you‚Äôll know how impossible it is to build a good abstraction over this limited instruction set
Quoted Message : I would have loved to plug Langchain here if they had absolutely anything which worked

Message : langchain is buggy as hell also.

Message : this is gold! üåü
Quoted Message : https://github.com/jerryjliu/llama_index/blob/main/gpt_index/prompts/default_prompts.py\n\nhttps://sourcegraph.com/search?q=context:global+repo:%5Egithub%5C.com/hwchase17/langchain%24+file:/prompt.py%24&patternType=standard&sm=1&groupBy=path\n\nThe most useful parts of langchain and llamaindex by far - but if you take 5 minutes to go through these you‚Äôll know how impossible it is to build a good abstraction over this limited instruction set

Message : Thanks! Will DM. We‚Äôre doing something similar - a simple moving window of 500 input tokens.
Quoted Message : Don't use langchain, absolute shit show at scale. Memory is essentially a list of chat messages, In our system, we save it in redis as a single serialised string, retrieved and constructed at run time. I've also implemented a moving window approach to summarise chat history to save on tokens. Happy to discuss more.

Message : fwiw we've been using llama index in prod for two weeks now doing around 500 questions on the company docs daily / no issues

Message : Please, can we make a simple colab notebook that has best practices of implementing rolling windows contexts?
Quoted Message : Thanks! Will DM. We‚Äôre doing something similar - a simple moving window of 500 input tokens.

Message : I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because "this is the first thing I said!"
Quoted Message : Don't use langchain, absolute shit show at scale. Memory is essentially a list of chat messages, In our system, we save it in redis as a single serialised string, retrieved and constructed at run time. I've also implemented a moving window approach to summarise chat history to save on tokens. Happy to discuss more.

Message : maybe do dynamic rolling window for every question? Store all messages but only pass the ones relevant to the current questio
Quoted Message : I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because \"this is the first thing I said!\"

Message : What about summarisation? We‚Äôve tried calling the openai summarisation API to summarise the prev chat but it‚Äôs slow af
Quoted Message : I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because \"this is the first thing I said!\"

Message : We need some inside info on how chatgpt is doing this ü´£

Message : OpenAI has a summarisation API? Didn't they deprecate that?
Quoted Message : What about summarisation? We‚Äôve tried calling the openai summarisation API to summarise the prev chat but it‚Äôs slow af

Message : Prompt engineering helps there. Think of your usecases as bucketed modules. Don't use a one size fits all prompt, but smartly create prompts that can preserve needed info. Has been working well for our usecases
Quoted Message : I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because \"this is the first thing I said!\"

Message : Openai once suggested to us in 2020 to use a smaller and faster model for summarisation here, wonder how well that works
Quoted Message : What about summarisation? We‚Äôve tried calling the openai summarisation API to summarise the prev chat but it‚Äôs slow af

Message : It's a trade off, experience vs expense. Have to take that call based on your product.
Quoted Message : maybe do dynamic rolling window for every question? Store all messages but only pass the ones relevant to the current questio

Message : use gpt-3.5 only, prompt it well, keep temp low.
Quoted Message : What about summarisation? We‚Äôve tried calling the openai summarisation API to summarise the prev chat but it‚Äôs slow af

Message : Had worked on Lucene (query side) and written custom rankers in Solr etc. But not worked with OpenSearch. It's been a while.
Quoted Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : @91944563xxxx
Quoted Message : There was a person from luma labs here no? ü§î

Message : Would this be of help? It creates a running summary of earlier conversations while also retaining the latest n interactions in their richer form.

https://python.langchain.com/en/latest/modules/memory/types/summary_buffer.html
Quoted Message : I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because \"this is the first thing I said!\"

Message : Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com

He would be delighted to do an online discussion.

Hit üëç if you are interested and I can reach out to him to set up a chat.

Message : I think we might have the answer why LangChain is so focused on tools and agents 

https://twitter.com/colintjarvis/status/1653425662407987201?s=46&t=icC0fizZK8E3ONsDVuGFWA
Quoted Message : I don't see it as a Langchain alternative yet (doesn't care about agents, data indexing, tools at all) ‚Äî but for the few things it does, it does have a cleaner API. I am planning to try it out if a project comes along

Message : Using tools and agents with LangChain officially part of OpenAI cookbook


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Prompt engineering helps there. Think of your usecases as bucketed modules. Don't use a one size fits all prompt, but smartly create prompts that can preserve needed info. Has been working well for our usecases
Quoted Message : I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because \"this is the first thing I said!\"

Message : Openai once suggested to us in 2020 to use a smaller and faster model for summarisation here, wonder how well that works
Quoted Message : What about summarisation? We‚Äôve tried calling the openai summarisation API to summarise the prev chat but it‚Äôs slow af

Message : It's a trade off, experience vs expense. Have to take that call based on your product.
Quoted Message : maybe do dynamic rolling window for every question? Store all messages but only pass the ones relevant to the current questio

Message : use gpt-3.5 only, prompt it well, keep temp low.
Quoted Message : What about summarisation? We‚Äôve tried calling the openai summarisation API to summarise the prev chat but it‚Äôs slow af

Message : Had worked on Lucene (query side) and written custom rankers in Solr etc. But not worked with OpenSearch. It's been a while.
Quoted Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : @91944563xxxx
Quoted Message : There was a person from luma labs here no? ü§î

Message : Would this be of help? It creates a running summary of earlier conversations while also retaining the latest n interactions in their richer form.

https://python.langchain.com/en/latest/modules/memory/types/summary_buffer.html
Quoted Message : I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because \"this is the first thing I said!\"

Message : Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com

He would be delighted to do an online discussion.

Hit üëç if you are interested and I can reach out to him to set up a chat.

Message : I think we might have the answer why LangChain is so focused on tools and agents 

https://twitter.com/colintjarvis/status/1653425662407987201?s=46&t=icC0fizZK8E3ONsDVuGFWA
Quoted Message : I don't see it as a Langchain alternative yet (doesn't care about agents, data indexing, tools at all) ‚Äî but for the few things it does, it does have a cleaner API. I am planning to try it out if a project comes along

Message : Using tools and agents with LangChain officially part of OpenAI cookbook

Message : Also a very basic question for anyone who can help 

I‚Äôm seeing a lot of hype on GPT-3.5 with Code Interpreter plug-in

It‚Äôs able to perform reasonably good data analysis on data dump in CSV,XLSX files


How is this different than giving access to a Python Repl to an LLM agent instance

Eg could be ->Load CSV/XLSX into a SQLite3 db/pandas df and then ask the agent to carry out relevant analysis

Message : You mean executing untrusted code from an LLM?
Quoted Message : Also a very basic question for anyone who can help \n\nI‚Äôm seeing a lot of hype on GPT-3.5 with Code Interpreter plug-in \n\nIt‚Äôs able to perform reasonably good data analysis on data dump in CSV,XLSX files \n\n\nHow is this different than giving access to a Python Repl to an LLM agent instance \n\nEg could be ->Load CSV/XLSX into a SQLite3 db/pandas df and then ask the agent to carry out relevant analysis

Message : Python environment can be sandboxed ?
Quoted Message : You mean executing untrusted code from an LLM?

Message : Also not an agent like AutoGPT/BabyAGI

More like custom LLM agent using LangChain
Quoted Message : You mean executing untrusted code from an LLM?

Message : Doing so in production at a decent scale
Quoted Message : My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?

Message : Awesome. Would love to talk. Will DM you
Quoted Message : Doing so in production at a decent scale

Message : What‚Äôs the scale?
Quoted Message : Doing so in production at a decent scale

Message : https://twitter.com/samim/status/1653289578390749186?s=46


@91876402xxxx integrating?

Message : Done ‚úÖ 
https://gooey.ai/compare-text-to-speech-engines/?example_id=m2royk7q
Quoted Message : https://twitter.com/samim/status/1653289578390749186?s=46\n\n\n@9187xxxxxxxx integrating?

Message : Nice

Message : GPT4 creates a vector DB: https://twitter.com/AlistairPullen/status/1653459578229788672?s=20

Message : Replit open source LLM just dropped. Its released under CC BY-SA 4.0, which allows for commercial use.

https://huggingface.co/replit

Message : ‚Äé<attached: 00002395-PHOTO-2023-05-03-08-13-31.jpg>

Message : is this what powers ghostwriter?

Message : https://twitter.com/grimezsz/status/1652696738820689921?s=46&t=v5MAnKU6XwMWCzMNzmBUuA

Message : Looks like he also called it out on his pod https://www.youtube.com/watch?v=WBgrfWW8xxA&t=2095s
Quoted Message : AutoGPT is now emerging as a catch all for any automation it seems. Jason Calacanis has posted a bounty worth $270 on Replit for outbound sales emails\n\nRIP high-volume, low-quality SDR:\n\nhttps://replit.com/bounties/@JasonCalacanis/aichrome-extension-t?t=applications

Message : Finetune on instruction dataset curated from geeksforgeeks
Quoted Message :  2023_05_03_3EB0C1CC8C19F30EC7F062.jpeg

Message : https://twitter.com/pirroh/status/1653586734641471490

Doesn't confirm if it is the same model that powers ghostwriter, ü§ûon updates and improvements
Quoted Message : is this what powers ghostwriter?

Message : Prompt Injection in less than 10 minutes (video, slides, transcripts): 
https://simonwillison.net/2023/May/2/prompt-injection-explained/

Excellent primer

Message : Also the very fun follow up article to why you can‚Äôt use AI to fix this üòÇ

https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/
Quoted Message : Prompt Injection in less than 10 minutes (video, slides, transcripts): \nhttps://simonwillison.net/2023/May/2/prompt-injection-explained/\n\nExcellent primer

Message : Anybody applied for the OpenAI service on Azure?

How long does it take for your application to get reviewed?

Message : Got ours withing a couple of days
Quoted Message : Anybody applied for the OpenAI service on Azure?\n\nHow long does it take for your application to get reviewed?

Message : JSONFormer: https://github.com/1rgs/jsonformer ‚Äî guaranteed JSON output with Huggingface LLMs

Message : cc Ankita @91882678xxxx is from Microsoft Azure India ‚Äî can reach out to her directly
Quoted Message : Anybody applied for the OpenAI service on Azure?\n\nHow long does it take for your application to get reviewed?

Message : Why would you do that? ü§£Sorry ankita be ready to be bombarded with api requests
Quoted Message : cc Ankita @9188xxxxxxxx is from Microsoft Azure India ‚Äî can reach out to her directly

Message : Please DM me - happy to help
Quoted Message : Anybody applied for the OpenAI service on Azure?\n\nHow long does it take for your application to get reviewed?

Message : the approach looks very promising!
Quoted Message : JSONFormer: https://github.com/1rgs/jsonformer ‚Äî guaranteed JSON output with Huggingface LLMs

Message : ‚Äé<attached: 00002412-PHOTO-2023-05-03-18-00-25.jpg>

Message : DeepFloyd or Multi-ControlNet?

Message : Abstract artwork I made using stable diffusion. Abstracts are hard to conceptualize and compose but they're a lot of fun!

Message : Neither
Quoted Message : DeepFloyd or Multi-ControlNet?

Message : Custom trained checkpoint, good use of prompts and neg prompts, inpainting, upscaling. And several iterative loops with tweaks in each interation

Message : Somewhat counterintuitive, but knowing art techniques, major movements and history really helps while working with Stable Diffusion. For example you will know to prompt "impressionism oil on canvas painting, thick brush strokes, palette knife technique"

Message : It was used in the prompt of several of the iterations used to make this

Message : Is there a model (other than gpt4) that can extract info from a image in JSON format? 

I tried Google's new pix2struct. It's horribly bad. The examples that they have shared are definitely handpicked.

Message : What kind of info?

Message : Basic OCR should be able to do that, unless you want only some part of the text
Quoted Message : Is there a model (other than gpt4) that can extract info from a image in JSON format? \n\nI tried Google's new pix2struct. It's horribly bad. The examples that they have shared are definitely handpicked.

Message : Does anyone know anyone who has access to multi-modal gpt4?

Message : That‚Äôs true for multiple mediums. People who understand cameras really well can describe various aspects of the image in precise instructions. Similarly I have seen experienced writers perform much better in my workshops while using chatgpt.
Quoted Message : Somewhat counterintuitive, but knowing art techniques, major movements and history really helps while working with Stable Diffusion. For example you will know to prompt \"impressionism oil on canvas painting, thick brush strokes, palette knife technique\"

Message : I feed it search result cards from any website and it gives me extracted data with {fieldName: value}

notice that value part is easy with OCR. But fieldName is often very hard.
Quoted Message : What kind of info?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Neither
Quoted Message : DeepFloyd or Multi-ControlNet?

Message : Custom trained checkpoint, good use of prompts and neg prompts, inpainting, upscaling. And several iterative loops with tweaks in each interation

Message : Somewhat counterintuitive, but knowing art techniques, major movements and history really helps while working with Stable Diffusion. For example you will know to prompt "impressionism oil on canvas painting, thick brush strokes, palette knife technique"

Message : It was used in the prompt of several of the iterations used to make this

Message : Is there a model (other than gpt4) that can extract info from a image in JSON format? 

I tried Google's new pix2struct. It's horribly bad. The examples that they have shared are definitely handpicked.

Message : What kind of info?

Message : Basic OCR should be able to do that, unless you want only some part of the text
Quoted Message : Is there a model (other than gpt4) that can extract info from a image in JSON format? \n\nI tried Google's new pix2struct. It's horribly bad. The examples that they have shared are definitely handpicked.

Message : Does anyone know anyone who has access to multi-modal gpt4?

Message : That‚Äôs true for multiple mediums. People who understand cameras really well can describe various aspects of the image in precise instructions. Similarly I have seen experienced writers perform much better in my workshops while using chatgpt.
Quoted Message : Somewhat counterintuitive, but knowing art techniques, major movements and history really helps while working with Stable Diffusion. For example you will know to prompt \"impressionism oil on canvas painting, thick brush strokes, palette knife technique\"

Message : I feed it search result cards from any website and it gives me extracted data with {fieldName: value}

notice that value part is easy with OCR. But fieldName is often very hard.
Quoted Message : What kind of info?

Message : Yes! That‚Äôs so true
Quoted Message : That‚Äôs true for multiple mediums. People who understand cameras really well can describe various aspects of the image in precise instructions. Similarly I have seen experienced writers perform much better in my workshops while using chatgpt.

Message : Infact, we can extract values without OCR as well. HTML contains most of the info anyways.
Quoted Message : I feed it search result cards from any website and it gives me extracted data with {fieldName: value}\n\nnotice that value part is easy with OCR. But fieldName is often very hard.

Message : @91748189xxxx check if this can help
Quoted Message : JSONFormer: https://github.com/1rgs/jsonformer ‚Äî guaranteed JSON output with Huggingface LLMs

Message : Thanks. But I think it's solving a different problem :(
Quoted Message : @9174xxxxxxxx check if this can help

Message : https://www.spellpage.com/?utm_source=bensbites&utm_medium=newsletter&utm_campaign=pi-the-new-ai-on-the-block

Message : autogpt app

Message : A schema of the output json would help
Quoted Message : Is there a model (other than gpt4) that can extract info from a image in JSON format? \n\nI tried Google's new pix2struct. It's horribly bad. The examples that they have shared are definitely handpicked.

Message : It should depend on how the clip model used to create  captions describes the image

That's a major difference between sd v1.5 and v2.0, from talking to many SD tinkerers, they prefer v1.5 because it's easier to do prompting on it compared to v2.0
Quoted Message : That‚Äôs true for multiple mediums. People who understand cameras really well can describe various aspects of the image in precise instructions. Similarly I have seen experienced writers perform much better in my workshops while using chatgpt.

Message : If these result cards are in tabular form, table-transformer might help. https://github.com/microsoft/table-transformer
Quoted Message : I feed it search result cards from any website and it gives me extracted data with {fieldName: value}\n\nnotice that value part is easy with OCR. But fieldName is often very hard.

Message : ‚Äé<attached: 00002436-PHOTO-2023-05-03-20-31-10.jpg>

Message : haha, been there!
Quoted Message :  2023_05_03_5E5A9BADD0A4C7DA85A3.jpeg

Message : Hey folks, can you help with the group invite link? (Can't find it in description)

Message : No issues at all
Quoted Message : Why would you do that? ü§£Sorry ankita be ready to be bombarded with api requests

Message : Sorry for delay in response earlier

Message : Have worked on this before. This kind of information is hard to parse in general case (sometimes value can be left of field or right of field, the field and value both can be non regex-able etc). Is there strong geometric structure or is the layout confirming to some standard (think specific bank forms etc). If not folks train specific models to extract these for specific class of documents. Little busy for next day or so, if not urgent message me and happy to chat later.
Quoted Message : I feed it search result cards from any website and it gives me extracted data with {fieldName: value}\n\nnotice that value part is easy with OCR. But fieldName is often very hard.

Message : Has anyone tried langflow here? Please DM if you have, thanks!

Message : https://techcrunch.com/2023/05/03/where-is-india-in-the-generative-ai-race/

Message : https://www.latent.space/p/reza-shabani#details

Message : interview with our head of ML and swyx

Message : While there are over 1500 AI-based startups in India with over $4 billion of funding, India is still losing the AI innovation battle,‚Äù said analysts at Sanford C. Bernstein.


This is outrageous. With UPI, ONDC, Healthcare we already are thought leaders with technology but this narrative underplays the India growth story!
What does it take to train a LLM in indigenous Indian languages, thoughts? @91773788xxxx @91994530xxxx
Quoted Message : https://techcrunch.com/2023/05/03/where-is-india-in-the-generative-ai-race/

Message : Chris Lattner's new ML focussed language

https://twitter.com/jeremyphoward/status/1653649643602051072?t=-IVYmQrfx4_-_wLaAHnaeg&s=19

Message : @91995246xxxx - is working on this. More from him.
Quoted Message : While there are over 1500 AI-based startups in India with over $4 billion of funding, India is still losing the AI innovation battle,‚Äù said analysts at Sanford C. Bernstein.\n\n\nThis is outrageous. With UPI, ONDC, Healthcare we already are thought leaders with technology but this narrative underplays the India growth story! \nWhat does it take to train a LLM in indigenous Indian languages, thoughts? @9177xxxxxxxx @9199xxxxxxxx

Message : Amazing. Would love to connect and contribute.
Quoted Message : @9199xxxxxxxx - is working on this. More from him.

Message : https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table

Message : I would also like to learn more and contribute in this project
Quoted Message : While there are over 1500 AI-based startups in India with over $4 billion of funding, India is still losing the AI innovation battle,‚Äù said analysts at Sanford C. Bernstein.\n\n\nThis is outrageous. With UPI, ONDC, Healthcare we already are thought leaders with technology but this narrative underplays the India growth story! \nWhat does it take to train a LLM in indigenous Indian languages, thoughts? @9177xxxxxxxx @9199xxxxxxxx

Message : I think the entire article can be summarised in 3 sentences - 
1. No foundational model training happening in India
2. IT Services companies starting gen AI implementation projects (pretty obvious, no surprise)
3. Startups just getting started but nothing newsworthy yet.
Quoted Message : While there are over 1500 AI-based startups in India with over $4 billion of funding, India is still losing the AI innovation battle,‚Äù said analysts at Sanford C. Bernstein.\n\n\nThis is outrageous. With UPI, ONDC, Healthcare we already are thought leaders with technology but this narrative underplays the India growth story! \nWhat does it take to train a LLM in indigenous Indian languages, thoughts? @9177xxxxxxxx @9199xxxxxxxx

Message : Yes, keen to learn more!
Quoted Message : @9199xxxxxxxx - is working on this. More from him.

Message : Can someone add the author Manish Singh from Tech Crunch to this group if they have the number https://twitter.com/refsrc?s=21

Message : We have coders, designers, PMs and VCs here but any journalists or media folks? Please say hi!

Message : Asking
Quoted Message : Can someone add the author Manish Singh from Tech Crunch to this group if they have the number https://twitter.com/refsrc?s=21

Message : Hi Manish üëãüèª
Quoted Message : Asking

Message : Thanks for adding Aakrit -- good to be here

Message : Good to see you here @91989918xxxx
Quoted Message : Thanks for adding Aakrit -- good to be here

Message : Good to see you here @91991631xxxx
Quoted Message : Good to see you here @9198xxxxxxxx

Message : Yes
Quoted Message : is this what powers ghostwriter?

Message : Glad to be a part - thanks for adding me @91992060xxxx 

Hey folks, I'm Rahul, was in BITS Pilani until 2020, now building stuff in fintech/edtech space.

Been dabbling w some generative AI stuff lately.

Here's something I built recently (generated a new physics lecture in feynman's personality,  cloned his voice/video): https://twitter.com/rahulchhabra07/status/1653828722519330817?s=20

would love to be a part of this group and jam on new ideas. :)

Message : Good to see you here!
Quoted Message : Glad to be a part - thanks for adding me @9199xxxxxxxx \n\nHey folks, I'm Rahul, was in BITS Pilani until 2020, now building stuff in fintech/edtech space. \n\nBeen dabbling w some generative AI stuff lately. \n\nHere's something I built recently (generated a new physics lecture in feynman's personality,  cloned his voice/video): https://twitter.com/rahulchhabra07/status/1653828722519330817?s=20 \n\nwould love to be a part of this group and jam on new ideas. :)

Message : Oh hi haha! likewise :)

Message : https://twitter.com/alexwan55/status/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19

Not sure if this was shared here before but the potential to poison LLM models during instruction training or RLHF has significant implications I believe considering how central the tech is becoming

Message : any model (large language or not) with many parameters suffers from the curse of dimensionality and it is fundamentally impractical to cover all modes of adversarial attack
Quoted Message : https://twitter.com/alexwan55/status/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19\n\nNot sure if this was shared here before but the potential to poison LLM models during instruction training or RLHF has significant implications I believe considering how central the tech is becoming


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Hi Manish üëãüèª
Quoted Message : Asking

Message : Thanks for adding Aakrit -- good to be here

Message : Good to see you here @91989918xxxx
Quoted Message : Thanks for adding Aakrit -- good to be here

Message : Good to see you here @91991631xxxx
Quoted Message : Good to see you here @9198xxxxxxxx

Message : Yes
Quoted Message : is this what powers ghostwriter?

Message : Glad to be a part - thanks for adding me @91992060xxxx 

Hey folks, I'm Rahul, was in BITS Pilani until 2020, now building stuff in fintech/edtech space.

Been dabbling w some generative AI stuff lately.

Here's something I built recently (generated a new physics lecture in feynman's personality,  cloned his voice/video): https://twitter.com/rahulchhabra07/status/1653828722519330817?s=20

would love to be a part of this group and jam on new ideas. :)

Message : Good to see you here!
Quoted Message : Glad to be a part - thanks for adding me @9199xxxxxxxx \n\nHey folks, I'm Rahul, was in BITS Pilani until 2020, now building stuff in fintech/edtech space. \n\nBeen dabbling w some generative AI stuff lately. \n\nHere's something I built recently (generated a new physics lecture in feynman's personality,  cloned his voice/video): https://twitter.com/rahulchhabra07/status/1653828722519330817?s=20 \n\nwould love to be a part of this group and jam on new ideas. :)

Message : Oh hi haha! likewise :)

Message : https://twitter.com/alexwan55/status/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19

Not sure if this was shared here before but the potential to poison LLM models during instruction training or RLHF has significant implications I believe considering how central the tech is becoming

Message : any model (large language or not) with many parameters suffers from the curse of dimensionality and it is fundamentally impractical to cover all modes of adversarial attack
Quoted Message : https://twitter.com/alexwan55/status/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19\n\nNot sure if this was shared here before but the potential to poison LLM models during instruction training or RLHF has significant implications I believe considering how central the tech is becoming

Message : arrey hey rahul üëã!
Quoted Message : Glad to be a part - thanks for adding me @9199xxxxxxxx \n\nHey folks, I'm Rahul, was in BITS Pilani until 2020, now building stuff in fintech/edtech space. \n\nBeen dabbling w some generative AI stuff lately. \n\nHere's something I built recently (generated a new physics lecture in feynman's personality,  cloned his voice/video): https://twitter.com/rahulchhabra07/status/1653828722519330817?s=20 \n\nwould love to be a part of this group and jam on new ideas. :)

Message : There is an opportunity here to create artist focussed digital painting tool using GenerativeAI, right now you are hacking with automatic1111, recursively using the output as the next input, using Photoshop to do what's not possible in automatic etc.

Similar story here - https://youtu.be/K0ldxCh3cnI
Quoted Message :  2023_05_03_3EB06E5F0CFDDF01B9D8A5.jpeg

Message : Hey folks, does anyone in this group have experience creating large scale datasets for llm model training?
Would love to have a chat if possible

Message : How large? I processed around 300GB for https://huggingface.co/aashay96/indic-BloomLM
Quoted Message : Hey folks, does anyone in this group have experience creating large scale datasets for llm model training?\nWould love to have a chat if possible

Message : 300gb is large enough DMing
Quoted Message : How large? I processed around 300GB for https://huggingface.co/aashay96/indic-BloomLM

Message : Folks, I feel openai/evals has many under appreciated concepts. But the documentation is gruesome to simply get started. I'm writing a detailed beginners guide to explain the concepts and how to include evaluations in any generation pipeline.

Any folks who would like to review & give feedback?

Message : cc @91876402xxxx @91955016xxxx would be great to hear from top of my head
Quoted Message : Folks, I feel openai/evals has many under appreciated concepts. But the documentation is gruesome to simply get started. I'm writing a detailed beginners guide to explain the concepts and how to include evaluations in any generation pipeline.\n\nAny folks who would like to review & give feedback?

Message : ‚Äé<attached: 00002478-PHOTO-2023-05-04-09-58-52.jpg>

Message : Can you please look at https://github.com/EleutherAI/lm-evaluation-harness as well? @91773788xxxx
Quoted Message : Folks, I feel openai/evals has many under appreciated concepts. But the documentation is gruesome to simply get started. I'm writing a detailed beginners guide to explain the concepts and how to include evaluations in any generation pipeline.\n\nAny folks who would like to review & give feedback?

Message : Doesn't have qdrant, Weaviate ‚Äî has the same libs as earlier, only adds Vespa as far as I can tell? Did Erik choose to wait for Weaviate feedback?
Quoted Message :  2023_05_04_3EB0F42C5E82EFB38997BA.jpeg

Message : Would love this
Quoted Message : Folks, I feel openai/evals has many under appreciated concepts. But the documentation is gruesome to simply get started. I'm writing a detailed beginners guide to explain the concepts and how to include evaluations in any generation pipeline.\n\nAny folks who would like to review & give feedback?

Message : A very interesting question to ask would be how does OpenAI do on the lm-evaluation-harness, and what does openai/evals which the harness does not?
Quoted Message : Can you please look at https://github.com/EleutherAI/lm-evaluation-harness as well? @9177xxxxxxxx

Message : Unfortunately the whole pipeline is hugginface based. Would require a lot of rewrite
Quoted Message : A very interesting question to ask would be how does OpenAI do on the lm-evaluation-harness, and what does openai/evals which the harness does not?

Message : ‚ÄúTo now be relevant as a SaaS co, depth+breadth of workflow is going to be more and more critical. Point problem solutions will find it harder to establish why they capture value‚Äù. . Good set of thoughts pinned by @91982082xxxx

https://www.linkedin.com/pulse/ai-eating-software-world-kumar-aakash-aacash-eth-?utm_source=share&utm_medium=member_ios&utm_campaign=share_via

Message : yep, was wondering what the choice for libraries was.. Redis seems to be doing very well though
Quoted Message : Doesn't have qdrant, Weaviate ‚Äî has the same libs as earlier, only adds Vespa as far as I can tell? Did Erik choose to wait for Weaviate feedback?

Message : Already building this artist‚Äôs tool üòâ
Didn‚Äôt make that art on Automatic
Quoted Message : There is an opportunity here to create artist focussed digital painting tool using GenerativeAI, right now you are hacking with automatic1111, recursively using the output as the next input, using Photoshop to do what's not possible in automatic etc.\n\nSimilar story here - https://youtu.be/K0ldxCh3cnI

Message : Oh nice üî•
Quoted Message : Already building this artist‚Äôs tool üòâ\nDidn‚Äôt make that art on Automatic

Message : HF <> Inferless (@91813040xxxx ) on deploying GenAI models meet-up on June 10th.
Check it out here - https://twitter.com/risingsayak/status/1653984521962807298?s=46

Message : Thanks for the shoutout Ravi! Folks, please share what all would you like us to cover specifically around model training and deployment.. I am all ears! üòÉ
Quoted Message : HF <> Inferless (@9181xxxxxxxx ) on deploying GenAI models meet-up on June 10th.\nCheck it out here - https://twitter.com/risingsayak/status/1653984521962807298?s=46

Message : Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com

He would be delighted to do an online discussion.

Hit üëç if you are interested and I can reach out to him to set up a chat.

Message : Hey folks - Vikram is excited to have a session. 

Any specific times work? Given he is in Canada, and most of us are nocturnal, I'm proposing next week (Tuesday/Wed) 9p Or 10p IST
Quoted Message : Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com\n\nHe would be delighted to do an online discussion. \n\nHit üëç if you are interested and I can reach out to him to set up a chat.

Message : Has anybody used weaviate ? I am trying to use the near_vector with my own vector embeddings and its not returning any results . I could use some help if somebody has done it before.

Message : I believe Soumendra @91749807xxxx was giving it a shot
Quoted Message : Has anybody used weaviate ? I am trying to use the near_vector with my own vector embeddings and its not returning any results . I could use some help if somebody has done it before.

Message : What do you mean by your own vector embeddings?
Quoted Message : Has anybody used weaviate ? I am trying to use the near_vector with my own vector embeddings and its not returning any results . I could use some help if somebody has done it before.

Message : How are you generating them?

Message : Thanks for responding. I am not using any of the prebuilt vectorizers.

Message : with client.batch as batch:
batch.batch_size=100
# Batch import all Questions
for i in range(len_total):
print(f"importing question: {i+1}")

properties = {
"text": Lines[i],
"vector": embeddings_all[i]
}

client.batch.add_data_object(properties, "Question")

Message : cc @91953570xxxx from RestOfWorld is here. He's also quite comfy with Midjourney and ChatGPT based apps.
Quoted Message : We have coders, designers, PMs and VCs here but any journalists or media folks? Please say hi!

Message : Here the embeddings are my vectors generated thru Sentence Transformers  [ choose  your model ]

Message : Example : from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')

Message : embeddings = model.encode(Lines)

Message : What does the search query look like?

Message : result = (
client.query
.get("Question", ["text","vector"])
.with_near_vector({
"vector": q_new_embeddings.tolist(),
})
.with_limit(5)
.do()
)

Message : See the near_vector please

Message : Moving this to one-on-ine as this is going to get technical

Message : Yes that's better

Message : Can you DM me output of print(result)? We'll take it forward from there.
Quoted Message : result = (\n    client.query\n    .get(\"Question\", [\"text\",\"vector\"])\n    .with_near_vector({\n        \"vector\": q_new_embeddings.tolist(),\n    })\n    .with_limit(5)\n    .do()\n)

Message : Maybe try reducing "certainty" to 0.7 and see?

Message : How one can achieve multi-tenancy in Qdrant?
Via filter or creating separate collection or something else?

Message : Thank you ; reduced further still no luck
Quoted Message : Maybe try reducing \"certainty\" to 0.7 and see?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : embeddings = model.encode(Lines)

Message : What does the search query look like?

Message : result = (
client.query
.get("Question", ["text","vector"])
.with_near_vector({
"vector": q_new_embeddings.tolist(),
})
.with_limit(5)
.do()
)

Message : See the near_vector please

Message : Moving this to one-on-ine as this is going to get technical

Message : Yes that's better

Message : Can you DM me output of print(result)? We'll take it forward from there.
Quoted Message : result = (\n    client.query\n    .get(\"Question\", [\"text\",\"vector\"])\n    .with_near_vector({\n        \"vector\": q_new_embeddings.tolist(),\n    })\n    .with_limit(5)\n    .do()\n)

Message : Maybe try reducing "certainty" to 0.7 and see?

Message : How one can achieve multi-tenancy in Qdrant?
Via filter or creating separate collection or something else?

Message : Thank you ; reduced further still no luck
Quoted Message : Maybe try reducing \"certainty\" to 0.7 and see?

Message : +1 have the same question about vector dbs
Quoted Message : How one can achieve multi-tenancy in Qdrant?\nVia filter or creating separate collection or something else?

Message : I have used Faiss and Milvus (via Haystack) for personal projects very long time ago. Used to create create separate collections for different type of datas. As that time filters were not common in these vector dbs. Now like to understand is there other better way, ideally separating storage from query layer.
Quoted Message : +1 have the same question about vector dbs

Message : Yes, separate collections is perhaps the cleanest way? 

https://qdrant.tech/documentation/how_to/#serve-vectors-for-many-independent-users
Quoted Message : How one can achieve multi-tenancy in Qdrant?\nVia filter or creating separate collection or something else?

Message : For folks interested in Generative Art, cool results from inpainting and other SD tricks there: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J

Message : ‚Äé<attached: 00002518-PHOTO-2023-05-04-12-38-35.jpg>

Message : https://github.com/unum-cloud/usearch

Yet another vector search engine

Message : From NimbleBox folks in India, @91805628xxxx and friends ‚Äî low-code for making chat experiences in particular: https://github.com/NimbleBoxAI/ChainFury

Message : Thanks for the shout-out Nirant üôèüèªüòä
Quoted Message : From NimbleBox folks in India, @9180xxxxxxxx and friends ‚Äî low-code for making chat experiences in particular: https://github.com/NimbleBoxAI/ChainFury

Message : I have done this. 
Quick question, were you using any vector store abstractions? Like haystack or langchain document store?
Quoted Message : Has anybody used weaviate ? I am trying to use the near_vector with my own vector embeddings and its not returning any results . I could use some help if somebody has done it before.

Message : What level of multi tenancy do you require? Separate collection is the easiest way, but you can go for a sharded approach, if you need horizontal scale
Quoted Message : How one can achieve multi-tenancy in Qdrant?\nVia filter or creating separate collection or something else?

Message : Hi everyone, 

We are using gpt-3 da-vinci-003 model for a clustering use case, basically creating a set of relatable data points for a given 'input prompt + data points'. Due to token limit of 4096, we are not able to process for more than 150 data points.

Any advise on how to solve around this? It will be very helpful.

Message : Average out the embeddings for the document
Quoted Message : Hi everyone, \n\nWe are using gpt-3 da-vinci-003 model for a clustering use case, basically creating a set of relatable data points for a given 'input prompt + data points'. Due to token limit of 4096, we are not able to process for more than 150 data points.\n\nAny advise on how to solve around this? It will be very helpful.

Message : Are you predicting related keywords for a given text and then clustering somehow ?
Quoted Message : Hi everyone, \n\nWe are using gpt-3 da-vinci-003 model for a clustering use case, basically creating a set of relatable data points for a given 'input prompt + data points'. Due to token limit of 4096, we are not able to process for more than 150 data points.\n\nAny advise on how to solve around this? It will be very helpful.

Message : For most prompts it's usually semantic keyword matching, in some scenarios there can be some logic involved
Quoted Message : Are you predicting related keywords for a given text and then clustering somehow ?

Message : Shyam, a few details which will help us answer your question better: 
1. Did you mean the OpenAI embedding endpoint?
2. What is the LLM doing in clustering directly? Are you using it to tag in some way?
Quoted Message : Hi everyone, \n\nWe are using gpt-3 da-vinci-003 model for a clustering use case, basically creating a set of relatable data points for a given 'input prompt + data points'. Due to token limit of 4096, we are not able to process for more than 150 data points.\n\nAny advise on how to solve around this? It will be very helpful.

Message : Could you describe your approach ?
Quoted Message : For most prompts it's usually semantic keyword matching, in some scenarios there can be some logic involved

Message : Example, if the user is prompting 'x of 10%', but the data point has the absolute value of that variable, then some logic will be needed.
Quoted Message : For most prompts it's usually semantic keyword matching, in some scenarios there can be some logic involved

Message : We don't implement the matching, because the prompts are varied as I mentioned, we are directly feeding the data and prompt to gpt-3
Quoted Message : Could you describe your approach ?

Message : Is there a reason for using text-davinci-003 and NOT gpt3.5-turbo?
Quoted Message : We don't implement the matching, because the prompts are varied as I mentioned, we are directly feeding the data and prompt to gpt-3

Message : 1. No, just the GPT-3 endpoint.
2. Not for tagging. We are using LLM to cluster based on user's input prompt directly.
Quoted Message : Shyam, a few details which will help us answer your question better: \n1. Did you mean the OpenAI embedding endpoint? \n2. What is the LLM doing in clustering directly? Are you using it to tag in some way?

Message : No reason, have to try gpt-3.5-turbo and compare results
Quoted Message : Is there a reason for using text-davinci-003 and NOT gpt3.5-turbo?

Message : Any links/readings to understand this in detail?
Quoted Message : Average out the embeddings for the document

Message : Thanks ! Can you also please share the invite link for this group
Quoted Message : For folks interested in Generative Art, cool results from inpainting and other SD tricks there: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J

Message : https://huggingface.co/gemasphi/laprador-document-encoder
Quoted Message : Any links/readings to understand this in detail?

Message : Has anybody used langchain or llama index for hybrid embeddings? I was looking through their code to find what they use for sparse embeddings. Llama seems to use BERT and langchain I couldn‚Äôt find

Message : The error was the Vectors were not inserted properly. The correct code [ highly simplified is here]
Quoted Message : I believe Soumendra @9174xxxxxxxx was giving it a shot

Message : with client.batch as batch:
batch.batch_size=100
# Batch import all Questions
for i in range(len_total):
print(f"importing question: {i+1}")

properties = {
"text": Lines[i]
}

client.batch.add_data_object(properties, "ENMAX",vector = embeddings_all[i])

Message : Vector =  < Place your VECTOR embeddings here>

Message : Llama Index has extensible Retrievers, so shouldn't matter either way no?
Quoted Message : Has anybody used langchain or llama index for hybrid embeddings? I was looking through their code to find what they use for sparse embeddings. Llama seems to use BERT and langchain I couldn‚Äôt find

Message : Thanks to  Soumendra @+91¬†74980¬†76111  for trying yo help me

Message : Thank you for your interest. I used simple Python and Weavite librarues
Quoted Message : I have done this. \nQuick question, were you using any vector store abstractions? Like haystack or langchain document store?

Message : Thanks Sharding is another good way.
Quoted Message : What level of multi tenancy do you require? Separate collection is the easiest way, but you can go for a sharded approach, if you need horizontal scale

Message : Ah got it. So BERT was just an example
Quoted Message : Llama Index has extensible Retrievers, so shouldn't matter either way no?

Message : Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.
Quoted Message : Thank you for your interest. I used simple Python and Weavite librarues

Message : cc @91974101xxxx was a Haystack contributor :)
Quoted Message : Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.

Message : Yeah, Llama Index has decent Retriever design. Some Custom examples: https://github.com/jerryjliu/llama_index/blob/main/examples/query/CustomRetrievers.ipynb
Quoted Message : Ah got it. So BERT was just an example

Message : I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty?
Quoted Message : Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.

Message : Ease of use, right place at right time, became viral too fast before people even knew about alternatives
Quoted Message : I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty?

Message : Once the GitHub stars started picking up everyone's eyes were on it.

No stopping that train

Message : Haystack is much better in code quality and documentation imo.
Langchain was mostly LLM focused, so got the hype, so the side things also got popularity I guess


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Thank you for your interest. I used simple Python and Weavite librarues
Quoted Message : I have done this. \nQuick question, were you using any vector store abstractions? Like haystack or langchain document store?

Message : Thanks Sharding is another good way.
Quoted Message : What level of multi tenancy do you require? Separate collection is the easiest way, but you can go for a sharded approach, if you need horizontal scale

Message : Ah got it. So BERT was just an example
Quoted Message : Llama Index has extensible Retrievers, so shouldn't matter either way no?

Message : Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.
Quoted Message : Thank you for your interest. I used simple Python and Weavite librarues

Message : cc @91974101xxxx was a Haystack contributor :)
Quoted Message : Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.

Message : Yeah, Llama Index has decent Retriever design. Some Custom examples: https://github.com/jerryjliu/llama_index/blob/main/examples/query/CustomRetrievers.ipynb
Quoted Message : Ah got it. So BERT was just an example

Message : I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty?
Quoted Message : Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.

Message : Ease of use, right place at right time, became viral too fast before people even knew about alternatives
Quoted Message : I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty?

Message : Once the GitHub stars started picking up everyone's eyes were on it.

No stopping that train

Message : Haystack is much better in code quality and documentation imo.
Langchain was mostly LLM focused, so got the hype, so the side things also got popularity I guess

Message : Chatgpt helped as well, probably they rode that wave, may be haystack didn't treat chatgpt as urgent requirement

I am out of semantic search for past 6mo, so just a guess

Message : Langchain is not about semantic search, it's about QA, Tools and Agents. In fact, there is no search API in Langchain.
Quoted Message : I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty?

Message : I mean there is overlap between both
Quoted Message : Langchain is not about semantic search, it's about QA, Tools and Agents. In fact, there is no search API in Langchain.

Message : indexes feels like semantic search interface - https://python.langchain.com/en/latest/modules/indexes/getting_started.html

but agree, tools, agents are unique to langchain

Message : Thanks, this discussion helped understanding strengths of langchain and/vs haystack
Quoted Message : Langchain is not about semantic search, it's about QA, Tools and Agents. In fact, there is no search API in Langchain.

Message : yeah, just discovered this: https://docs.haystack.deepset.ai/docs/document_store because of the discussion here. I was thinking of creating a similar abstraction layer (i.e. provide a single API for vector DBs, allowing any VectorDB to be plugged in), but I might just depend on this now

Message : True. Apart from code and documentation. Haystack is very good in design. Just check how haystack implemented PromptNode and compare it with Langchain. You will see the difference.
Quoted Message : Haystack is much better in code quality and documentation imo.\nLangchain was mostly LLM focused, so got the hype, so the side things also got popularity I guess

Message : ‚Äú This approach is the most flexible, but creating numerous collections may result in resource overhead.  only recommended to separate users into multiple collections if you have a limited number of users ‚Äú

Looks like it won‚Äôt work when 100s of  users of mine create 100s of independent collections
Quoted Message : Yes, separate collections is perhaps the cleanest way? \n\nhttps://qdrant.tech/documentation/how_to/#serve-vectors-for-many-independent-users

Message : Agreed. And the vector store abstraction too. Granted it's not perfect, but flexible enough to mould it the way we want.
Quoted Message : True. Apart from code and documentation. Haystack is very good in design. Just check how haystack implemented PromptNode and compare it with Langchain. You will see the difference.

Message : 100s should be pretty fine from what I've been told internally
Quoted Message : ‚Äú This approach is the most flexible, but creating numerous collections may result in resource overhead.  only recommended to separate users into multiple collections if you have a limited number of users ‚Äú\n\nLooks like it won‚Äôt work when 100s of  users of mine create 100s of independent collections

Message : 100x100 na
Quoted Message : 100s should be pretty fine from what I've been told internally

Message : ‚Äé<attached: 00002576-PHOTO-2023-05-04-14-36-07.jpg>

Message : Go for sharded approach imo, cluster will take care of fault tolerance, shards will take care of horizontal scaling. It's easy to build.
Don't know if there is an existing solution out there for this. Vitess architecture is pretty great and I've seen it work in massive load in production, would be cool to build something like this for vectore stores.
Quoted Message : 100x100 na

Message : fwiw, all FOSS Vector DBs offer cloud solutions so that you don't have to think about cluster sizing, managing servers, sharding and  problems like what @91807546xxxx just mentioned
Quoted Message : Go for sharded approach imo, cluster will take care of fault tolerance, shards will take care of horizontal scaling. It's easy to build.\nDon't know if there is an existing solution out there for this. Vitess architecture is pretty great and I've seen it work in massive load in production, would be cool to build something like this for vectore stores.

Message : Build vs Buy üòÑ
Quoted Message : fwiw, all FOSS Vector DBs offer cloud solutions so that you don't have to think about cluster sizing, managing servers, sharding and  problems like what @9180xxxxxxxx just mentioned

Message : Vitess is a great tool.

Even SQL proxy similar "VectorDB proxy" would also work üôÇ

Almost all RDBMS follow some variant of SQL standards but we don't have the same for Vector DBs. Maybe in the future ü§ûüèº
Quoted Message : Go for sharded approach imo, cluster will take care of fault tolerance, shards will take care of horizontal scaling. It's easy to build.\nDon't know if there is an existing solution out there for this. Vitess architecture is pretty great and I've seen it work in massive load in production, would be cool to build something like this for vectore stores.

Message : For folks wondering: https://vitess.io/ is a tool for sharding ‚Äî and here is a good primer for what sharding means: https://aws.amazon.com/what-is/database-sharding/

Message : Have y‚Äôall heard of Modular? Chris Lattner‚Äôs (authors of LLVM and Swift and programmer extraordinaire) startup that is trying to create a new AI programming language. Jeremy Howard is an adviser, and here he introduces the language. There are cases it is 3000x faster than equivalent Python code for matrix multiplication 

https://www.youtube.com/watch?v=6GvB5lZJqcE

Message : https://planetscale.com/ does managed Vitess as well. We were exploring it at Razorpay.
Quoted Message : For folks wondering: https://vitess.io/ is a tool for sharding ‚Äî and here is a good primer for what sharding means: https://aws.amazon.com/what-is/database-sharding/

Message : Reminder: Programming language is called Mojo. It's not Free or Open Source. Given how Java shaped up, I'm wary of using anything without a community around it to maintain and at least do basic security fixes for 5-10 years.
Quoted Message : Have y‚Äôall heard of Modular? Chris Lattner‚Äôs (authors of LLVM and Swift and programmer extraordinaire) startup that is trying to create a new AI programming language. Jeremy Howard is an adviser, and here he introduces the language. There are cases it is 3000x faster than equivalent Python code for matrix multiplication \n\nhttps://www.youtube.com/watch?v=6GvB5lZJqcE

Message : How did Razorpay end up doing sharding?
Quoted Message : https://planetscale.com/ does managed Vitess as well. We were exploring it at Razorpay.

Message : Not being open source at launch was a weird choice...  Can't remember the last time a language launched like that...
Quoted Message : Reminder: Programming language is called Mojo. It's not Free or Open Source. Given how Java shaped up, I'm wary of using anything without a community around it to maintain and at least do basic security fixes for 5-10 years.

Message : We didn't go ahead in the end. üòÖ
We bought some time through other means. So, there was still some time before we had the need to shard.
Quoted Message : How did Razorpay end up doing sharding?

Message : Jeremy was a strong proponent of TF Swift as well. But that hasn't seen major adoption even inside G so ymmv
Quoted Message : Have y‚Äôall heard of Modular? Chris Lattner‚Äôs (authors of LLVM and Swift and programmer extraordinaire) startup that is trying to create a new AI programming language. Jeremy Howard is an adviser, and here he introduces the language. There are cases it is 3000x faster than equivalent Python code for matrix multiplication \n\nhttps://www.youtube.com/watch?v=6GvB5lZJqcE

Message : https://open.substack.com/pub/semianalysis/p/google-we-have-no-moat-and-neither?r=2gao6&utm_medium=ios&utm_campaign=post

Message : ‚Äé<attached: 00002593-PHOTO-2023-05-04-16-17-18.jpg>

Message : (from the above article)

Message : Why do I think this graph is on a log scale üòÖ

Message : Hey, i wanted to understand the difference between generative pre training vs instruction tuning in terms of huggingface trainer class. How does the training objective change?

Message : This is using gpt4 as a judge having it rate llm outputs
Quoted Message :  2023_05_04_3EB08EDC4938ADA9392E44.jpeg

Message : https://lmsys.org/blog/2023-03-30-vicuna/

Message : ‚ÄúAccording to a fun and non-scientific evaluation with GPT-4. Further rigorous evaluation is needed.‚Äù

üòÇ

Message : Exactly!

Message : Maybe we run openi evals on it :)

Message : This eval doesn't make any sense to me. Already LLMs capabilities to produce such ranks/marks are highly debated to it's stochastic nature. It's like a teacher that gives a different score each time when she evaluates  answer from a different room
Quoted Message :  2023_05_04_3EB08EDC4938ADA9392E44.jpeg

Message : Yea... independent and good benchmarking of AI needs to be a thing...

Message : LLM evaluation is an open research question. We have some nlp eval methods like lm-eval-harness but need to improve from that.

Message : just to add one more point, alpaca and vinuca are LLAMA derivatives so I don't think it can fit in that graph since they aren't new base LLMs. Also I don't think its good idea to train models on chatgpts output like Alpaca did, if you're curious about the reason:https://twitter.com/Shahules786/status/1650898925178720256
Quoted Message :  2023_05_04_3EB08EDC4938ADA9392E44.jpeg

Message : Benchmarking has this weird dynamic of very useful for industry and their labs, but gives no glory to people who make them ‚Äî so it doesn't attract hackers or academics. 

But once you've a benchmark which is marketed by Stan-ahem-ahem-ford, everyone uses it and the PhD student gets a GoogleAI job on graduation
Quoted Message : Yea... independent and good benchmarking of AI needs to be a thing...

Message : Sure... at the research level some objective ones will help but also at the consumer and solutions level... We have a full tech gadget review industry... A similar AI review industry is needed...  This impacts everyone and everything now...
Quoted Message : LLM evaluation is an open research question. We have some nlp eval methods like lm-eval-harness but need to improve from that.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://lmsys.org/blog/2023-03-30-vicuna/

Message : ‚ÄúAccording to a fun and non-scientific evaluation with GPT-4. Further rigorous evaluation is needed.‚Äù

üòÇ

Message : Exactly!

Message : Maybe we run openi evals on it :)

Message : This eval doesn't make any sense to me. Already LLMs capabilities to produce such ranks/marks are highly debated to it's stochastic nature. It's like a teacher that gives a different score each time when she evaluates  answer from a different room
Quoted Message :  2023_05_04_3EB08EDC4938ADA9392E44.jpeg

Message : Yea... independent and good benchmarking of AI needs to be a thing...

Message : LLM evaluation is an open research question. We have some nlp eval methods like lm-eval-harness but need to improve from that.

Message : just to add one more point, alpaca and vinuca are LLAMA derivatives so I don't think it can fit in that graph since they aren't new base LLMs. Also I don't think its good idea to train models on chatgpts output like Alpaca did, if you're curious about the reason:https://twitter.com/Shahules786/status/1650898925178720256
Quoted Message :  2023_05_04_3EB08EDC4938ADA9392E44.jpeg

Message : Benchmarking has this weird dynamic of very useful for industry and their labs, but gives no glory to people who make them ‚Äî so it doesn't attract hackers or academics. 

But once you've a benchmark which is marketed by Stan-ahem-ahem-ford, everyone uses it and the PhD student gets a GoogleAI job on graduation
Quoted Message : Yea... independent and good benchmarking of AI needs to be a thing...

Message : Sure... at the research level some objective ones will help but also at the consumer and solutions level... We have a full tech gadget review industry... A similar AI review industry is needed...  This impacts everyone and everything now...
Quoted Message : LLM evaluation is an open research question. We have some nlp eval methods like lm-eval-harness but need to improve from that.

Message : Need a rtings.com of this space...

Message : That is exactly how ImageNet was born fwiw, and Stanford DAWN Bench and so on.

Message : ‚Äé<attached: 00002610-PHOTO-2023-05-04-16-32-05.jpg>
Quoted Message : ‚ÄúAccording to a fun and non-scientific evaluation with GPT-4. Further rigorous evaluation is needed.‚Äù\n\nüòÇ

Message : This is the exact problem with building a tool for Devs üòÖ
- most of the time they prefer to build
-  most of them don't have buying power

We also explored it for Careem but later we used open source only. üôÇ
Quoted Message : We didn't go ahead in the end. üòÖ\nWe bought some time through other means. So, there was still some time before we had the need to shard.

Message : Most devs actually have the highest buying power in any organisation. If a developer says they need to pay 100$/mo to keep their database up, that‚Äôs a bottom line for a business
Quoted Message : This is the exact problem with building a tool for Devs üòÖ\n- most of the time they prefer to build\n-  most of them don't have buying power\n\nWe also explored it for Careem but later we used open source only. üôÇ

Message : Devs are the end consumers
The decision makers for purchasing tools are not devs

If devs say that they need to keep db up and spend money,that‚Äôs BAU

For buying or integrating new tools  it‚Äôs more complicated
Quoted Message : Most devs actually have the highest buying power in any organisation. If a developer says they need to pay 100$/mo to keep their database up, that‚Äôs a bottom line for a business

Message : Hmm, as tempted as I am to chime in and ask questions on how Postman, Stripe, BrowserStack were able to do a dev-first GTM ‚Äî I'll resist the temptation since this is already off topic for a Generative AI focussed chat üòÖ

Message : We should jam separately on this, very different problems and implications :)
Quoted Message : Hmm, as tempted as I am to chime in and ask questions on how Postman, Stripe, BrowserStack were able to do a dev-first GTM ‚Äî I'll resist the temptation since this is already off topic for a Generative AI focussed chat üòÖ

Message : yeah. fastai was also going to build a tf swift version i think, but all those projects kinda got abandoned when Chris Lattner left Google.
Quoted Message : Jeremy was a strong proponent of TF Swift as well. But that hasn't seen major adoption even inside G so ymmv

Message : ‚Äé<attached: 00002625-PHOTO-2023-05-04-17-23-06.jpg>

Message : Generative Pretraining is the default "GPT" training objective, I'll let you dig this up on your own. If you don't mind reading papers, the original Radford et al is still relevant for this. 

On the words "instruction tuning", for all practical purposes ‚Äî it just means finetuning using instruction datasets
https://jasonwei20.github.io/files/FLAN%20talk%20external.pdf
Quoted Message : Hey, i wanted to understand the difference between generative pre training vs instruction tuning in terms of huggingface trainer class. How does the training objective change?

Message : On a concept level I understand the difference, but while training it, is there a difference? I checked databricks dolly script - https://github.com/databrickslabs/dolly/blob/master/training/trainer.py

There seems to be no difference.
Quoted Message : Generative Pretraining is the default \"GPT\" training objective, I'll let you dig this up on your own. If you don't mind reading papers, the original Radford et al is still relevant for this. \n\nOn the words \"instruction tuning\", for all practical purposes ‚Äî it just means finetuning using instruction datasets \nhttps://jasonwei20.github.io/files/FLAN%20talk%20external.pdf

Message : For wider audience, the code interpreter is largely a Python REPL and a GPT4-fork finetuned on Python/code. This is not a separate feature or anything like that. 

If you've GPT4 access, you can try this on your own by adding the Python REPL as a tool: https://python.langchain.com/en/latest/modules/agents/tools/examples/python.html
Quoted Message :  2023_05_04_3AAB7AC2A39E1522C0D1.jpeg

Message : Difference in outcomes or syntax/code which we write?
Quoted Message : On a concept level I understand the difference, but while training it, is there a difference? I checked databricks dolly script - https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n\nThere seems to be no difference.

Message : Syntax/code - essentially the training objective
Quoted Message : Difference in outcomes or syntax/code which we write?

Message : Going out on a limb, but I'd like to think that they should be identical with different configs ‚Äî finetuning and training objectives are often kept identical these days
Quoted Message : Syntax/code - essentially the training objective

Message : Understood. So we are still doing next word prediction on instruction dataset. Then how does it learn when to stop?
Quoted Message : Going out on a limb, but I'd like to think that they should be identical with different configs ‚Äî finetuning and training objectives are often kept identical these days

Message : Yep. Code interpreter is quite useful.  Threw a csv I had at it and it saved me at least an hour in data clean up if not more...
Quoted Message :  2023_05_04_3AAB7AC2A39E1522C0D1.jpeg

Message : Chatgpt code interpreter and gpt-4 browsing models are more useful than I anticipated.

Message : Guessing ‚Äî stop word markers in the instruction dataset?
Quoted Message : Understood. So we are still doing next word prediction on instruction dataset. Then how does it learn when to stop?

Message : Are there specific communities/ influencers to follow for generative AI content on Twitter ?I see a lot of content across all groups from Twitter hence asking here

Message : DM'd my list
Quoted Message : Are there specific communities/ influencers to follow for generative AI content on Twitter ?I see a lot of content across all groups from Twitter hence asking here

Message : https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table

This does seem upto date and is a very fine repository of all the models out there

Message : https://www.reddit.com/r/StableDiffusion/comments/137ex2j/controlnet_tile_can_generate_details_for_each/

ControlNet tike - who's played with this>?

Message : Does anyone have experience working with GPT4 for coding in Rust/working with libraries? GPT-3.5 is quite terrible, so wanted some insights on whether GPT4 is any better

Message : If it turns out to be as great as they are claiming, I‚Äôm sure someone will build and release open source version of Mojo soon, like OpenMojo etc, and it may create pressure on them.
Quoted Message : Reminder: Programming language is called Mojo. It's not Free or Open Source. Given how Java shaped up, I'm wary of using anything without a community around it to maintain and at least do basic security fixes for 5-10 years.

Message : Yeah, you train on( instruction+prompt, output). So the system learn from those instruction what the stop points are to some degree. But the real challenge is "how do tell these specific words really messed up". Here is where you do RLHF. Let me try to find some resource to explain this.
Quoted Message : Understood. So we are still doing next word prediction on instruction dataset. Then how does it learn when to stop?

Message : I need to see a training script
Quoted Message : Yeah, you train on( instruction+prompt, output). So the system learn from those instruction what the stop points are to some degree. But the real challenge is \"how do tell these specific words really messed up\". Here is where you do RLHF. Let me try to find some resource to explain this.

Message : Doesn't the dolly one do.

Message : For all thos who asked me earlier and I couldn't find the original resource. This a great one from Stanford. Explains big picture of pretraining, fine-tuning and RLHF. https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf

Message : One will need to deep dive into each of those areas for more details. This is big picture intuition.

Message : asking without asking part-2 üòÇ
Quoted Message : Hmm, as tempted as I am to chime in and ask questions on how Postman, Stripe, BrowserStack were able to do a dev-first GTM ‚Äî I'll resist the temptation since this is already off topic for a Generative AI focussed chat üòÖ

Message : https://twitter.com/pbteja1998/status/1654095756200931328?t=Q6vtkqrBGqOTgRE39s30Gg&s=08

Looks like OpenAI legal team sending a notice to companies using "GPT" in their product name.

Message : ‚Äé<attached: 00002663-PHOTO-2023-05-04-22-12-23.jpg>

Message : Like Flash Attention more than multi-query attention for the kind of use-cases we're looking at - would be super interesting to see how this one does though
Quoted Message :  2023_05_04_3EB08A7C6A1251AA662A5E.jpeg

Message : There are other differences: 

StarCoder is ~15.5B, Replit Codegen is ~2.7B
StarCoder is trained on 1T token, Replit is 525B tokens
StarCoder is OpenRAIL-M license, Replit is CC ‚Äî both are ok for commercial use
Quoted Message : Like Flash Attention more than multi-query attention for the kind of use-cases we're looking at - would be super interesting to see how this one does though

Message : StarCoder is open that their model is GPT2 ‚Äî so all GPT2 tricks, scripts will work!
Replit ‚Äî I didn't come across on model arch details

Message : Really interesting read from Simon Wilson on moats in closed source models quickly disappearing: https://simonwillison.net/2023/May/4/no-moat/

Message : https://blogs.microsoft.com/blog/2023/05/04/announcing-the-next-wave-of-ai-innovation-with-microsoft-bing-and-edge/

Message : If someone wants to start learning more about gpt model its training and how to train for a specific domain , any resources to recommend on this ,and has anyone found an opensource model which is comparable to gpt models mainly on context based converstion .. i saw dolly and open assist but if someone has to evaluate .. how someone can go about it ?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : One will need to deep dive into each of those areas for more details. This is big picture intuition.

Message : asking without asking part-2 üòÇ
Quoted Message : Hmm, as tempted as I am to chime in and ask questions on how Postman, Stripe, BrowserStack were able to do a dev-first GTM ‚Äî I'll resist the temptation since this is already off topic for a Generative AI focussed chat üòÖ

Message : https://twitter.com/pbteja1998/status/1654095756200931328?t=Q6vtkqrBGqOTgRE39s30Gg&s=08

Looks like OpenAI legal team sending a notice to companies using "GPT" in their product name.

Message : ‚Äé<attached: 00002663-PHOTO-2023-05-04-22-12-23.jpg>

Message : Like Flash Attention more than multi-query attention for the kind of use-cases we're looking at - would be super interesting to see how this one does though
Quoted Message :  2023_05_04_3EB08A7C6A1251AA662A5E.jpeg

Message : There are other differences: 

StarCoder is ~15.5B, Replit Codegen is ~2.7B
StarCoder is trained on 1T token, Replit is 525B tokens
StarCoder is OpenRAIL-M license, Replit is CC ‚Äî both are ok for commercial use
Quoted Message : Like Flash Attention more than multi-query attention for the kind of use-cases we're looking at - would be super interesting to see how this one does though

Message : StarCoder is open that their model is GPT2 ‚Äî so all GPT2 tricks, scripts will work!
Replit ‚Äî I didn't come across on model arch details

Message : Really interesting read from Simon Wilson on moats in closed source models quickly disappearing: https://simonwillison.net/2023/May/4/no-moat/

Message : https://blogs.microsoft.com/blog/2023/05/04/announcing-the-next-wave-of-ai-innovation-with-microsoft-bing-and-edge/

Message : If someone wants to start learning more about gpt model its training and how to train for a specific domain , any resources to recommend on this ,and has anyone found an opensource model which is comparable to gpt models mainly on context based converstion .. i saw dolly and open assist but if someone has to evaluate .. how someone can go about it ?

Message : 1. LM-evaluation-harness for Huggingface compatible models: https://github.com/EleutherAI/lm-evaluation-harness
2. OpenAI Evals for OpenAI models: https://github.com/openai/evals

Both have multiple tasks, including instructions, chat (often called dialogue as well) and some NLP tasks as well
Quoted Message : If someone wants to start learning more about gpt model its training and how to train for a specific domain , any resources to recommend on this ,and has anyone found an opensource model which is comparable to gpt models mainly on context based converstion .. i saw dolly and open assist but if someone has to evaluate .. how someone can go about it ?

Message : I've not had a chance to try Dolly and OpenAssist yet, but GPT-JT (https://huggingface.co/spaces/togethercomputer/GPT-JT) is definitely comparable to text-davinci-003, which was their claim.

Message : And I am honestly surprised that they were able to get this far by careful training data selection and training/finetuning params

Message : new model?
Quoted Message : I've not had a chance to try Dolly and OpenAssist yet, but GPT-JT (https://huggingface.co/spaces/togethercomputer/GPT-JT) is definitely comparable to text-davinci-003, which was their claim.

Message : Together are the ones behind redpyjamas right?

Message : I think it's a bit old? Dec 2022/Jan 2023?
Quoted Message : new model?

Message : Yes, I believe so
Quoted Message : Together are the ones behind redpyjamas right?

Message : okay

Message : https://twitter.com/lmsysorg/status/1653843200975704069?s=46

Message : seema perfectly reasonable
they are a small team, and because of the authors seminal work there will be lot of inbound activity

makes sense to stabilize the ideas and toolchains a little bit
They do mention they plan to open source it in future
Quoted Message : Not being open source at launch was a weird choice...  Can't remember the last time a language launched like that...

Message : Having tried all the models from Google, I fully agree they have no moat.

Message : You think OpenAI has no moat either?
Quoted Message : Having tried all the models from Google, I fully agree they have no moat.

Message : Community / dev side NFX is there
Quoted Message : You think OpenAI has no moat either?

Message : Also early mover is a real advantage for them. All that gets built/is getting built right .. tough/lethargy to rewrite/rewire

Message : NFX?
Quoted Message : Community / dev side NFX is there

Message : Network Effects
Quoted Message : NFX?

Message : Network effects üôà

Message : Of course not, which is why I pointedly talked only about Google üòÄ
Quoted Message : You think OpenAI has no moat either?

Message : Opensource models are far behind OpenAI right now. They may be able to catch up, and I do think they'll reach gpt4 level performance eventually, but there's a good chance OpenAI will be able to maintain its lead for 2 to 5 years or more, and that amount of moat is usually enough.

Message : I don't think community/nfx is a moat here. Look at what happened to tensorflow.
Quoted Message : Community / dev side NFX is there

Message : I think even if open source becomes comparable or even more effective, the possibilities of building a business does exist. 
Think about at OS market, linux vs microsoft vs macos.

Message : OpenAI's moat comes from aligning with MSFT/Azure. Government and finance domains are essentially theirs for the taking.
Quoted Message : You think OpenAI has no moat either?

Message : And the pace at with they can onboard other businesses on plugins- like uber, expedia

Message : That will take a while to mature, finance sector is where they'll make the big bags for now

Message : esp now that they have solved EDA with code interpreter

Message : This seems a bit panicky. It's not difficult for big tech to integrate oss stuff back in. They'll most likely wait a while to see what works best before integrating and releasing into products

Message : have u guys tried out the code interpreter? is that on the waiting list right ?

Message : With 3 million software devs in India second only to the US's 4 million, not sure about china numbers. I think the open source implementation may accelerate faster than commercial models. 
Kaggle has 286 grandmasters; 1,945 masters; 8,632 experts; 68,119. contributors maybe roughly ~10,000 potential folks(expert+) who can build the open source linux equivalent for LLMs
Quoted Message : This seems a bit panicky. It's not difficult for big tech to integrate oss stuff back in. They'll most likely wait a while to see what works best before integrating and releasing into products

Message : Not that I disagree. But as the terrain stands currently, (and please correct me if I'm wrong), all major oss developments in LLM (alpaca, llama.cpp etc) built on top of llama. It cost 30M to train that. I don't know how much we can replicate that in OSS.
Quoted Message : With 3 million software devs in India second only to the US's 4 million, not sure about china numbers. I think the open source implementation may accelerate faster than commercial models. \nKaggle has 286 grandmasters; 1,945 masters; 8,632 experts; 68,119. contributors maybe roughly ~10,000 potential folks(expert+) who can build the open source linux equivalent for LLMs

Message : Perhaps works like Bloom could prove me wrong?

Message : Another thing is that Microsoft+OpenAI can make inference costs so low that hosting other LLMs probably doesn't make sense unless compliance issue. Just like on-premise vs Cloud. While OSS models catch up on GPT4 quality, they are already working on inference optimization. Microsoft just announced today that they are investing in AMD to counter Nvidia GPU monopoly and also developing custom inference GPUs.
Quoted Message : Opensource models are far behind OpenAI right now. They may be able to catch up, and I do think they'll reach gpt4 level performance eventually, but there's a good chance OpenAI will be able to maintain its lead for 2 to 5 years or more, and that amount of moat is usually enough.

Message : Man, MSFT under Nadella is gonna be a business school 101 case study in a few years. He's trying to commoditize their complement: https://gwern.net/complement
Quoted Message : Another thing is that Microsoft+OpenAI can make inference costs so low that hosting other LLMs probably doesn't make sense unless compliance issue. Just like on-premise vs Cloud. While OSS models catch up on GPT4 quality, they are already working on inference optimization. Microsoft just announced today that they are investing in AMD to counter Nvidia GPU monopoly and also developing custom inference GPUs.

Message : Not sure if someone shared this here, but super interesting/scary (also expected):

Message : ‚Äé<attached: 00002706-PHOTO-2023-05-05-02-15-33.jpg>

Message : The nearest neighbors will fall first. Further away from it, less chance of being destroyed by the fast-moving train.

Message : https://www.semianalysis.com/p/google-we-have-no-moat-and-neither

Message : Hello awesome people. Missed a week (feels like a decade).
What‚Äôs new?

Message : wish there was an llm-summarisation hooked to this chatbox for the purpose, lol
Quoted Message : Hello awesome people. Missed a week (feels like a decade).\nWhat‚Äôs new?

Message : Hugging face just launched StarCoder LLM

https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_bigcode-chatgpt-copilot-activity-7059941239277678592-hUmn?utm_source=share&utm_medium=member_android

Message : You know this group became so big and intractable when you see the same article being shared 5 times in the past 100+ messages. üòÖ
Quoted Message : https://www.semianalysis.com/p/google-we-have-no-moat-and-neither


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Another thing is that Microsoft+OpenAI can make inference costs so low that hosting other LLMs probably doesn't make sense unless compliance issue. Just like on-premise vs Cloud. While OSS models catch up on GPT4 quality, they are already working on inference optimization. Microsoft just announced today that they are investing in AMD to counter Nvidia GPU monopoly and also developing custom inference GPUs.
Quoted Message : Opensource models are far behind OpenAI right now. They may be able to catch up, and I do think they'll reach gpt4 level performance eventually, but there's a good chance OpenAI will be able to maintain its lead for 2 to 5 years or more, and that amount of moat is usually enough.

Message : Man, MSFT under Nadella is gonna be a business school 101 case study in a few years. He's trying to commoditize their complement: https://gwern.net/complement
Quoted Message : Another thing is that Microsoft+OpenAI can make inference costs so low that hosting other LLMs probably doesn't make sense unless compliance issue. Just like on-premise vs Cloud. While OSS models catch up on GPT4 quality, they are already working on inference optimization. Microsoft just announced today that they are investing in AMD to counter Nvidia GPU monopoly and also developing custom inference GPUs.

Message : Not sure if someone shared this here, but super interesting/scary (also expected):

Message : ‚Äé<attached: 00002706-PHOTO-2023-05-05-02-15-33.jpg>

Message : The nearest neighbors will fall first. Further away from it, less chance of being destroyed by the fast-moving train.

Message : https://www.semianalysis.com/p/google-we-have-no-moat-and-neither

Message : Hello awesome people. Missed a week (feels like a decade).
What‚Äôs new?

Message : wish there was an llm-summarisation hooked to this chatbox for the purpose, lol
Quoted Message : Hello awesome people. Missed a week (feels like a decade).\nWhat‚Äôs new?

Message : Hugging face just launched StarCoder LLM

https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_bigcode-chatgpt-copilot-activity-7059941239277678592-hUmn?utm_source=share&utm_medium=member_android

Message : You know this group became so big and intractable when you see the same article being shared 5 times in the past 100+ messages. üòÖ
Quoted Message : https://www.semianalysis.com/p/google-we-have-no-moat-and-neither

Message : The Google doom story is about 6mo old, if they get their acts together, they can turn the tide as they still have their distribution intact
Quoted Message : Opensource models are far behind OpenAI right now. They may be able to catch up, and I do think they'll reach gpt4 level performance eventually, but there's a good chance OpenAI will be able to maintain its lead for 2 to 5 years or more, and that amount of moat is usually enough.

Message : Anyone using bharatforAI translation in prod? It seems to very require large server instances. Would love to chat if anyone has /is using

Message : Good intro + inference optimisations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up: https://docs.google.com/presentation/d/1cbcP-wpeb3jMS4-20cEKFmNJAObg13Q_JNbl0YV6qyU/edit#slide=id.g20f09001284_0_76 

I could only attend only few parts. If someone has notes, please share.

Message : Is there any good article with all available SoTA large models in multimodal space (text, image, video, audio, etc)

Message : I'm afk, but look up Amazon's mm-CoT on HF and explore tags from there. Similar for PapersWithCode.
Quoted Message : Is there any good article with all available SoTA large models in multimodal space (text, image, video, audio, etc)

Message : HF is huggingface.co

Message : we are getting alternatives now
gpt-j (old), pythia, open llama, cerebras gpt, etc
although without eval it is difficult to tell which might be better üòÖ
Quoted Message : Not that I disagree. But as the terrain stands currently, (and please correct me if I'm wrong), all major oss developments in LLM (alpaca, llama.cpp etc) built on top of llama. It cost 30M to train that. I don't know how much we can replicate that in OSS.

Message : Does anyone know if the probabilistic functions in generative models are truly random or deterministic?

Message : Can you elaborate on what you're trying to understand? This phrasing is hard to understand
Quoted Message : Does anyone know if the probabilistic functions in generative models are truly random or deterministic?

Message : if you are talking about RNGs then they are psuedo random and can be controlled via seed
Quoted Message : Does anyone know if the probabilistic functions in generative models are truly random or deterministic?

Message : although don't expect same results across devices (chipset)

the underlying rng implementation is different in many cases

Message : What's the difference between gpt-3.5-turbo and gpt-3.5-turbo-0301?

I remember there was an explainer here

Message : gpt-3.5-turbo is a "brand", it will change under the hood when the _next version_ of gpt3.5 comes out.  

gpt-3.5-turbo-0301 is a checkpoint/release which will not change
Quoted Message : What's the difference between gpt-3.5-turbo and gpt-3.5-turbo-0301?\n\nI remember there was an explainer here

Message : got it thanks

Message : The encoder takes in a sequence of input tokens, the decoder needs to generate/predict the output sequence. The decoder produces a probability distribution over the vocabulary of the language at each time step, conditioned on the previous tokens in the output sequence and the context vector. This probability distribution is then used to sample the next token in the sequence. 
The probability function that is used in the decoder to generate the response, if deterministic would essentially mean the model responses are not truly random but have a predictive/deterministic element to it.
Thinking out loud whoever controls that deterministic probability model essentially controls how the model hallucinates. Am I missing anything?
Quoted Message : Can you elaborate on what you're trying to understand? This phrasing is hard to understand

Message : as they both have separate rate limits, can we use gpt-3.5-turbo-0301 as fallback when gpt-3.5 limits are over?
Quoted Message : gpt-3.5-turbo is a \"brand\", it will change under the hood when the _next version_ of gpt3.5 comes out.  \n\ngpt-3.5-turbo-0301 is a checkpoint/release which will not change

Message : I think they've shared rate limits, but if they do separately -- yes
Quoted Message : as they both have separate rate limits, can we use gpt-3.5-turbo-0301 as fallback when gpt-3.5 limits are over?

Message : Depends on many parts in the decoder, from nucleus sampling to beam search. But safe to say that it's not a decoder problem. 

GPT isn't an encoder-decoder model either. It's autoregressive
Quoted Message : The encoder takes in a sequence of input tokens, the decoder needs to generate/predict the output sequence. The decoder produces a probability distribution over the vocabulary of the language at each time step, conditioned on the previous tokens in the output sequence and the context vector. This probability distribution is then used to sample the next token in the sequence. \nThe probability function that is used in the decoder to generate the response, if deterministic would essentially mean the model responses are not truly random but have a predictive/deterministic element to it. \nThinking out loud whoever controls that deterministic probability model essentially controls how the model hallucinates. Am I missing anything?

Message : Does it work that way? Or rate limits are key based
Quoted Message : as they both have separate rate limits, can we use gpt-3.5-turbo-0301 as fallback when gpt-3.5 limits are over?

Message : so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)?
Quoted Message : Depends on many parts in the decoder, from nucleus sampling to beam search. But safe to say that it's not a decoder problem. \n\nGPT isn't an encoder-decoder model either. It's autoregressive

Message : ‚Äé<attached: 00002739-PHOTO-2023-05-05-12-59-07.jpg>
Quoted Message : Does it work that way? Or rate limits are key based

Message : Sure

Message : Yes, but there is always some non determinism with GPUs.
Quoted Message : so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)?

Message : In GPT, the randomness comes from the probability distribution over the vocabulary right? Is there a way we set top-k/top-p values though the chat interface?
Quoted Message : Depends on many parts in the decoder, from nucleus sampling to beam search. But safe to say that it's not a decoder problem. \n\nGPT isn't an encoder-decoder model either. It's autoregressive

Message : What are some good tools for creating and managing prompts?

Prompt version control + feedback + easy collaboration

Message : Does anyone have resources around how to do chunking while creating code embeddings? Also, pointers to the best open source model for code embeddings would be great.

Message : Noob question: Can Meta's SAM (Segment Anything) and Track Anything - can be utilised for tracking logos from the video? 
We are building some use case around detecting logos from video. Would love some pointers.

Message : Yeah. Should work out of the box
Quoted Message : Noob question: Can Meta's SAM (Segment Anything) and Track Anything - can be utilised for tracking logos from the video? \nWe are building some use case around detecting logos from video. Would love some pointers.

Message : What are the best tools/repos to replicate the AI songs like the ghostwriter ones (drake wala)

Message : on the same chipset, yes, as long as all software versions are pinned down to the lowest levels including the os and kernel
Quoted Message : so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)?

Message : So-vita-svc, afaik
Quoted Message : What are the best tools/repos to replicate the AI songs like the ghostwriter ones (drake wala)

Message : https://agi-sphere.com/llama-models/

Message : so-vits-svc
Quoted Message : So-vita-svc, afaik

Message : Would be interested to know what artist you‚Äôre replicating

Message : Also, it would be a fun get together for anyone trying to make a song, I know I haven‚Äôt taken an initiative here, but would be thrilled to jam with anyone who does üôÇ

Message : There was a sheet here with a list of fine-tuned models - anyone have it?
Quoted Message : Also, it would be a fun get together for anyone trying to make a song, I know I haven‚Äôt taken an initiative here, but would be thrilled to jam with anyone who does üôÇ

Message : @91748189xxxx

Message : Can you share a link plij?
Quoted Message : So-vita-svc, afaik

Message : I've heard good things about this
https://github.com/voicepaw/so-vits-svc-fork
Quoted Message : Can you share a link plij?

Message : Hi
Akshat here.
Hoping to learn and share here. I would love to be a part of hackathons/competition groups if any too. Excited to be in this group.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : So-vita-svc, afaik
Quoted Message : What are the best tools/repos to replicate the AI songs like the ghostwriter ones (drake wala)

Message : https://agi-sphere.com/llama-models/

Message : so-vits-svc
Quoted Message : So-vita-svc, afaik

Message : Would be interested to know what artist you‚Äôre replicating

Message : Also, it would be a fun get together for anyone trying to make a song, I know I haven‚Äôt taken an initiative here, but would be thrilled to jam with anyone who does üôÇ

Message : There was a sheet here with a list of fine-tuned models - anyone have it?
Quoted Message : Also, it would be a fun get together for anyone trying to make a song, I know I haven‚Äôt taken an initiative here, but would be thrilled to jam with anyone who does üôÇ

Message : @91748189xxxx

Message : Can you share a link plij?
Quoted Message : So-vita-svc, afaik

Message : I've heard good things about this
https://github.com/voicepaw/so-vits-svc-fork
Quoted Message : Can you share a link plij?

Message : Hi
Akshat here.
Hoping to learn and share here. I would love to be a part of hackathons/competition groups if any too. Excited to be in this group.

Message : ‚Äé<attached: 00002759-PHOTO-2023-05-05-17-17-57.jpg>

Message : Well that so-vits-svc models sheet is deprecated now (obviously because decades have passed üòõ)

There's a discord community called AI Hub.  They train and share voice models all day and night. You can check out that instead.
Quoted Message : There was a sheet here with a list of fine-tuned models - anyone have it?

Message : I want to train on Arijit's voice but I'm quite occupied these days :')
Quoted Message : Also, it would be a fun get together for anyone trying to make a song, I know I haven‚Äôt taken an initiative here, but would be thrilled to jam with anyone who does üôÇ

Message : ++
Quoted Message : Also, it would be a fun get together for anyone trying to make a song, I know I haven‚Äôt taken an initiative here, but would be thrilled to jam with anyone who does üôÇ

Message : https://discord.gg/aihub a lot of models here. It‚Äôs 7000 people big and people say all kinds of stuff there. @91773788xxxx did an amazing job of keeping this community focused and productive for this long, everyday I am blown away looking at the cutting edge work you‚Äôll are doing. ‚ú®
Quoted Message : Well that so-vits-svc models sheet is deprecated now (obviously because decades have passed üòõ)\n\nThere's a discord community called AI Hub.  They train and share voice models all day and night. You can check out that instead.

Message : https://www.mosaicml.com/blog/mpt-7b

Mosaic announced a 7B LLM trained to 1T tokens...

Message : SlackGPT ‚Äî multiple business workflows, horizontally integrated with Slack.  
https://twitter.com/SlackHQ/status/1654050811238928386

Message : Might have to rename it, gpt trademark
Quoted Message : SlackGPT ‚Äî multiple business workflows, horizontally integrated with Slack.  \nhttps://twitter.com/SlackHQ/status/1654050811238928386

Message : salesforce v openai soon

Message : Salesforce vs Microsoft
Quoted Message : salesforce v openai soon

Message : Also didn‚Äôt Slack partner with OpenAI for this ?
Quoted Message : Might have to rename it, gpt trademark

Message : They are able to generate 84k tokens on a single A100 GPU by finetuning base model of 2k context length to finetuned model with context length of 65k.
Quoted Message : https://www.mosaicml.com/blog/mpt-7b\n\nMosaic announced a 7B LLM trained to 1T tokens...

Message : Just used for a few prompts that I tried for ChatGPT (GPT4), still a long way to go. I used mainly used code snippets and asked questions around it. I wasn't able to get  answers and abruptly stopped giving responses mid way.
Quoted Message : They are able to generate 84k tokens on a single A100 GPU by finetuning base model of 2k context length to finetuned model with context length of 65k.

Message : Which checkpoint did you use ? + it might not do that great with code understanding as it is trained only on 135B tokens from the stack.
Quoted Message : Just used for a few prompts that I tried for ChatGPT (GPT4), still a long way to go. I used mainly used code snippets and asked questions around it. I wasn't able to get  answers and abruptly stopped giving responses mid way.

Message : This one `MPT-7B-Instruct`
Quoted Message : Which checkpoint did you use ? + it might not do that great with code understanding as it is trained only on 135B tokens from the stack.

Message : I will also try it. Would be interesting to generate 6th book of GoT series as George RR Martin might never write it

Message : ‚Äé<attached: 00002775-AUDIO-2023-05-05-21-56-23.mp3>
Quoted Message : Also, it would be a fun get together for anyone trying to make a song, I know I haven‚Äôt taken an initiative here, but would be thrilled to jam with anyone who does üôÇ

Message : Taylor Swift singing a kannada song :D

Message : I genuinely want to try out The Weeknd singing Arijit songs üò¨

Message : Not sure if this has been shared / discussed before (since I joined late in this group), throwing it here. 
https://youtu.be/V4gGJ7XXlC0

Mojo, just being unveiled as we speak now, seems very promising in its ability to solve AI hardware constraints .

Message : https://wandb.ai/site/prompts

Super cool launch by wandb

Message : https://huggingface.co/spaces/mosaicml/mpt-7b-chat

Message : A very good post on what transformers are for some of us who are getting started and others who just want to deepen fundamentals.

https://txt.cohere.com/what-are-transformer-models/?twclid=218dxtuiktvp0bq92br7zvxeek

Love cohere blogs for the simplicity

Message : Luis Serrano and Jay Alammar - Cohere has two of best ML content creators ever.
Quoted Message : A very good post on what transformers are for some of us who are getting started and others who just want to deepen fundamentals.\n\nhttps://txt.cohere.com/what-are-transformer-models/?twclid=218dxtuiktvp0bq92br7zvxeek\n\nLove cohere blogs for the simplicity

Message : Hi. Anyone wants to join an already formed awesome team in Warpspeed GenAI hackathon? We have one open slot! We would love to have you.

Message : Does anyone have/made a list of top AI themed newsletters??

Message : I followed a few but found this the best bensbites.co
Quoted Message : Does anyone have/made a list of top AI themed newsletters??

Message : checkout 42papers.com
Quoted Message : Does anyone have/made a list of top AI themed newsletters??

Message : That's Twitter but worse because almost everything there is already from https://twitter.com/_akhaliq
Quoted Message : checkout 42papers.com

Message : These are the one's ive found quite useful:
- [https://www.bensbites.co/](https://www.bensbites.co/)
- [https://www.semafor.com/newsletters]
- [https://www.lennysnewsletter.com]
- [https://whatshot.substack.com/p/whats-in-enterprise-itvc-335?utm_source=substack&utm_medium=email]
- [https://therundown.ai/subscribe](https://t.co/Gm5KwesnA7)
- [https://tldr.tech/ai?utm_source=tldr](https://tldr.tech/ai?utm_source=tldr)
Quoted Message : Does anyone have/made a list of top AI themed newsletters??

Message : New open source LLM, better than Llama, commercial use allowed
https://www.together.xyz/blog/redpajama-models-v1

Message : "The 7B model is still training (at 800B tokens) and we see the training loss still decrease consistently. As a result, we will continue to train it to 1T tokens." Fascinating that models will start to touch the trillion mark!
Quoted Message : New open source LLM, better than Llama, commercial use allowed\nhttps://www.together.xyz/blog/redpajama-models-v1

Message : No. There are two ways to make it deterministic (this is not including RLHF magic, any fine-tuning magic etc, don't know what all they have here) but both with different behaviours. One by setting temp=0, here you are forcing softmax to select the top word pick, so this degenerates to greedy though you are sampling. Thus will have issues being it taking the most frequent word combinations.
Quoted Message : so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)?

Message : The other by setting seeds. This still allows you to 'actually'  generate using top-p/top-k. OpenAI does not let us to set the seed afaik. You can also play with combination of top-p and  temp for your particular problem to see when it is stable/deterministic, you don't need to always go to zero.

Message : Pro Tip for anyone trying to pursue this line of reasoning and looking for first hand experience: Take a GPT2 or BLOOM model and try to get consistent outputs ‚Äî you'll develop a very good mental model of what it takes to get a deterministic output.
Quoted Message : The other by setting seeds. This still allows you to 'actually'  generate using top-p/top-k. OpenAI does not let us to set the seed afaik. You can also play with combination of top-p and  temp for your particular problem to see when it is stable/deterministic, you don't need to always go to zero.

Message : Hey everyone, Chirag this side from Endiya Partners, an early stage VC. Happy to be here! 
Look forward to learning and exchanging notes on the space

Message : https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor
https://github.com/google-research/google-research/tree/master/musiq

@91773788xxxx @91876402xxxx :D

Message : ‚Äé<attached: 00002799-PHOTO-2023-05-06-14-06-48.jpg>
Quoted Message : https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor\nhttps://github.com/google-research/google-research/tree/master/musiq\n\n@9177xxxxxxxx @9187xxxxxxxx :D

Message : ‚Äé<attached: 00002800-PHOTO-2023-05-06-14-10-12.jpg>

Message : ‚Äé<attached: 00002801-PHOTO-2023-05-06-14-10-51.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : New open source LLM, better than Llama, commercial use allowed
https://www.together.xyz/blog/redpajama-models-v1

Message : "The 7B model is still training (at 800B tokens) and we see the training loss still decrease consistently. As a result, we will continue to train it to 1T tokens." Fascinating that models will start to touch the trillion mark!
Quoted Message : New open source LLM, better than Llama, commercial use allowed\nhttps://www.together.xyz/blog/redpajama-models-v1

Message : No. There are two ways to make it deterministic (this is not including RLHF magic, any fine-tuning magic etc, don't know what all they have here) but both with different behaviours. One by setting temp=0, here you are forcing softmax to select the top word pick, so this degenerates to greedy though you are sampling. Thus will have issues being it taking the most frequent word combinations.
Quoted Message : so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)?

Message : The other by setting seeds. This still allows you to 'actually'  generate using top-p/top-k. OpenAI does not let us to set the seed afaik. You can also play with combination of top-p and  temp for your particular problem to see when it is stable/deterministic, you don't need to always go to zero.

Message : Pro Tip for anyone trying to pursue this line of reasoning and looking for first hand experience: Take a GPT2 or BLOOM model and try to get consistent outputs ‚Äî you'll develop a very good mental model of what it takes to get a deterministic output.
Quoted Message : The other by setting seeds. This still allows you to 'actually'  generate using top-p/top-k. OpenAI does not let us to set the seed afaik. You can also play with combination of top-p and  temp for your particular problem to see when it is stable/deterministic, you don't need to always go to zero.

Message : Hey everyone, Chirag this side from Endiya Partners, an early stage VC. Happy to be here! 
Look forward to learning and exchanging notes on the space

Message : https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor
https://github.com/google-research/google-research/tree/master/musiq

@91773788xxxx @91876402xxxx :D

Message : ‚Äé<attached: 00002799-PHOTO-2023-05-06-14-06-48.jpg>
Quoted Message : https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor\nhttps://github.com/google-research/google-research/tree/master/musiq\n\n@9177xxxxxxxx @9187xxxxxxxx :D

Message : ‚Äé<attached: 00002800-PHOTO-2023-05-06-14-10-12.jpg>

Message : ‚Äé<attached: 00002801-PHOTO-2023-05-06-14-10-51.jpg>

Message : ‚Äé<attached: 00002802-PHOTO-2023-05-06-14-12-05.jpg>

Message : Might have a better time just running clip interrogator and just asking gpt for a score from that genenrated caption
Quoted Message : https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor\nhttps://github.com/google-research/google-research/tree/master/musiq\n\n@9177xxxxxxxx @9187xxxxxxxx :D

Message : Hallucination and determinism (the above definition of it, same output for same input) are not that related. Hallucination is largely an after effect of model learning patterns that aren't true, in the weights so to speak. The determinism issue is largely a final layer problem (and may be fine-tuning layers). As in how you select from most  reasonable walk amongst series of words choices (you essentially have k-ary tree starting from first word). Another meaning of determinism could be whether it could generalize well (minor perturbation of input don't lead to change in output), this is very related to hallucination and both are related model weights.
Quoted Message : The encoder takes in a sequence of input tokens, the decoder needs to generate/predict the output sequence. The decoder produces a probability distribution over the vocabulary of the language at each time step, conditioned on the previous tokens in the output sequence and the context vector. This probability distribution is then used to sample the next token in the sequence. \nThe probability function that is used in the decoder to generate the response, if deterministic would essentially mean the model responses are not truly random but have a predictive/deterministic element to it. \nThinking out loud whoever controls that deterministic probability model essentially controls how the model hallucinates. Am I missing anything?

Message : I don't think this is doing human profile scoring per se üòÄ. It is trained on AVA, so doing scene scoring. So nice sunsets or bokeh images, highly saturated colors etc should get good rating.
Quoted Message : https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor\nhttps://github.com/google-research/google-research/tree/master/musiq\n\n@9177xxxxxxxx @9187xxxxxxxx :D

Message : @91990072xxxx sir would you like to explain AVA and image dataset curation methods/conventions ‚Äî lot of folks here are not from Vision in particular
Quoted Message : I don't think this is doing human profile scoring per se üòÄ. It is trained on AVA, so doing scene scoring. So nice sunsets or bokeh images, highly saturated colors etc should get good rating.

Message : It is pretty bad at scene scoring too unfortunately. Only the examples they've shared score well.
Quoted Message : I don't think this is doing human profile scoring per se üòÄ. It is trained on AVA, so doing scene scoring. So nice sunsets or bokeh images, highly saturated colors etc should get good rating.

Message : Sorry, my bad. This is for the problem of Visual Aesthetic Scoring that is given a set of pictures, score pictures from interesting to least (think flickr interestingness if you know what that was, like what photos you will want in your album or showcase your photography talent). There were bunch of datasets created for this, AVA was one of those, I think curated from DPChallenge with score and sematic tags for each image.
Quoted Message : @9199xxxxxxxx sir would you like to explain AVA and image dataset curation methods/conventions ‚Äî lot of folks here are not from Vision in particular

Message : it's ranked based on likes etc not from a specific person also each paper is has a short summary as well as why it's important basically designed for a daily quick scan
Quoted Message : That's Twitter but worse because almost everything there is already from https://twitter.com/_akhaliq

Message : which part is worst always improving so happy to learn
Quoted Message : That's Twitter but worse because almost everything there is already from https://twitter.com/_akhaliq

Message : https://github.com/mosaicml/llm-foundry/tree/main/scripts/eval

Benchmarking framework but by Mosaic üòÖ

Message : ‚Äé<attached: 00002815-PHOTO-2023-05-06-15-02-53.jpg>
Quoted Message : https://github.com/mosaicml/llm-foundry/tree/main/scripts/eval\n\nBenchmarking framework but by Mosaic üòÖ

Message : there needs to be a standard that everyone can use. Was hoping HELM becomes that
Quoted Message : https://github.com/mosaicml/llm-foundry/tree/main/scripts/eval\n\nBenchmarking framework but by Mosaic üòÖ

Message : Any good library references to create datasets for LLMs? Say, training Vicuna/Dolly 7B/13B on a domain. I want to replicate what BloombergGPT did in finance but for a very specific bucket in finance. Also, any way to estimate infra cost for suchs training and hosting?

Message : Given a prompt, and a set of generations from the prompt, example, if the prompt is "black and gold colour scheme, blue sky, white mountains, red house,... " and 10 images are generated, is it possible to rank the generated images based on how well the prompt was followed?
Quoted Message : Sorry, my bad. This is for the problem of Visual Aesthetic Scoring that is given a set of pictures, score pictures from interesting to least (think flickr interestingness if you know what that was, like what photos you will want in your album or showcase your photography talent). There were bunch of datasets created for this, AVA was one of those, I think curated from DPChallenge with score and sematic tags for each image.

Message : Additionally, given that there are numerous generations where there are small issues, for example, extra hand in one, incorrect tshirt representation in another, is it possible to auto build a workflow, which figures out where the image is incorrect , masks it, and sends through another generation to fix that area?  If so, what would be required for it to detect errors in the image?

Message : ‚Äé<attached: 00002821-PHOTO-2023-05-06-15-11-25.jpg>

Message : Reply with: DM me üòÇ

Message : you can check out the stanford alpaca repository.  They explain the method that lets you create the dataset based on few hand written examples. That uses distilling datasets using LLM's from open AI. But if this is something that is going to be for commercial use you have to check the terms of service.
Quoted Message : Any good library references to create datasets for LLMs? Say, training Vicuna/Dolly 7B/13B on a domain. I want to replicate what BloombergGPT did in finance but for a very specific bucket in finance. Also, any way to estimate infra cost for suchs training and hosting?

Message : Could be a growth hack as well
Quoted Message :  2023_05_06_3EB02CD033C3C3F9D9D0C2.jpeg

Message : Are you a dev? Because you just pulled a "It's a not a bug, it's a feature" üòÇ
Quoted Message : Could be a growth hack as well

Message : No that is a different problem altogether. The above one is a very visual problem, doesn't depend on things like semantic meaning or the implications of those as much. So for example, it will rank the fanous Henry Cartier Bresson's Leap into unknown photo (this photo's context is Europe entering world war 2) poorly. The visual aesthetic problem to a decent degree is sort of solved. Many models are production use, where you can remove human time required. But this problem requires more understanding of real world (like humans have 2 hands etc). So training on that dataset probably won't work as well. I think @91961193xxxx and others have worked on this more. They can chime in on what works.
Quoted Message : Given a prompt, and a set of generations from the prompt, example, if the prompt is \"black and gold colour scheme, blue sky, white mountains, red house,... \" and 10 images are generated, is it possible to rank the generated images based on how well the prompt was followed?

Message : I mean, large scale deployments are common for Visual Aesthetic scoring, where revenue numbers can be impacted if you do poorly.

Message : Is it possible for a visual QA model to identify errors in a picture, if we use "errors in the image" as the question? Then use grounded SAM to auto-detect areas where the visual QA answered? And then use models which are finetuned on those datasets to fix those imperfections?

Message : I am asking more from a workflow, rather than one model doing it all. It would be difficult to make it work using a single model.

Message : this seems like a task for andrew ng's https://landing.ai/
Quoted Message : Is it possible for a visual QA model to identify errors in a picture, if we use \"errors in the image\" as the question? Then use grounded SAM to auto-detect areas where the visual QA answered? And then use models which are finetuned on those datasets to fix those imperfections?

Message : Any open source suggestions?

Message : Could you expand a bit on errors, what kind of errors are you expecting, like logical, or edited in errors?
Quoted Message : Is it possible for a visual QA model to identify errors in a picture, if we use \"errors in the image\" as the question? Then use grounded SAM to auto-detect areas where the visual QA answered? And then use models which are finetuned on those datasets to fix those imperfections?

Message : Oh I just saw the above messages, you mean errors between the prompt and the images.

Message : a naive idea that comes to my mind, is divide the images into multiscale patches, embed with CLIP and then check similarity with the prompt.

Message : The issue with this is that if the hands were incorrect, it would still return hands.
Quoted Message : a naive idea that comes to my mind, is divide the images into multiscale patches, embed with CLIP and then check similarity with the prompt.

Message : Discussion on HN about Langchain
https://news.ycombinator.com/item?id=35820931

- more useful when using OSS models
- all the magic resides in prompts
- good for building vector indices without worrying about writing adapters
- can be brittle at times
- the best on-ramp for "practical uses of llms" because it scratches just the right developer itch
- some people defected to deepset haystack

Lots more gems in the thread though

Message : similarity of the string "hands" will still be less for it, compared to a good set of hands, is what I am hoping. 
Another way (again, possibly naive) is to get the caption for the image, using BLIP-2 or something, and check if the logical components of the caption is same as the prompt.
Quoted Message : The issue with this is that if the hands were incorrect, it would still return hands.

Message : Any idea how much time does it take to get access to chatgptplugins?

Message : Thanks, I'll check.
Quoted Message : you can check out the stanford alpaca repository.  They explain the method that lets you create the dataset based on few hand written examples. That uses distilling datasets using LLM's from open AI. But if this is something that is going to be for commercial use you have to check the terms of service.

Message : Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?

Message : Bloomberg gpt.. but it quite expensive
Quoted Message : Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?

Message : they‚Äôve released a product? Last I knew it was a paper
Quoted Message : Bloomberg gpt.. but it quite expensive

Message : I think they released it into their terminal
Quoted Message : they‚Äôve released a product? Last I knew it was a paper

Message : someone was finetuning gpt with yahoo finance in this group?

Message : https://llava.hliu.cc/

LLaMa is everywhere


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Discussion on HN about Langchain
https://news.ycombinator.com/item?id=35820931

- more useful when using OSS models
- all the magic resides in prompts
- good for building vector indices without worrying about writing adapters
- can be brittle at times
- the best on-ramp for "practical uses of llms" because it scratches just the right developer itch
- some people defected to deepset haystack

Lots more gems in the thread though

Message : similarity of the string "hands" will still be less for it, compared to a good set of hands, is what I am hoping. 
Another way (again, possibly naive) is to get the caption for the image, using BLIP-2 or something, and check if the logical components of the caption is same as the prompt.
Quoted Message : The issue with this is that if the hands were incorrect, it would still return hands.

Message : Any idea how much time does it take to get access to chatgptplugins?

Message : Thanks, I'll check.
Quoted Message : you can check out the stanford alpaca repository.  They explain the method that lets you create the dataset based on few hand written examples. That uses distilling datasets using LLM's from open AI. But if this is something that is going to be for commercial use you have to check the terms of service.

Message : Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?

Message : Bloomberg gpt.. but it quite expensive
Quoted Message : Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?

Message : they‚Äôve released a product? Last I knew it was a paper
Quoted Message : Bloomberg gpt.. but it quite expensive

Message : I think they released it into their terminal
Quoted Message : they‚Äôve released a product? Last I knew it was a paper

Message : someone was finetuning gpt with yahoo finance in this group?

Message : https://llava.hliu.cc/

LLaMa is everywhere

Message : There‚Äôs an open source alternative to Bloomberg terminal called OpenBB. They released a blog on how one can train on their documentation to get the appropriate OpenBB command 
https://openbb.co/blog/role-of-ai-and-openbb-in-future-of-investment-research
Quoted Message : Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?

Message : I'm starting to look into the autonomous agents space

Any resources that covers the fundamentals of this field (and not the autogpt/babyagi hype)

üôè

Message : https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents

Message : i built something for myself along these lines much simpler and no dependencies
Quoted Message : Discussion on HN about Langchain\nhttps://news.ycombinator.com/item?id=35820931\n\n- more useful when using OSS models\n- all the magic resides in prompts\n- good for building vector indices without worrying about writing adapters\n- can be brittle at times\n- the best on-ramp for \"practical uses of llms\" because it scratches just the right developer itch\n- some people defected to deepset haystack\n\nLots more gems in the thread though

Message : https://github.com/dosco/minds
Quoted Message : Discussion on HN about Langchain\nhttps://news.ycombinator.com/item?id=35820931\n\n- more useful when using OSS models\n- all the magic resides in prompts\n- good for building vector indices without worrying about writing adapters\n- can be brittle at times\n- the best on-ramp for \"practical uses of llms\" because it scratches just the right developer itch\n- some people defected to deepset haystack\n\nLots more gems in the thread though

Message : OpenAI Chief Scientist Ilya S. explains that OpenAI is not doing closed source because of _safety reasons_ ‚Äî as they've hinted in the past, , but because of competitive reasons. He believes models can be improved to the point _in future_ where it becomes a safety concern.  

https://www.youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0

Message : competitive reasons aka MSFT in simple words

Message : If anyone wants a longer rant, look up yannic kilcher on YouTube üòÇ

Message : Try yubibert for India
Quoted Message : Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?

Message : As LLaMa adoption suggests, once you release the weights publicly, the ecosystem catches up very, very strongly

So I guess they're mindful of the same

Also, I don't think we have anything in OSS today that's close to GPT3.5, GPT4 or Claude but the key question is can we get there in 1-1.5 years
Quoted Message : OpenAI Chief Scientist Ilya S. explains that OpenAI is not doing closed source because of _safety reasons_ ‚Äî as they've hinted in the past, , but because of competitive reasons. He believes models can be improved to the point _in future_ where it becomes a safety concern.  \n\nhttps://www.youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0

Message : they will have the RLHF edge in 1-1.5 years where OSS will keep playing catchup
Quoted Message : As LLaMa adoption suggests, once you release the weights publicly, the ecosystem catches up very, very strongly\n\nSo I guess they're mindful of the same\n\nAlso, I don't think we have anything in OSS today that's close to GPT3.5, GPT4 or Claude but the key question is can we get there in 1-1.5 years

Message : True, and in 1-1.5 years they will have the RLHF edge which OSS will keep playing catchup on

Message : Here's where my thoughts are -

1/ LLaMa weights leaking was a lucky incident - if we believe that models will become larger (which I do), do we expect similar weights being leaked for bigger models going forward?

2/ If/As models become bigger, how many labs/companies would be able to keep up with the training costs?

It'd slowly start moving towards an oligopoly even for the OSS model providers

3/ That said, it's very well possible that OSS models form the bulk of AI usage moving forward

I guess Emad from Stability believes this and is playing to the playbook - let an AWS monetize the long tail of the OSS model usage while some of the biggest customers will pay premium for small, incremental better performance

Message : While @91876396xxxx already gets this, reminder for other readers: 

Most FOSS models, including Llama are probably to 80-90% of text-davinci-003 ‚Äî and do not show the reasoning and task planning abilities which GPT4 (or to a limited extent 3.5 show) _today_

Message : Which (as per my current level of understanding) matters more in an Autonomous Agent powered world

Running thought: in the consumer world atleast, I think the most popular way of doing model orchestration could be something like this - an interface like Jarvis or LangChain or Fixie or the like takes my inputs and remediates across a series of FMs to get a task done

The interface takes care of the memory and reasoning aspect and would likely include a closed source FM
Quoted Message : While @9187xxxxxxxx already gets this, reminder for other readers: \n\nMost FOSS models, including Llama are probably to 80-90% of text-davinci-003 ‚Äî and do not show the reasoning and task planning abilities which GPT4 (or to a limited extent 3.5 show) _today_

Message : Hot take from Jim Fan: 
https://twitter.com/drjimfan/status/1654926960165011456?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : ‚Äé<attached: 00002863-PHOTO-2023-05-07-18-03-08.jpg>

Message : Summary of everything that we discussed yesterday with all the links: 
https://nirantk.com/ai/6th-may-2023.html

Message : https://twitter.com/natolambert/status/1654190084428808194

Message : This is also a work-in-progress preview of a daily summary of this group chat ‚Äî going back to starting of the group itself:  https://nirantk.com/ai.html

This is hopefully useful:

1. Daily links ‚Äî so you can catch up on what we've talked about
2. Each page has a title and table of contents, so you can dig into topics of your interest

Message : Design Choices:

1. I've removed as much PII as possible, specially phone numbers
2. I've removed as many names as possible as well, unless they're part of the message itself
3. I've tried to add descriptions with links

Note that the poll indicated that people were okay with sender names being public, I've chosen to remove them out of abundance of caution. I want minorities in tech e.g. women to feel comfortable participating here despite being a large-public forum.

I've tried my best: read over 12 hours of summaries and >$100 in GPT bill so that summaries are useful ‚Äî and there is still an advantage of participating in active conversation e.g. details, specific questions, Q&A and so on.

Message : Asks: 
1. Please read the summaries and report issues, bugs to me.
2. This is a manual hacked together bunch of Jupyter notebooks right now: https://github.com/NirantK/nirantk.github.io/tree/main/community_dev/nbs ‚Äî would be really grateful for a single script which takes a .zip input and I can run every 2-3 days only on new data üôè

Message : Damn, I was about to start working on this exact thing!
Quoted Message : This is also a work-in-progress preview of a daily summary of this group chat ‚Äî going back to starting of the group itself:  https://nirantk.com/ai.html\n\nThis is hopefully useful: \n\n1. Daily links ‚Äî so you can catch up on what we've talked about\n2. Each page has a title and table of contents, so you can dig into topics of your interest

Message : The markdowns in content/ai/ are the summaries, right?
Quoted Message : Asks: \n1. Please read the summaries and report issues, bugs to me. \n2. This is a manual hacked together bunch of Jupyter notebooks right now: https://github.com/NirantK/nirantk.github.io/tree/main/community_dev/nbs ‚Äî would be really grateful for a single script which takes a .zip input and I can run every 2-3 days only on new data üôè

Message : Yes
Quoted Message : The markdowns in content/ai/ are the summaries, right?

Message : It's the markdown files which Hugo builds into static website served via Github Pages
The build is also a Github action on the same repo

Message : I'd love if we can use prettier CSS and better JS: https://quartz.jzhao.xyz/ ‚Äî this has fast search and is also markdown friendly

Message : I'll do 2. I'm guessing you have the zip file locally and you want to run manually for now?
Quoted Message : Asks: \n1. Please read the summaries and report issues, bugs to me. \n2. This is a manual hacked together bunch of Jupyter notebooks right now: https://github.com/NirantK/nirantk.github.io/tree/main/community_dev/nbs ‚Äî would be really grateful for a single script which takes a .zip input and I can run every 2-3 days only on new data üôè

Message : Yes. I've the zip file locally ‚Äî well everyone in the group can download it as well. And I want to run locally, but only incrementally.
Quoted Message : I'll do 2. I'm guessing you have the zip file locally and you want to run manually for now?

Message : Thanks so much for doing this @91773788xxxx. Maybe we can have a pool where we can contribute to the bill or something? Happy to support in whatever way you suggest. Also realise its a fraction of the total effort, so double thank you
Quoted Message : Asks: \n1. Please read the summaries and report issues, bugs to me. \n2. This is a manual hacked together bunch of Jupyter notebooks right now: https://github.com/NirantK/nirantk.github.io/tree/main/community_dev/nbs ‚Äî would be really grateful for a single script which takes a .zip input and I can run every 2-3 days only on new data üôè

Message : ‚Äé<attached: 00002877-GIF-2023-05-07-18-51-27.mp4>

Message : ‚Äé~‚ÄØNirant changed the group description

Message : ‚Äé<attached: 00002880-PHOTO-2023-05-07-20-52-53.jpg>

Message : You have to appreciate the hustle

Message : AI creating new jobs (NOT taking them away :P)

Message : Totally. Fiverrs a great window into what services are becoming valuable.

Prompting, especially for more complex art, will see a huge influx of freelancers

Message : Replit bounties are flooded with ChatGPT and AutoGPT related projects too.

Message : promptbase is a better signal

Message : They have loads of prompt engineers - they charge 50-500$ for custom prompts

Message : ‚Äé<attached: 00002887-PHOTO-2023-05-07-21-15-58.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00002877-GIF-2023-05-07-18-51-27.mp4>

Message : ‚Äé~‚ÄØNirant changed the group description

Message : ‚Äé<attached: 00002880-PHOTO-2023-05-07-20-52-53.jpg>

Message : You have to appreciate the hustle

Message : AI creating new jobs (NOT taking them away :P)

Message : Totally. Fiverrs a great window into what services are becoming valuable.

Prompting, especially for more complex art, will see a huge influx of freelancers

Message : Replit bounties are flooded with ChatGPT and AutoGPT related projects too.

Message : promptbase is a better signal

Message : They have loads of prompt engineers - they charge 50-500$ for custom prompts

Message : ‚Äé<attached: 00002887-PHOTO-2023-05-07-21-15-58.jpg>

Message : the google memo leak seems to think smaller os models are the future
Quoted Message : Here's where my thoughts are -\n\n1/ LLaMa weights leaking was a lucky incident - if we believe that models will become larger (which I do), do we expect similar weights being leaked for bigger models going forward?\n\n2/ If/As models become bigger, how many labs/companies would be able to keep up with the training costs?\n\nIt'd slowly start moving towards an oligopoly even for the OSS model providers\n\n3/ That said, it's very well possible that OSS models form the bulk of AI usage moving forward\n\nI guess Emad from Stability believes this and is playing to the playbook - let an AWS monetize the long tail of the OSS model usage while some of the biggest customers will pay premium for small, incremental better performance

Message : Reminder that is a single Google employee's opinion, not their company policy or even a team's mandate.
Quoted Message : the google memo leak seems to think smaller os models are the future

Message : https://arxiv.org/abs/2305.02301

Message : Is the memo written and leaked by a single employee, or it was a memo shared internally and leaked by an employee?
Quoted Message : Reminder that is a single Google employee's opinion, not their company policy or even a team's mandate.

Message : Written by a single employee, shared internally, like an internal forum, and shared outside by someone else presumably
Quoted Message : Is the memo written and leaked by a single employee, or it was a memo shared internally and leaked by an employee?

Message : Got it, I was thinking it was shared by higher ups in some meeting or something

Message : Google is quite open internally, ex you can view almost anyone's code if you're an employee. Most likely someone wrote a Google doc, shared in an internal Google group and it went viral / leaked. Similar to the memo written by James Demore
Quoted Message : Is the memo written and leaked by a single employee, or it was a memo shared internally and leaked by an employee?

Message : great thread wrt the  Google employee memo.

detailed thoughts on OpenAI's moats

https://twitter.com/labenz/status/1654853354529382407?t=zKjj004f4cWztIJbmGvWOw&s=19

Message : Koi tldr?
Quoted Message : great thread wrt the  Google employee memo.\n\ndetailed thoughts on OpenAI's moats\n\nhttps://twitter.com/labenz/status/1654853354529382407?t=zKjj004f4cWztIJbmGvWOw&s=19

Message : Hey, who can I dm for a referral at dashtoon? It is for a friend

Message : Ask admin literally.
Quoted Message : Hey, who can I dm for a referral at dashtoon? It is for a friend

Message : @91740765xxxx
Quoted Message : Hey, who can I dm for a referral at dashtoon? It is for a friend

Message : Thanks
Quoted Message : @9174xxxxxxxx

Message : Yes please DM me :D

Message : I love referrals for dashtoon specifically :P

Message : Personally am aligned to @91876396xxxx ‚Äòs #3rd point above.

Situation - I‚Äôm developing a FM app and I have the option of using either a closed source or a FOSS FM. If the FOSS FM‚Äôs capability for a particular genre of task eg summarisation is broadly in the same range as a closed source FM and there is significant advantage that I get from fine-tuning it on my data, the self hosted FOSS choice may be a no brainer.

For certain sophisticated tasks eg task list gen for an agent there might be value in using a closed source FM with meaningful better output. Not sure if that would be the majority of the functionality of the app, unlikely.

So just like the trad software world both ecosystems might exist in tandem + balance. Different players will monetise and dominate both.

The extent of FOSS presence may be a function of how true the GPT benchmarking of Vicuna-13B v Bard v GPT4 really is, and if over time Vicuna et al can continue to match closed FMs. Also if future FMs are open sourced like the Llama lucky break for the community to innovate on.

If anyone here can shed light on how much to take the google employee‚Äôs claims on the stackability + value of LoRA and training on limited high value datasets (specific strong GPT4 outputs), would be useful. The claims seemed compelling but not sure how actually reliable. üôè
Quoted Message : Here's where my thoughts are -\n\n1/ LLaMa weights leaking was a lucky incident - if we believe that models will become larger (which I do), do we expect similar weights being leaked for bigger models going forward?\n\n2/ If/As models become bigger, how many labs/companies would be able to keep up with the training costs?\n\nIt'd slowly start moving towards an oligopoly even for the OSS model providers\n\n3/ That said, it's very well possible that OSS models form the bulk of AI usage moving forward\n\nI guess Emad from Stability believes this and is playing to the playbook - let an AWS monetize the long tail of the OSS model usage while some of the biggest customers will pay premium for small, incremental better performance

Message : TLDR. worth reading the whole thread but pasting some main points below:

- People in general are super confused, unnerved, and even outright scared by AI. Thus, many will want to use the safest, most established option
- They used to say ‚ÄúNobody gets fired for going with IBM‚Äù; the modern echo might be "Nobody gets fired for going with OpenAI"
- OpenAI's product feedback loop.  They started with @ycombinator -style product-market fit obsession, & are now collecting data at unmatched scale via ChatGPT free tier
- pricing power. OpenAI has led the market on price cuts, with ~97% price reduction over the last 9 months. No reason to think they're done. Developers are often surprisingly resistant to paying for software, but at $2 / 1M tokens, open source can only undercut so much
- talent density extends to all parts of OpenAI, btw, including sales & account management.
- insane distribution and partnerships. bing, consulting firms etc
- network effects.  While AI doesn't seem to have the same network effects as web 2.0 / social media, it's still notable that every "Prompting 101" course, performance benchmark, library, and tool is built for / on / with OpenAI models first.
Quoted Message : great thread wrt the  Google employee memo.\n\ndetailed thoughts on OpenAI's moats\n\nhttps://twitter.com/labenz/status/1654853354529382407?t=zKjj004f4cWztIJbmGvWOw&s=19

Message : ‚¨ÜÔ∏è done
Quoted Message : Koi tldr?

Message : What's the current hypothesis on how OpenAI is able to offer such a low price?
Quoted Message : TLDR. worth reading the whole thread but pasting some main points below:\n\n- People in general are super confused, unnerved, and even outright scared by AI. Thus, many will want to use the safest, most established option\n- They used to say ‚ÄúNobody gets fired for going with IBM‚Äù; the modern echo might be \"Nobody gets fired for going with OpenAI\"\n- OpenAI's product feedback loop.  They started with @ycombinator -style product-market fit obsession, & are now collecting data at unmatched scale via ChatGPT free tier  \n- pricing power. OpenAI has led the market on price cuts, with ~97% price reduction over the last 9 months. No reason to think they're done. Developers are often surprisingly resistant to paying for software, but at $2 / 1M tokens, open source can only undercut so much\n- talent density extends to all parts of OpenAI, btw, including sales & account management.\n- insane distribution and partnerships. bing, consulting firms etc\n- network effects.  While AI doesn't seem to have the same network effects as web 2.0 / social media, it's still notable that every \"Prompting 101\" course, performance benchmark, library, and tool is built for / on / with OpenAI models first.

Message : I think if we dive a little deeper, openai has been making lots of optimisation on the inference side. Hence the cost is continuously coming down. Lilian weng (applied scientist at openai) wrote this -https://lilianweng.github.io/posts/2023-01-10-inference-optimization/
Quoted Message : What's the current hypothesis on how OpenAI is able to offer such a low price?

Message : Hi everyone, I am experimenting on the prompts with gpt3.5 api
For cases where it doesn‚Äôt know the answer, it states the answer like ‚ÄúAs an AI language model‚Äù. How can I improve my prompt in such a way that for such answers, it can say something like ‚ÄúI'll get back to you on this‚Äù.

My system prompt -
If you are unable to answer a question and if the question is out of your scope, you can say that "I am still learning, I'll get back to you on this"

I tried adding it in the user prompt, but it still answers the same.

Message : Current result -
User - What is the current time?
AI - I'm sorry, but as an AI language model, I do not have access to real-time information. However, you can check the current time on your device or by searching online. Is there anything else I can assist you with?

Message : Is this the answer everytime? Have you tried it multiple times?
Quoted Message : Current result -\nUser - What is the current time?\nAI - I'm sorry, but as an AI language model, I do not have access to real-time information. However, you can check the current time on your device or by searching online. Is there anything else I can assist you with?

Message : https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html?highlight=don%27t%20know#the-stuff-chain

Refer to this.
Quoted Message : Current result -\nUser - What is the current time?\nAI - I'm sorry, but as an AI language model, I do not have access to real-time information. However, you can check the current time on your device or by searching online. Is there anything else I can assist you with?

Message : optimization is one reason but OpenAI's had a $540M loss last year. idk how much of the loss if from Free ChatGPT vs cheap API.
lower pricing has also helped increase usage. search applications, chatbots, langchain, llama-index started taking off when OpenAI reduced embeddings model cost by 95% back in December.
Quoted Message : What's the current hypothesis on how OpenAI is able to offer such a low price?

Message : ‚Äé<attached: 00002913-PHOTO-2023-05-07-23-31-18.jpg>
Quoted Message : optimization is one reason but OpenAI's had a $540M loss last year. idk how much of the loss if from Free ChatGPT vs cheap API.\nlower pricing has also helped increase usage. search applications, chatbots, langchain, llama-index started taking off when OpenAI reduced embeddings model cost by 95% back in December.

Message : The part ‚ÄúAs an AI language model‚Äù is consistent in all the messages which model doesn‚Äôt know
Quoted Message : Is this the answer everytime? Have you tried it multiple times?

Message : Let me go through this
Quoted Message : https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html?highlight=don%27t%20know#the-stuff-chain\n\nRefer to this.

Message : have you tried few-shot prompting? Prime with examples where you respond with "I am still learning, I'll get back to you on this"
Quoted Message : The part ‚ÄúAs an AI language model‚Äù is consistent in all the messages which model doesn‚Äôt know

Message : Not yet. Didn‚Äôt try it because I am running the bot which is solving multiple cases and for those cases prompt is already big.

Adding examples for this case, makes the prompt bigger which I was trying to avoid.
Quoted Message : have you tried few-shot prompting? Prime with examples where you respond with \"I am still learning, I'll get back to you on this\"

Message : This group is cutting edge, folks! Can be monetised. üòÑ

Message : Absolutely! These daily chat summaries can be signal amidst all the noise around AI for a lot of people as newsletter/podcasts(maybe with weekly frequency reviewed by mods).
Quoted Message : This group is cutting edge, folks! Can be monetised. üòÑ

Message : hard to speculate anything from losses they are a creation of accounting often sv companies have large stock comp. based losses. i work with llms in production mostly using react and other simpler prompting openai is the most consistent llm i can be confident around, cohere is the second most
Quoted Message : optimization is one reason but OpenAI's had a $540M loss last year. idk how much of the loss if from Free ChatGPT vs cheap API.\nlower pricing has also helped increase usage. search applications, chatbots, langchain, llama-index started taking off when OpenAI reduced embeddings model cost by 95% back in December.

Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?

Please send suggestions to Soumyadeep @91740765xxxx
Context: Looking for a May meetup speaker

Message : @3248663xxxx
Quoted Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?\n\nPlease send suggestions to Soumyadeep @9174xxxxxxxx \nContext: Looking for a May meetup speaker

Message : Thanks bhai. Will DM Nirant and Somu
Quoted Message : @324xxxxxxxx

Message : Rohan from Inkers.
Quoted Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?\n\nPlease send suggestions to Soumyadeep @9174xxxxxxxx \nContext: Looking for a May meetup speaker

Message : Might schedule a meet with an executive at Midjourney soon.

Any questions you would like me to ask?

Message : are they profitable?

also what makes them stick to discord for so long, why not invest in their app
Quoted Message : Might schedule a meet with an executive at Midjourney soon.\n\nAny questions you would like me to ask?

Message : What is their plan for the long run? The discord model cannot be that sustainable.
Quoted Message : Might schedule a meet with an executive at Midjourney soon.\n\nAny questions you would like me to ask?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This group is cutting edge, folks! Can be monetised. üòÑ

Message : Absolutely! These daily chat summaries can be signal amidst all the noise around AI for a lot of people as newsletter/podcasts(maybe with weekly frequency reviewed by mods).
Quoted Message : This group is cutting edge, folks! Can be monetised. üòÑ

Message : hard to speculate anything from losses they are a creation of accounting often sv companies have large stock comp. based losses. i work with llms in production mostly using react and other simpler prompting openai is the most consistent llm i can be confident around, cohere is the second most
Quoted Message : optimization is one reason but OpenAI's had a $540M loss last year. idk how much of the loss if from Free ChatGPT vs cheap API.\nlower pricing has also helped increase usage. search applications, chatbots, langchain, llama-index started taking off when OpenAI reduced embeddings model cost by 95% back in December.

Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?

Please send suggestions to Soumyadeep @91740765xxxx
Context: Looking for a May meetup speaker

Message : @3248663xxxx
Quoted Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?\n\nPlease send suggestions to Soumyadeep @9174xxxxxxxx \nContext: Looking for a May meetup speaker

Message : Thanks bhai. Will DM Nirant and Somu
Quoted Message : @324xxxxxxxx

Message : Rohan from Inkers.
Quoted Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?\n\nPlease send suggestions to Soumyadeep @9174xxxxxxxx \nContext: Looking for a May meetup speaker

Message : Might schedule a meet with an executive at Midjourney soon.

Any questions you would like me to ask?

Message : are they profitable?

also what makes them stick to discord for so long, why not invest in their app
Quoted Message : Might schedule a meet with an executive at Midjourney soon.\n\nAny questions you would like me to ask?

Message : What is their plan for the long run? The discord model cannot be that sustainable.
Quoted Message : Might schedule a meet with an executive at Midjourney soon.\n\nAny questions you would like me to ask?

Message : hey admins, is there a way we can do beta launches in the group. Interestingly the first ever demo of the product was presented at deep hackathon. Thanks for adding @91966317xxxx in the first place. At a slightly more mature and functional stage now.

Message : Glad to hear that you've a more mature product! ü´∂üèª

Perhaps Product Hunt, Twitter and other hackathons (there are 2-3 of them across BLR, BOM in the next 50 days) are better forums for launches/demos than trying to have them over a WA group?

That said, if there are 3-5 people wanting to demo _exceptional_ work, please DM Loom demos to me and we'll take it from there üòÅ
Quoted Message : hey admins, is there a way we can do beta launches in the group. Interestingly the first ever demo of the product was presented at deep hackathon. Thanks for adding @9196xxxxxxxx in the first place. At a slightly more mature and functional stage now.

Message : I believe @91990072xxxx literally did his PhD on this :)
Quoted Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?\n\nPlease send suggestions to Soumyadeep @9174xxxxxxxx \nContext: Looking for a May meetup speaker

Message : He was our first pick as well, unfortunately he is occupied on the meetup dates
Quoted Message : I believe @9199xxxxxxxx literally did his PhD on this :)

Message : some users have access to the web app.

i think all the moves they've done till now, esp the discord one are pretty brilliant.


acc to their founder: not focussed on building a "platform" from the beginning. main focus right now is product.

i mean just look at Dalle. it has a webapp, API but i doubt anybody uses it srsly in a product. i have a ton of unused credits i got from OpenAI Artist grant. even with a webapp, Dalle UX is worse than MJ when you actually map out the workflow.

also 1-2 months back they did say that API is in the works.

my guess is they'll start testing it after they release v6 (2-3 months)
Quoted Message : What is their plan for the long run? The discord model cannot be that sustainable.

Message : Sure. Thanks Nirant. Will DM you with more context mid week.
Quoted Message : Glad to hear that you've a more mature product! ü´∂üèª\n\nPerhaps Product Hunt, Twitter and other hackathons (there are 2-3 of them across BLR, BOM in the next 50 days) are better forums for launches/demos than trying to have them over a WA group?\n\nThat said, if there are 3-5 people wanting to demo _exceptional_ work, please DM Loom demos to me and we'll take it from there üòÅ

Message : David's tweet https://twitter.com/DavidSHolz/status/1655122525616242690?t=aM1R-2Vk5gvrOIScY4ipWg&s=19
Quoted Message : some users have access to the web app.\n\ni think all the moves they've done till now, esp the discord one are pretty brilliant.\n\n\nacc to their founder: not focussed on building a \"platform\" from the beginning. main focus right now is product. \n\ni mean just look at Dalle. it has a webapp, API but i doubt anybody uses it srsly in a product. i have a ton of unused credits i got from OpenAI Artist grant. even with a webapp, Dalle UX is worse than MJ when you actually map out the workflow. \n\nalso 1-2 months back they did say that API is in the works.\n\nmy guess is they'll start testing it after they release v6 (2-3 months)

Message : Wouldn‚Äôt the investor group be a good fit for this
Quoted Message : Glad to hear that you've a more mature product! ü´∂üèª\n\nPerhaps Product Hunt, Twitter and other hackathons (there are 2-3 of them across BLR, BOM in the next 50 days) are better forums for launches/demos than trying to have them over a WA group?\n\nThat said, if there are 3-5 people wanting to demo _exceptional_ work, please DM Loom demos to me and we'll take it from there üòÅ

Message : API. When are they launching official API for their products.

So many unofficial API providers mushrooming due to lack of official API.
Quoted Message : Might schedule a meet with an executive at Midjourney soon.\n\nAny questions you would like me to ask?

Message : Sorry folks, too many things this month.
Quoted Message : He was our first pick as well, unfortunately he is occupied on the meetup dates

Message : @91886100xxxx
Quoted Message : Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?\n\nPlease send suggestions to Soumyadeep @9174xxxxxxxx \nContext: Looking for a May meetup speaker

Message : Thanks Sudarshan.. Happy to share with the community!

Message : He's published in ICCV, CVPR, consults a good number of startups, and has worked with IIIT-H. Much more too, but this is what I remember from our small chat at the Nvidia meetup :)

Message : when API
Quoted Message : Might schedule a meet with an executive at Midjourney soon.\n\nAny questions you would like me to ask?

Message : How did they approach their hiring? 
One of the most impressive things about them is their lean team. Would definitely love to learn about how they found the right people.
Quoted Message : Might schedule a meet with an executive at Midjourney soon.\n\nAny questions you would like me to ask?

Message : I guess it would just be the leap motion team na?
Quoted Message : How did they approach their hiring? \nOne of the most impressive things about them is their lean team. Would definitely love to learn about how they found the right people.

Message : https://twitter.com/bindureddy/status/1655253111659978752?s=46

Bard vs chatgpt will be like android vs ios. Different Ux, prompting, featuresüòÖ

Message : Hi All,

Any idea on the timelines for GPT 4 api access?
We need it for a pilot we are doing with an organisation. If anyone of you have it, we are looking to utilise it and pay for the usage.

Message : Ping @91773788xxxx
Quoted Message : Hi All,\n\nAny idea on the timelines for GPT 4 api access? \nWe need it for a pilot we are doing with an organisation. If anyone of you have it, we are looking to utilise it and pay for the usage.

Message : I am able to fix this. I made few changes in prompt. I have mentioned about the type of message it can send & have specifically mentioned avoid saying the line.

Avoid saying that you are "AI language model"
If you are unable to answer a question, you should ask the student to give more context about the question but refrain from making up the answer.
Quoted Message : Current result -\nUser - What is the current time?\nAI - I'm sorry, but as an AI language model, I do not have access to real-time information. However, you can check the current time on your device or by searching online. Is there anything else I can assist you with?

Message : you can email Atty from OpenAI / he is pretty helpful
Quoted Message : Hi All,\n\nAny idea on the timelines for GPT 4 api access? \nWe need it for a pilot we are doing with an organisation. If anyone of you have it, we are looking to utilise it and pay for the usage.

Message : Facing the same issue.
If any of you have any hack for this- do help!
Quoted Message : Hi All,\n\nAny idea on the timelines for GPT 4 api access? \nWe need it for a pilot we are doing with an organisation. If anyone of you have it, we are looking to utilise it and pay for the usage.

Message : Go live with GPT3.5 and show traction worked really well for us

Message : I have access to both 3.5 turbo and 4.
GPT 4 is both slower, more expensive and isnt necessarily a whole lot better than 3.5 Turbo. What worked more for us was iterating with system messages and measuring improvements to output.

Message : GPT4 is slower, more expensive and almost 2-5x better for any reasoning e.g. QA or agent behaviour e.g. AutoGPT kinda things.
Quoted Message : I have access to both 3.5 turbo and 4.\nGPT 4 is both slower, more expensive and isnt necessarily a whole lot better than 3.5 Turbo. What worked more for us was iterating with system messages and measuring improvements to output.

Message : no, we applied two weeks ago and haven't gotten gpt4 yet

Message : ‚Äé<attached: 00002958-PHOTO-2023-05-08-16-21-45.jpg>

Message : Yes 100%. 
This is already achieved for my company though.

For the pilot with an organisation we needed the access.
Quoted Message : Go live with GPT3.5 and show traction worked really well for us

Message : Any good material on how folks are monetizing the GPT plugins?

Message : There is another way to solve this, I am able to add context block for starting any communication with the llm model one of the fields of the context block is currentDateTime: <ISO string format> 
Whenever the model needs to refer to the date for some output I explicitly mentioned that refer to context block for any missing info,.

For ever further fine-tuning ask it to follow a certain output format. If you are able to prompt back to user then great but if you are orchestrating the communication between two agents then expecting a proper formatting will help you reduce round trips for your llm model to understand what the instructions want.
let me know if you want to explore. - I have played around with langchain for past 3 months now
Quoted Message : I am able to fix this. I made few changes in prompt. I have mentioned about the type of message it can send & have specifically mentioned avoid saying the line.\n\nAvoid saying that you are \"AI language model\"\nIf you are unable to answer a question, you should ask the student to give more context about the question but refrain from making up the answer.

Message : roughly equivalent to their api pricing plan because ultimately it calls their api?
Quoted Message : Any good material on how folks are monetizing the GPT plugins?

Message : Let me try this out. Have not thought about it yet
Quoted Message : There is another way to solve this, I am able to add context block for starting any communication with the llm model one of the fields of the context block is currentDateTime: <ISO string format> \nWhenever the model needs to refer to the date for some output I explicitly mentioned that refer to context block for any missing info,.\n\nFor ever further fine-tuning ask it to follow a certain output format. If you are able to prompt back to user then great but if you are orchestrating the communication between two agents then expecting a proper formatting will help you reduce round trips for your llm model to understand what the instructions want. \nlet me know if you want to explore. - I have played around with langchain for past 3 months now

Message : Has anyone even monetized?
Quoted Message : Any good material on how folks are monetizing the GPT plugins?

Message : Hey folks, 

Any body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.

Help would be appreciated!

Message : Exactly my question - especially for plugins that are not for an existing business like Open Table. Want to understand how folks are thinking about mid-term monetization
Quoted Message : Has anyone even monetized?

Message : I paid using an axis bank corporate debit card and it worked, lol.
Quoted Message : Hey folks, \n\nAny body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.\n\nHelp would be appreciated!

Message : Hello,
What's the best resource to read up on the LoRA config (number of attention heads, scaling factor) settings best practices? I'm specifically interested in fine-tuning the OPT6.7B on my custom dataset.

Message : For short term, you can do stuff like custom search in slack, notion etc
Quoted Message : Exactly my question - especially for plugins that are not for an existing business like Open Table. Want to understand how folks are thinking about mid-term monetization

Message : Facing same problem. Unable to pay for past 2 months üòÖüòÖ
Quoted Message : Hey folks, \n\nAny body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.\n\nHelp would be appreciated!

Message : we use USA issued cards and those work fine
Quoted Message : Hey folks, \n\nAny body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.\n\nHelp would be appreciated!


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : roughly equivalent to their api pricing plan because ultimately it calls their api?
Quoted Message : Any good material on how folks are monetizing the GPT plugins?

Message : Let me try this out. Have not thought about it yet
Quoted Message : There is another way to solve this, I am able to add context block for starting any communication with the llm model one of the fields of the context block is currentDateTime: <ISO string format> \nWhenever the model needs to refer to the date for some output I explicitly mentioned that refer to context block for any missing info,.\n\nFor ever further fine-tuning ask it to follow a certain output format. If you are able to prompt back to user then great but if you are orchestrating the communication between two agents then expecting a proper formatting will help you reduce round trips for your llm model to understand what the instructions want. \nlet me know if you want to explore. - I have played around with langchain for past 3 months now

Message : Has anyone even monetized?
Quoted Message : Any good material on how folks are monetizing the GPT plugins?

Message : Hey folks, 

Any body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.

Help would be appreciated!

Message : Exactly my question - especially for plugins that are not for an existing business like Open Table. Want to understand how folks are thinking about mid-term monetization
Quoted Message : Has anyone even monetized?

Message : I paid using an axis bank corporate debit card and it worked, lol.
Quoted Message : Hey folks, \n\nAny body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.\n\nHelp would be appreciated!

Message : Hello,
What's the best resource to read up on the LoRA config (number of attention heads, scaling factor) settings best practices? I'm specifically interested in fine-tuning the OPT6.7B on my custom dataset.

Message : For short term, you can do stuff like custom search in slack, notion etc
Quoted Message : Exactly my question - especially for plugins that are not for an existing business like Open Table. Want to understand how folks are thinking about mid-term monetization

Message : Facing same problem. Unable to pay for past 2 months üòÖüòÖ
Quoted Message : Hey folks, \n\nAny body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.\n\nHelp would be appreciated!

Message : we use USA issued cards and those work fine
Quoted Message : Hey folks, \n\nAny body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.\n\nHelp would be appreciated!

Message : ‚Äé<attached: 00002973-PHOTO-2023-05-08-17-49-09.jpg>

Message : And manual payment goes through smoothly

Message : ‚Äé<attached: 00002975-PHOTO-2023-05-08-18-14-57.jpg>

Message : https://archive.is/elhiG

Future visions of Google Search

Message : Hello 
Anyone who had published a paper in top-tier conferences like
Neurips, CVPR, ICCV, ECCV, ICASSP, ACL, and NAACL as a 1st or 2nd author.
I am looking for some people to collaborate with me on the research.

Message : Hi, any suggestions for Natural Language to Code. Something similar to OpenAI Codex.

Message : What are you looking for? I've an ACL SemEval paper: https://aclanthology.org/2020.semeval-1.119/
Quoted Message : Hello \nAnyone who had published a paper in top-tier conferences like \nNeurips, CVPR, ICCV, ECCV, ICASSP, ACL, and NAACL as a 1st or 2nd author.\nI am looking for some people to collaborate with me on the research.

Message : Do you want something which can follow instruction? If yes, this is the best FOSS I've seen so far: https://huggingface.co/bigcode/starcoder 

If you're looking for more Github Copilot like completion: https://huggingface.co/replit/replit-code-v1-3b
Quoted Message : Hi, any suggestions for Natural Language to Code. Something similar to OpenAI Codex.

Message : I am currently doing research mostly on MultiModel (Speech, Language, video) systems if you like to collaborate DM me
Quoted Message : What are you looking for? I've an ACL SemEval paper: https://aclanthology.org/2020.semeval-1.119/

Message : Thanks.
Quoted Message : Do you want something which can follow instruction? If yes, this is the best FOSS I've seen so far: https://huggingface.co/bigcode/starcoder \n\nIf you're looking for more Github Copilot like completion: https://huggingface.co/replit/replit-code-v1-3b

Message : Not an academic  ‚Äî the ACL Paper was to help an intern get into academia, done mostly as a hobby :)
Quoted Message : I am currently doing research mostly on MultiModel (Speech, Language, video) systems if you like to collaborate DM me

Message : Ohh Fine !
Quoted Message : Not an academic  ‚Äî the ACL Paper was to help an intern get into academia, done mostly as a hobby :)

Message : Please anyone is interested let me know
Quoted Message : Hello \nAnyone who had published a paper in top-tier conferences like \nNeurips, CVPR, ICCV, ECCV, ICASSP, ACL, and NAACL as a 1st or 2nd author.\nI am looking for some people to collaborate with me on the research.

Message : Does KDD count? I know my friend who had worked on a paper at glance and it got published
Quoted Message : Please anyone is interested let me know

Message : He can probably help you

Message : Ohh yaa KDD will also count in

Message : What's up? I've published in ACL in low parameter adptation - https://arxiv.org/abs/2107.09622
Quoted Message : Hello \nAnyone who had published a paper in top-tier conferences like \nNeurips, CVPR, ICCV, ECCV, ICASSP, ACL, and NAACL as a 1st or 2nd author.\nI am looking for some people to collaborate with me on the research.

Message : Ohh Jawahar's student üôè
Quoted Message : What's up? I've published in ACL in low parameter adptation - https://arxiv.org/abs/2107.09622

Message : Haha yeap...
Quoted Message : Ohh Jawahar's student üôè

Message : your too jawahar sir student
Quoted Message : What's up? I've published in ACL in low parameter adptation - https://arxiv.org/abs/2107.09622

Message : What's the solution for storing and querying embeddings in/from a MySQL db?

Message : np.array(SELECT * FROM db) üòÇü´∂
Quoted Message : What's the solution for storing and querying embeddings in/from a MySQL db?

Message : https://twitter.com/jxnlco/status/1655368751657676800?t=5t9flIlOSbLwO-N2fhza5A&s=19

Cool stuff and an even cooler name

Message : facing massive timeout issues with /chat/completions/gpt-3.5-turbo. Status page is all green. Anyone been facing this lately?

Message : yes happens a bunch of times and can see some 50-60 timeouts yesterday. you can put retries in place if not already. 95% of 50 timeouts succeeded on retry.
Quoted Message : facing massive timeout issues with /chat/completions/gpt-3.5-turbo. Status page is all green. Anyone been facing this lately?

Message : anyone knows what's the fastest open source llm right now?

been meaning to tinker with open llms for a while but haven't gotten to it, can anyone share some suggestions on what are the good ones with resources available in terms of documentation.

Message : https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec
has anyone explored this technique? Seems very interesting

Message : ‚Äé<attached: 00003002-PHOTO-2023-05-09-06-25-52.jpg>

Message : https://twitter.com/kevinafischer/status/1655734333720633348?s=48&t=ACPHEfclkXmi9Z92RTsh9g

Message : It shines when doing eda kind of work...
Quoted Message :  2023_05_09_3EB085525EF86F0ABC6685.jpeg

Message : Oooof. Socher, the OG Prompter, woke up and chose violence against academic peer review today

https://twitter.com/RichardSocher/status/1655554763562385409

Message : If somebody has to build a chat, summarize and index type of application today, would yo recommend:
1. Cohere
2. Steamship
3. Write the code on your own (the openapi APIs are fairly straightforward to use)

Message : Langchain or Llama Index ‚Äî retain the flexibility to change both the underlying models, and how you interact with them with powerful abstractions
Quoted Message : If somebody has to build a chat, summarize and index type of application today, would yo recommend:\n1. Cohere\n2. Steamship\n3. Write the code on your own (the openapi APIs are fairly straightforward to use)

Message : What is cohere and steamship's play?

Cohere has 165m in funding.

Message : ‚Äé~‚ÄØNirant changed the group description

Message : OpenAI apis , + Langchain to start
Quoted Message : If somebody has to build a chat, summarize and index type of application today, would yo recommend:\n1. Cohere\n2. Steamship\n3. Write the code on your own (the openapi APIs are fairly straightforward to use)

Message : ‚Äé<attached: 00003011-PHOTO-2023-05-09-09-30-29.jpg>

Message : I am assuming doesn‚Äôt work for all hf models? Since they need to have an endpoint.
Quoted Message :  2023_05_09_3EB033015CA35F44620A1A.jpeg

Message : Is there a SAM but for audio?

Message : You can convert it from speech to text and try for text
Quoted Message : Is there a SAM but for audio?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Oooof. Socher, the OG Prompter, woke up and chose violence against academic peer review today

https://twitter.com/RichardSocher/status/1655554763562385409

Message : If somebody has to build a chat, summarize and index type of application today, would yo recommend:
1. Cohere
2. Steamship
3. Write the code on your own (the openapi APIs are fairly straightforward to use)

Message : Langchain or Llama Index ‚Äî retain the flexibility to change both the underlying models, and how you interact with them with powerful abstractions
Quoted Message : If somebody has to build a chat, summarize and index type of application today, would yo recommend:\n1. Cohere\n2. Steamship\n3. Write the code on your own (the openapi APIs are fairly straightforward to use)

Message : What is cohere and steamship's play?

Cohere has 165m in funding.

Message : ‚Äé~‚ÄØNirant changed the group description

Message : OpenAI apis , + Langchain to start
Quoted Message : If somebody has to build a chat, summarize and index type of application today, would yo recommend:\n1. Cohere\n2. Steamship\n3. Write the code on your own (the openapi APIs are fairly straightforward to use)

Message : ‚Äé<attached: 00003011-PHOTO-2023-05-09-09-30-29.jpg>

Message : I am assuming doesn‚Äôt work for all hf models? Since they need to have an endpoint.
Quoted Message :  2023_05_09_3EB033015CA35F44620A1A.jpeg

Message : Is there a SAM but for audio?

Message : You can convert it from speech to text and try for text
Quoted Message : Is there a SAM but for audio?

Message : For music?.. Something that strip away all instrumental + vocal layers

Message : Yes I think there are
Quoted Message : For music?.. Something that strip away all instrumental + vocal layers

Message : Open assistant
Quoted Message : anyone knows what's the fastest open source llm right now?\n\nbeen meaning to tinker with open llms for a while but haven't gotten to it, can anyone share some suggestions on what are the good ones with resources available in terms of documentation.

Message : Are you looking for a source separation?

Message : You can try spleeter

Message : I am part of OA team (safety and ML), I can help if you're interested in opensource LLMs.
Quoted Message : anyone knows what's the fastest open source llm right now?\n\nbeen meaning to tinker with open llms for a while but haven't gotten to it, can anyone share some suggestions on what are the good ones with resources available in terms of documentation.

Message : What do you suggest for tabular data which contains Questions and Answers along with user queries. I want to use the questions set and return the answer for a particular query.

Message : Embed ‚Üí Nearest Neighbor ‚Üí Return answer

Is there reason this cannot work for you?
Quoted Message : What do you suggest for tabular data which contains Questions and Answers along with user queries. I want to use the questions set and return the answer for a particular query.

Message : Currently using BERT where I trained by grouping a set of questions and the related queries and labelling them either 0 or 1 based on if the query belongs to a set of questions. Then generating the similarity score for the new queries. 
This method becomes slow in cases where the search space increases.
Quoted Message : Embed ‚Üí Nearest Neighbor ‚Üí Return answer\n\nIs there reason this cannot work for you?

Message : Will try this
Quoted Message : Embed ‚Üí Nearest Neighbor ‚Üí Return answer\n\nIs there reason this cannot work for you?

Message : I'm guessing the dataset is fairly large, hence the question. Perhaps look into https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec
Quoted Message : What do you suggest for tabular data which contains Questions and Answers along with user queries. I want to use the questions set and return the answer for a particular query.

Message : Why is NN slow for embedding? I can do about a million comparisons in less than a second on 2vCPU and more on a modern M1/M2 Pro machine
Quoted Message : Currently using BERT where I trained by grouping a set of questions and the related queries and labelling them either 0 or 1 based on if the query belongs to a set of questions. Then generating the similarity score for the new queries. \nThis method becomes slow in cases where the search space increases.

Message : Women in AI, Bengaluru meetup: 
https://hasgeek.com/generativeAI/women-in-ai-meetup/

Please share with your colleagues e.g. copy-paste to Slack, forward to friends WA groups :)

Message : You can try FAISS
Quoted Message : Currently using BERT where I trained by grouping a set of questions and the related queries and labelling them either 0 or 1 based on if the query belongs to a set of questions. Then generating the similarity score for the new queries. \nThis method becomes slow in cases where the search space increases.

Message : Alternatively you can do PCA or similar methods for dimensionality reduction. This can improve speed

Message : This approach, along with feeding the results into a reader model to refine the answer might work even better.
Quoted Message : Embed ‚Üí Nearest Neighbor ‚Üí Return answer\n\nIs there reason this cannot work for you?

Message : For hindi texts
Quoted Message : This approach, along with feeding the results into a reader model to refine the answer might work even better.

Message : At the cost of accuracy
Quoted Message : Alternatively you can do PCA or similar methods for dimensionality reduction. This can improve speed

Message : What are the techniques or preprocessing steps to reduce prompt with context tokens while sending it OpenAI without affecting outcome?

Message : Removing stop words is a low hanging fruit

If your context has non-English characters (they consume a ton of tokens) explore if you can use some kind of translation to English to keep the same functionality

A few weeks back GPTs compression language was doing a lot of rounds, might be worth exploring

Try a map-reduce / summarisation approach where you try to summarise your context into atomic units
Quoted Message : What are the techniques or preprocessing steps to reduce prompt with context tokens while sending it OpenAI without affecting outcome?

Message : I'm sure people here can give you many other techniques to try

Message : I remember someone shared about compression. Thanks for reminding me about it. My data mostly have English chars only.
Quoted Message : Removing stop words is a low hanging fruit\n\nIf your context has non-English characters (they consume a ton of tokens) explore if you can use some kind of translation to English to keep the same functionality\n\nA few weeks back GPTs compression language was doing a lot of rounds, might be worth exploring\n\nTry a map-reduce / summarisation approach where you try to summarise your context into atomic units

Message : what were the results using traditional keyword/BM-25 approach? what is not working with the traditional approach to apply the semantic search result techniques?
Quoted Message : What do you suggest for tabular data which contains Questions and Answers along with user queries. I want to use the questions set and return the answer for a particular query.

Message : If the use case is very defined, consider fine-tuning
Quoted Message : What are the techniques or preprocessing steps to reduce prompt with context tokens while sending it OpenAI without affecting outcome?

Message : Not yet. It is still in the experimental phase.
Quoted Message : If the use case is very defined, consider fine-tuning

Message : how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key

Message : Use the product, revoke every Wednesday üòÖ
Quoted Message : how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key

Message : Write logs from each service and review them in sumologic or coralogix for attribution.
Quoted Message : how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key

Message : but these services are not under my control. I'm talking about external products which have a "enter OpenAI API key" flow

Message : Then you need to wrap the actual call and provide the wrapper to every service. That way you can control the abuse of the key and tag incoming calls for attribution.
Quoted Message : but these services are not under my control. I'm talking about external products which have a \"enter OpenAI API key\" flow

Message : Little tedious üòÖ
Quoted Message : Then you need to wrap the actual call and provide the wrapper to every service. That way you can control the abuse of the key and tag incoming calls for attribution.

Message : that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?
Quoted Message : Then you need to wrap the actual call and provide the wrapper to every service. That way you can control the abuse of the key and tag incoming calls for attribution.

Message : Bottom line is to agree to a central wrapper call. Managed in one place.

That can be optimized at various levels within this layer.
Quoted Message : but these services are not under my control. I'm talking about external products which have a \"enter OpenAI API key\" flow

Message : Stop providing the keys, that's the point of creating a wrapper so that you control the key.
Quoted Message : that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?

Message : Basically a proxy server is what he‚Äôs saying. Should be about 20 lines of fastapi
Quoted Message : that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?

Message : Precisely. Didn't want to use 'proxy server' to avoid confusion.
Quoted Message : Basically a proxy server is what he‚Äôs saying. Should be about 20 lines of fastapi

Message : Wait but the openai endpoint url should be editable on the service/product you give the api key to
Quoted Message : how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key

Message : @91797731xxxx is a CMU grad and Professional ML Engineer via Meta
@91954705xxxx is a Lead DS at Razorpay

Please create as much confusion as you both want. I trust you both are technical enough üòÖ

Message : Talking about things like:
https://thesamur.ai/mygpt
https://www.chatorg.ai/

Asking because I want to create an app which could benefit from using user's API keys, but not sure if people are actually providing their keys to these services

Message : Can you share the ss of the place where you enter the api key
Quoted Message : Talking about things like:\nhttps://thesamur.ai/mygpt\nhttps://www.chatorg.ai/\n\nAsking because I want to create an app which could benefit from using user's API keys, but not sure if people are actually providing their keys to these services


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Little tedious üòÖ
Quoted Message : Then you need to wrap the actual call and provide the wrapper to every service. That way you can control the abuse of the key and tag incoming calls for attribution.

Message : that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?
Quoted Message : Then you need to wrap the actual call and provide the wrapper to every service. That way you can control the abuse of the key and tag incoming calls for attribution.

Message : Bottom line is to agree to a central wrapper call. Managed in one place.

That can be optimized at various levels within this layer.
Quoted Message : but these services are not under my control. I'm talking about external products which have a \"enter OpenAI API key\" flow

Message : Stop providing the keys, that's the point of creating a wrapper so that you control the key.
Quoted Message : that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?

Message : Basically a proxy server is what he‚Äôs saying. Should be about 20 lines of fastapi
Quoted Message : that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?

Message : Precisely. Didn't want to use 'proxy server' to avoid confusion.
Quoted Message : Basically a proxy server is what he‚Äôs saying. Should be about 20 lines of fastapi

Message : Wait but the openai endpoint url should be editable on the service/product you give the api key to
Quoted Message : how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key

Message : @91797731xxxx is a CMU grad and Professional ML Engineer via Meta
@91954705xxxx is a Lead DS at Razorpay

Please create as much confusion as you both want. I trust you both are technical enough üòÖ

Message : Talking about things like:
https://thesamur.ai/mygpt
https://www.chatorg.ai/

Asking because I want to create an app which could benefit from using user's API keys, but not sure if people are actually providing their keys to these services

Message : Can you share the ss of the place where you enter the api key
Quoted Message : Talking about things like:\nhttps://thesamur.ai/mygpt\nhttps://www.chatorg.ai/\n\nAsking because I want to create an app which could benefit from using user's API keys, but not sure if people are actually providing their keys to these services

Message : ‚Äé<attached: 00003057-PHOTO-2023-05-09-13-50-30.jpg>

Message : ‚Äé<attached: 00003058-PHOTO-2023-05-09-13-50-31.jpg>

Message : they seem to be storing the key in plain text, which is kinda crazy in itself

Message : @91915162xxxx what are your thoughts about this?

Message : Yeah I dont think the proxy / wrapper will work here
Quoted Message :  2023_05_09_3EB0ABF6A5F58E83578FDD.jpeg

Message : ‚Äé<attached: 00003062-PHOTO-2023-05-09-13-54-30.jpg>

Message : thanks, I'd forgotten about this. OpenAI is so miserably bad a devx

Message : they should have like monthly views etc.

Message : My bad, I assumed you were talking about service hosted within a company and you are trying to manage all those.
Quoted Message :  2023_05_09_3EB07B2FF96986CC2E40F9.jpeg

Message : The standard MS response is to use OpenAI through Azure
Quoted Message : thanks, I'd forgotten about this. OpenAI is so miserably bad a devx

Message : https://github.com/eugeneyan/open-llms

Message : Has anyone faced the following issue while using gpt-4 model?: https://github.com/openai/openai-cookbook/issues/405

Message : It rarely works at scale. Keeps failing after $100/day
Quoted Message :  2023_05_09_3A824C3212E4C15F61F7.jpeg

Message : Try this I suppose

Message : Are you using Azure? I‚Äôve faced this same issue using Azure APIs
Quoted Message : Has anyone faced the following issue while using gpt-4 model?: https://github.com/openai/openai-cookbook/issues/405

Message : No, im calling the APIs directly from my local machine
Quoted Message : Are you using Azure? I‚Äôve faced this same issue using Azure APIs

Message : how did you fix it?
Quoted Message : Are you using Azure? I‚Äôve faced this same issue using Azure APIs

Message : https://github.com/openai/tiktoken/blob/main/tiktoken/model.py

Check this file for the model names being implemented
Quoted Message : how did you fix it?

Message : This does a match with the model name while calling the APIs 

If the model name doesn‚Äôt match then this error is shown

Message : I‚Äôm doing per documentation for calling gpt-4
Quoted Message : https://github.com/openai/tiktoken/blob/main/tiktoken/model.py\n\nCheck this file for the model names being implemented

Message : Power users of Langchain, do you end up using custom prompts or default ones in tools / zero shot etc?

Message : I solved it by keeping deployment id of Azure same as model name 

There‚Äôs an added headache in Azure that you have to set deployment id of model
Quoted Message : how did you fix it?

Message : interesting

Message : Custom. Mostly experiment with  the prompt using the chat interface in playground and then use that prompt. Ofcourse not scalable if you need to check with vector embeddings etc. In that case tune the prompt on a small dataset and benchmark on a larger set
Quoted Message : Power users of Langchain, do you end up using custom prompts or default ones in tools / zero shot etc?

Message : documentation suggests doing something like ```encoding = tiktoken.encoding_for_model(‚Äúgpt-4‚Äù)``` , which is exactly what Im doing, but it‚Äôs throwing ```KeyError: ‚ÄòCould not automatically map gpt-3 to a tokenizer. Please use ‚Äò tiktok.get_encoding‚Äô to explicitly get the tokeniser you expect.‚Äô```

Message : From the screenshot of the bug you‚Äôve raised it‚Äôs the model.py file which is throwing the exception 

Try to match the model names in the file exactly if possible
Quoted Message : I‚Äôm doing per documentation for calling gpt-4

Message : Any idea which encodinf gpt-4 uses?

Message : gpt-4": "cl100k_base",

Message : nice, thanks üëçüèº
Quoted Message : gpt-4\": \"cl100k_base\",

Message : Changing it to tiktoken.get_encoding(‚Äúcl100k_base‚Äù) fixed the error
Quoted Message : From the screenshot of the bug you‚Äôve raised it‚Äôs the model.py file which is throwing the exception \n\nTry to match the model names in the file exactly if possible

Message : It‚Äôs funny that the error message suggests ‚Äútry ```tiktok.get_encoding()```‚Äù instead of ```‚Äútiktoken.get_encoding()‚Äù``` 
Probably that‚Äôs how tiktoken is imported in ```application.py```
Quoted Message : From the screenshot of the bug you‚Äôve raised it‚Äôs the model.py file which is throwing the exception \n\nTry to match the model names in the file exactly if possible

Message : Entrepreneur First India will be in conversation with a stellar panel of early career founders at *Draper Startup House* this _*Friday, 12th May at 6:00 PM*_.

Register here (https://joinef.info/3nIOZIk) to hear our speakers debunk all the myths around early entrepreneurship.
‚Äã
_-Rahul Samat (Partner & Head of Entrepreneur First India)_
_- ‚ÄãRishabh Shekhar (Co-founder & COO, Pepper Content)_
_- ‚ÄãShourya Lala (Co-founder & CTO, Fello)_
_- ‚ÄãAnanya Singhal (Co-founder & COO, Rigi)_
‚Äã
Pepper Content, Fello & Rigi are fast-growing startups backed by the world‚Äôs best investors like Sequoia, Accel, Elevation Capital, Bessemer, Lightspeed, YC & more!

Message : Could be relevant to some folks here!
Quoted Message : Entrepreneur First India will be in conversation with a stellar panel of early career founders at *Draper Startup House* this _*Friday, 12th May at 6:00 PM*_.\n\nRegister here (https://joinef.info/3nIOZIk) to hear our speakers debunk all the myths around early entrepreneurship.\n‚Äã\n_-Rahul Samat (Partner & Head of Entrepreneur First India)_\n_- ‚ÄãRishabh Shekhar (Co-founder & COO, Pepper Content)_\n_- ‚ÄãShourya Lala (Co-founder & CTO, Fello)_\n_- ‚ÄãAnanya Singhal (Co-founder & COO, Rigi)_\n‚Äã\nPepper Content, Fello & Rigi are fast-growing startups backed by the world‚Äôs best investors like Sequoia, Accel, Elevation Capital, Bessemer, Lightspeed, YC & more!

Message : ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right? 
Passing ```model=‚Äúgpt-4‚Äù``` with ```ask()``` function like they‚Äôve shown in _More Examples_ section is throwing an error. You have to explicitly mention ```encoding = tiktoken.get_encoding(‚Äúcl100k_base‚Äù)``` instead of ```encoding = tiktoken.encoding_for_model(‚Äúgpt-4‚Äù)``` to make it work?
Can someone see if they can reproduce the error?

Message : edit: *is imported in ```model.py``` (not ```application.py```)
Quoted Message : It‚Äôs funny that the error message suggests ‚Äútry ```tiktok.get_encoding()```‚Äù instead of ```‚Äútiktoken.get_encoding()‚Äù``` \nProbably that‚Äôs how tiktoken is imported in ```application.py```

Message : The ```encoding``` variable is being set in ```num_tokens()``` method in _Ask_ section, incase anyone is looking into the code.
Quoted Message : ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right? \nPassing ```model=‚Äúgpt-4‚Äù``` with ```ask()``` function like they‚Äôve shown in _More Examples_ section is throwing an error. You have to explicitly mention ```encoding = tiktoken.get_encoding(‚Äúcl100k_base‚Äù)``` instead of ```encoding = tiktoken.encoding_for_model(‚Äúgpt-4‚Äù)``` to make it work?\nCan someone see if they can reproduce the error?

Message : AH OKAY, updating ```tiktoken``` to ```version 0.4.0``` solved the issue. It was just released 2 days ago
Quoted Message : ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right? \nPassing ```model=‚Äúgpt-4‚Äù``` with ```ask()``` function like they‚Äôve shown in _More Examples_ section is throwing an error. You have to explicitly mention ```encoding = tiktoken.get_encoding(‚Äúcl100k_base‚Äù)``` instead of ```encoding = tiktoken.encoding_for_model(‚Äúgpt-4‚Äù)``` to make it work?\nCan someone see if they can reproduce the error?

Message : Actually a combination - there are certain things where using things out of the box helps -purely depends on the use-case. 
As mentioned my Aashay Sachdeva - when leveraging the vector embedding things might get difficult to integrate if you are using custom prompts - doable but slightly difficult.
Since langchain has grown so much in such a short time it is difficult to comprehend what capabilities can be used to achieve what use-case. Reading their use-case documentation can help you understand the framework better.
Hope this helps.
Quoted Message : Power users of Langchain, do you end up using custom prompts or default ones in tools / zero shot etc?

Message : does anyone know of a contact/ email of someone in Warpspeed GenAI hackathon organising team?

Message : or if there is any open position in any team in case someone drops out


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : It‚Äôs funny that the error message suggests ‚Äútry ```tiktok.get_encoding()```‚Äù instead of ```‚Äútiktoken.get_encoding()‚Äù``` 
Probably that‚Äôs how tiktoken is imported in ```application.py```
Quoted Message : From the screenshot of the bug you‚Äôve raised it‚Äôs the model.py file which is throwing the exception \n\nTry to match the model names in the file exactly if possible

Message : Entrepreneur First India will be in conversation with a stellar panel of early career founders at *Draper Startup House* this _*Friday, 12th May at 6:00 PM*_.

Register here (https://joinef.info/3nIOZIk) to hear our speakers debunk all the myths around early entrepreneurship.
‚Äã
_-Rahul Samat (Partner & Head of Entrepreneur First India)_
_- ‚ÄãRishabh Shekhar (Co-founder & COO, Pepper Content)_
_- ‚ÄãShourya Lala (Co-founder & CTO, Fello)_
_- ‚ÄãAnanya Singhal (Co-founder & COO, Rigi)_
‚Äã
Pepper Content, Fello & Rigi are fast-growing startups backed by the world‚Äôs best investors like Sequoia, Accel, Elevation Capital, Bessemer, Lightspeed, YC & more!

Message : Could be relevant to some folks here!
Quoted Message : Entrepreneur First India will be in conversation with a stellar panel of early career founders at *Draper Startup House* this _*Friday, 12th May at 6:00 PM*_.\n\nRegister here (https://joinef.info/3nIOZIk) to hear our speakers debunk all the myths around early entrepreneurship.\n‚Äã\n_-Rahul Samat (Partner & Head of Entrepreneur First India)_\n_- ‚ÄãRishabh Shekhar (Co-founder & COO, Pepper Content)_\n_- ‚ÄãShourya Lala (Co-founder & CTO, Fello)_\n_- ‚ÄãAnanya Singhal (Co-founder & COO, Rigi)_\n‚Äã\nPepper Content, Fello & Rigi are fast-growing startups backed by the world‚Äôs best investors like Sequoia, Accel, Elevation Capital, Bessemer, Lightspeed, YC & more!

Message : ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right? 
Passing ```model=‚Äúgpt-4‚Äù``` with ```ask()``` function like they‚Äôve shown in _More Examples_ section is throwing an error. You have to explicitly mention ```encoding = tiktoken.get_encoding(‚Äúcl100k_base‚Äù)``` instead of ```encoding = tiktoken.encoding_for_model(‚Äúgpt-4‚Äù)``` to make it work?
Can someone see if they can reproduce the error?

Message : edit: *is imported in ```model.py``` (not ```application.py```)
Quoted Message : It‚Äôs funny that the error message suggests ‚Äútry ```tiktok.get_encoding()```‚Äù instead of ```‚Äútiktoken.get_encoding()‚Äù``` \nProbably that‚Äôs how tiktoken is imported in ```application.py```

Message : The ```encoding``` variable is being set in ```num_tokens()``` method in _Ask_ section, incase anyone is looking into the code.
Quoted Message : ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right? \nPassing ```model=‚Äúgpt-4‚Äù``` with ```ask()``` function like they‚Äôve shown in _More Examples_ section is throwing an error. You have to explicitly mention ```encoding = tiktoken.get_encoding(‚Äúcl100k_base‚Äù)``` instead of ```encoding = tiktoken.encoding_for_model(‚Äúgpt-4‚Äù)``` to make it work?\nCan someone see if they can reproduce the error?

Message : AH OKAY, updating ```tiktoken``` to ```version 0.4.0``` solved the issue. It was just released 2 days ago
Quoted Message : ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right? \nPassing ```model=‚Äúgpt-4‚Äù``` with ```ask()``` function like they‚Äôve shown in _More Examples_ section is throwing an error. You have to explicitly mention ```encoding = tiktoken.get_encoding(‚Äúcl100k_base‚Äù)``` instead of ```encoding = tiktoken.encoding_for_model(‚Äúgpt-4‚Äù)``` to make it work?\nCan someone see if they can reproduce the error?

Message : Actually a combination - there are certain things where using things out of the box helps -purely depends on the use-case. 
As mentioned my Aashay Sachdeva - when leveraging the vector embedding things might get difficult to integrate if you are using custom prompts - doable but slightly difficult.
Since langchain has grown so much in such a short time it is difficult to comprehend what capabilities can be used to achieve what use-case. Reading their use-case documentation can help you understand the framework better.
Hope this helps.
Quoted Message : Power users of Langchain, do you end up using custom prompts or default ones in tools / zero shot etc?

Message : does anyone know of a contact/ email of someone in Warpspeed GenAI hackathon organising team?

Message : or if there is any open position in any team in case someone drops out

Message : What's up
Quoted Message : does anyone know of a contact/ email of someone in Warpspeed GenAI hackathon organising team?

Message : Better to mask ids while sharing on public platforms unless they are dummy IDs. üòÖ

Message : Its a public id na, the key is emerphal anyway
Quoted Message : Better to mask ids while sharing on public platforms unless they are dummy IDs. üòÖ

Message : Hey Manjot, I have one question regarding the Warpspeed hackathon.
Have the invites for who gets to attend, been sent out already?
Quoted Message : What's up

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ~‚ÄØSabbih

Message : I can't comment about OpenAI but if I had designed their rate limiter and someone use this org id or user id for their brute force attack then it would have certainly banned that account tagging it as compromised account.
Quoted Message : Its a public id na, the key is emerphal anyway

Message : We built an internal tool when the one mentioned in this group for tracking OpenAI bills had some bugs, while charging $10 dollars per month ü•≤ and we wanted some more features. We recently made the initial version available for everyone at https://puddl.io/ . User level data is next on this tiny tool's roadmap. Check it out and let me know. ü´°
Quoted Message :  2023_05_09_3A824C3212E4C15F61F7.jpeg

Message : hey guys!
anyone working on document/custom sources based chatbots?

I am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like "hi, hello" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.

one solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.

can anyone recommend other solutions they must have tried and worked for them?

thanks

Message : The LLM can perform intent recognition and entity extraction fairly well and respond/route accordingly.
Quoted Message : hey guys!\nanyone working on document/custom sources based chatbots?\n\nI am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like \"hi, hello\" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.\n\none solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.\n\ncan anyone recommend other solutions they must have tried and worked for them?\n\nthanks

Message : A lot of them yes, but not all invites are out yet
Quoted Message : Hey Manjot, I have one question regarding the Warpspeed hackathon.\nHave the invites for who gets to attend, been sent out already?

Message : Got it, thanks for the update. ü§ûüèºin that case
Quoted Message : A lot of them yes, but not all invites are out yet

Message : Have you tried this from Llama Index 

The RouterQueryEngine seems handy for exact such use cases
https://github.com/jerryjliu/llama_index/blob/main/docs/examples/query_engine/RouterQueryEngine.ipynb
Quoted Message : hey guys!\nanyone working on document/custom sources based chatbots?\n\nI am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like \"hi, hello\" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.\n\none solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.\n\ncan anyone recommend other solutions they must have tried and worked for them?\n\nthanks

Message : Have checked this link and spoken to Ruthvik ‚Äî I don't think this counts as self promotion and hence leaving it here. Sharing the decision here before someone forwards this to me üòÖ
Quoted Message : We built an internal tool when the one mentioned in this group for tracking OpenAI bills had some bugs, while charging $10 dollars per month ü•≤ and we wanted some more features. We recently made the initial version available for everyone at https://puddl.io/ . User level data is next on this tiny tool's roadmap. Check it out and let me know. ü´°

Message : One cheap way to write a script similar to this https://community.openai.com/t/how-to-track-individual-usage/15935/6 , deploy in some hourly cron push data to Airtable/DB/Excel and create graphs (excel graphs would be easy)
Quoted Message : how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key

Message : Tried RasaGPT?
Quoted Message : hey guys!\nanyone working on document/custom sources based chatbots?\n\nI am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like \"hi, hello\" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.\n\none solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.\n\ncan anyone recommend other solutions they must have tried and worked for them?\n\nthanks

Message : I run a small service, pushing events from that API key to Simple Analytics. All successful, failed events go there with the key in metadata üòÖ
Quoted Message : how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key

Message : checking this.
currently trying guardrails
Quoted Message : Have you tried this from Llama Index \n\nThe RouterQueryEngine seems handy for exact such use cases \nhttps://github.com/jerryjliu/llama_index/blob/main/docs/examples/query_engine/RouterQueryEngine.ipynb

Message : I have also came across similar problem, one solution is to build a simple classifier and reroute prompts based on it's output.
Quoted Message : hey guys!\nanyone working on document/custom sources based chatbots?\n\nI am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like \"hi, hello\" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.\n\none solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.\n\ncan anyone recommend other solutions they must have tried and worked for them?\n\nthanks

Message : In my case I had a specific list of queries that I wanted bot to not answer using context, I kept them in a separate vector db and comparing incoming prompts with that list can also act as a classifier.

Message : not sure if a classifier will work
for eg. if someone asks "What's the weather today?"

this is still a question, but not related to the context. User can attack the chatbot if not built efficiently so I guess some level of language understand is important here
Quoted Message : I have also came across similar problem, one solution is to build a simple classifier and reroute prompts based on it's output.

Message : Yeh, solution for this depends very much of the distribution of prompts you're getting.

Message : https://jam.dev/

Very cool product

Message : cc @91903012xxxx @91986758xxxx I'm sure you've seen this since you're building in the adjacent space. Thought this might be interesting to you
Quoted Message : https://jam.dev/\n\nVery cool product

Message : who ever is building this
should check this: https://twitter.com/pbteja1998/status/1654130363567071233
Quoted Message : https://jam.dev/\n\nVery cool product

Message : anyone tried GPT4All and Atlas? Just met the founder and they're doing something very interesting. Runs on CPUs / open source / visualization on top of embeddings 
https://gpt4all.io/index.html
https://atlas.nomic.ai/

Message : Wonder if openai will tolerate the use of GPT4 In their name. Likely no.
Quoted Message : anyone tried GPT4All and Atlas? Just met the founder and they're doing something very interesting. Runs on CPUs / open source / visualization on top of embeddings \nhttps://gpt4all.io/index.html\nhttps://atlas.nomic.ai/

Message : Thread about StarCoder, seems like there‚Äôs a correlation between coding and reasoning capability in a language model? 

https://twitter.com/loubnabenallal1/status/1655932400541769728?s=46&t=iGppsOleuAsMXDWuVmzUPQ

Message : One thing that worked well for me was to play with temp and p to get the system to output on consistent output  format. Takes away some richness (with low temp) but if you give enough stakes points (think of using CoT, or other reasoning with intermediate steps etc) you can get enough richness.
Quoted Message : hey guys!\nanyone working on document/custom sources based chatbots?\n\nI am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like \"hi, hello\" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.\n\none solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.\n\ncan anyone recommend other solutions they must have tried and worked for them?\n\nthanks

Message : But again, depends on application. The above was more for a reasoning sort of application.

Message : i built this library to help work with llms it has lots of examples, supports multiple llms openai, cohere, etc. has sensible defaults for parameters etc and zero dependencies. designed to be easy and quick to use https://github.com/dosco/minds

Message : Instead of using the bert model directly to output 0 or 1, use it as a vectoriser to extract embeddings, and then follow what Nirant suggested. Inference won't be slower as the search space increases, and this will likely perform better if you have trained your bert well
Quoted Message : Currently using BERT where I trained by grouping a set of questions and the related queries and labelling them either 0 or 1 based on if the query belongs to a set of questions. Then generating the similarity score for the new queries. \nThis method becomes slow in cases where the search space increases.

Message : We use Mrkl agent with custom built tools. Works well for now. It is WIP
Quoted Message : hey guys!\nanyone working on document/custom sources based chatbots?\n\nI am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like \"hi, hello\" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.\n\none solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.\n\ncan anyone recommend other solutions they must have tried and worked for them?\n\nthanks

Message : Was reading this - https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1
Quoted Message : Thread about StarCoder, seems like there‚Äôs a correlation between coding and reasoning capability in a language model? \n\nhttps://twitter.com/loubnabenallal1/status/1655932400541769728?s=46&t=iGppsOleuAsMXDWuVmzUPQ

Message : https://twitter.com/MetaAI/status/1655989274620358656?s=20 - ImageBlind from MetaAI - model capable of binding data from six modalities at once.

Message : ‚Äé<attached: 00003134-PHOTO-2023-05-10-01-06-49.jpg>
Quoted Message : https://twitter.com/MetaAI/status/1655989274620358656?s=20 - ImageBlind from MetaAI - model capable of binding data from six modalities at once.

Message : Does a great job recognizing Chunky Pandey too. :)
Quoted Message :  2023_05_10_3EB0154E506D0CB9911E7C.jpeg

Message : Has great conceptual memory: Works for smiling woman with red hair, dog - finds a celeb with golden retriever hair üòÜ

Message : Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well

Message : Was going to index my iCloud library. Will share results on how it went.
Quoted Message : Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well

Message : Hmm. Yes. You can build your own Google Photos now. With power booster search --- better than anything Google can offer today
Quoted Message : Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Instead of using the bert model directly to output 0 or 1, use it as a vectoriser to extract embeddings, and then follow what Nirant suggested. Inference won't be slower as the search space increases, and this will likely perform better if you have trained your bert well
Quoted Message : Currently using BERT where I trained by grouping a set of questions and the related queries and labelling them either 0 or 1 based on if the query belongs to a set of questions. Then generating the similarity score for the new queries. \nThis method becomes slow in cases where the search space increases.

Message : We use Mrkl agent with custom built tools. Works well for now. It is WIP
Quoted Message : hey guys!\nanyone working on document/custom sources based chatbots?\n\nI am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like \"hi, hello\" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.\n\none solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.\n\ncan anyone recommend other solutions they must have tried and worked for them?\n\nthanks

Message : Was reading this - https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1
Quoted Message : Thread about StarCoder, seems like there‚Äôs a correlation between coding and reasoning capability in a language model? \n\nhttps://twitter.com/loubnabenallal1/status/1655932400541769728?s=46&t=iGppsOleuAsMXDWuVmzUPQ

Message : https://twitter.com/MetaAI/status/1655989274620358656?s=20 - ImageBlind from MetaAI - model capable of binding data from six modalities at once.

Message : ‚Äé<attached: 00003134-PHOTO-2023-05-10-01-06-49.jpg>
Quoted Message : https://twitter.com/MetaAI/status/1655989274620358656?s=20 - ImageBlind from MetaAI - model capable of binding data from six modalities at once.

Message : Does a great job recognizing Chunky Pandey too. :)
Quoted Message :  2023_05_10_3EB0154E506D0CB9911E7C.jpeg

Message : Has great conceptual memory: Works for smiling woman with red hair, dog - finds a celeb with golden retriever hair üòÜ

Message : Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well

Message : Was going to index my iCloud library. Will share results on how it went.
Quoted Message : Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well

Message : Hmm. Yes. You can build your own Google Photos now. With power booster search --- better than anything Google can offer today
Quoted Message : Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well

Message : https://imagebind.metademolab.com/demo

This demo is freaking insane.

Message : google photos does face recognition
Quoted Message : Hmm. Yes. You can build your own Google Photos now. With power booster search --- better than anything Google can offer today

Message : So do these embeddings in a way, NN to a person is dead easy to find. It finds Jet Li by name -- that's face recognition already :)
Quoted Message : google photos does face recognition

Message : How??
Quoted Message : So do these embeddings in a way, NN to a person is dead easy to find. It finds Jet Li by name -- that's face recognition already :)

Message : Check the Google Colab notebook I shared, that demos this
Quoted Message : How??

Message : google photos does one-shot face recognition from custom labels

Message : E.g. this notebook won't find Nirant :3

Message : If it has some concept of celeb faces, then the embeddings would have atleast some one-shot recognition capabilities

Message : If it has one photo of me, easy to do a nearest neighbor on that and expand from there
Quoted Message : E.g. this notebook won't find Nirant :3

Message : Can replace the whole foley part of film making if executed on a huge dataset
Quoted Message : https://imagebind.metademolab.com/demo\n\nThis demo is freaking insane.

Message : ‚Äé<attached: 00003150-PHOTO-2023-05-10-01-57-50.jpg>
Quoted Message : If it has one photo of me, easy to do a nearest neighbor on that and expand from there

Message : This looks more the result of shallow feature matching.
Quoted Message :  2023_05_10_3EB0393015762367823A54.jpeg

Message : https://colab.research.google.com/drive/1wFFG4TbuXUPPppymqxdgKg8XShMfoGJZ?usp=sharing

Message : Jawahar sir's former Student is the first author
Quoted Message : https://imagebind.metademolab.com/demo\n\nThis demo is freaking insane.

Message : Is that an ad in the bottom? Even that ad has Nirant üòµ‚Äçüí´
Quoted Message :  2023_05_10_3EB0393015762367823A54.jpeg

Message : Anyone worked on OCR? Need some quick pointers

Message : try face recognition + aligned cropping (use keypoints to align faces)
Quoted Message :  2023_05_10_3EB0393015762367823A54.jpeg

Message : It is also very likely that the performance would vary a lot for different race, gender, age, etc. 
FWIW this model was anyway not designed specifically for face identification/matching

Message : I've been wanting a tool which can recommend soundtrack for shorts/reels. Looks like this might almost be there.
Quoted Message : https://imagebind.metademolab.com/demo\n\nThis demo is freaking insane.

Message : yeah that ad probably needs a crop :D
Quoted Message : Is that an ad in the bottom? Even that ad has Nirant üòµ‚Äçüí´

Message : you mean detection + alignment? https://github.com/1adrianb/face-alignment
Quoted Message : try face recognition + aligned cropping (use keypoints to align faces)

Message : Yeah
Quoted Message : you mean detection + alignment? https://github.com/1adrianb/face-alignment

Message : I had a similar project with @91889057xxxx way back to play soundtracks based on mood. this could do it from facial expressions / heartbeat sounds / tone of my voice etc. üòµ
Quoted Message : I've been wanting a tool which can recommend soundtrack for shorts/reels. Looks like this might almost be there.

Message : 5 landmark points are usually enough though, you can check - https://github.com/ZhaoJ9014/face.evoLVe
Quoted Message : you mean detection + alignment? https://github.com/1adrianb/face-alignment

Message : First and last both IIITH folks :)
Quoted Message : Jawahar sir's former Student is the first author

Message : Yes
Quoted Message : Anyone worked on OCR? Need some quick pointers

Message : ‚Äé<attached: 00003166-PHOTO-2023-05-10-02-56-01.jpg>
Quoted Message : Yeah

Message : thanks, pinging you in DM
Quoted Message : Yes

Message : But this is a great way to find doppelgangers
Quoted Message :  2023_05_10_3EB064F7FA9030713DD7D6.jpeg

Message : https://openai.com/research/language-models-can-explain-neurons-in-language-models

Message : https://twitter.com/assemblyai/status/1656005887343960079?s=46 - LeMUR - AssemblyAI- LLM‚Äôs on audio files - now you can perform QA on your audio files directly.

Message : As i understand, it will transcript the audio files into text, chunk and index it in vector db, then allow QnA on those transcripts, right?

It's similar to QnA on large documents or is there anything different?
Quoted Message : https://twitter.com/assemblyai/status/1656005887343960079?s=46 - LeMUR - AssemblyAI- LLM‚Äôs on audio files - now you can perform QA on your audio files directly.

Message : What‚Äôs the dataset of images? One of them is my friend.
Quoted Message :  2023_05_10_3EB064F7FA9030713DD7D6.jpeg

Message : I don‚Äôt think he‚Äôs in this group
Quoted Message : What‚Äôs the dataset of images? One of them is my friend.

Message : ‚Äé<attached: 00003174-PHOTO-2023-05-10-08-02-50.jpg>
Quoted Message : As i understand, it will transcript the audio files into text, chunk and index it in vector db, then allow QnA on those transcripts, right?\n\nIt's similar to QnA on large documents or is there anything different?

Message : Ugh I thought it was something new on modelling side
Quoted Message :  2023_05_10_3EB022F411E594C831BCD2.jpeg

Message : Same, clever marketing, repackage and give it an acronym üòÇ
Quoted Message : Ugh I thought it was something new on modelling side

Message : This is retrieving the audio from a database?
Quoted Message : https://imagebind.metademolab.com/demo\n\nThis demo is freaking insane.

Message : The database has 3 files in the demo, but yes, that is the intent.
Quoted Message : This is retrieving the audio from a database?

Message : Would perhaps be better to ask an outline of your questions? 

E.g. I am curious about fine-tuned OCR for handwriting for Math or Musical Notations
Quoted Message : Anyone worked on OCR? Need some quick pointers


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://twitter.com/assemblyai/status/1656005887343960079?s=46 - LeMUR - AssemblyAI- LLM‚Äôs on audio files - now you can perform QA on your audio files directly.

Message : As i understand, it will transcript the audio files into text, chunk and index it in vector db, then allow QnA on those transcripts, right?

It's similar to QnA on large documents or is there anything different?
Quoted Message : https://twitter.com/assemblyai/status/1656005887343960079?s=46 - LeMUR - AssemblyAI- LLM‚Äôs on audio files - now you can perform QA on your audio files directly.

Message : What‚Äôs the dataset of images? One of them is my friend.
Quoted Message :  2023_05_10_3EB064F7FA9030713DD7D6.jpeg

Message : I don‚Äôt think he‚Äôs in this group
Quoted Message : What‚Äôs the dataset of images? One of them is my friend.

Message : ‚Äé<attached: 00003174-PHOTO-2023-05-10-08-02-50.jpg>
Quoted Message : As i understand, it will transcript the audio files into text, chunk and index it in vector db, then allow QnA on those transcripts, right?\n\nIt's similar to QnA on large documents or is there anything different?

Message : Ugh I thought it was something new on modelling side
Quoted Message :  2023_05_10_3EB022F411E594C831BCD2.jpeg

Message : Same, clever marketing, repackage and give it an acronym üòÇ
Quoted Message : Ugh I thought it was something new on modelling side

Message : This is retrieving the audio from a database?
Quoted Message : https://imagebind.metademolab.com/demo\n\nThis demo is freaking insane.

Message : The database has 3 files in the demo, but yes, that is the intent.
Quoted Message : This is retrieving the audio from a database?

Message : Would perhaps be better to ask an outline of your questions? 

E.g. I am curious about fine-tuned OCR for handwriting for Math or Musical Notations
Quoted Message : Anyone worked on OCR? Need some quick pointers

Message : Hello! 

Shubhi Saxena @91903012xxxx (Coval.ai, Yellow.ai) has lined up an impressive speaker line up for the Women in AI meetup.

She's looking for a volunteer emcee for the event ‚Äî can be anyone in tech e.g. folks from Product, Engineering, Marketing, everyone is welcome!

If you'd like to volunteer, or want to recommend a friend, please ping her!

Message : All,
Need some help....
For the past few days I have been trying to replicate the performance of a multimodal LLM using a much smaller LLM purely by crafting a high quality dataset. With Vicuna7B the results are pretty amazing but I would like to get similar quality from OPT2.7B which is still a very powerful LLM but tends to hallucinate way more. My gut feel is that I should try stacking a bunch of LoRA adapters, each trained on a small high quality dataset to achieve this goal. Has anyone had success with such stacking. Does this FUSE method work? (https://docs.adapterhub.ml/adapter_composition.html#fuse)
If anyone wants to collaborate, please ping me - I have a few A100s to spare.

Message : https://twitter.com/generatorman_ai/status/1655941986627772419

Message : https://twitter.com/OpenMMLab/status/1656127026687000578?t=bwtsiMeA6SNW2hWGHIo8Ww&s=19

Message : doston, link dump na karo, ek line likh do what that link is about üòÖ

Message : Lots of claims in this post - what do you guys think?
Quoted Message : https://twitter.com/generatorman_ai/status/1655941986627772419

Message : 65B model, calling a prompt a "constitution", worse performance than Vicuna ‚Äî marketing team at IBM should be rewarded for doing such technical work
Quoted Message : Lots of claims in this post - what do you guys think?

Message : More underwhelming than Watson actually üòÖ
Quoted Message : 65B model, calling a prompt a \"constitution\", worse performance than Vicuna ‚Äî marketing team at IBM should be rewarded for doing such technical work

Message : But what about the practicality of the approach? Seems promising, much better than distilling, which increases hallucinations
Quoted Message : 65B model, calling a prompt a \"constitution\", worse performance than Vicuna ‚Äî marketing team at IBM should be rewarded for doing such technical work

Message : https://twitter.com/_akhaliq/status/1656144222204903426?s=46&t=icC0fizZK8E3ONsDVuGFWA


Can someone help me understand this ?

This paper sclaims that their proposed Generative Retrieval is better than embedding and ANN based approach

But the way they have proposed is to generate ‚ÄúSemantic IDs‚Äù of items based on text description

How is it different than embedding the description and mapping it to 1 item ?

Message : For ex.as per the paper‚Äôs method 
Semantic ID for ‚ÄúAn orange leather shoe ‚Äú will be sequence of tokens representing orange,leather and shoe

Message : This is  similar to jerry liu‚Äôs new blogpost? @91955016xxxx
Quoted Message : https://twitter.com/_akhaliq/status/1656144222204903426?s=46&t=icC0fizZK8E3ONsDVuGFWA\n\n\nCan someone help me understand this ?\n\nThis paper sclaims that their proposed Generative Retrieval is better than embedding and ANN based approach \n\nBut the way they have proposed is to generate ‚ÄúSemantic IDs‚Äù of items based on text description \n\nHow is it different than embedding the description and mapping it to 1 item ?

Message : Is that one using LLM for retrieval ?
Quoted Message : This is  similar to jerry liu‚Äôs new blogpost? @9195xxxxxxxx

Message : From what I‚Äôve understood of Jerry‚Äôs post That was more like passing entire doc/doc summary to choose documents using LLM

This paper seems to propose a different approach
Quoted Message : Is that one using LLM for retrieval ?

Message : Reminds me of triplet generation from the bygones era. 

Zooming out:

1. Dataset/Domain: This paper tests an approach on a single eCommerce use case heavy dataset. Such domains are usually quite noun and descriptors heavy (large sofa, blue Anarkali dress, and so on) ‚Äî this does not translate well to most other domains.
Quoted Message : https://twitter.com/_akhaliq/status/1656144222204903426?s=46&t=icC0fizZK8E3ONsDVuGFWA\n\n\nCan someone help me understand this ?\n\nThis paper sclaims that their proposed Generative Retrieval is better than embedding and ANN based approach \n\nBut the way they have proposed is to generate ‚ÄúSemantic IDs‚Äù of items based on text description \n\nHow is it different than embedding the description and mapping it to 1 item ?

Message : Type karne do bhai log ü§£

Message : ‚Äé<attached: 00003197-PHOTO-2023-05-10-11-40-14.jpg>

Message : ‚Äé<attached: 00003198-PHOTO-2023-05-10-11-42-39.jpg>

Message : Analogy:

They've mapped every SKU to a code in the same way devs map errors: We know that 4xx is different from 5xx and 429 or 404 means.

If I tell a model that a service is seeing a lot of 429 errors, what error will you expect a few minutes or hours later? Perhaps a 404 or 5xx based on what we know from how services scale?

Message : That's a terribly written on-the-fly blog on a paper which I read 20 minutes ago for the first time, but can answer more questions on DM üòÖ

Message : Still a good overall explanation üôåüèªüôåüèª thanks @91773788xxxx
Quoted Message : That's a terribly written on-the-fly blog on a paper which I read 20 minutes ago for the first time, but can answer more questions on DM üòÖ

Message : ‚Äé<attached: 00003203-PHOTO-2023-05-10-12-40-23.jpg>
Quoted Message : All,\nNeed some help....\nFor the past few days I have been trying to replicate the performance of a multimodal LLM using a much smaller LLM purely by crafting a high quality dataset. With Vicuna7B the results are pretty amazing but I would like to get similar quality from OPT2.7B which is still a very powerful LLM but tends to hallucinate way more. My gut feel is that I should try stacking a bunch of LoRA adapters, each trained on a small high quality dataset to achieve this goal. Has anyone had success with such stacking. Does this FUSE method work? (https://docs.adapterhub.ml/adapter_composition.html#fuse)\nIf anyone wants to collaborate, please ping me - I have a few A100s to spare.

Message : Yes, in fact that Y-axes is likely to be logarithmic, not linear
Quoted Message :  2023_05_10_8057DD561D3D09C94834CFBCD8AE1B11.jpeg

Message : emergent capabilities in ImageBind:

"Our model has new emergent capabilities, or scaling behavior ‚Äî that is, abilities that didn‚Äôt exist in smaller models but appear in larger versions. This might include recognizing which audio fits with a certain image or predicting the depth of a scene from a photo....

We discovered that ImageBind features can be used for few-shot audio and depth classification tasks and can outperform prior methods tailored for those modalities. For example, ImageBind significantly outperforms Meta‚Äôs self-supervised AudioMAE model trained on Audioset and a supervised AudioMAE model fine-tuned on audio classification, with gains of approximately 40 percent accuracy in top-1 accuracy on ‚â§four-shot classification.

ImageBind also achieved new SOTA performance on emergent zero-shot recognition tasks across modalities, even outperforming recent models that were trained to recognize concepts for that modality."

https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/

Message : If someone wants to try ImageBind: colab.research.google.com/drive/1_erdut6xnikv5f1qnbutoik4us-w3pxm?authuser=0#scrollto=zjl-nv30rngb

Can also scroll up and see @91876402xxxx proving that ImageBind doesn't know "Nirant's face" well. Excellent hacker demos!
Quoted Message : emergent capabilities in ImageBind:\n\n\"Our model has new emergent capabilities, or scaling behavior ‚Äî that is, abilities that didn‚Äôt exist in smaller models but appear in larger versions. This might include recognizing which audio fits with a certain image or predicting the depth of a scene from a photo....\n\nWe discovered that ImageBind features can be used for few-shot audio and depth classification tasks and can outperform prior methods tailored for those modalities. For example, ImageBind significantly outperforms Meta‚Äôs self-supervised AudioMAE model trained on Audioset and a supervised AudioMAE model fine-tuned on audio classification, with gains of approximately 40 percent accuracy in top-1 accuracy on ‚â§four-shot classification.\n\nImageBind also achieved new SOTA performance on emergent zero-shot recognition tasks across modalities, even outperforming recent models that were trained to recognize concepts for that modality.\"\n\nhttps://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/

Message : PSA for Technical Folks: Fifthelephant ‚Äî India's best ML Conference has the Call for Talks open: 
https://hasgeek.com/fifthelephant/2023/sub

If you're someone who has done great work but don't know how to slot it or submit a proposal, please DM me ‚Äî happy to assist in fleshing out the idea

Message : https://colab.research.google.com/drive/1wFFG4TbuXUPPppymqxdgKg8XShMfoGJZ?usp=sharing

The proof
Quoted Message : If someone wants to try ImageBind: colab.research.google.com/drive/1_erdut6xnikv5f1qnbutoik4us-w3pxm?authuser=0#scrollto=zjl-nv30rngb\n\nCan also scroll up and see @9187xxxxxxxx proving that ImageBind doesn't know \"Nirant's face\" well. Excellent hacker demos!

Message : üöÄAnnouncing the May Generative AI Meetup with more focus on Visuals - Images, Videos, Games  üéÆüé®üìΩÔ∏è

Structure being 2 talks opening up more time for discussions as compared to 3 last time.
Secure Your Spot Now - https://hasgeek.com/generativeAI/may-meetup/
Seats are limited as always.

1 talk is already finalised and 1 slot for a technical deep dive like the one on Quantisation is still open. DM me for interest, sharing ideas  or volunteering to speak.

Message : Potential game changer 

https://arxiv.org/abs/2305.01625?utm_source=tldrai

Message : Just an FYI it is CC BY-NC not truly open source.

In case one plans to use it commercially. I hope soon we will get a pure open-source version.
Quoted Message : emergent capabilities in ImageBind:\n\n\"Our model has new emergent capabilities, or scaling behavior ‚Äî that is, abilities that didn‚Äôt exist in smaller models but appear in larger versions. This might include recognizing which audio fits with a certain image or predicting the depth of a scene from a photo....\n\nWe discovered that ImageBind features can be used for few-shot audio and depth classification tasks and can outperform prior methods tailored for those modalities. For example, ImageBind significantly outperforms Meta‚Äôs self-supervised AudioMAE model trained on Audioset and a supervised AudioMAE model fine-tuned on audio classification, with gains of approximately 40 percent accuracy in top-1 accuracy on ‚â§four-shot classification.\n\nImageBind also achieved new SOTA performance on emergent zero-shot recognition tasks across modalities, even outperforming recent models that were trained to recognize concepts for that modality.\"\n\nhttps://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/

Message : Dude the third photo is of a friends üòÖ
Quoted Message :  2023_05_10_3EB064F7FA9030713DD7D6.jpeg

Message : 2nd photo looks freakishly like my IITD electronics prof. üôà Really hoping it‚Äôs not him
Quoted Message : Dude the third photo is of a friends üòÖ

Message : Fun use of diffusion - https://youtu.be/KrjL_TSOFrI

Message : Glad to learn that even my face isn't unique friends

Message : https://www.zdziarski.com/blog/?p=12001

Interesting and well written, if cynical, take on FMs by a famous iOS security expert. üôÇ

Message : What he wrote makes quite a lot of sense, and OpenAI's yesterday's research on understanding _which neurons_ is probably an answer in that direction
Quoted Message : https://www.zdziarski.com/blog/?p=12001\n\nInteresting and well written, if cynical, take on FMs by a famous iOS security expert. üôÇ

Message : Which are some of the good Robotics, AI/ML newsletters I can follow?

Message : This message was answered just couple of days back. I'll copy paste:
These are the one's ive found quite useful:
- [https://www.bensbites.co/](https://www.bensbites.co/)
- [https://www.semafor.com/newsletters]
- [https://www.lennysnewsletter.com]
- [https://whatshot.substack.com/p/whats-in-enterprise-itvc-335?utm_source=substack&utm_medium=email]
- [https://therundown.ai/subscribe](https://t.co/Gm5KwesnA7)
- [https://tldr.tech/ai?utm_source=tldr](https://tldr.tech/ai?utm_source=tldr)

Message : Thankyou!
Quoted Message : This message was answered just couple of days back. I'll copy paste:\nThese are the one's ive found quite useful:\n- [https://www.bensbites.co/](https://www.bensbites.co/)\n- [https://www.semafor.com/newsletters]\n- [https://www.lennysnewsletter.com]\n- [https://whatshot.substack.com/p/whats-in-enterprise-itvc-335?utm_source=substack&utm_medium=email]\n- [https://therundown.ai/subscribe](https://t.co/Gm5KwesnA7)\n- [https://tldr.tech/ai?utm_source=tldr](https://tldr.tech/ai?utm_source=tldr)

Message : I have generated embedding vectors using np.array, and the file size is roughly 230mb (saved as a csv).
Im deploying an app on azure which uses this; any idea best place to store the embeddings?
I‚Äôve tried gdrive, azure blob storage and even gh-lfs(this changes the encodings of the file which openai api cant read it seems, so ive ruled this out), but everything is considerably slow


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Dude the third photo is of a friends üòÖ
Quoted Message :  2023_05_10_3EB064F7FA9030713DD7D6.jpeg

Message : 2nd photo looks freakishly like my IITD electronics prof. üôà Really hoping it‚Äôs not him
Quoted Message : Dude the third photo is of a friends üòÖ

Message : Fun use of diffusion - https://youtu.be/KrjL_TSOFrI

Message : Glad to learn that even my face isn't unique friends

Message : https://www.zdziarski.com/blog/?p=12001

Interesting and well written, if cynical, take on FMs by a famous iOS security expert. üôÇ

Message : What he wrote makes quite a lot of sense, and OpenAI's yesterday's research on understanding _which neurons_ is probably an answer in that direction
Quoted Message : https://www.zdziarski.com/blog/?p=12001\n\nInteresting and well written, if cynical, take on FMs by a famous iOS security expert. üôÇ

Message : Which are some of the good Robotics, AI/ML newsletters I can follow?

Message : This message was answered just couple of days back. I'll copy paste:
These are the one's ive found quite useful:
- [https://www.bensbites.co/](https://www.bensbites.co/)
- [https://www.semafor.com/newsletters]
- [https://www.lennysnewsletter.com]
- [https://whatshot.substack.com/p/whats-in-enterprise-itvc-335?utm_source=substack&utm_medium=email]
- [https://therundown.ai/subscribe](https://t.co/Gm5KwesnA7)
- [https://tldr.tech/ai?utm_source=tldr](https://tldr.tech/ai?utm_source=tldr)

Message : Thankyou!
Quoted Message : This message was answered just couple of days back. I'll copy paste:\nThese are the one's ive found quite useful:\n- [https://www.bensbites.co/](https://www.bensbites.co/)\n- [https://www.semafor.com/newsletters]\n- [https://www.lennysnewsletter.com]\n- [https://whatshot.substack.com/p/whats-in-enterprise-itvc-335?utm_source=substack&utm_medium=email]\n- [https://therundown.ai/subscribe](https://t.co/Gm5KwesnA7)\n- [https://tldr.tech/ai?utm_source=tldr](https://tldr.tech/ai?utm_source=tldr)

Message : I have generated embedding vectors using np.array, and the file size is roughly 230mb (saved as a csv).
Im deploying an app on azure which uses this; any idea best place to store the embeddings?
I‚Äôve tried gdrive, azure blob storage and even gh-lfs(this changes the encodings of the file which openai api cant read it seems, so ive ruled this out), but everything is considerably slow

Message : npy files?

Message : saved as csv

Message : yes, npy files are much faster
Quoted Message : saved as csv

Message : https://runwayml.com/hosted-models/

TIL runwayml  has a serverless gpu offering?!

Message : https://mmappickle.readthedocs.io/en/latest/

Message : Nothing is going to be faster than mmap. I think pickle supports storing objects as mmaps too.
Quoted Message : I have generated embedding vectors using np.array, and the file size is roughly 230mb (saved as a csv).\nIm deploying an app on azure which uses this; any idea best place to store the embeddings? \nI‚Äôve tried gdrive, azure blob storage and even gh-lfs(this changes the encodings of the file which openai api cant read it seems, so ive ruled this out), but everything is considerably slow

Message : This is likely just what you need
Quoted Message : https://mmappickle.readthedocs.io/en/latest/

Message : And you're storing the object itself. Very very unlikely to lose any accuracy.

Message : If mmap doesn't work for you, then just use pickle (slower, but faster than anything else).

Message : This is lovely
Quoted Message : https://mmappickle.readthedocs.io/en/latest/

Message : But you could still lose accuracy/encounter changed embeddings even if you pickle an object. Ensure you recreate your environment exactly with venv or poetry.
Quoted Message : And you're storing the object itself. Very very unlikely to lose any accuracy.

Message : Do you have to use locks to handle concurrent writes though btw?

Message : Pickling is lossy? TIL
Quoted Message : But you could still lose accuracy/encounter changed embeddings even if you pickle an object. Ensure you recreate your environment exactly with venv or poetry.

Message : yeah i think it's been there for a long time. i remember seeing something like this back when Runway had a few GAN models only (for generating shoes, cars etc )
Quoted Message : https://runwayml.com/hosted-models/\n\nTIL runwayml  has a serverless gpu offering?!

Message : Yes, depends on versions in your env. You can get by for a while, usually, but there are no guarantees in the long run.
Quoted Message : Pickling is lossy? TIL

Message : Okay. I used to think its comprehensive Ser/Deser
Quoted Message : Yes, depends on versions in your env. You can get by for a while, usually, but there are no guarantees in the long run.

Message : Depends on how you plan to write. If you're code guarantees it, you don't need locks, otherwise you do.
Quoted Message : Do you have to use locks to handle concurrent writes though btw?

Message : Far from it. Pickling itself might break with version changes, forget about guaranteeing losslessness
Quoted Message : Okay. I used to think its comprehensive Ser/Deser

Message : ‚Äé<attached: 00003244-PHOTO-2023-05-10-21-57-19.jpg>
Quoted Message : Far from it. Pickling itself might break with version changes, forget about guaranteeing losslessness

Message : That's correct if you're only storing native python objects. He's interested in storing numpy arrays. Which may still be fine. As I said, you can get by for a while, but no guarantees in the long run.

Message : The ling-run doing the heavy lifting üòÇ

Message : *long-run

Message : Thanks, ill look into this
Quoted Message : This is likely just what you need

Message : Hi All, I'm looking to generate images for words that can illustrate meaning of the word . To be used by school children. Tried by various prompts to illustrate using stable diffusion. Example : illustrate the word 'abhor'. 
Provided different ways of conveying the meaning in sentences. Failed to create good illustrations for words in a scalable manner.
Looking for help in the same. Also if there is anyone working in similar space to get inputs. Thanks.

Message : https://www.assemblyai.com/blog/lemur-early-access/

Message : We've already roasted this enough today. Please resist the temptation - note for myself
Quoted Message : https://www.assemblyai.com/blog/lemur-early-access/

Message : You are a day late ü§£
Quoted Message : https://www.assemblyai.com/blog/lemur-early-access/

Message : üôàüôà missed today‚Äôs chatter

Message : ugh, in that case why not just us numpy native mmap that guarantees backwards compat?

https://numpy.org/devdocs/reference/generated/numpy.lib.format.open_memmap.html
Quoted Message : That's correct if you're only storing native python objects. He's interested in storing numpy arrays. Which may still be fine. As I said, you can get by for a while, but no guarantees in the long run.

Message : I say this because I have a huge openai bill, 300$ of which is just embeddings, because I had to recompute them a bunch of times due to backwards incompat

Message : On a related note, @91999047xxxx has built out an OpenAI embeddings API cost calculator: https://llmtown.com/e/openai-cost-calculator. Thought this might be interesting to folks here
Quoted Message : I say this because I have a huge openai bill, 300$ of which is just embeddings, because I had to recompute them a bunch of times due to backwards incompat

Message : Not sure where it mentions backward compatibility. It probably does it now. For small usecases it is perfectly fine.
Quoted Message : ugh, in that case why not just us numpy native mmap that guarantees backwards compat?\n\nhttps://numpy.org/devdocs/reference/generated/numpy.lib.format.open_memmap.html

Message : I don't like that flush() operation though. I have to call it every single time I update something in the array!

Message : ‚Äé<attached: 00003259-PHOTO-2023-05-10-22-55-01.jpg>

Message : Primary reason why I don't use npy

Message : Awesome üëçüèª
Quoted Message :  2023_05_10_3EB0D6AAE7051CF394BE49.jpeg

Message : As I said, this is perfectly fine for small usecases.

Message : What were you using to store the embeddings?
Quoted Message : I say this because I have a huge openai bill, 300$ of which is just embeddings, because I had to recompute them a bunch of times due to backwards incompat

Message : pickle, but my backwards compat issue was more of a data format upgrade not a file format upgrade

Message : Ah ok, so you were storing them in a class you created or provided by a package or something?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : On a related note, @91999047xxxx has built out an OpenAI embeddings API cost calculator: https://llmtown.com/e/openai-cost-calculator. Thought this might be interesting to folks here
Quoted Message : I say this because I have a huge openai bill, 300$ of which is just embeddings, because I had to recompute them a bunch of times due to backwards incompat

Message : Not sure where it mentions backward compatibility. It probably does it now. For small usecases it is perfectly fine.
Quoted Message : ugh, in that case why not just us numpy native mmap that guarantees backwards compat?\n\nhttps://numpy.org/devdocs/reference/generated/numpy.lib.format.open_memmap.html

Message : I don't like that flush() operation though. I have to call it every single time I update something in the array!

Message : ‚Äé<attached: 00003259-PHOTO-2023-05-10-22-55-01.jpg>

Message : Primary reason why I don't use npy

Message : Awesome üëçüèª
Quoted Message :  2023_05_10_3EB0D6AAE7051CF394BE49.jpeg

Message : As I said, this is perfectly fine for small usecases.

Message : What were you using to store the embeddings?
Quoted Message : I say this because I have a huge openai bill, 300$ of which is just embeddings, because I had to recompute them a bunch of times due to backwards incompat

Message : pickle, but my backwards compat issue was more of a data format upgrade not a file format upgrade

Message : Ah ok, so you were storing them in a class you created or provided by a package or something?

Message : As in, curious about why the embeddings were not recoverable from the pickle.

Message : changed the preprocessing a bunch of times, chunking strategies, X -> text conversion, added cleaning steps to transcripts, changed transcription engines, etc.

Message : Oh acha, there's no fighting against this. Went with Weaviate modules from the start to avoid this cost.

Message : text2vec-bert?

Message : With the I/O event, I think Bard is now almost generally available. I applied through the waitlist and got access within minutes.

Message : They haven't released it for workspace yet

Message : Which is surprising

Message : Can you point me to where you saw that it is using lossy. This is news to me.
Quoted Message : But you could still lose accuracy/encounter changed embeddings even if you pickle an object. Ensure you recreate your environment exactly with venv or poetry.

Message : I would have thought it would begin there

Message : Models from sbert.io (sentencebert, they come with Weaviate modules by default)
Quoted Message : text2vec-bert?

Message : This happened with version upgrade mismatches of tf 1.x (pre tf2 era).
Quoted Message : Can you point me to where you saw that it is using lossy. This is news to me.

Message : We started with saving embeddings in a db, which was obviously bad. Then pickling sometimes led to this. Eventually we put some tests in place. I think GPU arch mismatch also had a role to play, but I may be misremembering that. We just matched everything and put tests in place.

Message : Microsoft Researcher used GPT4 to solve a simple maze game. Quite clever hints for you to think about how to evoke world building with text based models. 

cc @91966317xxxx might be interesting to you?
https://ekzhu.medium.com/gpt-4s-maze-navigation-a-deep-dive-into-react-agent-and-llm-s-thoughts-b1823fb266ee

Message : Fun fact. I‚Äòve tried to run similar experiments with chess. And had some mind = blown moments initially.
Quoted Message : Microsoft Researcher used GPT4 to solve a simple maze game. Quite clever hints for you to think about how to evoke world building with text based models. \n\ncc @9196xxxxxxxx might be interesting to you? \nhttps://ekzhu.medium.com/gpt-4s-maze-navigation-a-deep-dive-into-react-agent-and-llm-s-thoughts-b1823fb266ee

Message : But it turned out that as games went on it started suggesting random/illegal moves.

Message : And all the aha moments came from games that were probably in its training data.

Message : ‚Äé<attached: 00003282-PHOTO-2023-05-11-00-23-30.jpg>

Message : Really wanted to try giving it access to a chess engine so it could evaluate moves, before making them. That‚Äôll be the equivalent of giving it access to the code interpreter like the Microsoft researcher talks about in this blog.

Message : It‚Äôs on my weekend side projects list for now. Sigh‚Ä¶ so much to do. Such little time‚Ä¶

Message : Render.com added pgvector to their PostgreSQL databases. 

https://twitter.com/marckohlbrugge/status/1656294501483413504?t=ZeWpPLYJ4bDE19sfYXZmZg&s=19

Message : https://twitter.com/scottbelsky/status/1656365796761694218?t=c9Gvl0xFQKA3Vn4nPnEtbA&s=08

Message : its sneaky / I got an email asking for a commitment of $2500/month for 6 months to be part of it. LOL
Quoted Message :  2023_05_08_3EB0D48520BE62ED273185.jpeg

Message : Ohh damn. That's _not startups_, that's just a VC funded Series B co
Quoted Message : its sneaky / I got an email asking for a commitment of $2500/month for 6 months to be part of it. LOL

Message : yeah / I get that they are good but this is very bad / if you had this commitment then be upfront before you ask companies to fill a long form to apply

Message : If you pay upfront annual
Quoted Message :  2023_05_08_3EB0D48520BE62ED273185.jpeg

Message : Ah others already pointed that
Quoted Message : If you pay upfront annual

Message : It‚Äôs unclear what does small and big mean. I think the disparity is small. I haven‚Äôt found any research on scaling laws of fine-tuning but know from experiments that for a narrow task the gap between small and big is not much. Palm 2 small beats Palm 540B. So it‚Äôs not a pure function of size. 

From Palm 2 paper it seems chasing just language modelling loss is not correct

‚ÄúHowever, the training loss is not a perfect proxy for downstream metrics. For example, the 8.95B model, which shows the lowest loss (Table 1) and is closest to the optimal model, slightly underperforms the 14.7B model on downstream tasks. This suggests that while scaling laws can be used to achieve optimal training loss for a given quantity of FLOPs, this does not necessarily transfer to achieving optimal performance for a given task.‚Äù
Quoted Message :  2023_05_10_8057DD561D3D09C94834CFBCD8AE1B11.jpeg

Message : one point to consider is task accuracy is evaluated using discontinuous non-linear metrics like exact match
Quoted Message : It‚Äôs unclear what does small and big mean. I think the disparity is small. I haven‚Äôt found any research on scaling laws of fine-tuning but know from experiments that for a narrow task the gap between small and big is not much. Palm 2 small beats Palm 540B. So it‚Äôs not a pure function of size. \n\nFrom Palm 2 paper it seems chasing just language modelling loss is not correct \n\n‚ÄúHowever, the training loss is not a perfect proxy for downstream metrics. For example, the 8.95B model, which shows the lowest loss (Table 1) and is closest to the optimal model, slightly underperforms the 14.7B model on downstream tasks. This suggests that while scaling laws can be used to achieve optimal training loss for a given quantity of FLOPs, this does not necessarily transfer to achieving optimal performance for a given task.‚Äù

Message : About PaLM2, I'm impressed by the reasoning ability of it as it has shown better performance with reasoning tasks than GPT-4

Message : ‚Äé<attached: 00003296-PHOTO-2023-05-11-09-53-57.jpg>

Message : this is total waste. üòÇ
Quoted Message :  2023_05_11_8CAEAC0689D5C78D604FA82777FB1AE4.jpeg

Message : Couple of months? üò≥

Wow
Quoted Message :  2023_05_11_8CAEAC0689D5C78D604FA82777FB1AE4.jpeg

Message : Does anybody have access to ChatGPT plugins API?

I applied for it sometime ago. Any hacks?

Message : What do you mean by Plugins API?
Quoted Message : Does anybody have access to ChatGPT plugins API?\n\nI applied for it sometime ago. Any hacks?

Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : ‚Äé<attached: 00003302-PHOTO-2023-05-11-09-59-04.jpg>
Quoted Message : What do you mean by Plugins API?

Message : OpenAI Evals, LM-Harness for HF models, and the extremely entertaining, useful and wrong ELO rating approach
Quoted Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : This is precisely what I wanted  to acquaint myself with well known benchmarks atleast. ELO doesnt seem to be a good measure of llm performance

Message : Thanks

Message : ‚Äé<attached: 00003306-PHOTO-2023-05-11-10-01-36.jpg>
Quoted Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : this is total waste. üòÇ
Quoted Message :  2023_05_11_8CAEAC0689D5C78D604FA82777FB1AE4.jpeg

Message : Couple of months? üò≥

Wow
Quoted Message :  2023_05_11_8CAEAC0689D5C78D604FA82777FB1AE4.jpeg

Message : Does anybody have access to ChatGPT plugins API?

I applied for it sometime ago. Any hacks?

Message : What do you mean by Plugins API?
Quoted Message : Does anybody have access to ChatGPT plugins API?\n\nI applied for it sometime ago. Any hacks?

Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : ‚Äé<attached: 00003302-PHOTO-2023-05-11-09-59-04.jpg>
Quoted Message : What do you mean by Plugins API?

Message : OpenAI Evals, LM-Harness for HF models, and the extremely entertaining, useful and wrong ELO rating approach
Quoted Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : This is precisely what I wanted  to acquaint myself with well known benchmarks atleast. ELO doesnt seem to be a good measure of llm performance

Message : Thanks

Message : ‚Äé<attached: 00003306-PHOTO-2023-05-11-10-01-36.jpg>
Quoted Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : ‚Äé<attached: 00003307-PHOTO-2023-05-11-10-01-38.jpg>
Quoted Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : ‚Äé<attached: 00003308-PHOTO-2023-05-11-10-01-44.jpg>
Quoted Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : This looks good thank you

Message : https://arxiv.org/pdf/2303.17564.pdf

Source:BloombergGPT team released quite few details on training their model ,it‚Äôs quite interesting to read
Quoted Message :  2023_05_11_3A5E318ACBE588DB1C0D.jpeg

Message : Checkout Big bench
Quoted Message : Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc

Message : Big Bench is a dataset curated by Google to make Google models look good, OpenAI Evals makes GPT4 looks good, only LM-Harness is real ‚Äî it makes everyone look great! ü§£

https://paperswithcode.com/dataset/big-bench
Quoted Message : Checkout Big bench

Message : Only benchmarking that truly matters is community benchmarking

Message : Controversial Take: Benchmarks don't matter when your product is great. Benchmarks are for plebs. 

So imma go and work on my Vector Database benchmark üòÖ
Quoted Message : Only benchmarking that truly matters is community benchmarking

Message : I think the fundamental difference is openai is doing all it can to break gpt-4, while google trying to show they are as good at chatgpt so use us

Message : what is the source for this? What is the Elo based on?
Quoted Message :  2023_05_11_8CAEAC0689D5C78D604FA82777FB1AE4.jpeg

Message : Curious - why don't Elo ratings work? Because this is not a true head-to-head comparison?
Quoted Message : OpenAI Evals, LM-Harness for HF models, and the extremely entertaining, useful and wrong ELO rating approach

Message : https://lmsys.org/blog/2023-05-10-leaderboard/?s=09

Message : Sequoia APAC is doing a curated *virtual* demo day called Bird of Feather on Generative AI next week. Has 15 curated demos from the wider web, not just their folio. 

cc Shashwat @91775505xxxx since you had asked about a demo day

If you've questions, Vedant @91999802xxxx from Sequoia is here and please ping directly

If you're interested in attending: https://share.hsforms.com/1Oj8R_ze3QDeUnGAEGv5v6A406r9

Message : superb thanks for the callout. Missed this ealrier

Message : https://arxiv.org/pdf/2305.05576.pdf

Paper by AI4bharat on why India needs its own stack and how these technologies can have a broad societal impact in india

Message : +1. Love what @91775505xxxx is building.
Quoted Message : Sequoia APAC is doing a curated *virtual* demo day called Bird of Feather on Generative AI next week. Has 15 curated demos from the wider web, not just their folio. \n\ncc Shashwat @9177xxxxxxxx since you had asked about a demo day\n\nIf you've questions, Vedant @9199xxxxxxxx from Sequoia is here and please ping directly\n\nIf you're interested in attending: https://share.hsforms.com/1Oj8R_ze3QDeUnGAEGv5v6A406r9

Message : What are some of the most useful resources for exploring AutoGPT and creating agents?

Message : anyone knows here which model powers Sage bot on Poe?

the bot works pretty well compared to chat GPT 3.5 even on code tasks

Message : https://python.langchain.com/en/latest/use_cases/autonomous_agents/autogpt.html

https://github.com/Significant-Gravitas/Auto-GPT
Quoted Message : What are some of the most useful resources for exploring AutoGPT and creating agents?

Message : Claude+ from Anthropic?
Quoted Message : anyone knows here which model powers Sage bot on Poe?\n\nthe bot works pretty well compared to chat GPT 3.5 even on code tasks

Message : don't think so since Poe has a seperate bot for Claude+ and that's paid

poe.com/sage is free
poe.com/claude%2b is paid
Quoted Message : Claude+ from Anthropic?

Message : ‚Äé<attached: 00003329-PHOTO-2023-05-11-12-29-58.jpg>

Message : oh they have added "powered by 3.5" now. wasn't there earlier.

Message : why two bots for same model tho? poe.com/chatgpt is also by 3.5 turbo

Message : but good to know it's the same model üòÖ

I was feeling fomo if I missed any ground breaking model announcement

Message : thank you
Quoted Message : https://python.langchain.com/en/latest/use_cases/autonomous_agents/autogpt.html\n\nhttps://github.com/Significant-Gravitas/Auto-GPT

Message : this to me feels like a NFT-like scam, only if they ICO'd with these kind of models lol. Creating own LLM powered by gpt-3.5
Quoted Message : oh they have added \"powered by 3.5\" now. wasn't there earlier.

Message : I‚Äôd assume different first ‚Äúsystem‚Äù message if you‚Äôre seeing diff responses from both bots

Message : it cud also be different model config. tempertaure,  etc.
Quoted Message : I‚Äôd assume different first ‚Äúsystem‚Äù message if you‚Äôre seeing diff responses from both bots

Message : A masterclass on how to PichAI

h/t @91990170xxxx @91876396xxxx
https://www.linkedin.com/posts/yangpeter_its-really-hard-to-raise-money-right-now-ugcPost-7062259610383974400-IAgT/

Message : If you‚Äôre interested in reading paper checkout ReAct paper
Quoted Message : What are some of the most useful resources for exploring AutoGPT and creating agents?

Message : Im trying to make an agent with a finetuned model
Quoted Message : If you‚Äôre interested in reading paper checkout ReAct paper

Message : Actually 2-3 agents with separate finetuned models and I want to see them interact üòõ

Message : just as a fun sideproject‚Ä¶will share if I succeed

Message : How do you tell which one us better at what task though is the key! üòÜ

Message : By separate finetuned models I mean not separate llms‚Ä¶for now im just trying to finetune gpt with separate additional informations about a particular subject

Message : i.e. separate context and instructions using prompt engineering?
Quoted Message : By separate finetuned models I mean not separate llms‚Ä¶for now im just trying to finetune gpt with separate additional informations about a particular subject

Message : not prompt engineering. Already trained models (im not training them)
for example, say make BloombergGPT debate with YahooFinanceGPT whether its good to invest in a particular stock at this time or not
Quoted Message : i.e. separate context and instructions using prompt engineering?

Message : Has anyone here worked extensively with LlamaIndex. Was going through it's docs, have some questions regarding it's base architecture.

Message : cc @91955016xxxx is a Llama index contributor. 

A general great practice is to ask the question(s) directly because:

1. Folks other than who we know already can chip in e.g. @91963283xxxx has used Llama Index extensively as well from a business+dev lens

2. People benefit from the answer greatly even if they've a passing interest in the topic
Quoted Message : Has anyone here worked extensively with LlamaIndex. Was going through it's docs, have some questions regarding it's base architecture.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : If you‚Äôre interested in reading paper checkout ReAct paper
Quoted Message : What are some of the most useful resources for exploring AutoGPT and creating agents?

Message : Im trying to make an agent with a finetuned model
Quoted Message : If you‚Äôre interested in reading paper checkout ReAct paper

Message : Actually 2-3 agents with separate finetuned models and I want to see them interact üòõ

Message : just as a fun sideproject‚Ä¶will share if I succeed

Message : How do you tell which one us better at what task though is the key! üòÜ

Message : By separate finetuned models I mean not separate llms‚Ä¶for now im just trying to finetune gpt with separate additional informations about a particular subject

Message : i.e. separate context and instructions using prompt engineering?
Quoted Message : By separate finetuned models I mean not separate llms‚Ä¶for now im just trying to finetune gpt with separate additional informations about a particular subject

Message : not prompt engineering. Already trained models (im not training them)
for example, say make BloombergGPT debate with YahooFinanceGPT whether its good to invest in a particular stock at this time or not
Quoted Message : i.e. separate context and instructions using prompt engineering?

Message : Has anyone here worked extensively with LlamaIndex. Was going through it's docs, have some questions regarding it's base architecture.

Message : cc @91955016xxxx is a Llama index contributor. 

A general great practice is to ask the question(s) directly because:

1. Folks other than who we know already can chip in e.g. @91963283xxxx has used Llama Index extensively as well from a business+dev lens

2. People benefit from the answer greatly even if they've a passing interest in the topic
Quoted Message : Has anyone here worked extensively with LlamaIndex. Was going through it's docs, have some questions regarding it's base architecture.

Message : Has anyone encountered this error from OpenAI when embedding? AFAIK it‚Äôs not a rate limit 

The server is currently overloaded with other requests. Sorry about that! You can retry your request, or contact us through our help center at http://help.openai.com if the error persists.' error_param=None error_type=server_error message='OpenAI API error received

Message : I think this is a common ‚Äútoo many requests, try again later‚Äù error when their servers are flooding. I‚Äôve encountered this multiple times but resolves with retry after some time
Quoted Message : Has anyone encountered this error from OpenAI when embedding? AFAIK it‚Äôs not a rate limit \n\nThe server is currently overloaded with other requests. Sorry about that! You can retry your request, or contact us through our help center at http://help.openai.com if the error persists.' error_param=None error_type=server_error message='OpenAI API error received

Message : @91998226xxxx can you help me with this, i.e., your approach?
@91959920xxxx said you‚Äôve worked on something similar
Quoted Message : not prompt engineering. Already trained models (im not training them)\nfor example, say make BloombergGPT debate with YahooFinanceGPT whether its good to invest in a particular stock at this time or not

Message : I meant this ^
Quoted Message : Actually 2-3 agents with separate finetuned models and I want to see them interact üòõ

Message : Anyone tried the Bhashini APIs?
Quoted Message : https://arxiv.org/pdf/2305.05576.pdf\n\nPaper by AI4bharat on why India needs its own stack and how these technologies can have a broad societal impact in india

Message : Asr Models yes, not APIs
Quoted Message : Anyone tried the Bhashini APIs?

Message : how are the results with asr models? can be used in prod?
Quoted Message : Asr Models yes, not APIs

Message : Using in prod. Best models for indic languages

Message : Not very good for long files, they use nemo, and doing chunked asr on it is not trivial

Message : Timestamps also are an issue

Message : Do they support streaming??

Message : But the asr quality is good

Message : https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/intro.html

Message : This is what they use

Message : Seems to support streaming
Quoted Message : https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/intro.html

Message : https://github.com/opennyai/jugalbandi-api

Message : https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi

There‚Äôs a visual mathematician Grant Sanderson with a YT channel named 3Blue1Brown who makes some fascinating videos on the intuition behind mathematical concepts.

There‚Äôs this ^ set of four on neural nets which forms a visual intuition of gradient descent, inference and backpropagation. Might be useful for anyone not very mathematically inclined but keen to have an intuitive sense of how simple NNs work.

Message : ‚Äé<attached: 00003371-PHOTO-2023-05-11-21-40-32.jpg>

Message : https://www-moneycontrol-com.cdn.ampproject.org/c/s/www.moneycontrol.com/news/business/startup/foreign-firms-like-google-have-to-invest-in-indian-ai-start-ups-for-access-to-countrys-data-sets-rajeev-chandrasekhar-10569191.html/amp

Message : Seems like a smart idea. Thinking in the right direction, at least.
Quoted Message : https://www-moneycontrol-com.cdn.ampproject.org/c/s/www.moneycontrol.com/news/business/startup/foreign-firms-like-google-have-to-invest-in-indian-ai-start-ups-for-access-to-countrys-data-sets-rajeev-chandrasekhar-10569191.html/amp

Message : https://twitter.com/AnthropicAI/status/1656700154190389248?s=20 -  Claude‚Äôs 100k tokens context window

Message : What exactly? @91775505xxxx can you please share a link?
Quoted Message : +1. Love what @9177xxxxxxxx is building.

Message : Hey sure. We are building in co-pilot for Analyst space. Given business context in.csv file you can use it for text 2 SQL translation. Sharing the link in DM.
Quoted Message : What exactly? @9177xxxxxxxx can you please share a link?

Message : ‚Äé<attached: 00003378-VIDEO-2023-05-11-22-41-01.mp4>

Message : @91857287xxxx - Something you experimented with as well right!
Quoted Message : Hey sure. We are building in co-pilot for Analyst space. Given business context in.csv file you can use it for text 2 SQL translation. Sharing the link in DM.

Message : We are in closed beta. Feel free to DM for early access.
Quoted Message :  2023_05_11_C46096FBE8A6EDE20F0A13743629A590.mp4

Message : Would love to check it out
Quoted Message : We are in closed beta. Feel free to DM for early access.

Message : Yes. Quite a few player in this space. About 4-5 just last month in Bangalore. Overall 50+ in this space. Not seen true PMF yet. 

Also, success of MSFT copilot system's now Google Bard AI in spreadsheet & Collab plays a key role in success of such 3P platforms.
Quoted Message : @9185xxxxxxxx - Something you experimented with as well right!

Message : Will the increase in context window size also increase latency of LLM's in any way?
Quoted Message : https://twitter.com/AnthropicAI/status/1656700154190389248?s=20 -  Claude‚Äôs 100k tokens context window

Message : ‚ÄúWe fed Claude-Instant The Great Gatsby (72K tokens), except we modified one line to say that Mr. Carraway was "a software engineer that works on machine learning tooling at Anthropic." We asked the model to spot what was added - it responded with the right answer in 22 seconds.‚Äù

Message : The first 2 inputs were the 72K tokens and third input was the query right? In that case why the latency?
Quoted Message : ‚ÄúWe fed Claude-Instant The Great Gatsby (72K tokens), except we modified one line to say that Mr. Carraway was \"a software engineer that works on machine learning tooling at Anthropic.\" We asked the model to spot what was added - it responded with the right answer in 22 seconds.‚Äù

Message : This size of the attention window sounds like an amazing technical leap but not going to be practical with the current hardware. For that attention, the per 1k token prize is going to be crazy once out of beta and burning VC money.

Message : ‚Äé<attached: 00003388-PHOTO-2023-05-12-02-23-23.jpg>

Message : https://www.mosaicml.com/blog/mpt-7b

Message : Doesn‚Äôt seem so - for the smaller models maybe it is feasible
Quoted Message : This size of the attention window sounds like an amazing technical leap but not going to be practical with the current hardware. For that attention, the per 1k token prize is going to be crazy once out of beta and burning VC money.

Message : ‚Äé<attached: 00003391-PHOTO-2023-05-12-02-24-41.jpg>

Message : It took 22second and the entire infra to generate something that is probably less than 50 tokens from 72K token

Message : May be I'm wrong, and may have to read some more documents.

Message : Whats the time complexity w.r.t. # of params?

Trillion parameters on 8k tokens vs billion params on 65k tokens?
Quoted Message :  2023_05_12_3EB02AEC31FAE0FDE2AC88.jpeg

Message : Good question. I don't know how significantly parameters will affect or which model they are using for this demo.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : The first 2 inputs were the 72K tokens and third input was the query right? In that case why the latency?
Quoted Message : ‚ÄúWe fed Claude-Instant The Great Gatsby (72K tokens), except we modified one line to say that Mr. Carraway was \"a software engineer that works on machine learning tooling at Anthropic.\" We asked the model to spot what was added - it responded with the right answer in 22 seconds.‚Äù

Message : This size of the attention window sounds like an amazing technical leap but not going to be practical with the current hardware. For that attention, the per 1k token prize is going to be crazy once out of beta and burning VC money.

Message : ‚Äé<attached: 00003388-PHOTO-2023-05-12-02-23-23.jpg>

Message : https://www.mosaicml.com/blog/mpt-7b

Message : Doesn‚Äôt seem so - for the smaller models maybe it is feasible
Quoted Message : This size of the attention window sounds like an amazing technical leap but not going to be practical with the current hardware. For that attention, the per 1k token prize is going to be crazy once out of beta and burning VC money.

Message : ‚Äé<attached: 00003391-PHOTO-2023-05-12-02-24-41.jpg>

Message : It took 22second and the entire infra to generate something that is probably less than 50 tokens from 72K token

Message : May be I'm wrong, and may have to read some more documents.

Message : Whats the time complexity w.r.t. # of params?

Trillion parameters on 8k tokens vs billion params on 65k tokens?
Quoted Message :  2023_05_12_3EB02AEC31FAE0FDE2AC88.jpeg

Message : Good question. I don't know how significantly parameters will affect or which model they are using for this demo.

Message : ‚Äé<attached: 00003396-PHOTO-2023-05-12-02-29-17.jpg>

Message : I'm going to let someone else figure it out and post a detailed analysis on Twitter. They are not saying the size of the model that will be used for 100k API. If they use 1T model for 100K, it is probably going to be very expensive to accommodate practical use cases. ü§∑‚Äç‚ôÇÔ∏è but then my temporal snapshot of knowledge is changing every day.

Message : https://bard.google.com

This is so fast üòµ and does 3 parallel generations at once too!

Message : They're probably showing top 3 probable beams as a part of their beam search decoding. Afaict, all LLMs do perform this decoding but other providers just give the top most beam
Quoted Message : https://bard.google.com\n\nThis is so fast üòµ and does 3 parallel generations at once too!

Message : User shares preview from Anthropic's 100K tokens context window
https://twitter.com/harishkgarg/status/1656718619651477505

Message : https://twitter.com/lijunnan0409/status/1656821806593101827?s=46 - InstructBLIP - sales force - vision language instruction tuning framework

Message : https://twitter.com/harishkgarg/status/1656724079183798273?s=20 - 100k tokens seem to cost ~$1, for 100k tokens with GPT4 it would cost ~$0.5. Multiple hits on a doc from users are still costly with 100k tokens with a compromise on latency probably ü§î
Quoted Message : User shares preview from Anthropic's 100K tokens context window\nhttps://twitter.com/harishkgarg/status/1656718619651477505

Message : Meta comment:
- You sleep
- You wake up

There are 2-3 new advances in this space to catch up on :)

Message : Need a news ticker for AI advances as a -1 screen replacement.

Message : future tools will be helpful. https://www.futuretools.io/news
Quoted Message : Need a news ticker for AI advances as a -1 screen replacement.

Message : ‚Äé<attached: 00003407-PHOTO-2023-05-12-09-28-09.jpg>

Message : ‚Äé<attached: 00003408-PHOTO-2023-05-12-09-28-10.jpg>

Message : ‚Äé<attached: 00003409-PHOTO-2023-05-12-09-28-11.jpg>

Message : ‚Äé<attached: 00003410-PHOTO-2023-05-12-09-30-23.jpg>

Message : This is excellent!! 
Did you build this model yourself? Or are you using any other open source model?

Message : Can I try this out?

Message : This is running on Vicuna13B. Even 7B is giving out awesome results

Message : Pretty cool
Quoted Message :  2023_05_12_3EB091AE00C6A70C6178D4.jpeg

Message : Looks very interesting. Details available?
Quoted Message :  2023_05_12_3EB09DDFBFBB6C5997C1B2.jpeg

Message : I will send you the link Siddharth - ping me please

Message : What is the attack here?  Can you give us a brief summary?  That looks impressive!
Quoted Message : This is running on Vicuna13B. Even 7B is giving out awesome results

Message : ‚Äé<attached: 00003418-PHOTO-2023-05-12-09-44-04.jpg>

Message : ‚Äé<attached: 00003419-PHOTO-2023-05-12-09-44-05.jpg>

Message : Ok. here is the high level view of how it works. 
A vision transformer (frozen model) converts the image to a fixed sized embedding. An LLM (vicuna in this case) uses that information, and the user question/context to generate text.

Message : Anyone try instruct-blip yet?

Message : This IS instruct blip

Message : Oh

Message : That‚Äôs all we need for multi-modal gpt, right? This is all solved now üòÖ

Message : The open source projects which will help you all get up to speed are BLIP2, MiniGPT4 and Instruct-BLIP (which came out yesterday)

Message : Here is the challenge - this works quite well at 7B params. But with OPT2.7B it hallucinates a lot. Some of us have been trying to make that better over the past 4 days....it's slowly getting there

Message : Is this on mid journey
Quoted Message :  2023_05_12_3A13E4F3A9AB43A675DA.jpeg

Message : popups and cookie requests are annoying. Numerous extensions have been built to tackle it and there's reader mode too, but none of them is perfect. If an AI extension which runs on the machine can tackle this, it's a $B idea. Essentially, it needs to - take a screenshot whenever there's a substantial change in the page, detect what needs to be clicked, click on it. If it runs on the machine, it can even go ahead do some slightly more advanced stuff like automatically login on sites which have logged you out, etc as well

Message : Don't already many tools exist to automate this?
Also, taking a screenshot is a bit heavier approach than reading HTML data on a client machine?
Like to understand what can't be automated except a captcha, which requires such AI-powered automation?
Quoted Message : popups and cookie requests are annoying. Numerous extensions have been built to tackle it and there's reader mode too, but none of them is perfect. If an AI extension which runs on the machine can tackle this, it's a $B idea. Essentially, it needs to - take a screenshot whenever there's a substantial change in the page, detect what needs to be clicked, click on it. If it runs on the machine, it can even go ahead do some slightly more advanced stuff like automatically login on sites which have logged you out, etc as well

Message : Is there any model to perform QA on video?

Message : Can make one with Instruct BLIP + Vicuna now
Quoted Message : Is there any model to perform QA on video?

Message : I think we can wait till Monday for someone else to do it ü•≤

Message : I like this approach these days.

Message : I have it for video.

Message : ‚Äé<attached: 00003435-VIDEO-2023-05-12-10-34-12.mp4>

Message : ‚Äé<attached: 00003436-PHOTO-2023-05-12-10-34-26.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Is this on mid journey
Quoted Message :  2023_05_12_3A13E4F3A9AB43A675DA.jpeg

Message : popups and cookie requests are annoying. Numerous extensions have been built to tackle it and there's reader mode too, but none of them is perfect. If an AI extension which runs on the machine can tackle this, it's a $B idea. Essentially, it needs to - take a screenshot whenever there's a substantial change in the page, detect what needs to be clicked, click on it. If it runs on the machine, it can even go ahead do some slightly more advanced stuff like automatically login on sites which have logged you out, etc as well

Message : Don't already many tools exist to automate this?
Also, taking a screenshot is a bit heavier approach than reading HTML data on a client machine?
Like to understand what can't be automated except a captcha, which requires such AI-powered automation?
Quoted Message : popups and cookie requests are annoying. Numerous extensions have been built to tackle it and there's reader mode too, but none of them is perfect. If an AI extension which runs on the machine can tackle this, it's a $B idea. Essentially, it needs to - take a screenshot whenever there's a substantial change in the page, detect what needs to be clicked, click on it. If it runs on the machine, it can even go ahead do some slightly more advanced stuff like automatically login on sites which have logged you out, etc as well

Message : Is there any model to perform QA on video?

Message : Can make one with Instruct BLIP + Vicuna now
Quoted Message : Is there any model to perform QA on video?

Message : I think we can wait till Monday for someone else to do it ü•≤

Message : I like this approach these days.

Message : I have it for video.

Message : ‚Äé<attached: 00003435-VIDEO-2023-05-12-10-34-12.mp4>

Message : ‚Äé<attached: 00003436-PHOTO-2023-05-12-10-34-26.jpg>

Message : Any links to Instruct BLIP?
Quoted Message : Can make one with Instruct BLIP + Vicuna now

Message : https://github.com/salesforce/LAVIS/tree/main/projects/instructblip

Message : ‚Äé<attached: 00003439-PHOTO-2023-05-12-10-39-32.jpg>

Message : ‚Äé<attached: 00003440-PHOTO-2023-05-12-10-48-25.jpg>

Message : What approach? Is there an intro / write up to it?
Quoted Message : I like this approach these days.

Message : How do you find salient frames?
Quoted Message : I have it for video.

Message : Good question. Increasing information density is the first step. short answer: cosine distances. Long answer: a lot of back and forth between LLMs and the ViT
Quoted Message : How do you find salient frames?

Message : I was talking about Nirant‚Äôs approach of waiting for someone on Twitter to do it and post üòÅ
Quoted Message : What approach? Is there an intro / write up to it?

Message : someone took their tweets from last 1 year and dumped them into Anthropic 100k üòÇ. 

got a summary in 38 seconds.

https://twitter.com/altryne/status/1656798898487463940?t=bPP8X-QmhxbnCC7vTeDVMA&s=19

Message : Damn! Can this be a step forward to do live commentary  for blind people with some obvious latency?
Quoted Message :  2023_05_12_3EB0754224B2991C0E5C5C.mp4

Message : Yeah, I don't see why. With the speeds we achieve now (in known envs) this could happen sooner than people realize

Message : Exactly!!
Quoted Message : Damn! Can this be a step forward to do live commentary  for blind people with some obvious latency?

Message : I started a project back in march with the high hopes of this üòÖ Had talked to @91773788xxxx about the lofty aims.
This looks very cool! I‚Äôd be very interested to lend a hand of help if I fit anywhere
Quoted Message : Yeah, I don't see why. With the speeds we achieve now (in known envs) this could happen sooner than people realize

Message : We are trying to get the vicuna7B performance out of OPT2.7B. 
If you can help fine-tune, I'm happy to offer a few A100s.

Message : Google's PaLM 2 model training data is up to Feb 2023!

https://twitter.com/minimaxir/status/1656791154581700608?t=Fn9SFITeLhsLkkfzsQk8tw&s=19

Message : I‚Äôll dm for more details
Quoted Message : We are trying to get the vicuna7B performance out of OPT2.7B. \nIf you can help fine-tune, I'm happy to offer a few A100s.

Message : ‚Äé<attached: 00003456-PHOTO-2023-05-12-12-50-14.jpg>
Quoted Message : The open source projects which will help you all get up to speed are BLIP2, MiniGPT4 and Instruct-BLIP (which came out yesterday)

Message : No

Message : Wait, minigpt4 can be used. It's BSD3

Message : what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful

Message : LLaMa I think
Quoted Message : what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful

Message : I‚Äôve already heard a couple of people/teams doing so

Message : There's this company called bemyeyes which used to do this with volunteers- where someone who was visually impaired would open up the app camera and wait for someone on other end to describe it to them- now replaced with GPT- 4
Quoted Message : Damn! Can this be a step forward to do live commentary  for blind people with some obvious latency?

Message : https://twitter.com/BeMyEyes/status/1635690254689599488?t=qEPFpSZg2Rn8_PJu9CU0Vw&s=19

Message : Insanely impactful stuff
Quoted Message : https://twitter.com/BeMyEyes/status/1635690254689599488?t=qEPFpSZg2Rn8_PJu9CU0Vw&s=19

Message : Related to previous discussion on vector DBs 
Check this by vector DB service MS Azure

https://techcommunity.microsoft.com/t5/azure-data-explorer-blog/azure-data-explorer-for-vector-similarity-search/ba-p/3819626

Message : right, but the volunteer thing reminded me of a funny incident. Someone once asked me, ‚Äúso tell me, do you actually sit at the back and solve those tough integration problems and quickly return then when someone asks wolfram alpha?‚Äù üòÇ
Quoted Message : There's this company called bemyeyes which used to do this with volunteers- where someone who was visually impaired would open up the app camera and wait for someone on other end to describe it to them- now replaced with GPT- 4

Message : gpt integration with bemyeyes is v cool but they had a few limitations and challenges, mostly trained on west-accented tts/stt and not opensource

Message : Yeah I saw the license file, but can we commercially use a model which is built on top of another non commercial model.
Quoted Message : Wait, minigpt4 can be used. It's BSD3

Message : The Vicuna, MiniGPT4 shows license Apache 2.0 or BSD3. Which makes one belive that we can use this commercially.
However LLaMa weights are not available commercially, making Vicuna model only usable for research purpose and not commercially.

Message : p.s. Vicuna is fine-tunned LLaMa.

Message : Code? StarCoder
Quoted Message : what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful

Message : Salesforce's codegen endpoint is also good alongside StarCoder
Quoted Message : what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful

Message : folks, question: how do you iterate your prompts?

i'm exploring an automatic way to do this.

original prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate

(optionally also add user feedback in addition to second LLM)

Any thoughts? ideas?

Message : Try evaluations.. create a test data set

Then run models through the different evals. Did a lot of reading on this and is probably a great way to automate this

Message : can you elaborate?
Quoted Message : Try evaluations.. create a test data set\n\nThen run models through the different evals. Did a lot of reading on this and is probably a great way to automate this

Message : Iterate on them a lot. I've used this approach. Give GPT4 the outcome I want and then ask it to tell me what would be the most useful inputs. It's a good starting point
Quoted Message : folks, question: how do you iterate your prompts?\n\ni'm exploring an automatic way to do this.\n\noriginal prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate\n\n(optionally also add user feedback in addition to second LLM)\n\nAny thoughts? ideas?

Message : One layman approach that works for me a number of times :

For prompts that are intended to generate output during user interaction : I tend to form a hypothesis around the parts of my prompt that are responsible for unsatisfactory output. And ask the LLM itself why it did not create my desired output (with example) : often hear feedback on what I could do better in my prompt. GPT-4 is quite good at that.

I believe there are better technical methods, keen to know especially for images.
Quoted Message : folks, question: how do you iterate your prompts?\n\ni'm exploring an automatic way to do this.\n\noriginal prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate\n\n(optionally also add user feedback in addition to second LLM)\n\nAny thoughts? ideas?

Message : Rohit can't plug since he wrote this, but I can: portkey.ai/blog/decoding-openai-evals/
Quoted Message : can you elaborate?

Message : read this too https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : p.s. Vicuna is fine-tunned LLaMa.

Message : Code? StarCoder
Quoted Message : what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful

Message : Salesforce's codegen endpoint is also good alongside StarCoder
Quoted Message : what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful

Message : folks, question: how do you iterate your prompts?

i'm exploring an automatic way to do this.

original prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate

(optionally also add user feedback in addition to second LLM)

Any thoughts? ideas?

Message : Try evaluations.. create a test data set

Then run models through the different evals. Did a lot of reading on this and is probably a great way to automate this

Message : can you elaborate?
Quoted Message : Try evaluations.. create a test data set\n\nThen run models through the different evals. Did a lot of reading on this and is probably a great way to automate this

Message : Iterate on them a lot. I've used this approach. Give GPT4 the outcome I want and then ask it to tell me what would be the most useful inputs. It's a good starting point
Quoted Message : folks, question: how do you iterate your prompts?\n\ni'm exploring an automatic way to do this.\n\noriginal prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate\n\n(optionally also add user feedback in addition to second LLM)\n\nAny thoughts? ideas?

Message : One layman approach that works for me a number of times :

For prompts that are intended to generate output during user interaction : I tend to form a hypothesis around the parts of my prompt that are responsible for unsatisfactory output. And ask the LLM itself why it did not create my desired output (with example) : often hear feedback on what I could do better in my prompt. GPT-4 is quite good at that.

I believe there are better technical methods, keen to know especially for images.
Quoted Message : folks, question: how do you iterate your prompts?\n\ni'm exploring an automatic way to do this.\n\noriginal prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate\n\n(optionally also add user feedback in addition to second LLM)\n\nAny thoughts? ideas?

Message : Rohit can't plug since he wrote this, but I can: portkey.ai/blog/decoding-openai-evals/
Quoted Message : can you elaborate?

Message : read this too https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids

Message : Source preprint which the blog discusses:
https://arxiv.org/abs/2212.08073
Quoted Message : read this too https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids

Message : How to get Chatgpt to just output the code that I've asked it for instead of any other extra text. I've tried mentioning this multiple times but it ignores those instructions.

Message : https://github.com/irgolic/AutoPR
Quoted Message : How to get Chatgpt to just output the code that I've asked it for instead of any other extra text. I've tried mentioning this multiple times but it ignores those instructions.

Message : Thanks, I'll check it out!
Quoted Message : https://github.com/irgolic/AutoPR

Message : Folks - what are sources where I can find standard evaluation datasets?

I was checking the Stanform/Helm github repo - I can dig into code and find each of the tar files, but is there a better way?

Message : huggingface.co/docs/datasets
Quoted Message : Folks - what are sources where I can find standard evaluation datasets?\n\nI was checking the Stanform/Helm github repo - I can dig into code and find each of the tar files, but is there a better way?

Message : yea, was browsing this.. any way to filter LLM specific evaluation datasets?

Message : https://huggingface.co/datasets?task_categories=task_categories:text2text-generation&sort=downloads
Quoted Message : yea, was browsing this.. any way to filter LLM specific evaluation datasets?

Message : thanks so much man!

Message : Can you explain what happens in iterate?
Quoted Message : folks, question: how do you iterate your prompts?\n\ni'm exploring an automatic way to do this.\n\noriginal prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate\n\n(optionally also add user feedback in addition to second LLM)\n\nAny thoughts? ideas?

Message : This might be useful 
https://arxiv.org/abs/2302.12822

Message : ‚Äé<attached: 00003493-PHOTO-2023-05-12-18-42-53.jpg>
Quoted Message : folks, question: how do you iterate your prompts?\n\ni'm exploring an automatic way to do this.\n\noriginal prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate\n\n(optionally also add user feedback in addition to second LLM)\n\nAny thoughts? ideas?

Message : thanks
Quoted Message :  2023_05_12_786FB7A12593B9A61F.jpeg

Message : reading material

https://aclanthology.org/2020.emnlp-main.346.pdf
https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know
https://arxiv.org/pdf/2101.00190.pdf
Quoted Message :  2023_05_12_786FB7A12593B9A61F.jpeg

Message : Do we have extremely small llms that can work in js in the browser? A link would be nice.

Message : https://simonwillison.net/2023/Apr/16/web-llm/
Quoted Message : Do we have extremely small llms that can work in js in the browser? A link would be nice.

Message : Yes this! Thanks
Quoted Message : https://simonwillison.net/2023/Apr/16/web-llm/

Message : ‚Äé<attached: 00003499-PHOTO-2023-05-12-20-02-55.jpg>

Message : Nirant shared this earlier

https://www.chatpdf.com/
Quoted Message :  2023_05_12_3EB08DE058C0FC729BE6.jpeg

Message : This also struggles to answer meta questions like summarising. Answers precise questions well, in my experience.
Quoted Message : Nirant shared this earlier\n\nhttps://www.chatpdf.com/

Message : ‚Äé<attached: 00003503-PHOTO-2023-05-12-20-22-22.jpg>

Message : This is a good blog

Message : https://medium.com/geekculture/prompt-engineering-with-llamaindex-and-openai-gpt-3-f52114aba8b7

Message : On a side note, just notized that the first author, Manzil, was a senior from college and his room was right next to mine.
Quoted Message :  2023_05_12_3EB08DE058C0FC729BE6.jpeg

Message : So you're the first-adjacent author of this paper? üòÄ
Quoted Message : On a side note, just notized that the first author, Manzil, was a senior from college and his room was right next to mine.

Message : https://twitter.com/AiBreakfast/status/1656881667116613636 Could anyone tell me how computationally intensive is this technology?

Message : Or can we say he‚Äôs the literal ‚ÄòApproximate Nearest Neighbour‚Äô üòÅüòÅ
Quoted Message : So you're the first-adjacent author of this paper? üòÄ

Message : ‚ÄéPOLL:
Assuming early adopters of this group wud be using some kind of wrapper LLM tool by now, how satisfied are you with these (text2x) tools in general? Have you been able to use any in production env.
‚ÄéOPTION: 1 (3 votes)
‚ÄéOPTION: 2 (0 votes)
‚ÄéOPTION: 3 (3 votes)
‚ÄéOPTION: 4 (0 votes)
‚ÄéOPTION: 5 (very satisfied) (0 votes)

Message : Discovered chatpdf.com early. 

Was early user but couldn't really extract value from a medical insurance pdf.
Quoted Message : This also struggles to answer meta questions like summarising. Answers precise questions well, in my experience.

Message : Have been a avid user of chatgpt directly

Message : Will call it 5/5. Especially gpt4.

Message : I have heard good things about the new feature they have. 

https://twitter.com/gpt_index/status/1655590126074863616
Quoted Message :  2023_05_12_3EB01EF6F2A9A31AFCB0.jpeg

Message : Someone created an architectural overview of Langchain. It is useful to understand it's concepts.
https://app.heptabase.com/w/12484a51f631edbddd6415dafbad56d8ae119058ece8bcb3e8d9a5a3ba80a45b?id=7d359c3d-b443-4547-a852-d384457cd23b

Message : Full Stack DL released their LLM Bootcamp lectures for free

https://twitter.com/full_stack_dl/status/1656683085524795393?t=Y0SGVw9taqbppYgNsmkDLQ&s=19

Message : https://lmql.ai/

Such a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Does it work with open ai models?

Those don‚Äôt offer logits, right?
Quoted Message : https://lmql.ai/\n\nSuch a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Nice! Does this have similar concepts as jsonformer?
Quoted Message : https://lmql.ai/\n\nSuch a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Something similar to minddb

https://docs.mindsdb.com/custom-model/openai
Quoted Message : https://lmql.ai/\n\nSuch a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Mean query engine

Message : For LLM training, what is the impact of choosing different hardware architectures across training and inference?

For instance, P2/P3 instance for training and P3/G3 for deployment? I'm aware that recent architectures provide functional advantage for efficiency, read somewhere that FastAttention(FA) uses it.

But is FA irrelevant for a P2, and if not, can I trade time for less cost and train and then benefit during inference?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Will call it 5/5. Especially gpt4.

Message : I have heard good things about the new feature they have. 

https://twitter.com/gpt_index/status/1655590126074863616
Quoted Message :  2023_05_12_3EB01EF6F2A9A31AFCB0.jpeg

Message : Someone created an architectural overview of Langchain. It is useful to understand it's concepts.
https://app.heptabase.com/w/12484a51f631edbddd6415dafbad56d8ae119058ece8bcb3e8d9a5a3ba80a45b?id=7d359c3d-b443-4547-a852-d384457cd23b

Message : Full Stack DL released their LLM Bootcamp lectures for free

https://twitter.com/full_stack_dl/status/1656683085524795393?t=Y0SGVw9taqbppYgNsmkDLQ&s=19

Message : https://lmql.ai/

Such a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Does it work with open ai models?

Those don‚Äôt offer logits, right?
Quoted Message : https://lmql.ai/\n\nSuch a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Nice! Does this have similar concepts as jsonformer?
Quoted Message : https://lmql.ai/\n\nSuch a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Something similar to minddb

https://docs.mindsdb.com/custom-model/openai
Quoted Message : https://lmql.ai/\n\nSuch a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints

Message : Mean query engine

Message : For LLM training, what is the impact of choosing different hardware architectures across training and inference?

For instance, P2/P3 instance for training and P3/G3 for deployment? I'm aware that recent architectures provide functional advantage for efficiency, read somewhere that FastAttention(FA) uses it.

But is FA irrelevant for a P2, and if not, can I trade time for less cost and train and then benefit during inference?

Message : cc @91996355xxxx was on the original TPU firmware team, would love to hear from him on training-inference trade offs for hardware
Quoted Message : For LLM training, what is the impact of choosing different hardware architectures across training and inference?\n\nFor instance, P2/P3 instance for training and P3/G3 for deployment? I'm aware that recent architectures provide functional advantage for efficiency, read somewhere that FastAttention(FA) uses it.\n\nBut is FA irrelevant for a P2, and if not, can I trade time for less cost and train and then benefit during inference?

Message : Might be too technical for this group, but purely from a nvidia hardware point of view 

H100 > A100 (P4D) > V100 (P3)
K80 (P2) at this point is very old
You can also train on T4 (G4DN) and A10 (G5), however these in chips have lower number of tensor cores as well as lower TDP - they can't go as fast but that also makes them less power hungry.
You can exploit K80, P100s for cheap inference now - seemingly no one wants them.

Volta onwards - V100, T4, A10, A100, H100 - have special tensor cores that are specially made for fast matrix multiplications, allow mixed precision training, etc

Going beyond single gpu on a single machine - prefer V100, A100, H100 that are connected via high bandwidth NVLink and infiniband connections so you don't get bottlenecked by data, gradients and weights transfers

Going beyond a single machine, now you are entering the DGX/HGX super pods territory where multiple pods (1 pod = 8 gpu chips) are interconnected via high bandwidth NVSwitches and NVLink

https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/#The_Most_Important_GPU_Specs_for_Deep_Learning_Processing_Speed

https://www.nextplatform.com/2022/03/23/nvidia-will-be-a-prime-contractor-for-big-ai-supercomputers/
Quoted Message : For LLM training, what is the impact of choosing different hardware architectures across training and inference?\n\nFor instance, P2/P3 instance for training and P3/G3 for deployment? I'm aware that recent architectures provide functional advantage for efficiency, read somewhere that FastAttention(FA) uses it.\n\nBut is FA irrelevant for a P2, and if not, can I trade time for less cost and train and then benefit during inference?

Message : You can surely do this and in most cases save cost. But a lot depends on your input workloads, model architecture, pipeline etc. How much of it is/can be parallelized and how much is the actual utilization.
This will also have a much more pronounced effect if you use inference focused accelerators which will provide a much bigger bang for the buck per watt compared to off the shelf GPU hardware
Quoted Message : For LLM training, what is the impact of choosing different hardware architectures across training and inference?\n\nFor instance, P2/P3 instance for training and P3/G3 for deployment? I'm aware that recent architectures provide functional advantage for efficiency, read somewhere that FastAttention(FA) uses it.\n\nBut is FA irrelevant for a P2, and if not, can I trade time for less cost and train and then benefit during inference?

Message : Thanks for the detailed response Chirag. The first paragraph is a great chronological summary. I'm aware of what you mentioned in the 2,3,4 paragraphs. My question is primarily around the cost/time trade-offs while choosing a specific hardware during training, and the switching to something else during inference.

For example, if I train on A100s and get my model and then I want to host on K80 or P100, I am bound to loose the Fast Attention properties because that architecture doesn't support that optimisation. Can I do the opposite? Train on cheap K80 or P100 and then host on V100 to get all matrix multiplication efficiency boost?
Quoted Message : Might be too technical for this group, but purely from a nvidia hardware point of view \n\nH100 > A100 (P4D) > V100 (P3)\nK80 (P2) at this point is very old\nYou can also train on T4 (G4DN) and A10 (G5), however these in chips have lower number of tensor cores as well as lower TDP - they can't go as fast but that also makes them less power hungry.\nYou can exploit K80, P100s for cheap inference now - seemingly no one wants them.\n\nVolta onwards - V100, T4, A10, A100, H100 - have special tensor cores that are specially made for fast matrix multiplications, allow mixed precision training, etc\n\nGoing beyond single gpu on a single machine - prefer V100, A100, H100 that are connected via high bandwidth NVLink and infiniband connections so you don't get bottlenecked by data, gradients and weights transfers\n\nGoing beyond a single machine, now you are entering the DGX/HGX super pods territory where multiple pods (1 pod = 8 gpu chips) are interconnected via high bandwidth NVSwitches and NVLink\n\nhttps://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/#The_Most_Important_GPU_Specs_for_Deep_Learning_Processing_Speed\n\nhttps://www.nextplatform.com/2022/03/23/nvidia-will-be-a-prime-contractor-for-big-ai-supercomputers/

Message : ‚Äé<attached: 00003529-PHOTO-2023-05-13-13-05-54.jpg>
Quoted Message : Does it work with open ai models?\n\nThose don‚Äôt offer logits, right?

Message : Ah I read your query the other way round. TBH this needs you to do some work either in the terms of architecturally mapping your model's architecture and compute/memory needs to the cores/sram/vram utilization besides the architectural needs to consider not just the performance but even feasibility of being able to do this. OR just try it out and see what the results you get.
Quoted Message : Thanks for the detailed response Chirag. The first paragraph is a great chronological summary. I'm aware of what you mentioned in the 2,3,4 paragraphs. My question is primarily around the cost/time trade-offs while choosing a specific hardware during training, and the switching to something else during inference.\n\nFor example, if I train on A100s and get my model and then I want to host on K80 or P100, I am bound to loose the Fast Attention properties because that architecture doesn't support that optimisation. Can I do the opposite? Train on cheap K80 or P100 and then host on V100 to get all matrix multiplication efficiency boost?

Message : Let's say for any QnA or text summarisation task for a domain specific model (assume Llama-30B fine-tuned works well), and less than 2K tokens a query, if I can train using a P2/P3 8xlarge and then switch to a V100 during inference, does it affect my performance? 

I am not able to comprehend of the same attention matrix can behave differently. I an guessing the optimisation comes not purely due to more cores and better I/O but advanced data representation at compile time. The metadata to make that happen could be non-tranferable across architectures. All of this is in my head, I may be absolutely wrong.
Quoted Message : You can surely do this and in most cases save cost. But a lot depends on your input workloads, model architecture, pipeline etc. How much of it is/can be parallelized and how much is the actual utilization.\nThis will also have a much more pronounced effect if you use inference focused accelerators which will provide a much bigger bang for the buck per watt compared to off the shelf GPU hardware

Message : cheap would be subjective I guess
considering A100 can go 10s of orders faster than K80
at some point training for lesser time on expensive A100 would be cheaper than training for longer on cheaper K80

that being said I am reading flash attention this week, so might be able to answer after that üòÖ
Quoted Message : Thanks for the detailed response Chirag. The first paragraph is a great chronological summary. I'm aware of what you mentioned in the 2,3,4 paragraphs. My question is primarily around the cost/time trade-offs while choosing a specific hardware during training, and the switching to something else during inference.\n\nFor example, if I train on A100s and get my model and then I want to host on K80 or P100, I am bound to loose the Fast Attention properties because that architecture doesn't support that optimisation. Can I do the opposite? Train on cheap K80 or P100 and then host on V100 to get all matrix multiplication efficiency boost?

Message : Agreed. Training cost is one of the factor. More important is performance during inference.
Quoted Message : cheap would be subjective I guess\nconsidering A100 can go 10s of orders faster than K80\nat some point training for lesser time on expensive A100 would be cheaper than training for longer on cheaper K80\n\nthat being said I am reading flash attention this week, so might be able to answer after that üòÖ

Message : It may or may not impact you. I am not that conversant with off the shelf GPU HW and hence the need to test this. For inference accelerators, like Qualcomm's NPU or Google's TPUs, you get compilers/sdk that translates your trained model to best utilize the hardware during inference. LLMs are very tricky though, even run of the mill LSTMs for that matter, and we used to continuously run into lot more nuances there.
Quoted Message : Let's say for any QnA or text summarisation task for a domain specific model (assume Llama-30B fine-tuned works well), and less than 2K tokens a query, if I can train using a P2/P3 8xlarge and then switch to a V100 during inference, does it affect my performance? \n\nI am not able to comprehend of the same attention matrix can behave differently. I an guessing the optimisation comes not purely due to more cores and better I/O but advanced data representation at compile time. The metadata to make that happen could be non-tranferable across architectures. All of this is in my head, I may be absolutely wrong.

Message : danke friends, learnt more about Inference optim and GPUs in this convo than 4 hours of Googling and reading blogs üôè

Message : ChatGPT Plugins will be rolled out to _all_ ChatGPT Plus ($20/mo) users in the coming week
https://twitter.com/sama/status/1657143368198279168

Message : What's stopping you from running a small experiment with off the shelf model with these GPUs to find throughout / $ on a single GPU? 

When going to multi GPU on same machine / multiple machine setup, the metric gets more complicated to compute and assumptions depend on your usecase
Quoted Message : Thanks for the detailed response Chirag. The first paragraph is a great chronological summary. I'm aware of what you mentioned in the 2,3,4 paragraphs. My question is primarily around the cost/time trade-offs while choosing a specific hardware during training, and the switching to something else during inference.\n\nFor example, if I train on A100s and get my model and then I want to host on K80 or P100, I am bound to loose the Fast Attention properties because that architecture doesn't support that optimisation. Can I do the opposite? Train on cheap K80 or P100 and then host on V100 to get all matrix multiplication efficiency boost?

Message : How much of it can be attributed to Bard?

Bard is surprisingly good for some use-cases but hallucinates still
Quoted Message : ChatGPT Plugins will be rolled out to _all_ ChatGPT Plus ($20/mo) users in the coming week\nhttps://twitter.com/sama/status/1657143368198279168

Message : Nothing, I plan to do that. Was looking for suggestions.
Quoted Message : What's stopping you from running a small experiment with off the shelf model with these GPUs to find throughout / $ on a single GPU? \n\nWhen going to multi GPU on same machine / multiple machine setup, the metric gets more complicated to compute and assumptions depend on your usecase

Message : Weights maybe the same but set of operations  performed / opset might be different for different card generations.
Quoted Message : Let's say for any QnA or text summarisation task for a domain specific model (assume Llama-30B fine-tuned works well), and less than 2K tokens a query, if I can train using a P2/P3 8xlarge and then switch to a V100 during inference, does it affect my performance? \n\nI am not able to comprehend of the same attention matrix can behave differently. I an guessing the optimisation comes not purely due to more cores and better I/O but advanced data representation at compile time. The metadata to make that happen could be non-tranferable across architectures. All of this is in my head, I may be absolutely wrong.

Message : Haven't found a use case where Bard is better than GPT4 yet
Quoted Message : How much of it can be attributed to Bard?\n\nBard is surprisingly good for some use-cases but hallucinates still

Message : https://youtu.be/u_dSUtp4eM8

Palm2 is better in some tasks
Quoted Message : Haven't found a use case where Bard is better than GPT4 yet

Message : Clearly in multilingual capability but also in some other tasks in english too

Message : Surfing the web and embedded "Google it"

Ask it to summarize yesterday's news or for a weather update for the coming week
Quoted Message : Haven't found a use case where Bard is better than GPT4 yet

Message : ‚Äé<attached: 00003546-PHOTO-2023-05-13-14-40-17.jpg>

Message : ‚Äé<attached: 00003547-PHOTO-2023-05-13-14-40-41.jpg>

Message : Plus its blazing fast compared to the web browsing plugin probably because its google and they have internal indexes and tpus

Message : ‚Äé<attached: 00003549-PHOTO-2023-05-13-14-44-29.jpg>
Quoted Message :  2023_05_13_3A6489077162222C93C2.jpeg

Message : Plug-in mila nahi hai so far :( 

But yeah, it's a very good way to search the web + summarize news

Message : Like a follow-up prompt could be summarize what social media is saying about this and the results are pretty accurate
Quoted Message :  2023_05_13_3A6489077162222C93C2.jpeg

Message : And there's always the Google It button below for us to click

Message : But this is so wrong? Am i getting something wrong?
Quoted Message :  2023_05_13_3A4D94C052A74C2B5EDF.jpeg

Message : ‚Äé<attached: 00003554-PHOTO-2023-05-13-14-46-01.jpg>

Message : The crazy part is that in the exit polls it shows correctly, guess this is where the chat rlhf stuff is lacking
Quoted Message :  2023_05_13_3A6489077162222C93C2.jpeg

Message : With my limited usage.

I found Bard faster than GPT4. One reason could be Bard publishes full completion output but GPT4 uses SSE/https.

Bard hallucinates more than GPT4. For example "Compare supabase and appwrite" prompt Bard mentions that appwrite supports PostgreSQL which is not true.
Quoted Message : Haven't found a use case where Bard is better than GPT4 yet

Message : Bard is worse at code than my intern, GPT4 is better
Quoted Message : With my limited usage.\n\nI found Bard faster than GPT4. One reason could be Bard publishes full completion output but GPT4 uses SSE/https.\n\nBard hallucinates more than GPT4. For example \"Compare supabase and appwrite\" prompt Bard mentions that appwrite supports PostgreSQL which is not true.

Message : ‚Äé<attached: 00003559-PHOTO-2023-05-13-15-44-16.jpg>

Message : ‚Äé<attached: 00003560-PHOTO-2023-05-13-15-44-17.jpg>

Message : "During exams, always attempt to answer the questions even though you don't know the real answer, but never leave any questions" - AI learned from students
Quoted Message :  2023_05_13_3EB0FD5E36A2E8134A0434.jpeg

Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : Human evaluators write code for the model to train on, even do stuff like time and space complexity analysis

Message : My friend used to work with them
Quoted Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : Regarding Software Engineer rates: Which Software Engineer? TCS, Swiggy, Atlassian or Quant funds?
Quoted Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : I saw a blog post recently which said they paid $15/hr to contractors.
Going by that number, it comes to ~25lpa for 40hrs worked per week.
Quoted Message : Regarding Software Engineer rates: Which Software Engineer? TCS, Swiggy, Atlassian or Quant funds?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : With my limited usage.

I found Bard faster than GPT4. One reason could be Bard publishes full completion output but GPT4 uses SSE/https.

Bard hallucinates more than GPT4. For example "Compare supabase and appwrite" prompt Bard mentions that appwrite supports PostgreSQL which is not true.
Quoted Message : Haven't found a use case where Bard is better than GPT4 yet

Message : Bard is worse at code than my intern, GPT4 is better
Quoted Message : With my limited usage.\n\nI found Bard faster than GPT4. One reason could be Bard publishes full completion output but GPT4 uses SSE/https.\n\nBard hallucinates more than GPT4. For example \"Compare supabase and appwrite\" prompt Bard mentions that appwrite supports PostgreSQL which is not true.

Message : ‚Äé<attached: 00003559-PHOTO-2023-05-13-15-44-16.jpg>

Message : ‚Äé<attached: 00003560-PHOTO-2023-05-13-15-44-17.jpg>

Message : "During exams, always attempt to answer the questions even though you don't know the real answer, but never leave any questions" - AI learned from students
Quoted Message :  2023_05_13_3EB0FD5E36A2E8134A0434.jpeg

Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : Human evaluators write code for the model to train on, even do stuff like time and space complexity analysis

Message : My friend used to work with them
Quoted Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : Regarding Software Engineer rates: Which Software Engineer? TCS, Swiggy, Atlassian or Quant funds?
Quoted Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : I saw a blog post recently which said they paid $15/hr to contractors.
Going by that number, it comes to ~25lpa for 40hrs worked per week.
Quoted Message : Regarding Software Engineer rates: Which Software Engineer? TCS, Swiggy, Atlassian or Quant funds?

Message : 35lpa
Quoted Message : Regarding Software Engineer rates: Which Software Engineer? TCS, Swiggy, Atlassian or Quant funds?

Message : They have many more projects, more deeper than just ranking, happy to take questions also. üòÇ

Message : Goddamn!
Quoted Message : 35lpa

Message : I thought openai does data labelling through Surge AI?

Message : This is a moonlight btw
Quoted Message : 35lpa

Message : ‚Äé<attached: 00003574-PHOTO-2023-05-13-21-11-00.jpg>

Message : So basically Indians are leading in AI in every possible way :p
Quoted Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : AI stands for Anonymous Indians
Quoted Message : So basically Indians are leading in AI in every possible way :p

Message : Is it wfh though?
Quoted Message : 35lpa

Message : I expect all the prize money is in this photo?
Quoted Message :  2023_05_13_3AE088F1E3F2420AF5DE.jpeg

Message : We're doing an edtech project
Quoted Message : I expect all the prize money is in this photo?

Message : The name? 
parh.ai

Message : The name deserves an award in itself üòÅ
Quoted Message : The name? \nparh.ai

Message : hey good people, had one simple question:

in running chats with a bot, upon receiving a new message from the user, currently I try to find the exact question [using the LLM itself] that user is asking before doing similarity search. I do this because sometimes users type "with Sam" after "can you give me a brief summary of meeting"

new message -> fetch chat history + new message -> prompt the LLM to put exact question that user is asking -> similarity search -> LLM -> output

wanted to know if there are more creative solves for this

Message : Do you want to do similarity search based on new message from user?
Quoted Message : hey good people, had one simple question:\n\nin running chats with a bot, upon receiving a new message from the user, currently I try to find the exact question [using the LLM itself] that user is asking before doing similarity search. I do this because sometimes users type \"with Sam\" after \"can you give me a brief summary of meeting\"\n\nnew message -> fetch chat history + new message -> prompt the LLM to put exact question that user is asking -> similarity search -> LLM -> output\n\nwanted to know if there are more creative solves for this

Message : Why not do the similarity search directly? What‚Äôs the LLM outputting on the first call?
Quoted Message : hey good people, had one simple question:\n\nin running chats with a bot, upon receiving a new message from the user, currently I try to find the exact question [using the LLM itself] that user is asking before doing similarity search. I do this because sometimes users type \"with Sam\" after \"can you give me a brief summary of meeting\"\n\nnew message -> fetch chat history + new message -> prompt the LLM to put exact question that user is asking -> similarity search -> LLM -> output\n\nwanted to know if there are more creative solves for this

Message : ‚Äé<attached: 00003586-PHOTO-2023-05-13-22-51-51.jpg>

Message : Have LLMs analyze this

Message : What questions are interesting you? Can throw the csv to code interpreter and ask questions
Quoted Message : Have LLMs analyze this

Message : Are these the only columns

Message : What's the churned senders Column mean actually?

Message : People who have replied or sent a message here earlier but then stopped, presumably because they've muted or archived this group.
Quoted Message : What's the churned senders Column mean actually?

Message : Ok.

Message : Got it. At the moment, not a lot of questions to ask.

Message : LOL what were the themes for last few questions/statements from churned senders & group responses thereof, and are there any patterns there.
Quoted Message : What questions are interesting you? Can throw the csv to code interpreter and ask questions

Message : But if all the Colmns are the ones being shown. It's not really much that can be asked
Quoted Message : LOL what were the themes for last few questions/statements from churned senders & group responses thereof, and are there any patterns there.

Message : yes. like if this was a chat happening

AI: how can I help?
User: what's the stock price for
AI: sorry, can you share for what?
User: tsla

now in my knowledge base, I can't do similiarity search for just "tsla" and will need a question like "stock price of tsla" before hitting the DB
Quoted Message : Do you want to do similarity search based on new message from user?

Message : Prompt engineering here
Quoted Message : yes. like if this was a chat happening\n\nAI: how can I help?\nUser: what's the stock price for\nAI: sorry, can you share for what?\nUser: tsla\n\nnow in my knowledge base, I can't do similiarity search for just \"tsla\" and will need a question like \"stock price of tsla\" before hitting the DB

Message : Most active time period?
Most discussed topics/theme?

A few fun queries: Avg time to get a reply, Active replies etc
Quoted Message :  2023_05_13_3EB07F6AF6EA16F4EDFEFC.jpeg

Message : Thought this might be interesting to you: HyDE ‚Äî https://arxiv.org/abs/2212.10496

Has some implementations
Quoted Message : yes. like if this was a chat happening\n\nAI: how can I help?\nUser: what's the stock price for\nAI: sorry, can you share for what?\nUser: tsla\n\nnow in my knowledge base, I can't do similiarity search for just \"tsla\" and will need a question like \"stock price of tsla\" before hitting the DB

Message : Please contrib functions/code here 
https://github.com/nirantk/nirantk.github.io/tree/main/community_dev

üôè
Quoted Message : Most active time period?\nMost discussed topics/theme?\n\nA few fun queries: Avg time to get a reply, Active replies etc

Message : can you explain more? prompt what on which step?

also corner case of it might not always be just 4 last chats that mentions the context of the question user is asking and instead might be something mentioned in last 10 chats

what I'm doing right now is to summarise chat history and then pass new message of user and prompt LLM to generate a "question with full context"
Quoted Message : Prompt engineering here

Message : checking, thanks for sharing üôèüèª
Quoted Message : Thought this might be interesting to you: HyDE ‚Äî https://arxiv.org/abs/2212.10496\n\nHas some implementations

Message : "question with full context" ‚Üí give it a name as well and a conference workshop paper idea right there üòÖ
Quoted Message : can you explain more? prompt what on which step?\n\nalso corner case of it might not always be just 4 last chats that mentions the context of the question user is asking and instead might be something mentioned in last 10 chats\n\nwhat I'm doing right now is to summarise chat history and then pass new message of user and prompt LLM to generate a \"question with full context\"

Message : Arrey yaar. I'd done this for work a month back. Should publish this üòÇ
Quoted Message : \"question with full context\" ‚Üí give it a name as well and a conference workshop paper idea right there üòÖ

Message : I'll message you on this
Quoted Message : can you explain more? prompt what on which step?\n\nalso corner case of it might not always be just 4 last chats that mentions the context of the question user is asking and instead might be something mentioned in last 10 chats\n\nwhat I'm doing right now is to summarise chat history and then pass new message of user and prompt LLM to generate a \"question with full context\"

Message : You can ask GPT4 to write the paper as well, just give all the titles, method outline and results üòÇ
Quoted Message : Arrey yaar. I'd done this for work a month back. Should publish this üòÇ

Message : Haan. Although long form mai Claude is very good. I'm liking it a little more. But gpt4 is very powerful
Quoted Message : You can ask GPT4 to write the paper as well, just give all the titles, method outline and results üòÇ

Message : for picking relevant messages
- Langchain has a few memory management techniques like storing summary of previous chats beyond a certain context
- embeddings to filter out relevant messages from old chat (not sure if there in langchain but I've used this)

Prompt to basically tell the AI to only focus on conversations and then tell it to generate a response if its not in the context

You might want to tweak your params here. temperature etc to avoid further hallucinations
Quoted Message : I'll message you on this

Message : How are you exporting files? Automated or doing it manually everyday?
Quoted Message : Please contrib functions/code here \nhttps://github.com/nirantk/nirantk.github.io/tree/main/community_dev\n\nüôè


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Please contrib functions/code here 
https://github.com/nirantk/nirantk.github.io/tree/main/community_dev

üôè
Quoted Message : Most active time period?\nMost discussed topics/theme?\n\nA few fun queries: Avg time to get a reply, Active replies etc

Message : can you explain more? prompt what on which step?

also corner case of it might not always be just 4 last chats that mentions the context of the question user is asking and instead might be something mentioned in last 10 chats

what I'm doing right now is to summarise chat history and then pass new message of user and prompt LLM to generate a "question with full context"
Quoted Message : Prompt engineering here

Message : checking, thanks for sharing üôèüèª
Quoted Message : Thought this might be interesting to you: HyDE ‚Äî https://arxiv.org/abs/2212.10496\n\nHas some implementations

Message : "question with full context" ‚Üí give it a name as well and a conference workshop paper idea right there üòÖ
Quoted Message : can you explain more? prompt what on which step?\n\nalso corner case of it might not always be just 4 last chats that mentions the context of the question user is asking and instead might be something mentioned in last 10 chats\n\nwhat I'm doing right now is to summarise chat history and then pass new message of user and prompt LLM to generate a \"question with full context\"

Message : Arrey yaar. I'd done this for work a month back. Should publish this üòÇ
Quoted Message : \"question with full context\" ‚Üí give it a name as well and a conference workshop paper idea right there üòÖ

Message : I'll message you on this
Quoted Message : can you explain more? prompt what on which step?\n\nalso corner case of it might not always be just 4 last chats that mentions the context of the question user is asking and instead might be something mentioned in last 10 chats\n\nwhat I'm doing right now is to summarise chat history and then pass new message of user and prompt LLM to generate a \"question with full context\"

Message : You can ask GPT4 to write the paper as well, just give all the titles, method outline and results üòÇ
Quoted Message : Arrey yaar. I'd done this for work a month back. Should publish this üòÇ

Message : Haan. Although long form mai Claude is very good. I'm liking it a little more. But gpt4 is very powerful
Quoted Message : You can ask GPT4 to write the paper as well, just give all the titles, method outline and results üòÇ

Message : for picking relevant messages
- Langchain has a few memory management techniques like storing summary of previous chats beyond a certain context
- embeddings to filter out relevant messages from old chat (not sure if there in langchain but I've used this)

Prompt to basically tell the AI to only focus on conversations and then tell it to generate a response if its not in the context

You might want to tweak your params here. temperature etc to avoid further hallucinations
Quoted Message : I'll message you on this

Message : How are you exporting files? Automated or doing it manually everyday?
Quoted Message : Please contrib functions/code here \nhttps://github.com/nirantk/nirantk.github.io/tree/main/community_dev\n\nüôè

Message : Yes, manual
Quoted Message : How are you exporting files? Automated or doing it manually everyday?

Message : Never Split the Difference: Negotiating As If Your Life Depended On It by Chris Voss.

GPT-4 was trained on this book and can implement Chris Voss‚Äô negotiating strategies quite effectively.

Message : I know someone whose favorite prompt is : Based on Robert Greene‚Äôs advice in xyz book, how should I deal with following situation.  
Getting specific and not generic gyaan is a good use case .
Quoted Message : Never Split the Difference: Negotiating As If Your Life Depended On It by Chris Voss.\n\nGPT-4 was trained on this book and can implement Chris Voss‚Äô negotiating strategies quite effectively.

Message : can also do something like, take a chapter of the book you like to base your answer on, feed it to claude 100k and ask it to asnwer in the tone of that chapter
Quoted Message : Never Split the Difference: Negotiating As If Your Life Depended On It by Chris Voss.\n\nGPT-4 was trained on this book and can implement Chris Voss‚Äô negotiating strategies quite effectively.

Message : Dealing with the same problems. There is a query decomposition module in llamaindex that jerry demo'd in the gen ai hackathon that I'm eager to try out
Quoted Message : hey good people, had one simple question:\n\nin running chats with a bot, upon receiving a new message from the user, currently I try to find the exact question [using the LLM itself] that user is asking before doing similarity search. I do this because sometimes users type \"with Sam\" after \"can you give me a brief summary of meeting\"\n\nnew message -> fetch chat history + new message -> prompt the LLM to put exact question that user is asking -> similarity search -> LLM -> output\n\nwanted to know if there are more creative solves for this

Message : Query bundle is something you need to try out.
Quoted Message : Dealing with the same problems. There is a query decomposition module in llamaindex that jerry demo'd in the gen ai hackathon that I'm eager to try out

Message : Ok since people are DMing me - here are more deets on this -

This is a friend from Banaras who got this on a contract basis from Turing. He can't get us a referral either so no luck there :D

The more exciting part, though, is the sheer level of human training they are doing, which raises interesting questions about how intelligent their models are.

He said there are about 350 people that join the global meeting. And they run like 10s of different campaigns across that team.

He worked on 5 of them -

1. Plugins - Write lots of plugins, rate the responses on how accurately the model calls the plugins and give natural language feedback.

2. RLHF Ranking + Natural language feedback on responses from chatgpt and their internal QA testers + everything else they work on

3. Coding tasks - ask gpt to write code for common problems, rate the code it writes, provide feedback on how it could write better, give it time/space complexity analysis.

4. Maths - design chat sessions where someone is trying to solve maths problems - then they run those sessions with chatgpt to make sure it follows the script & gets to an answer

5. Truncation - In cases where it generates too verbose an output or spaghetti code, tell it how to truncate the output
Quoted Message : TIL - openai pays indian contractors software engineer rates to train its models for code and maths

Message : What this implies IMO, is that these models are really still just awesome search engines rather than general reasoning engines. (this is something people have been suspecting since the first time gpt3 paper did 2-digit arithmetic - it's probably parroting it from some table online)

Message : Langchain planning to host a webinar about Education and the role these tools, specially Langchain can play there

https://www.crowdcast.io/c/q5y8g08f1f74

Message : ‚Äé<attached: 00003628-PHOTO-2023-05-14-12-19-44.jpg>

Message : Software subscriptions also 20% more expensive upfront 
OpenAI bills just got more prohibitive

Message : No, no. They got cheaper for funded companies. They will just not move money to India for these transactions anymore. Have a Delaware LLC, keep the money there.
Quoted Message : Software subscriptions also 20% more expensive upfront \nOpenAI bills just got more prohibitive

Message : ‚Äé<attached: 00003631-GIF-2023-05-14-12-24-30.mp4>

Message : Anyone know of colo providers in India? 

Idea being I buy hardware and then pay them to house my server and I pay for rent and internet.

Message : I intend to just ship them to @91740765xxxx's house?
Quoted Message : Anyone know of colo providers in India? \n\nIdea being I buy hardware and then pay them to house my server and I pay for rent and internet.

Message : üòÄ

Message : What's "colo"?

Message : Colocation

Message : I see

Message : https://www.esds.co.in/colocation-services?gclid=CjwKCAjwjYKjBhB5EiwAiFdSfsRbekZqh6173zJpqhDv4xaODkp1-2UxTy6mT2JSG8Vvg1nG9AGfqhoCbHAQAvD_BwE

Message : This is an example. 

Was looking for recommendations. (I know there are providers in India but don't know anyone whove used them)

Message : In the spirit of suggesting solutions, for those doing >$100K in business/earnings: 

$500 to setup, $100/year recurring, $1000 annual expense ‚Äî voila, you've a US entity: https://stripe.com/en-in/atlas

You can then head to privacy.com and use Virtual Credit Cards for online transactions.
Quoted Message : Software subscriptions also 20% more expensive upfront \nOpenAI bills just got more prohibitive

Message : e2enetworks? NSE listed company
Quoted Message : This is an example. \n\nWas looking for recommendations. (I know there are providers in India but don't know anyone whove used them)

Message : They don't do colo AFAIK. I've used their stuff in the past.
Quoted Message : e2enetworks? NSE listed company

Message : You also get openai credits if you‚Äôre a stripe atlas customer ü§©
Quoted Message : In the spirit of suggesting solutions, for those doing >$100K in business/earnings: \n\n$500 to setup, $100/year recurring, $1000 annual expense ‚Äî voila, you've a US entity: https://stripe.com/en-in/atlas\n\nYou can then head to privacy.com and use Virtual Credit Cards for online transactions.

Message : no gotchas like "valid for only 1 year" ?
Quoted Message : You also get openai credits if you‚Äôre a stripe atlas customer ü§©

Message : https://twitter.com/jeff_weinstein/status/1636035301536833538?s=20

(2500$)
Quoted Message : no gotchas like \"valid for only 1 year\" ?

Message : üëç. i meant whether they expire within a certain timeframe. like how the trial $18 expired in 3 months.
Quoted Message : https://twitter.com/jeff_weinstein/status/1636035301536833538?s=20\n\n(2500$)

Message : ICYMI: Community's Generative AI May Meetups: 

Open for all:
https://hasgeek.com/generativeAI/may-meetup/

Women in AI:
https://hasgeek.com/generativeAI/women-in-ai-meetup/

Message : 644fce359d9b266dd4f60a80_Trends in Chinas LLMs.pdf ‚Ä¢ ‚Äé14 pages ‚Äé<attached: 00003649-644fce359d9b266dd4f60a80_Trends in Chinas LLMs.pdf>

Message : Request:  Please add 1-2 lines about what you found interesting and why we should read this when sharing a 14 page pdf üòÖ
Quoted Message :  2023_05_14_5EECB0DEF4DB0C9307B5.pdf

Message : Sure. 

For those interested in building global AI infrastructure they will benefit from perhaps a first peek into how Chinese companies are approaching their model developments. The key players and where they stand.

Not a lot of information on what‚Äôs happening behind the curtain wall and just like for some things Chinese cloud providers tended to be cheaper / better than US hyperscalers.

Didn‚Äôt find much to change my assumptions from this report but sharing in case anyone here is going deeper into infra engineering

New to the group and please excuse if that‚Äôs not the protocol
Quoted Message : Request:  Please add 1-2 lines about what you found interesting and why we should read this when sharing a 14 page pdf üòÖ

Message : ‚Äé<attached: 00003652-PHOTO-2023-05-14-13-25-14.jpg>

Message : ‚Äé<attached: 00003653-PHOTO-2023-05-14-13-25-15.jpg>

Message : https://twitter.com/goodside/status/1657396491676164096 üò∂‚Äçüå´Ô∏è
Quoted Message :  2023_05_13_3EB0FD5E36A2E8134A0434.jpeg

Message : ‚Äé<attached: 00003655-PHOTO-2023-05-14-13-35-11.jpg>
Quoted Message : https://twitter.com/goodside/status/1657396491676164096 üò∂‚Äçüå´Ô∏è

Message : ‚Äé<attached: 00003656-PHOTO-2023-05-14-13-35-12.jpg>

Message : Wow

Message : Bard is underwhelming for reasoning - where it works is that it's connected to the web & can do things that GPT4 cannot w/o the browser plug-in 

Do not have the Browser Plug-in to compare performance & accuracy

Message : Simple prompt: try asking both for LangChain, GPT will respond saying nothing existed in the training corpus while Bard does this bit well atleast


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Request:  Please add 1-2 lines about what you found interesting and why we should read this when sharing a 14 page pdf üòÖ
Quoted Message :  2023_05_14_5EECB0DEF4DB0C9307B5.pdf

Message : Sure. 

For those interested in building global AI infrastructure they will benefit from perhaps a first peek into how Chinese companies are approaching their model developments. The key players and where they stand.

Not a lot of information on what‚Äôs happening behind the curtain wall and just like for some things Chinese cloud providers tended to be cheaper / better than US hyperscalers.

Didn‚Äôt find much to change my assumptions from this report but sharing in case anyone here is going deeper into infra engineering

New to the group and please excuse if that‚Äôs not the protocol
Quoted Message : Request:  Please add 1-2 lines about what you found interesting and why we should read this when sharing a 14 page pdf üòÖ

Message : ‚Äé<attached: 00003652-PHOTO-2023-05-14-13-25-14.jpg>

Message : ‚Äé<attached: 00003653-PHOTO-2023-05-14-13-25-15.jpg>

Message : https://twitter.com/goodside/status/1657396491676164096 üò∂‚Äçüå´Ô∏è
Quoted Message :  2023_05_13_3EB0FD5E36A2E8134A0434.jpeg

Message : ‚Äé<attached: 00003655-PHOTO-2023-05-14-13-35-11.jpg>
Quoted Message : https://twitter.com/goodside/status/1657396491676164096 üò∂‚Äçüå´Ô∏è

Message : ‚Äé<attached: 00003656-PHOTO-2023-05-14-13-35-12.jpg>

Message : Wow

Message : Bard is underwhelming for reasoning - where it works is that it's connected to the web & can do things that GPT4 cannot w/o the browser plug-in 

Do not have the Browser Plug-in to compare performance & accuracy

Message : Simple prompt: try asking both for LangChain, GPT will respond saying nothing existed in the training corpus while Bard does this bit well atleast

Message : I feel Phind.com (GPT-4 under the hood tho) somehow is in between, and works best for reasoning + information retrieval use cases.
Quoted Message : Bard is underwhelming for reasoning - where it works is that it's connected to the web & can do things that GPT4 cannot w/o the browser plug-in \n\nDo not have the Browser Plug-in to compare performance & accuracy

Message : ‚Äé<attached: 00003661-PHOTO-2023-05-14-13-41-50.jpg>
Quoted Message : Simple prompt: try asking both for LangChain, GPT will respond saying nothing existed in the training corpus while Bard does this bit well atleast

Message : ‚Äé<attached: 00003662-PHOTO-2023-05-14-13-41-58.jpg>

Message : This raises so many thoughts üí≠üòÖ
Quoted Message :  2023_05_14_3EB00AC0FB9DC603FEA748.jpeg

Message : If Shakespeare knew we're calling this a Bard, he'd roll in his grave.
Quoted Message : This raises so many thoughts üí≠üòÖ

Message : Try comparing for UPSC predictions? And validate in a few weeks üòÖ

Message : UPSC predictions? There is a betting market on who will become IAS now?
Quoted Message : Try comparing for UPSC predictions? And validate in a few weeks üòÖ

Message : This is w/ Browser Plug-in?
Quoted Message :  2023_05_14_3EB02AAD128BC3408F5D54.jpeg

Message : UPSC prelims exam is due in a few weeks. So basis old question papers, predict major themes for current year exam
Quoted Message : UPSC predictions? There is a betting market on who will become IAS now?

Message : I've the entirety of humanity's history on the tip of my fingers. I am not using that for anything boring. ü§£
Quoted Message : UPSC prelims exam is due in a few weeks. So basis old question papers, predict major themes for current year exam

Message : ‚Äé<attached: 00003670-GIF-2023-05-14-13-46-48.mp4>

Message : Either it underlearns, or it overlearns, here's an example of the latter: https://masto.ai/@amodm/110353717014726946
Quoted Message :  2023_05_14_3EB00AC0FB9DC603FEA748.jpeg

Message : Yes. Have used a few across India from udaan.
Quoted Message : Anyone know of colo providers in India? \n\nIdea being I buy hardware and then pay them to house my server and I pay for rent and internet.

Message : Actions like "making it up" is what brings a bad name to AI, why is Pichai doing this escapes me.
Quoted Message : Either it underlearns, or it overlearns, here's an example of the latter: https://masto.ai/@amodm/110353717014726946

Message : The dream is to make it a colo one step at a time üòÖ
Quoted Message : I intend to just ship them to @9174xxxxxxxx's house?

Message : ‚ÄúI saw the greatest minds of my generation

embrace 175b param models capable of creativity, reasoning, the knowledge of a thousand Libraries of Alexandria

rent massive clouds of $200,000 GPUs flashed to nanometer precision

to do document question answering with semantic search‚Äù


Having UPSC questions doesn‚Äôt seem so bad in comparison üòù
Quoted Message : I've the entirety of humanity's history on the tip of my fingers. I am not using that for anything boring. ü§£

Message : ‚Äé<attached: 00003676-PHOTO-2023-05-14-14-02-51.jpg>
Quoted Message : UPSC prelims exam is due in a few weeks. So basis old question papers, predict major themes for current year exam

Message : Can anyone with ChatGPT browsing plugin try this
https://twitter.com/averma12/status/1657302210760560640
@91773788xxxx maybe?

Message : Imagine sitting in a meeting explaining how AI tech works. In my experience ML explanations were always hard in senior management levels. My glance experience was quite satisfactory tho.
Quoted Message :  2023_05_14_3EB03B00E1D274878350B3.jpeg

Message : ‚Äé<attached: 00003679-PHOTO-2023-05-14-14-08-47.jpg>
Quoted Message : Can anyone with ChatGPT browsing plugin try this\nhttps://twitter.com/averma12/status/1657302210760560640\n@9177xxxxxxxx maybe?

Message : ya this is correct

Message : I am curious how long before GPT is forced to add such a capability! Its a singificant problem for not having latest knowledge
Quoted Message : Simple prompt: try asking both for LangChain, GPT will respond saying nothing existed in the training corpus while Bard does this bit well atleast

Message : GPT has this capability for at least last 2 months
Quoted Message : I am curious how long before GPT is forced to add such a capability! Its a singificant problem for not having latest knowledge

Message : So it is trained on latest knowledge? Or is it via browser plugin?
Quoted Message : GPT has this capability for at least last 2 months

Message : Ah, but increasingly, you wouldn't need to. 

An analogy would be explaining the science behind fission, in a discussion about nuclear proliferation.

Topically relevant, but can be abstracted away at certain levels
Quoted Message : Imagine sitting in a meeting explaining how AI tech works. In my experience ML explanations were always hard in senior management levels. My glance experience was quite satisfactory tho.

Message : via browser plugin
Quoted Message : So it is trained on latest knowledge? Or is it via browser plugin?

Message : On that note, need some help from a technical person here. I am trying to make use of my Notion knowledge base (lots books summaries, podcasts, articles, etc)  using OpenAI. Built a prorotype using langchain, chromaDb, and OpenAi embeddings. But anwers are very rudimentary.
How do I improve it?
Improve the prompts or any other tricks?

Message : Related to teaching. 

discovered about Gilbert Strang's final lecture @ MIT. Details for his email, linear algebra book and Livestream link >

https://www.linkedin.com/posts/consumableai_genai-gilbertstrang-linearalgebra-activity-7063390633398325248-VyLk?utm_source=share&utm_medium=member_android
Quoted Message : Ah, but increasingly, you wouldn't need to. \n\nAn analogy would be explaining the science behind fission, in a discussion about nuclear proliferation. \n\nTopically relevant, but can be abstracted away at certain levels

Message : +1

Also the speed. Any way to improve the speed of 3.5 turbo?
Quoted Message : On that note, need some help from a technical person here. I am trying to make use of my Notion knowledge base (lots books summaries, podcasts, articles, etc)  using OpenAI. Built a prorotype using langchain, chromaDb, and OpenAi embeddings. But anwers are very rudimentary.\nHow do I improve it?\nImprove the prompts or any other tricks?

Message : You can use streaming here
Quoted Message : +1\n\nAlso the speed. Any way to improve the speed of 3.5 turbo?

Message : ‚ÄéPOLL:
Any fans here for Gil Strang?
‚ÄéOPTION: Watched his video (11 votes)
‚ÄéOPTION: Watched at 2x (0 votes)
‚ÄéOPTION: Felt addicted (1 vote)
‚ÄéOPTION: Have his book/ notes (7 votes)

Message : I hear today is his last lecture. Or was it yesterday

Message : It's 16May 830PM IST

Message : Can you tell about how many tokens you're trying to generate here? That affects speed of model
Quoted Message : +1\n\nAlso the speed. Any way to improve the speed of 3.5 turbo?

Message : ‚Äé<attached: 00003694-PHOTO-2023-05-14-14-37-16.jpg>

Message : If you guys want to try any interesting VQA examples, please let me know!

Message : is vicuna multi modal?
Quoted Message :  2023_05_14_3EB01D8A692CD7321FAB47.jpeg

Message : is there any browsing plugin that can be used with langchain? if yes can someone link its manifest json file here?

Message : with langchain you can integrate the serp tool
Quoted Message : is there any browsing plugin that can be used with langchain? if yes can someone link its manifest json file here?

Message : I'm already using serp api as tool btw. would using a browser plugin change much?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚ÄéPOLL:
Any fans here for Gil Strang?
‚ÄéOPTION: Watched his video (11 votes)
‚ÄéOPTION: Watched at 2x (0 votes)
‚ÄéOPTION: Felt addicted (1 vote)
‚ÄéOPTION: Have his book/ notes (7 votes)

Message : I hear today is his last lecture. Or was it yesterday

Message : It's 16May 830PM IST

Message : Can you tell about how many tokens you're trying to generate here? That affects speed of model
Quoted Message : +1\n\nAlso the speed. Any way to improve the speed of 3.5 turbo?

Message : ‚Äé<attached: 00003694-PHOTO-2023-05-14-14-37-16.jpg>

Message : If you guys want to try any interesting VQA examples, please let me know!

Message : is vicuna multi modal?
Quoted Message :  2023_05_14_3EB01D8A692CD7321FAB47.jpeg

Message : is there any browsing plugin that can be used with langchain? if yes can someone link its manifest json file here?

Message : with langchain you can integrate the serp tool
Quoted Message : is there any browsing plugin that can be used with langchain? if yes can someone link its manifest json file here?

Message : I'm already using serp api as tool btw. would using a browser plugin change much?

Message : no.
Quoted Message : I'm already using serp api as tool btw. would using a browser plugin change much?

Message : serp api is pretty costly no?
Quoted Message : I'm already using serp api as tool btw. would using a browser plugin change much?

Message : yes it is costly $
Quoted Message : serp api is pretty costly no?

Message : Please advice this with disclaimer. If you use your personal Indian credit card to incorporate US entity then you have to follow RBI's FEMA compliances. It is easy to neglect small things which may cause issue at later stages. Specially how you move your money across the border. This article by Upekkha is good to learn about this topic https://www.upekkha.io/blog/indian-saas-startups-going-global-a-detailed-legal-incorporation-guide

This is an important quote mentioned in this article -
‚ÄúWe didn‚Äôt pay enough attention to how we recorded our personal investment in our own US company. Yes, you are supposed to have a specific form and remittance showing the RBI that you are buying shares in a foreign entity (even your own). This mistake and other small discoveries caused us several delays at the time of acquisition. These days it is a well-known fact but please do the process cleanly. Founders still ignore this fact.‚Äù - Raj Sheth, co-founder Recruiterbox.
Quoted Message : In the spirit of suggesting solutions, for those doing >$100K in business/earnings: \n\n$500 to setup, $100/year recurring, $1000 annual expense ‚Äî voila, you've a US entity: https://stripe.com/en-in/atlas\n\nYou can then head to privacy.com and use Virtual Credit Cards for online transactions.

Message : I suspect a lot of the second half complications is when you've an intent to involve a third party e.g. an investor, acquirer or similar. As long as it's just vendors and buyers ‚Äî only the first part should be applicable?
Quoted Message : Please advice this with disclaimer. If you use your personal Indian credit card to incorporate US entity then you have to follow RBI's FEMA compliances. It is easy to neglect small things which may cause issue at later stages. Specially how you move your money across the border. This article by Upekkha is good to learn about this topic https://www.upekkha.io/blog/indian-saas-startups-going-global-a-detailed-legal-incorporation-guide\n\nThis is an important quote mentioned in this article -\n‚ÄúWe didn‚Äôt pay enough attention to how we recorded our personal investment in our own US company. Yes, you are supposed to have a specific form and remittance showing the RBI that you are buying shares in a foreign entity (even your own). This mistake and other small discoveries caused us several delays at the time of acquisition. These days it is a well-known fact but please do the process cleanly. Founders still ignore this fact.‚Äù - Raj Sheth, co-founder Recruiterbox.

Message : Not entirely as you have to show your foreign holdings with your income tax (foreign bank account, equities etc) every year as well. Anyway I am not legal and compliance expert but my suggestion is  to use their advice before taking any steps.
Quoted Message : I suspect a lot of the second half complications is when you've an intent to involve a third party e.g. an investor, acquirer or similar. As long as it's just vendors and buyers ‚Äî only the first part should be applicable?

Message : This is a nightmare with services like firstbase positioning themselves as Indian founder friendly, but not paying attention to any of this

Message : Anyone here use a FEMA compliant service which is more template based and not a full overhead law firm that actually does it right ?

Message : https://docs.cohere.com/docs/llmu

LLM university by CohereAI

Message : Zomatos childgpt feature is neat deployment

Message : Passing about 2500 in context and prompt
Quoted Message : Can you tell about how many tokens you're trying to generate here? That affects speed of model

Message : Set max as 4096

Message : I've tried streaming, but still takes a bit of time to begin

Message : What is a bit of time? What is your tooling here? Llama Index/Langchain or something else?
Quoted Message : I've tried streaming, but still takes a bit of time to begin

Message : Varies. About 8 sec to 15 sec

Message : Using Langchain

Message : Doesn‚Äôt seem like it‚Äôs generating anything in real time 
It seems more like set of pre generated images and poems mapped to each possible response
Quoted Message : Zomatos childgpt feature is neat deployment

Message : ‚Äé<attached: 00003717-PHOTO-2023-05-14-15-07-24.jpg>

Message : Didn't stress test. It's be stupid if they still did that. Lol

Message : Is 8 sec normal

Message : Any way to improve that?

Message : It doesn't actually take time to begin once the prompt has been sent. Atleast not this long. Might need to check how langchain is handling the streaming request. What module does langchain use for this
Quoted Message : Using Langchain

Message : Langchain is Python async
Quoted Message : It doesn't actually take time to begin once the prompt has been sent. Atleast not this long. Might need to check how langchain is handling the streaming request. What module does langchain use for this

Message : I'm still confused on the time it takes to begin streaming the responses. In my experience 3.5 turbo is actually really fast.

Message : Unless the api is slow at that point

Message : Ah maybe

Message : Let me try a few things again

Message : On a related note, here's a q if you kind folks could help

Is this the normal flow for chat interfaces?

1. User asks a question from a browser client

2. Client invokes an API, which pipes back the response as a text stream using SSE

3. The response is displayed on the client. And when done, is written to a DB as a chat log

Does 2 have to come before 3? Is there a way to handle both in parallel?

Message : Anybody in this group building on top of https://data.gov.in/apis?

It will be interesting to take all of this data and allow people to ask questions like -> "Which sector GDP has slowed down over the years. Now compare that with stock prices for companies in that segment" ...

I think something can be built quickly on streamlit.

Message : Very cool idea
Quoted Message : Anybody in this group building on top of https://data.gov.in/apis?\n\nIt will be interesting to take all of this data and allow people to ask questions like -> \"Which sector GDP has slowed down over the years. Now compare that with stock prices for companies in that segment\" ...\n\nI think something can be built quickly on streamlit.

Message : Someone from the group shared that Chroma is pretty fast for upsert/insert operations ‚Äî beating Huggingface lib in the embedding operation. If someone has similar experiences, would love to hear!
Quoted Message :  2023_05_14_3EB08E927DAA5211EAC243.jpeg

Message : Hey everyone,
This is Nikhilesh. I'm a Product Manager at a startup where we utilize AI to minimize waste in manufacturing plants.
Currently, I'm investigating how we might leverage Large Language Models (LLMs) to assist plant personnel in performing root cause analyses. This would involve identifying causes for waste generation, machinery breakdowns, and pinpointing appropriate corrective actions.
As part of my research, I'm wrapping up Coursera's NLP specialization, which includes a focus on Transformers. While I've been doing some research, I haven't yet found any resources that specifically address the application of LLMs for analyzing Industrial Internet of Things (IIoT) data, or using raw data for similar purposes or integrating LLM with ERP data.
A rudimentary example of what I'm envisioning is something like this - "Based on sensor data, Machine X is exhibiting higher than usual vibrations, and maintenance hasn't been conducted for two months. It might be beneficial to utilize the free servicing that is due to expire in two months."
As you can clearly see, my thoughts are still in the early stages, but I'm excited about the potential. If any of you have come across resources or have experience that could help guide this exploration, I would greatly appreciate your insights. Thanks in advance!

Message : 1. What you are describing is an appealing Avenue but not exactly evidently appealing for a newcomer in the AI field. 
2. I mention this because Coursera in my opinion is vested in courses which indulge that target sector, even if it's something as inherently irresistible as AI
3. Plenty out there in regards to this though:
https://marcosanguineti.medium.com/the-importance-of-artificial-intelligence-for-industrial-engineers-how-ai-empowers-the-engineering-441cc94e92e8
Quoted Message : Hey everyone,\nThis is Nikhilesh. I'm a Product Manager at a startup where we utilize AI to minimize waste in manufacturing plants.\nCurrently, I'm investigating how we might leverage Large Language Models (LLMs) to assist plant personnel in performing root cause analyses. This would involve identifying causes for waste generation, machinery breakdowns, and pinpointing appropriate corrective actions.\nAs part of my research, I'm wrapping up Coursera's NLP specialization, which includes a focus on Transformers. While I've been doing some research, I haven't yet found any resources that specifically address the application of LLMs for analyzing Industrial Internet of Things (IIoT) data, or using raw data for similar purposes or integrating LLM with ERP data.\nA rudimentary example of what I'm envisioning is something like this - \"Based on sensor data, Machine X is exhibiting higher than usual vibrations, and maintenance hasn't been conducted for two months. It might be beneficial to utilize the free servicing that is due to expire in two months.\"\nAs you can clearly see, my thoughts are still in the early stages, but I'm excited about the potential. If any of you have come across resources or have experience that could help guide this exploration, I would greatly appreciate your insights. Thanks in advance!

Message : Google search term was

Message : Industrial process optimization ai

Message : Thanks, @91933437xxxx We do use good traditional (non LLM) models like good old Random Forest and more sophisticated versions for optimization. But I am looking to explore the NLP part to facilitate Root cause analysis.

Message : Got it

Message : You can't do both in parallel as you want to save the entire thing at once.
Quoted Message : On a related note, here's a q if you kind folks could help\n\nIs this the normal flow for chat interfaces?\n\n1. User asks a question from a browser client\n\n2. Client invokes an API, which pipes back the response as a text stream using SSE\n\n3. The response is displayed on the client. And when done, is written to a DB as a chat log\n\nDoes 2 have to come before 3? Is there a way to handle both in parallel?

Message : Got it. Thanks

Message : Interesting article:
https://www.forbes.com/sites/forbestechcouncil/2023/03/28/can-large-language-models-enhance-efficiency-in-industrial-robotics/
Quoted Message : Thanks, @9193xxxxxxxx We do use good traditional (non LLM) models like good old Random Forest and more sophisticated versions for optimization. But I am looking to explore the NLP part to facilitate Root cause analysis.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Someone from the group shared that Chroma is pretty fast for upsert/insert operations ‚Äî beating Huggingface lib in the embedding operation. If someone has similar experiences, would love to hear!
Quoted Message :  2023_05_14_3EB08E927DAA5211EAC243.jpeg

Message : Hey everyone,
This is Nikhilesh. I'm a Product Manager at a startup where we utilize AI to minimize waste in manufacturing plants.
Currently, I'm investigating how we might leverage Large Language Models (LLMs) to assist plant personnel in performing root cause analyses. This would involve identifying causes for waste generation, machinery breakdowns, and pinpointing appropriate corrective actions.
As part of my research, I'm wrapping up Coursera's NLP specialization, which includes a focus on Transformers. While I've been doing some research, I haven't yet found any resources that specifically address the application of LLMs for analyzing Industrial Internet of Things (IIoT) data, or using raw data for similar purposes or integrating LLM with ERP data.
A rudimentary example of what I'm envisioning is something like this - "Based on sensor data, Machine X is exhibiting higher than usual vibrations, and maintenance hasn't been conducted for two months. It might be beneficial to utilize the free servicing that is due to expire in two months."
As you can clearly see, my thoughts are still in the early stages, but I'm excited about the potential. If any of you have come across resources or have experience that could help guide this exploration, I would greatly appreciate your insights. Thanks in advance!

Message : 1. What you are describing is an appealing Avenue but not exactly evidently appealing for a newcomer in the AI field. 
2. I mention this because Coursera in my opinion is vested in courses which indulge that target sector, even if it's something as inherently irresistible as AI
3. Plenty out there in regards to this though:
https://marcosanguineti.medium.com/the-importance-of-artificial-intelligence-for-industrial-engineers-how-ai-empowers-the-engineering-441cc94e92e8
Quoted Message : Hey everyone,\nThis is Nikhilesh. I'm a Product Manager at a startup where we utilize AI to minimize waste in manufacturing plants.\nCurrently, I'm investigating how we might leverage Large Language Models (LLMs) to assist plant personnel in performing root cause analyses. This would involve identifying causes for waste generation, machinery breakdowns, and pinpointing appropriate corrective actions.\nAs part of my research, I'm wrapping up Coursera's NLP specialization, which includes a focus on Transformers. While I've been doing some research, I haven't yet found any resources that specifically address the application of LLMs for analyzing Industrial Internet of Things (IIoT) data, or using raw data for similar purposes or integrating LLM with ERP data.\nA rudimentary example of what I'm envisioning is something like this - \"Based on sensor data, Machine X is exhibiting higher than usual vibrations, and maintenance hasn't been conducted for two months. It might be beneficial to utilize the free servicing that is due to expire in two months.\"\nAs you can clearly see, my thoughts are still in the early stages, but I'm excited about the potential. If any of you have come across resources or have experience that could help guide this exploration, I would greatly appreciate your insights. Thanks in advance!

Message : Google search term was

Message : Industrial process optimization ai

Message : Thanks, @91933437xxxx We do use good traditional (non LLM) models like good old Random Forest and more sophisticated versions for optimization. But I am looking to explore the NLP part to facilitate Root cause analysis.

Message : Got it

Message : You can't do both in parallel as you want to save the entire thing at once.
Quoted Message : On a related note, here's a q if you kind folks could help\n\nIs this the normal flow for chat interfaces?\n\n1. User asks a question from a browser client\n\n2. Client invokes an API, which pipes back the response as a text stream using SSE\n\n3. The response is displayed on the client. And when done, is written to a DB as a chat log\n\nDoes 2 have to come before 3? Is there a way to handle both in parallel?

Message : Got it. Thanks

Message : Interesting article:
https://www.forbes.com/sites/forbestechcouncil/2023/03/28/can-large-language-models-enhance-efficiency-in-industrial-robotics/
Quoted Message : Thanks, @9193xxxxxxxx We do use good traditional (non LLM) models like good old Random Forest and more sophisticated versions for optimization. But I am looking to explore the NLP part to facilitate Root cause analysis.

Message : Yes get a good lawyer here, especially if you plan to do a subsidiary too (which you probably will need if you are based out of india)
Quoted Message : Please advice this with disclaimer. If you use your personal Indian credit card to incorporate US entity then you have to follow RBI's FEMA compliances. It is easy to neglect small things which may cause issue at later stages. Specially how you move your money across the border. This article by Upekkha is good to learn about this topic https://www.upekkha.io/blog/indian-saas-startups-going-global-a-detailed-legal-incorporation-guide\n\nThis is an important quote mentioned in this article -\n‚ÄúWe didn‚Äôt pay enough attention to how we recorded our personal investment in our own US company. Yes, you are supposed to have a specific form and remittance showing the RBI that you are buying shares in a foreign entity (even your own). This mistake and other small discoveries caused us several delays at the time of acquisition. These days it is a well-known fact but please do the process cleanly. Founders still ignore this fact.‚Äù - Raj Sheth, co-founder Recruiterbox.

Message : Using proxy nginx/envoy you can do. check this blog something similar you can do adding extra things in proxy to publish SSE response to some queue as well.

https://medium.com/blogging-greymatter-io/server-sent-events-http-2-and-envoy-6927c70368bb
Quoted Message : On a related note, here's a q if you kind folks could help\n\nIs this the normal flow for chat interfaces?\n\n1. User asks a question from a browser client\n\n2. Client invokes an API, which pipes back the response as a text stream using SSE\n\n3. The response is displayed on the client. And when done, is written to a DB as a chat log\n\nDoes 2 have to come before 3? Is there a way to handle both in parallel?

Message : Thanks a bunch. Will look through

Message : ‚Äé<attached: 00003744-PHOTO-2023-05-14-18-08-45.jpg>

Message : I still need to understand this. You can only save to the database at the end of generation. You can't keep updating the same object after every token generation it is too expensive and costly.
Quoted Message : Using proxy nginx/envoy you can do. check this blog something similar you can do adding extra things in proxy to publish SSE response to some queue as well.\n\nhttps://medium.com/blogging-greymatter-io/server-sent-events-http-2-and-envoy-6927c70368bb

Message : I am writing a simpler version using python itself and share gist. What I shared was for scalable approach which is bit complex.
Quoted Message : I still need to understand this. You can only save to the database at the end of generation. You can't keep updating the same object after every token generation it is too expensive and costly.

Message : A try: {generation stream} finally: {save to db} seems like a good approach to handle failures too
Quoted Message : I still need to understand this. You can only save to the database at the end of generation. You can't keep updating the same object after every token generation it is too expensive and costly.

Message : Yes but this is sequential not parallel
Quoted Message : A try: {generation stream} finally: {save to db} seems like a good approach to handle failures too

Message : Why would you need to save in parallel to the db?
Quoted Message : Yes but this is sequential not parallel

Message : That's what the question was

Message : Our Team *parh.ai* won *$1000 from Google Cloud* for our work.

Here is the demo of our work:
https://youtu.be/7p56GS7hrg0

@91997100xxxx @91990072xxxx @91708142xxxx
Quoted Message :  2023_05_14_3A1AA73133BA9C7EBC57.jpeg

Message : I don‚Äôt see a very good reason unless you are doing realtime stuff to multiple frontends and would like them to be synced without dealing witht multiple hierarchies of data sources
Quoted Message : That's what the question was

Message : Yes I agree.
Quoted Message : I don‚Äôt see a very good reason unless you are doing realtime stuff to multiple frontends and would like them to be synced without dealing witht multiple hierarchies of data sources

Message : I can help you setup H2O LLM Studio for it ü´°
Quoted Message : We are trying to get the vicuna7B performance out of OPT2.7B. \nIf you can help fine-tune, I'm happy to offer a few A100s.

Message : (After I‚Äôm back from LLM vacation^ üòÇ)

Message : Very nice work man. I worked on a similar problem some time ago. Using a diagnostic test, understanding the students concept mastery and then prepare a adaptive learning journey for the student. We used mainly BKT ( also deep knowledge tracing can be used) to estimate concept mastery for students
Quoted Message : Our Team *parh.ai* won *$1000 from Google Cloud* for our work.\n\nHere is the demo of our work: \nhttps://youtu.be/7p56GS7hrg0\n\n@9199xxxxxxxx @9199xxxxxxxx @9170xxxxxxxx

Message : Created this sample gist using GPT4 itself which store SSE data to DB and along with serving frontend client. But as pointed out with @91982023xxxx it will not essentially parallel but storing will happen during wait period.
https://gist.github.com/lalitpagaria/940573ea15bcd8d859243607c9564e75
Quoted Message : On a related note, here's a q if you kind folks could help\n\nIs this the normal flow for chat interfaces?\n\n1. User asks a question from a browser client\n\n2. Client invokes an API, which pipes back the response as a text stream using SSE\n\n3. The response is displayed on the client. And when done, is written to a DB as a chat log\n\nDoes 2 have to come before 3? Is there a way to handle both in parallel?

Message : Can finally claim I got seed funded by Google
Quoted Message : Our Team *parh.ai* won *$1000 from Google Cloud* for our work.\n\nHere is the demo of our work: \nhttps://youtu.be/7p56GS7hrg0\n\n@9199xxxxxxxx @9199xxxxxxxx @9170xxxxxxxx

Message : This is generated by gpt4? What did you edit?
Quoted Message : Created this sample gist using GPT4 itself which store SSE data to DB and along with serving frontend client. But as pointed out with @9198xxxxxxxx it will not essentially parallel but storing will happen during wait period.\nhttps://gist.github.com/lalitpagaria/940573ea15bcd8d859243607c9564e75

Message : I did prompting to improve the output, first one was very bad. And added few things like disclaimer and description but that also generated by it GPT, thats why you may see gist edits :)
I tested it though.
Quoted Message : This is generated by gpt4? What did you edit?

Message : Checks out. I would say about 10% of it is usable in prod ü´£
Quoted Message : I did prompting to improve the output, first one was very bad. And added few things like disclaimer and description but that also generated by it GPT, thats why you may see gist edits :)\nI tested it though.

Message : You should try feeding this into gpt4 and see if it understands üòÇ 

https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/

Message : https://amp-lepoint-fr.cdn.ampproject.org/c/s/amp.lepoint.fr/2519782

Message : Of course it is sample code only showing a simple way to tap streaming data from openai api. Need proper DB schema (key against data to preserve), multiple clients, multiple api instances, latency, regeneration and many more required for production use.
Quoted Message : Checks out. I would say about 10% of it is usable in prod ü´£

Message : Any takeaways?
Quoted Message : https://amp-lepoint-fr.cdn.ampproject.org/c/s/amp.lepoint.fr/2519782

Message : QnA generation looks solid. Congratulations üéâ
Quoted Message : Our Team *parh.ai* won *$1000 from Google Cloud* for our work.\n\nHere is the demo of our work: \nhttps://youtu.be/7p56GS7hrg0\n\n@9199xxxxxxxx @9199xxxxxxxx @9170xxxxxxxx

Message : Thank you. 

We also went a step ahead and added a story telling mode where a concept is explained via a fictional story. We sent that story to ElevenLabs to speak as an old, authoritative man. Parallely we set up another LLM that can make image generation prompts out of the story, and got a few cool relevant images.

We then just combined the story, with the narration, with the AI generated images.

Here's a demo : https://youtu.be/B4Y9-x7DC9M
Quoted Message : QnA generation looks solid. Congratulations üéâ

Message : This story is an explanation of relativity

Message : Just first two paragraphs of the entire story, which is slightly longer. Happy to share if anyone likes.

Message : Looks absolutely amazing.

Message : Noice! I think there‚Äôs a lot of potential in auto learning generation. I‚Äôm trying to learn Dutch based on how I would converse with a paid in person tutor. The first pass seems solid

Message : You can add t e x t on video with latest Floyd update. All sorts of engagement possibilities to convert any content into high dopamine content. That, with equitable access, is non-zero sum.
Quoted Message : Looks absolutely amazing.

Message : Play.HT has some decent Dutch voices, which are monotone, but works well while hearing the pitch and pronunciation

Message : It doesn't exactly cater to our "AI tutor for all-nighters" main course of action. 

This story mode is meant to help when you're eating or taking a break. I know for sure that I watched educational videos whenever I was taking a break in an all-nighter. I just couldn't bear the guilt of watching movies during study breaks :p

Message : Perhaps it's value lies more in the long term study plans

Message : When you've been freshly introduced to a topic and exams are still far away

Message : That's when these stories could help cement concepts

Message : You are saying not suitable for goal based education?

Message : Aligned
Quoted Message : You can add t e x t on video with latest Floyd update. All sorts of engagement possibilities to convert any content into high dopamine content. That, with equitable access, is non-zero sum.

Message : Yeah i would imagine students that reap the most benefit from all nighters are ones who focus exclusively on question answering. These stories shouldn't really be a part of those student's productive time.
Quoted Message : You are saying not suitable for goal based education?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Noice! I think there‚Äôs a lot of potential in auto learning generation. I‚Äôm trying to learn Dutch based on how I would converse with a paid in person tutor. The first pass seems solid

Message : You can add t e x t on video with latest Floyd update. All sorts of engagement possibilities to convert any content into high dopamine content. That, with equitable access, is non-zero sum.
Quoted Message : Looks absolutely amazing.

Message : Play.HT has some decent Dutch voices, which are monotone, but works well while hearing the pitch and pronunciation

Message : It doesn't exactly cater to our "AI tutor for all-nighters" main course of action. 

This story mode is meant to help when you're eating or taking a break. I know for sure that I watched educational videos whenever I was taking a break in an all-nighter. I just couldn't bear the guilt of watching movies during study breaks :p

Message : Perhaps it's value lies more in the long term study plans

Message : When you've been freshly introduced to a topic and exams are still far away

Message : That's when these stories could help cement concepts

Message : You are saying not suitable for goal based education?

Message : Aligned
Quoted Message : You can add t e x t on video with latest Floyd update. All sorts of engagement possibilities to convert any content into high dopamine content. That, with equitable access, is non-zero sum.

Message : Yeah i would imagine students that reap the most benefit from all nighters are ones who focus exclusively on question answering. These stories shouldn't really be a part of those student's productive time.
Quoted Message : You are saying not suitable for goal based education?

Message : Well, I guess we know what byjus is buying next

Message : Does anyone know the diff between langchain python and js featuresets? A client has a typescript backend and doesn't want to have a python microservice for the LLM app

Message : https://langchain.com/integrations.html
https://langchain.com/features.html
Quoted Message : Does anyone know the diff between langchain python and js featuresets? A client has a typescript backend and doesn't want to have a python microservice for the LLM app

Message : in langchain is there any agent flow which is for correcting hallucination that occur in generation.
something along these lines
https://github.com/jagilley/fact-checker
You pass in a statement and it checks for correction in the statement. This uses langchain. I was wondering if there are more such flows or if langchain has some internal mechanism like ReAct which helps in this

Message : This is so scary
Quoted Message : in langchain is there any agent flow which is for correcting hallucination that occur in generation.\nsomething along these lines\nhttps://github.com/jagilley/fact-checker\nYou pass in a statement and it checks for correction in the statement. This uses langchain. I was wondering if there are more such flows or if langchain has some internal mechanism like ReAct which helps in this

Message : What doomsday scenario has come to your mind
Quoted Message : This is so scary

Message : A ny times journalist using this to fact check something
Quoted Message : What doomsday scenario has come to your mind

Message : They will bias it to their own views.

No. Elizabeth Holmes is not evil üòÇ

Message : chain of thought reasoning on open domain Q&A will only lead to more hallucinations no?
Quoted Message : in langchain is there any agent flow which is for correcting hallucination that occur in generation.\nsomething along these lines\nhttps://github.com/jagilley/fact-checker\nYou pass in a statement and it checks for correction in the statement. This uses langchain. I was wondering if there are more such flows or if langchain has some internal mechanism like ReAct which helps in this

Message : haan, this repo is good. although has some limitations
Quoted Message : chain of thought reasoning on open domain Q&A will only lead to more hallucinations no?

Message : https://twitter.com/gdb/status/1657860994956410880?s=20


Bet this is dalle3

Message : https://twitter.com/main_horse/status/1657810453278658560?s=20
Quoted Message : I'm going to let someone else figure it out and post a detailed analysis on Twitter. They are not saying the size of the model that will be used for 100k API. If they use 1T model for 100K, it is probably going to be very expensive to accommodate practical use cases. ü§∑‚Äç‚ôÇÔ∏è but then my temporal snapshot of knowledge is changing every day.

Message : What's your use case? Hyde is one approach to improve quality of answer. You can also reduce hallucinations with better prompts.
Quoted Message : in langchain is there any agent flow which is for correcting hallucination that occur in generation.\nsomething along these lines\nhttps://github.com/jagilley/fact-checker\nYou pass in a statement and it checks for correction in the statement. This uses langchain. I was wondering if there are more such flows or if langchain has some internal mechanism like ReAct which helps in this

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØPhani Srikanth

Message : Hello everyone! üëã 

I‚Äôm Phani Srikanth and I‚Äôve been in Data Sciences space since 2013.

I can attribute most of what I know to open communities such as Kaggle, fast.ai, Analytics Vidhya, the amazing DS peers and the companies I‚Äôve worked with. Heard so much about this vibrant community and so glad to have been invited here.

Most recently, I‚Äôve worked as a Data Scientist at Microsoft in the security space (both as an IC and a manager) for the last 4 years.

Just this week, I‚Äôve relocated from Seattle, USA to Hyderabad, India and I‚Äôll be glad to share my move back to India experiences with anyone interested.

So looking forward to contributing and learning from this community. Thanks!

Message : https://docs.cohere.com/docs/llmu

Message : There is this and then fullstackdeeplearning came up with a course which @91773788xxxx posted on Twitter!

Anyone knows which one would be better to go down the rabbit hole.
Quoted Message : https://docs.cohere.com/docs/llmu

Message : If you're working on NLP heavy areas e.g. search, chat, question-answering: https://docs.cohere.com/docs/llmu ‚Äî this is perhaps more deverloper-friendly because NLP is Cohere's bread and better.

If you're someone who is well-versed with basics e.g. everything from finetuning your own LMs to beam search: https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/
Quoted Message : There is this and then fullstackdeeplearning came up with a course which @9177xxxxxxxx posted on Twitter!\n\nAnyone knows which one would be better to go down the rabbit hole.

Message : Thanks. Still working my way through basics and building small applications.

Langchain seemed perfect way to start! Now need to go deeper.
Quoted Message : If you're working on NLP heavy areas e.g. search, chat, question-answering: https://docs.cohere.com/docs/llmu ‚Äî this is perhaps more deverloper-friendly because NLP is Cohere's bread and better.\n\nIf you're someone who is well-versed with basics e.g. everything from finetuning your own LMs to beam search: https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/

Message : Oh I've done all that. Taking this one step further.
Quoted Message : What's your use case? Hyde is one approach to improve quality of answer. You can also reduce hallucinations with better prompts.

Message : Abhinav @91982023xxxx would you be open to giving an advanced prompting for Q&A talk at the BOM meetup in June? 

cc the BOM meetup curator Lalit @91974101xxxx can help you convert your code to a talk
Quoted Message : Oh I've done all that. Taking this one step further.

Message : Does anyone here understand how hashing works in recommendation systems?

Been reading about the two tower architecture of recommendation systems where items and users are embedded in the same space and relevant items are found through cosine similarly to user embedding.

But a paper like Monolith (TikTok recommendation system) talks about hashing but I don‚Äôt understand where and how is it used. Any idea?

Message : Paper https://arxiv.org/pdf/2209.07663.pdf

Message : I understood Cuckoo Hashing, but why is hash used when you have an embedding?

Message : Embeddings start to collide at social media scale because power creators and consumers skew the distribution: 

This is a delightful exposition to why/where hash when embed exists from Instagram Engineering in 2019:
https://instagram-engineering.com/core-modeling-at-instagram-a51e0158aa48
Quoted Message : I understood Cuckoo Hashing, but why is hash used when you have an embedding?

Message : ‚Äé<attached: 00003810-PHOTO-2023-05-15-11-37-05.jpg>

Message : What would embed start to collide mean?

Does it mean say in word2vec sort of a context, different words will have same embedding?

I don‚Äôt think it‚Äôs clear to me why in social media embedding will collide and how hash algorithms prevent it
Quoted Message : Embeddings start to collide at social media scale because power creators and consumers skew the distribution: \n\nThis is a delightful exposition to why/where hash when embed exists from Instagram Engineering in 2019: \nhttps://instagram-engineering.com/core-modeling-at-instagram-a51e0158aa48

Message : Haven't seen the paper. Hashing is the general technique and some of these are related to Locality Sensitive Hashing, where the idea is instead of hashing to random locations to use probability theory of local chance of collision, here you want similar things to hash to similar locations. These are different class of hashing algorithms.
Quoted Message : Does anyone here understand how hashing works in recommendation systems?\n\nBeen reading about the two tower architecture of recommendation systems where items and users are embedded in the same space and relevant items are found through cosine similarly to user embedding.\n\nBut a paper like Monolith (TikTok recommendation system) talks about hashing but I don‚Äôt understand where and how is it used. Any idea?

Message : Two cents, busy to into details.

Message : word2vec isn't a good analogy for recsys embedding perhaps. But yes, that is one way to imagine. 

Different words have _similar_ embedding.

As @91990072xxxx mentioned, you want them to be co-located in storage perhaps? One figures out an embedding-aware hash to do so ‚Äî this 2 step sometimes also improves throughput
Quoted Message : What would embed start to collide mean?\n\nDoes it mean say in word2vec sort of a context, different words will have same embedding?\n\nI don‚Äôt think it‚Äôs clear to me why in social media embedding will collide and how hash algorithms prevent it

Message : Got it.

So instead of using raw feature for learning embedding, you hash it and then learn embeddings in the hash

Message : ‚Äé<attached: 00003816-PHOTO-2023-05-15-11-46-32.jpg>

Message : It is moving away from one-got encoding -> embedding

To

Hash -> embedding

Did I get it right?

Message : Sorry if I caused more confusions. Embeddings are a type of hashing. You can do them from pure theoretical computer science ways, think Random Projections, Kernel Embeddings etc. Or you can do using a neural network. We in ML community (atleast these days), generally this the embedding. Sorry we use words means too many thing.
Quoted Message : Got it.\n\nSo instead of using raw feature for learning embedding, you hash it and then learn embeddings in the hash

Message : So people might be using it interchangeably, except when they are not and using embedding followed by hashing (not sure when this is useful).

Message : Yeah, I understand embedding is a type of embedding (compression)

I meant in colloquial sense.

Embedding (learned function), hash (deterministic function)

Combining both is what I understood modern large scale recommendation systems are using
Quoted Message : Sorry if I caused more confusions. Embeddings are a type of hashing. You can do them from pure theoretical computer science ways, think Random Projections, Kernel Embeddings etc. Or you can do using a neural network. We in ML community (atleast these days), generally this the embedding. Sorry we use words means too many thing.

Message : Embedding is a type of hashing*
Quoted Message : Yeah, I understand embedding is a type of embedding (compression)\n\nI meant in colloquial sense.\n\nEmbedding (learned function), hash (deterministic function)\n\nCombining both is what I understood modern large scale recommendation systems are using

Message : Will look at the paper and come back later. Can you send the link to the original paper.
Quoted Message : It is moving away from one-got encoding -> embedding\n\nTo\n\nHash -> embedding\n\nDid I get it right?

Message : Ya.
Quoted Message : Abhinav @9198xxxxxxxx would you be open to giving an advanced prompting for Q&A talk at the BOM meetup in June? \n\ncc the BOM meetup curator Lalit @9197xxxxxxxx can help you convert your code to a talk

Message : This is the paper I wanted to understand and got stuck up on hashes

https://arxiv.org/pdf/2209.07663.pdf
Quoted Message : Will look at the paper and come back later. Can you send the link to the original paper.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Got it.

So instead of using raw feature for learning embedding, you hash it and then learn embeddings in the hash

Message : ‚Äé<attached: 00003816-PHOTO-2023-05-15-11-46-32.jpg>

Message : It is moving away from one-got encoding -> embedding

To

Hash -> embedding

Did I get it right?

Message : Sorry if I caused more confusions. Embeddings are a type of hashing. You can do them from pure theoretical computer science ways, think Random Projections, Kernel Embeddings etc. Or you can do using a neural network. We in ML community (atleast these days), generally this the embedding. Sorry we use words means too many thing.
Quoted Message : Got it.\n\nSo instead of using raw feature for learning embedding, you hash it and then learn embeddings in the hash

Message : So people might be using it interchangeably, except when they are not and using embedding followed by hashing (not sure when this is useful).

Message : Yeah, I understand embedding is a type of embedding (compression)

I meant in colloquial sense.

Embedding (learned function), hash (deterministic function)

Combining both is what I understood modern large scale recommendation systems are using
Quoted Message : Sorry if I caused more confusions. Embeddings are a type of hashing. You can do them from pure theoretical computer science ways, think Random Projections, Kernel Embeddings etc. Or you can do using a neural network. We in ML community (atleast these days), generally this the embedding. Sorry we use words means too many thing.

Message : Embedding is a type of hashing*
Quoted Message : Yeah, I understand embedding is a type of embedding (compression)\n\nI meant in colloquial sense.\n\nEmbedding (learned function), hash (deterministic function)\n\nCombining both is what I understood modern large scale recommendation systems are using

Message : Will look at the paper and come back later. Can you send the link to the original paper.
Quoted Message : It is moving away from one-got encoding -> embedding\n\nTo\n\nHash -> embedding\n\nDid I get it right?

Message : Ya.
Quoted Message : Abhinav @9198xxxxxxxx would you be open to giving an advanced prompting for Q&A talk at the BOM meetup in June? \n\ncc the BOM meetup curator Lalit @9197xxxxxxxx can help you convert your code to a talk

Message : This is the paper I wanted to understand and got stuck up on hashes

https://arxiv.org/pdf/2209.07663.pdf
Quoted Message : Will look at the paper and come back later. Can you send the link to the original paper.

Message : Thank you for offering to help @91990072xxxx

Message : just bumping this thread back again to see if there is any plugin i can use to enable browsing via API except using serp as a tool? or any other library that's optimised on cost.
Quoted Message : is there any browsing plugin that can be used with langchain? if yes can someone link its manifest json file here?

Message : I want to summarize a long piece of text consisting of several 100 thousand+ tokens. What open source model can I use?

Message : Could anyone help?

Message : Llama index
Quoted Message : I want to summarize a long piece of text consisting of several 100 thousand+ tokens. What open source model can I use?

Message : Thank you!!!

Message : you can do map reduce on langchain. load summarize chain and do with map reduce chain type.

just double check the prompts that langchain is using in their repo, I've found tweaking those in your custom implementation works better for your use case
Quoted Message : I want to summarize a long piece of text consisting of several 100 thousand+ tokens. What open source model can I use?

Message : You can see some of the community discussions here: https://nirantk.com/ai 

They're all made with Langchain's Map Reduce + Custom Prompts
Quoted Message : you can do map reduce on langchain. load summarize chain and do with map reduce chain type.\n\njust double check the prompts that langchain is using in their repo, I've found tweaking those in your custom implementation works better for your use case

Message : This is great!!
Quoted Message : You can see some of the community discussions here: https://nirantk.com/ai \n\nThey're all made with Langchain's Map Reduce + Custom Prompts

Message : code is here if it helps: 
https://github.com/NirantK/nirantk.github.io/tree/main/community_dev
Quoted Message : This is great!!

Message : It can be turned into newsletter as well.
Quoted Message : You can see some of the community discussions here: https://nirantk.com/ai \n\nThey're all made with Langchain's Map Reduce + Custom Prompts

Message : üëã Hello everyone! üéâ 

On popular request ‚Äî we have some exciting job opportunities to share with you today:

üë• *Posted by*: Kunal Bhatia, Cofounder, hexo.ai
üîπ *Role*: Generative AI includes all text, vision, typically
üìù *Job Description*: Senior ML engineer (3-4y exp), founding team role (team <6 people), should have some understanding of how diffusion models work
üîó *Apply here*: https://wellfound.com/l/2yJX3z
‚ùì *Questions? Contact*: Reach out to Vignesh (Co-founder) https://www.linkedin.com/in/vigneshbaskaran0123/

-------------------------------

üë• *Posted by*: Twishmay Shankar, Founder PsyTech.AI
üîπ *Role*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps ‚Äî making internal tools
üìù *Job Description*: Looking for someone who can help us upgrade and build our AI product stack. Willingness to learn, tinker, and grit to make lots of mistakes yet emerge with insight is what we are fundamentally looking for. Also a strong interest in maths and physics and comp science.
üîó *Apply here*: No link. Direct DM my number / email on people@psytech.ai
‚ùì *Questions? Contact*: WA, Email twishmay@psytech.ai, Twitter @twishmay and IRL in NCR.

-------------------------------

üë• *Posted by*: Data Science/GenerativeAI Interns
üîπ *Role*: Generative AI includes all text, vision, typically
üìù *Job Description*: Looking for self-motivated, self-driven Data Science/GenerativeAI interns, students, learners, or enthusiasts interested in working on real-world use cases. You should have a passion for technology and a constant desire to learn. Please share your GenerativeAI work, including GitHub, blogs, apps, and/or hackathon participation along with your application.
üîó *Apply here*: amir@memexai.company
‚ùì *Questions? Contact*: amir@memexai.company

-------------------------------

üë• *Posted by*: Aishwarya Goel, Cofounder, Inferless Backed by Sequoia)
üîπ *Role*: Not Related to Generative AI directly, but broad ML role
üìù *Job Description*: Looking for a young technical product manager for our serverless gpu offering who can closely work with engineering team & founders and lead user retention & onboarding.
üîó *Apply here*: https://wellfound.com/l/2yNHw2
‚ùì *Questions? Contact*: aishwarya@inferless.com

-------------------------------

üë• *Posted by*: Founder, Writesonic
üîπ *Role*: Generative AI includes all text, vision, typically
üìù *Job Description*: Looking for a builder with a track record of building their own generative AI side projects and a desire to learn and iterate quickly.
üîó *Apply here*: https://writesonic.notion.site/Machine-Learning-Engineer-NLP-44bf67fd4f464af1ba5aa473ad5aa428
‚ùì *Questions? Contact*: Samanyou Garg - sam@writesonic.com

-------------------------------

Best of luck with your applications! üçÄ

Message : The approach would be to break it down and summarize each chunk separately.
Quoted Message : I want to summarize a long piece of text consisting of several 100 thousand+ tokens. What open source model can I use?

Message : If you want to make hiring posts: https://nirantk.com/ai/community.html

[This is free]

Message : A friend is looking for using GenAI for AR/VR - any pointers ?

Message : I essentially want to build something similar to anthropic where I can give long texts, pdfs, transcripts, entire tweets of a hashtag per day - and then can ask to generate insights out of it.
Quoted Message : The approach would be to break it down and summarize each chunk separately.

Message : Want to do it for personal use first, so okay with extra cost of personal hosting, etc.
Quoted Message : The approach would be to break it down and summarize each chunk separately.

Message : Would have to be a bot ore specific. XR + gen AI super wide
Quoted Message : A friend is looking for using GenAI for AR/VR - any pointers ?

Message : FYI. If anybody is interested:

https://twitter.com/mundinmd/status/1657434764821905408?s=46&t=JFQp6n8tGBMX2faQoAuY3g

Message : Any open-source alternative for https://www.glean.com/?

Message : Few examples

- https://segment-anything.com/
- https://www.blockadelabs.com/index.html (pure gen AI for VR)
Quoted Message : A friend is looking for using GenAI for AR/VR - any pointers ?

Message : He is a logistics researcher, wants to create city traffic simulations - so wants to create cities with roads and traffic etc
Quoted Message : Would have to be a bot ore specific. XR + gen AI super wide

Message : cc Devanshu @91800314xxxx, Yash @91777403xxxx and Charu @91998208xxxx have worked on doing simulations based on user input. Phenomenal project.
Quoted Message : He is a logistics researcher, wants to create city traffic simulations - so wants to create cities with roads and traffic etc

Message : Should check google + unity workflow if for research purposes. Can bring in all of google earth into a rendering engine now 
Render pipelines for procedural setups if want to build apps
Would have to also solve for occlusion culling if building for real time AR. Not an easy problem to solve.

Message : Have you built something with it? Or have a demo someone can start off?
Quoted Message : Should check google + unity workflow if for research purposes. Can bring in all of google earth into a rendering engine now \nRender pipelines for procedural setups if want to build apps \nWould have to also solve for occlusion culling if building for real time AR. Not an easy problem to solve.

Message : Recently saw this demo on twitter by a dude who made a Google Maps driving game:
https://twitter.com/ollietylerr/status/1657796265890009088?s=46&t=WT1iAtjftW-5_e62F8FZTg

The creator said this about how it was made:
‚ÄúIt‚Äôs using Google‚Äôs new GeoSpatial API for Unity to generate the world mesh and then building everything on top of that!‚Äù

Message : This api was recently released in Google IO: 
https://developers.google.com/ar/geospatialcreator

Message : There are quite few things out there. Along with what folks mentioned. Do look at ADAS simulators (Carla etc), in this case you can simulate without even GenAI. Not quite sure what the specific problem is, so can't comment if this will fit.
Quoted Message : He is a logistics researcher, wants to create city traffic simulations - so wants to create cities with roads and traffic etc

Message : Have been playing with luma + unreal. 
Saw g earth on rendering engine done by some in gaming discord. Shall share link
Quoted Message : Have you built something with it? Or have a demo someone can start off?

Message : This is so cool! I am completely new to this space. The only thing I've tried in unity is building a small 360 immersive world so that I can use my pico4 to chill in it. This stuff is fascinating.
Quoted Message : Recently saw this demo on twitter by a dude who made a Google Maps driving game:\nhttps://twitter.com/ollietylerr/status/1657796265890009088?s=46&t=WT1iAtjftW-5_e62F8FZTg\n\nThe creator said this about how it was made:\n‚ÄúIt‚Äôs using Google‚Äôs new GeoSpatial API for Unity to generate the world mesh and then building everything on top of that!‚Äù

Message : But if any of you want to generate 360 images for VR, please check out https://skybox.blockadelabs.com/
Instant generation and immersion. quality is almost SD2.0 level and it's currently free for anyone to try.

Message : Found a good paper on this: https://arxiv.org/pdf/2010.10784.pdf
Quoted Message : This is the paper I wanted to understand and got stuck up on hashes\n\nhttps://arxiv.org/pdf/2209.07663.pdf

Message : PS: This is a good tool to breakdown papers and learn faster : https://www.explainpaper.com/
Quoted Message : Found a good paper on this: https://arxiv.org/pdf/2010.10784.pdf

Message : Summary of contextual bandits and recommendation systems.pdf ‚Ä¢ ‚Äé4 pages ‚Äé<attached: 00003861-Summary of contextual bandits and recommendation systems.pdf>

Message : Has anyone ran into rate limit issues with OpenAI api?
chat models have 90000 TPM
We are planning to do multiple accounts and balance the load between them, but is there a better way?

Message : If you're looking at rec systems broad ideas, this webpage has some good ones: https://vinija.ai/recsys/papers/

Message : Contextual bandits are amazing framework.. Even under the hood of RLHF/ RLAIF, these systems are being contextual bandits with context being all the tokens except last and action being log probabilities.

Message : Hey

Message : Folks, is there a JS or TS wrapper for llamaindex?

Message : Can't seem to find it in the official docs


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : But if any of you want to generate 360 images for VR, please check out https://skybox.blockadelabs.com/
Instant generation and immersion. quality is almost SD2.0 level and it's currently free for anyone to try.

Message : Found a good paper on this: https://arxiv.org/pdf/2010.10784.pdf
Quoted Message : This is the paper I wanted to understand and got stuck up on hashes\n\nhttps://arxiv.org/pdf/2209.07663.pdf

Message : PS: This is a good tool to breakdown papers and learn faster : https://www.explainpaper.com/
Quoted Message : Found a good paper on this: https://arxiv.org/pdf/2010.10784.pdf

Message : Summary of contextual bandits and recommendation systems.pdf ‚Ä¢ ‚Äé4 pages ‚Äé<attached: 00003861-Summary of contextual bandits and recommendation systems.pdf>

Message : Has anyone ran into rate limit issues with OpenAI api?
chat models have 90000 TPM
We are planning to do multiple accounts and balance the load between them, but is there a better way?

Message : If you're looking at rec systems broad ideas, this webpage has some good ones: https://vinija.ai/recsys/papers/

Message : Contextual bandits are amazing framework.. Even under the hood of RLHF/ RLAIF, these systems are being contextual bandits with context being all the tokens except last and action being log probabilities.

Message : Hey

Message : Folks, is there a JS or TS wrapper for llamaindex?

Message : Can't seem to find it in the official docs

Message : Maybe an unofficial fork you've seen?

Message : I'm unclear on your exact use case but if it's something like QA over documents, https://github.com/gmpetrov/databerry is perhaps a better fit for you
Quoted Message : Folks, is there a JS or TS wrapper for llamaindex?

Message : ‚Äé<attached: 00003873-PHOTO-2023-05-15-17-08-48.jpg>

Message : Would this be a single gpu? Or multiple in one machine
Quoted Message :  2023_05_15_3AAEAA196C331A7FE496.jpeg

Message : Multiple in 1.

Message : It can also be a shared box.

Message : How can this even work
Quoted Message : It can also be a shared box.

Message : Its not a cpu where you can easily share memory

Message : You have to divide memory na

Message : What I meant is there can be motherboards that has more than 8 A6000

Message : I was actually trying to check how common are they.

Message : Actually not very common so probably you have 1 full box/machine to yourself.

Message : Gigabyte G481-S80 is likely the motherboard

Message : It can support 8 double width GPUs i.e. A6000.

Message : It's common to have 8 GPU boxes and then giving access to hosts with 1,2,4 or 8 GPUs.
Quoted Message : Actually not very common so probably you have 1 full box/machine to yourself.

Message : Supermicro SYS-4029GP-TRT is the only one I found that takes 10 double width GPUs üòÆ

Message : Yea. But the image shows access to 8.
Quoted Message : It's common to have 8 GPU boxes and then giving access to hosts with 1,2,4 or 8 GPUs.

Message : Yeah
Quoted Message : Yea. But the image shows access to 8.

Message : ‚Äé<attached: 00003890-PHOTO-2023-05-15-17-40-58.jpg>
Quoted Message :  2023_05_15_3AAEAA196C331A7FE496.jpeg

Message : who is using llamaindex here ? just curious if ur finding any particular advantage in using it versus langchain + vector db ?

Message : @91963283xxxx is using it in production systems. I'm migrating a consulting client from Langchain to Llama because Langchain is üíîü•≤

@91955016xxxx is a Llama Index contributor
Quoted Message : who is using llamaindex here ? just curious if ur finding any particular advantage in using it versus langchain + vector db ?

Message : ‚Äé<attached: 00003895-PHOTO-2023-05-15-19-22-01.jpg>

Message : Kailash Nadh is the CTO of India's largest brokerage by transaction volume: Zerodha. He is also an active FOSS contributor: https://github.com/knadh

Message : Can we get him in this group?
Quoted Message :  2023_05_15_3EB057CBD8C45EC43867D4.jpeg

Message : In the same breath https://economictimes.indiatimes.com/news/company/corporate-trends/nithin-kamath-unveils-zerodhas-ai-policy-will-not-fire-anyone/no-job-loss-because-of-ai/slideshow/100210374.cms?from=mdr
Quoted Message :  2023_05_15_3EB057CBD8C45EC43867D4.jpeg

Message : when I used langchain with vector db (hnswlib) for analysing metrics , sometimes it returned incorrect info . llama worked better . depends on usecases though
Quoted Message : who is using llamaindex here ? just curious if ur finding any particular advantage in using it versus langchain + vector db ?

Message : This is very interesting. Can u talk more about this ?

It was the same vector db and same prompt, etc ?
Quoted Message : when I used langchain with vector db (hnswlib) for analysing metrics , sometimes it returned incorrect info . llama worked better . depends on usecases though

Message : This is expected. These models only work well when you do prompt engg over your specific data distribution. Both libraries make prompt engineering so opaque üò≠ (langchain has not so good default prompts too)
Quoted Message : when I used langchain with vector db (hnswlib) for analysing metrics , sometimes it returned incorrect info . llama worked better . depends on usecases though

Message : For metric analysis is vector embedding a good approach ? 

How does embedding data point work?
For ex I embed data of something like number of orders per city and use QnA db chain over it can I ask questions like ‚ÄúWhich city showed highest growth in orders‚Äù ?
Quoted Message : when I used langchain with vector db (hnswlib) for analysing metrics , sometimes it returned incorrect info . llama worked better . depends on usecases though

Message : Nahi, nahi. You're better off asking that to something like a defog.ai for warehousing or https://github.com/gventuri/pandas-ai
Quoted Message : For metric analysis is vector embedding a good approach ? \n\nHow does embedding data point work? \nFor ex I embed data of something like number of orders per city and use QnA db chain over it can I ask questions like ‚ÄúWhich city showed highest growth in orders‚Äù ?

Message : Exactly I was thinking of txt2sql approach using LangChain sqlagent or Python agent using sqllite3 db
Quoted Message : Nahi, nahi. You're better off asking that to something like a defog.ai for warehousing or https://github.com/gventuri/pandas-ai

Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : ‚Äé<attached: 00003910-GIF-2023-05-15-19-52-40.mp4>
Quoted Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : ‚Äé<attached: 00003911-PHOTO-2023-05-15-19-52-54.jpg>
Quoted Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : yes same prompt. different vector store (pinecone)
Quoted Message : This is very interesting. Can u talk more about this ?\n\nIt was the same vector db and same prompt, etc ?

Message : Yeah, I pay a therapist to teach me how to do this again again. Thank you, thank you for confirming that it's working ü§£üòÇ
Quoted Message :  2023_05_15_3A2B769D25951D285606.mp4

Message : Any pointers on how to do this on nested tree like data? Eg website crawlers
Quoted Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : Say more, what do you mean by a nest? E.g. can you do DFS on the crawler path and flatten it out?
Quoted Message : Any pointers on how to do this on nested tree like data? Eg website crawlers

Message : interesting, I will try this and check
Quoted Message : Exactly I was thinking of txt2sql approach using LangChain sqlagent or Python agent using sqllite3 db

Message : I can flatten it out without ai, and feed that into a vector db - but that would loose the hirearchical structure.

Eg one webpage has say, list of contacts, and each contact has a link to the contact‚Äôs details
Quoted Message : Say more, what do you mean by a nest? E.g. can you do DFS on the crawler path and flatten it out?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Exactly I was thinking of txt2sql approach using LangChain sqlagent or Python agent using sqllite3 db
Quoted Message : Nahi, nahi. You're better off asking that to something like a defog.ai for warehousing or https://github.com/gventuri/pandas-ai

Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : ‚Äé<attached: 00003910-GIF-2023-05-15-19-52-40.mp4>
Quoted Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : ‚Äé<attached: 00003911-PHOTO-2023-05-15-19-52-54.jpg>
Quoted Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : yes same prompt. different vector store (pinecone)
Quoted Message : This is very interesting. Can u talk more about this ?\n\nIt was the same vector db and same prompt, etc ?

Message : Yeah, I pay a therapist to teach me how to do this again again. Thank you, thank you for confirming that it's working ü§£üòÇ
Quoted Message :  2023_05_15_3A2B769D25951D285606.mp4

Message : Any pointers on how to do this on nested tree like data? Eg website crawlers
Quoted Message : Disclosure: I've a business relationship with Defog.ai ‚Äî so I also know how good their tech is since I built it üòÖ

Message : Say more, what do you mean by a nest? E.g. can you do DFS on the crawler path and flatten it out?
Quoted Message : Any pointers on how to do this on nested tree like data? Eg website crawlers

Message : interesting, I will try this and check
Quoted Message : Exactly I was thinking of txt2sql approach using LangChain sqlagent or Python agent using sqllite3 db

Message : I can flatten it out without ai, and feed that into a vector db - but that would loose the hirearchical structure.

Eg one webpage has say, list of contacts, and each contact has a link to the contact‚Äôs details
Quoted Message : Say more, what do you mean by a nest? E.g. can you do DFS on the crawler path and flatten it out?

Message : Basically want to build my own algolia crawler but powered by new embeddings and llm tech - https://www.algolia.com/products/search-and-discovery/crawler/

Message : Thought this might be interesting to you: https://github.com/typesense/typesense
Quoted Message : Basically want to build my own algolia crawler but powered by new embeddings and llm tech - https://www.algolia.com/products/search-and-discovery/crawler/

Message : From what I can tell (earlier read, not tonight) ‚Äî that is already flat content, right?
Quoted Message : Basically want to build my own algolia crawler but powered by new embeddings and llm tech - https://www.algolia.com/products/search-and-discovery/crawler/

Message : Hmm, you can always recompose by having navigation history in each chunk. You've to invent something to capture what positional embedding, circa 2018, did
Quoted Message : I can flatten it out without ai, and feed that into a vector db - but that would loose the hirearchical structure.\n\nEg one webpage has say, list of contacts, and each contact has a link to the contact‚Äôs details

Message : I've tried this navigational history ‚Üí chunk trick only till depth 5 though ü§î

Message : ‚Äé<attached: 00003924-PHOTO-2023-05-15-20-03-02.jpg>

Message : You're trying to capture backlink information?
Quoted Message :  2023_05_15_3EB0A803E7E2E3F4736762.jpeg

Message : https://twitter.com/aakrit/status/1658116297178112004?t=FhTQTej4iq5k_keIJfeA3Q&s=08

Message : Mumbai Hackathon for AI.

Message : I think so, because if you have say this list
Quoted Message : You're trying to capture backlink information?

Message : # /resources/awesome_programmers.md

Here's a list of awesome AI programmers

1. [Nirant](/resources/awesome_programmers/nirant.md)
2. ...
3. ...
.
.
.

Message : and the links resolve to a doc like this -

Message : # /resources/awesome_programmers/nirant.md

Nirant K

Website: https://nirantk.com/
Bio: I enjoy working with text and language challenges. So much so, that I even wrote a book and gave a lot of talks about it.
...

Message : Then the end nodes don't make any sense without the backlinks

Message : We've gone too deep into this? Let's move this to DMs

Message : A more expensive approach but will give you a more natural interface is to retrieve the closest vector to the question from the vector db, pass it as history in the prompt to chat gpt and let it give you the final answer.

Message : Clever: "HyDe-lite"
Quoted Message : A more expensive approach but will give you a more natural interface is to retrieve the closest vector to the question from the vector db, pass it as history in the prompt to chat gpt and let it give you the final answer.

Message : ‚Äéimage omitted

Message : Love the set-up
Quoted Message :  2023_05_15_3A19C7B202555EF4286B.jpeg

Message : ‚Äé<attached: 00003940-PHOTO-2023-05-15-20-29-27.jpg>

Message : Dope keyboard
Quoted Message :  2023_05_15_3A19C7B202555EF4286B.jpeg

Message : Does torch.compile also work with pytorch2?
Quoted Message :  2023_05_15_3EB0C474F67CD30F42C4CF.jpeg

Message : Haven't tried this.
Quoted Message : Does torch.compile also work with pytorch2?

Message : It only works in pytorch2
Quoted Message : Does torch.compile also work with pytorch2?

Message : https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/#more-561

Message : Few things you can explore in LlamaIndex:

1. Query bundle/ query decomposition for retrieval
2. Recency of nodes/ chunks filtered
3. Masking of personal information before giving it to LLM
4. Post processing of retrieved nodes/ chunks.
5. Evaluation module is done differently compared to langchain
6. Custom retrievers
Quoted Message : who is using llamaindex here ? just curious if ur finding any particular advantage in using it versus langchain + vector db ?

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØJithin James

Message : ‚Äé<attached: 00003948-PHOTO-2023-05-15-22-37-03.jpg>

Message : LlamaIndex has made an integration with Poe API - https://github.com/poe-platform/poe-protocol/tree/main/llama_poe
Quoted Message :  2023_05_15_A01D2130EE0315B2E9FE03683DECC3F2.jpeg

Message : awesome!

Message : Invited him :D
Quoted Message : Kailash Nadh is the CTO of India's largest brokerage by transaction volume: Zerodha. He is also an active FOSS contributor: https://github.com/knadh

Message : Anyone using humanloop actively?

Message : Had a few questions

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : https://dontasktoask.com

Message : reminds me of this and slack DMs at work üòÑ https://nohello.net/en/
Quoted Message : https://dontasktoask.com

Message : This is the exact link from community guidelines: https://nirantk.com/ai/community.html

At the same time, I think it's unlikely that everyone will read that or the other super secret link in the group description. Their loss if you ask me üòÖ
Quoted Message : https://dontasktoask.com

Message : *running similar web on nirantk.com* :p
Quoted Message : This is the exact link from community guidelines: https://nirantk.com/ai/community.html\n\nAt the same time, I think it's unlikely that everyone will read that or the other super secret link in the group description. Their loss if you ask me üòÖ

Message : Sorry guys was doing some user research so potentially would‚Äôve involved many noob qs. But noted

Message : Ouch
Quoted Message : https://dontasktoask.com


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Invited him :D
Quoted Message : Kailash Nadh is the CTO of India's largest brokerage by transaction volume: Zerodha. He is also an active FOSS contributor: https://github.com/knadh

Message : Anyone using humanloop actively?

Message : Had a few questions

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : https://dontasktoask.com

Message : reminds me of this and slack DMs at work üòÑ https://nohello.net/en/
Quoted Message : https://dontasktoask.com

Message : This is the exact link from community guidelines: https://nirantk.com/ai/community.html

At the same time, I think it's unlikely that everyone will read that or the other super secret link in the group description. Their loss if you ask me üòÖ
Quoted Message : https://dontasktoask.com

Message : *running similar web on nirantk.com* :p
Quoted Message : This is the exact link from community guidelines: https://nirantk.com/ai/community.html\n\nAt the same time, I think it's unlikely that everyone will read that or the other super secret link in the group description. Their loss if you ask me üòÖ

Message : Sorry guys was doing some user research so potentially would‚Äôve involved many noob qs. But noted

Message : Ouch
Quoted Message : https://dontasktoask.com

Message : Noob questions are fine, what they're pointing out is that don't ask for permission/context to ask. Just ask your question directly. Don't try to save your time, save the community's time.
Quoted Message : Sorry guys was doing some user research so potentially would‚Äôve involved many noob qs. But noted

Message : 50k livestream views for strangs final lecture

Message : ‚Äé<attached: 00003966-PHOTO-2023-05-16-01-35-23.jpg>

Message : Team, before I get roasted, I thought I‚Äôd check if it‚Äôs okay to share about events in thr group? 

Context ‚Äî we got someone cool from Anthropic to do a webinar alongside us. It‚Äôs an open invite and  we want to invite builders, recruiters to the webinar.

Message : Just met with OpenAI in their office. Signed an nda so can‚Äôt talk about what‚Äôs coming but got a couple of demos. If anyone has feedback on their API, lmk. They want to hear from devs on how can they get better.

Message : I have this request - https://community.openai.com/t/is-there-a-way-to-set-a-a-random-seed-for-responses-with-temperature-0/4164
Quoted Message : Just met with OpenAI in their office. Signed an nda so can‚Äôt talk about what‚Äôs coming but got a couple of demos. If anyone has feedback on their API, lmk. They want to hear from devs on how can they get better.

Message : Pls join if this seems relevant to you, or pls pass it along to anyone who may benefit. 

This is open to all, and the agenda is still getting curated tbh but if anyone has requests let me know (we want to keep the conversation AI first but use cases may be recruiting focused so anything that annoys you about recruiting is fair game hah)

https://www.linkedin.com/posts/rohan-manchanda-74812b15_aiinrecruitment-activity-7064004613942751232-MJXH?utm_source=share&utm_medium=member_ios
Quoted Message : Team, before I get roasted, I thought I‚Äôd check if it‚Äôs okay to share about events in thr group? \n\nContext ‚Äî we got someone cool from Anthropic to do a webinar alongside us. It‚Äôs an open invite and  we want to invite builders, recruiters to the webinar.

Message : https://levelup.gitconnected.com/mpt-7b-the-times-of-commercially-usable-language-models-has-come-8c9c6c3316ef

An interesting development. Has anyone tested this model's performance?

Message : FYI: This was the press coverage then. You cannot use it commercially.
Quoted Message : https://levelup.gitconnected.com/mpt-7b-the-times-of-commercially-usable-language-models-has-come-8c9c6c3316ef\n\nAn interesting development. Has anyone tested this model's performance?

Message : Confidence score for each reply. This is the huge problem for enterprise deployment, prompt testing...basically everything.
Quoted Message : Just met with OpenAI in their office. Signed an nda so can‚Äôt talk about what‚Äôs coming but got a couple of demos. If anyone has feedback on their API, lmk. They want to hear from devs on how can they get better.

Message : Even base?

Message : logprobs used to solve this to some extent before chat completion endpoints
Quoted Message : Confidence score for each reply. This is the huge problem for enterprise deployment, prompt testing...basically everything.

Message : for prompt testing - have you tried evals?

Message : Wow! Access to the most brilliant minds on earth right now! 
Whats your take on AGI? How are we are from it! :)
Quoted Message : Just met with OpenAI in their office. Signed an nda so can‚Äôt talk about what‚Äôs coming but got a couple of demos. If anyone has feedback on their API, lmk. They want to hear from devs on how can they get better.

Message : This is an involved question. How will u eval ? String match, embedding match or statistical match?

One of the papers to follow is this https://arxiv.org/pdf/2210.09150.pdf

This is not easy. Even when u try to match, the reliability score is unpredictable if u have temperature above zero.
Quoted Message : for prompt testing - have you tried evals?

Message : Would depend on the task at hand I assume.

Unpredictable yes - but with an eval model you could build a confidence function based on semantic match / similarity score or relevance confidence

Message : Also, sorry - what‚Äôs an ‚Äúinvolved question‚Äù?

Message : Yes you are right. In their particular case, they are using a collision less hashing (here ids span 2^48 space). Here hashing being normal hashing (not semantic/LSH). They needed a hash function that hashes to smaller space (after removal of some of the long tail data) with extra properties, like ability to remove hashes cheaply (as things get stale), ability to add new IDs (as they do online learning on new IDs as they come in). You can DM, if you have more questions.
Quoted Message : It is moving away from one-got encoding -> embedding\n\nTo\n\nHash -> embedding\n\nDid I get it right?

Message : Thanks for asking this question, sharing the write up (helped me understand where you are), the paper was quite interesting with lots of sys  details, though tad bit badly written. I also learned few things üòÄ.

Message : thanks for answering.

it's interesting to note that most such companies leave out a few crucial details always. for example, i dont think they mentioned what all features do they end up using for personalization
Quoted Message : Thanks for asking this question, sharing the write up (helped me understand where you are), the paper was quite interesting with lots of sys  details, though tad bit badly written. I also learned few things üòÄ.

Message : Haha. Yeah, that is their sauce for üí∏

Message : Also keeps engineers employable
Quoted Message : Haha. Yeah, that is their sauce for üí∏

Message : It seems to me that ML engineering is where the moat is, not so much in ML research.
Quoted Message : Also keeps engineers employable

Message : Yeah, I've bet my career on that since 2018
Quoted Message : It seems to me that ML engineering is where the moat is, not so much in ML research.

Message : Timeout of their api can be improved and we should be able to pass custom values. The current ones don't work
Quoted Message : Just met with OpenAI in their office. Signed an nda so can‚Äôt talk about what‚Äôs coming but got a couple of demos. If anyone has feedback on their API, lmk. They want to hear from devs on how can they get better.

Message : Hey folks, came across replicate.com. Would this be a good way to begin working with open source models for a newbie?

Their APIs look good.

Message : Yes. At least for me have been using this and found free lancers comfortable using it for a prototype
Quoted Message : Hey folks, came across replicate.com. Would this be a good way to begin working with open source models for a newbie?\n\nTheir APIs look good.

Message : I think @91773788xxxx already has some experience with this. He can share some points on this
Quoted Message : Hey folks, came across replicate.com. Would this be a good way to begin working with open source models for a newbie?\n\nTheir APIs look good.

Message : From what I see, we can run predictions easily. Apart from predictions, can we use replicate for training the existing models with custom datasets too?
Quoted Message : Yes. At least for me have been using this and found free lancers comfortable using it for a prototype

Message : Best part of replicate is you can test the model on their UI to see if it works for your use case and then spend time on setting things up.

Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : Same here. Is there any plugin which does the same?
Quoted Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : did you enable it on your account settings?
Quoted Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : Don't have it in the options yet
Quoted Message : did you enable it on your account settings?

Message : cuz if its not visible there then probably hasnt been rolled out to your account. they're doing it in tranches

Message : All other plugins are there

Message : its a different model and not a plugin
Quoted Message : Same here. Is there any plugin which does the same?

Message : Hey everyone! *A request*

I'm Nilesh, a tech reporter for restofworld.org, an international publication covering the impact of tech in non-western countries

I'm currently reporting a story on voice manipulation and the potential risks associated with synthetic voice cloning, through a real-life example that's playing out in India. I need a couple of experts to independently test 2 audio clips, and ascertain if they are real or synthetic. If anyone is interested in discussing/collaborating on this project, can you DM me?

Message : My profile: https://restofworld.org/author/nilesh-christopher/

Message : Can recommend helping out Nilesh, high integrity. He wrote about the Generative AI Hackathon winners as well: 
https://restofworld.org/2023/india-generative-ai-hackathon-2023-projects/

Shouldn't take unreasonably long: 1-2 hours for Googling and trying out tools and 2-4 hours for setting a Colab/Jupyter notebook if needed

If you're ever in BLR, happy to buy you coffee for helping out Nilesh!
Quoted Message : Hey everyone! *A request*\n\nI'm Nilesh, a tech reporter for restofworld.org, an international publication covering the impact of tech in non-western countries\n\nI'm currently reporting a story on voice manipulation and the potential risks associated with synthetic voice cloning, through a real-life example that's playing out in India. I need a couple of experts to independently test 2 audio clips, and ascertain if they are real or synthetic. If anyone is interested in discussing/collaborating on this project, can you DM me?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : Same here. Is there any plugin which does the same?
Quoted Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : did you enable it on your account settings?
Quoted Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : Don't have it in the options yet
Quoted Message : did you enable it on your account settings?

Message : cuz if its not visible there then probably hasnt been rolled out to your account. they're doing it in tranches

Message : All other plugins are there

Message : its a different model and not a plugin
Quoted Message : Same here. Is there any plugin which does the same?

Message : Hey everyone! *A request*

I'm Nilesh, a tech reporter for restofworld.org, an international publication covering the impact of tech in non-western countries

I'm currently reporting a story on voice manipulation and the potential risks associated with synthetic voice cloning, through a real-life example that's playing out in India. I need a couple of experts to independently test 2 audio clips, and ascertain if they are real or synthetic. If anyone is interested in discussing/collaborating on this project, can you DM me?

Message : My profile: https://restofworld.org/author/nilesh-christopher/

Message : Can recommend helping out Nilesh, high integrity. He wrote about the Generative AI Hackathon winners as well: 
https://restofworld.org/2023/india-generative-ai-hackathon-2023-projects/

Shouldn't take unreasonably long: 1-2 hours for Googling and trying out tools and 2-4 hours for setting a Colab/Jupyter notebook if needed

If you're ever in BLR, happy to buy you coffee for helping out Nilesh!
Quoted Message : Hey everyone! *A request*\n\nI'm Nilesh, a tech reporter for restofworld.org, an international publication covering the impact of tech in non-western countries\n\nI'm currently reporting a story on voice manipulation and the potential risks associated with synthetic voice cloning, through a real-life example that's playing out in India. I need a couple of experts to independently test 2 audio clips, and ascertain if they are real or synthetic. If anyone is interested in discussing/collaborating on this project, can you DM me?

Message : ‚Äé<attached: 00004008-PHOTO-2023-05-16-13-02-00.jpg>
Quoted Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : Not sure why the clicks are falling

Message : Try WebPilot or Keymate.Ai Search if u have access to that
Quoted Message : Same here. Is there any plugin which does the same?

Message : ‚Äé<attached: 00004011-PHOTO-2023-05-16-13-03-29.jpg>
Quoted Message : I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?

Message : I've enabled it this way
Quoted Message :  2023_05_16_FBEA6868F67D7F9CF55D52809D401FF3.jpeg

Message : Just curious to know the impact of launching plugin on business metrics: traffic, revenue, CSAT, etc?
One major problem I see in the OpenAI interface: discoverability of plugin, no search and filter option :(

Message : Do we have a list of good learning resource? Bunch of college grads have started reaching out asking for resources which can make them industry ready in the ML/AI space, specially Generative ?

Message : course.fast.ai is all you need if you've some programming exposure e.g. 1 year of Python/2 years of JS/6 months of Rust

Also, this community discussions can be used as a learning resource: https://nirantk.com/ai
Quoted Message : Do we have a list of good learning resource? Bunch of college grads have started reaching out asking for resources which can make them industry ready in the ML/AI space, specially Generative ?

Message : and stats?

Message : and  LangChain for structure?

Message : I'd recommend every beginner against Langchain. These libs evolve fast. And they might over index on the wrong ideas e.g. vector similarity is how search is done ü§¢
Quoted Message : and  LangChain for structure?

Message : got it..

Message : Would you recommend Fast.ai over Hugging Face course?

Message : I hope most undergrad students know this better than me, given that they practiced for entrance exams:

Free 101 stuff, but

https://www.udacity.com/course/statistics--st095
https://www.udacity.com/course/intro-to-inferential-statistics--ud201
Quoted Message : and stats?

Message : Trust me they have not..
Quoted Message : I hope most undergrad students know this better than me, given that they practiced for entrance exams:\n\nFree 101 stuff, but\n\nhttps://www.udacity.com/course/statistics--st095\nhttps://www.udacity.com/course/intro-to-inferential-statistics--ud201

Message : I have interviewed around 50-100 folks in past..

Message : Lot more folks from SDE background are in the market than statistics background

Message : ‚Äé<attached: 00004025-PHOTO-2023-05-16-13-35-07.jpg>
Quoted Message : Not sure why the clicks are falling

Message : Has anyone developed plugins here yet?

Message : Any idea how to set custom metadata?

Message : I‚Äôve ```/upsert``` -ed the documents using chatgpt-retrieval-plugin, but not being able to make custom metadata work yet

Message : the custom metadata needs to be added both in the vector db model as well as the openapi spec. did u change the openapi as well ?
theres a bit of trial and error here, since the openapi spec is what chatgpt uses to interpret the data. sometimes the descriptions are off..ull need to iterate.
Quoted Message : I‚Äôve ```/upsert``` -ed the documents using chatgpt-retrieval-plugin, but not being able to make custom metadata work yet

Message : Yes I‚Äôve changed the openapi specs, particularly ```models.py``` in ```/models``` and ```openapi.yaml``` in ```/.well-known``` if you‚Äôre a acquainted with the repo

Message : But maybe I‚Äôve not defined the custom metadata correctly

Message : Anyone who had worked in this direction, a tutorial if available, or a small screenshot where they‚Äôve defined their custom metadata if shareable, would be really helpful

Message : some background before a question, 
so in my team, we have worked on different kinds of use cases with vectors, and more or less based on availability we had gone with newer or at that time which looked better as a vector DB choice.
some of them are Qdrant ( product entity related use-case which needed filtering etc, and qdrant apis were good level of abstraction given .), FAISS simple and for FAQ kind of use-case it was simpler and easy to use, and now chromadb for LLM related usecase.
so chromadb because of the parquet file and all we were hoping would be better and will just move it to that , for all usecases but when we started using it we noticed that they cache the embedding for collection so when user asks for collection moomentarily they get embeddings in memory, i understand we may want embedding in memory to do faster cosine embedding have seen them also raised an MR with SQLite as sqlite with the disk on ssd is way faster and very less memory usage as well and gives the ACID property as well on metadata.

so this was my dilemma, for various such use cases what are u guys using as your vector-related use cases, and why. what are memory and CPU usages while indexing and searching ( as searching should be faster )...

hope my question makes sense, because when I calculated embeddings size for my chromadb stored vector it was around 50 Mb But in my docker it was taking around 1.3GB and growing ..

Message : ‚Äé<attached: 00004037-PHOTO-2023-05-16-16-06-17.jpg>
Quoted Message : some background before a question, \nso in my team, we have worked on different kinds of use cases with vectors, and more or less based on availability we had gone with newer or at that time which looked better as a vector DB choice. \nsome of them are Qdrant ( product entity related use-case which needed filtering etc, and qdrant apis were good level of abstraction given .), FAISS simple and for FAQ kind of use-case it was simpler and easy to use, and now chromadb for LLM related usecase. \nso chromadb because of the parquet file and all we were hoping would be better and will just move it to that , for all usecases but when we started using it we noticed that they cache the embedding for collection so when user asks for collection moomentarily they get embeddings in memory, i understand we may want embedding in memory to do faster cosine embedding have seen them also raised an MR with SQLite as sqlite with the disk on ssd is way faster and very less memory usage as well and gives the ACID property as well on metadata.\n\nso this was my dilemma, for various such use cases what are u guys using as your vector-related use cases, and why. what are memory and CPU usages while indexing and searching ( as searching should be faster )... \n\nhope my question makes sense, because when I calculated embeddings size for my chromadb stored vector it was around 50 Mb But in my docker it was taking around 1.3GB and growing ..

Message : ‚Äé<attached: 00004038-PHOTO-2023-05-16-16-09-36.jpg>

Message : thanks, I think in chromadb server sometimes takes up the memory and stores things in memory of python itself. In qdrant can u share the file mode-related ref... or are u talking about payloads stored in disk ...
Quoted Message :  2023_05_16_3EB0288FDED09808A01430.jpeg

Message : Not just payloads, you can also pipe the vectors to local. Syntax from memory is something like this: 

from qdrant_client import QdrantClient

client = QdrantClient(":memory:")
# or
client = QdrantClient(path="path/to/db")  # Persists changes to disk
Quoted Message : thanks, I think in chromadb server sometimes takes up the memory and stores things in memory of python itself. In qdrant can u share the file mode-related ref... or are u talking about payloads stored in disk ...

Message : interesting, oh I did not know this, this must be new let me try to find a ref

Message : Happy to help, also I should disclose I've a business relationship with Qdrant.
Quoted Message : interesting, oh I did not know this, this must be new let me try to find a ref

Message : this is almost starting to sound like ‚ÄúAs an AI language model,‚Ä¶.‚Äù ü´£
Quoted Message : Happy to help, also I should disclose I've a business relationship with Qdrant.

Message : ‚Äé<attached: 00004044-GIF-2023-05-16-16-34-45.mp4>
Quoted Message : this is almost starting to sound like ‚ÄúAs an AI language model,‚Ä¶.‚Äù ü´£

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØAnubhab

Message : Hi all,

Glad to be here !

I am a Data Scientist with Ericsson R&D with expertise in analyzing real world complex data and drawing actionable insights to solve them.Working on 5G use-cases now.

Here is my LinkedIn profile in case anyone is curious.

https://www.linkedin.com/in/anubhab-samal-0a5075183/

If you're interested in collaborating, please don't hesitate to connect with me.

Message : Sam Altman proposes to the US Congress that licenses be issued for building AI

https://www.reuters.com/technology/openai-chief-goes-before-us-congress-propose-licenses-building-ai-2023-05-16/

Message : This agi stuff is just an excuse to build a monopoly

Message : He's come a long way from *Open* AI

Message : Regardless of intentions. I don't think government should just listen to a for profit organization. You might not know AGI but you know greed


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : interesting, oh I did not know this, this must be new let me try to find a ref

Message : Happy to help, also I should disclose I've a business relationship with Qdrant.
Quoted Message : interesting, oh I did not know this, this must be new let me try to find a ref

Message : this is almost starting to sound like ‚ÄúAs an AI language model,‚Ä¶.‚Äù ü´£
Quoted Message : Happy to help, also I should disclose I've a business relationship with Qdrant.

Message : ‚Äé<attached: 00004044-GIF-2023-05-16-16-34-45.mp4>
Quoted Message : this is almost starting to sound like ‚ÄúAs an AI language model,‚Ä¶.‚Äù ü´£

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØAnubhab

Message : Hi all,

Glad to be here !

I am a Data Scientist with Ericsson R&D with expertise in analyzing real world complex data and drawing actionable insights to solve them.Working on 5G use-cases now.

Here is my LinkedIn profile in case anyone is curious.

https://www.linkedin.com/in/anubhab-samal-0a5075183/

If you're interested in collaborating, please don't hesitate to connect with me.

Message : Sam Altman proposes to the US Congress that licenses be issued for building AI

https://www.reuters.com/technology/openai-chief-goes-before-us-congress-propose-licenses-building-ai-2023-05-16/

Message : This agi stuff is just an excuse to build a monopoly

Message : He's come a long way from *Open* AI

Message : Regardless of intentions. I don't think government should just listen to a for profit organization. You might not know AGI but you know greed

Message : Sad part is that, if enough new software solutions built using GPT emerge as job providers, openAI will be at the forefront of making legislation for all things pertaining to AI

Message : Haan.

Message : Microsoft wants a return on its investment

Message : This feels like jio days when everyone and their dogs were getting aadhaar biometric based sim card activated in shortest possible time.

And all of sudden in sometime after jio Onboarding done at record scale, the rules changed for aadhaar based Onboarding
Quoted Message : Sam Altman proposes to the US Congress that licenses be issued for building AI\n\nhttps://www.reuters.com/technology/openai-chief-goes-before-us-congress-propose-licenses-building-ai-2023-05-16/

Message : Microsoft is also an investor in Jio.
Quoted Message : This feels like jio days when everyone and their dogs were getting aadhaar biometric based sim card activated in shortest possible time.\n\nAnd all of sudden in sometime after jio Onboarding done at record scale, the rules changed for aadhaar based Onboarding

Message : Is openai profitable on unit economics?

Message : Not yet
Quoted Message : Is openai profitable on unit economics?

Message : Satya vachan
Quoted Message : Microsoft is also an investor in Jio.

Message : How long before buying GPUs gets licensed ?
Quoted Message : Sam Altman proposes to the US Congress that licenses be issued for building AI\n\nhttps://www.reuters.com/technology/openai-chief-goes-before-us-congress-propose-licenses-building-ai-2023-05-16/

Message : No reason for Jenson to block potential buyers. Now, if we're talking about using GPUs in data centers, that's already a messed up area
Quoted Message : How long before buying GPUs gets licensed ?

Message : Any room with more than 5 computers (or some smallish number) can be considered a data center and therefore you cannot use the RTX family of GPUs in such a setup

Message : https://home.mlops.community/public/events/fine-tuning-llms-best-practices-and-when-to-go-small-2023-05-17

Short session tomorrow Eve. Sharing incase anyone is interested

Message : When you do embedding based retrieval, what threshold are you using for the similarity score? I know it depends on the use case but we are having to do a lot of trial and error so I‚Äôm curious

Message : Don't just focus on this part...focus more on creating the embeddings. For e.g. the OpenAI Tiktoken library is the BPE algorithm. U can switch this out...have tokens overlap, etc etc. Lots of stuff u can do.
Quoted Message : When you do embedding based retrieval, what threshold are you using for the similarity score? I know it depends on the use case but we are having to do a lot of trial and error so I‚Äôm curious

Message : Thanks! You mean focus more on the content being used to create the embeddings and any other parameters you can control?
Quoted Message : Don't just focus on this part...focus more on creating the embeddings. For e.g. the OpenAI Tiktoken library is the BPE algorithm. U can switch this out...have tokens overlap, etc etc. Lots of stuff u can do.

Message : Karpathy has a very interesting take on this.  Checkout his notebook 
https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
Quoted Message : When you do embedding based retrieval, what threshold are you using for the similarity score? I know it depends on the use case but we are having to do a lot of trial and error so I‚Äôm curious

Message : :-)

Message : This is very cool!
Quoted Message : Karpathy has a very interesting take on this.  Checkout his notebook \nhttps://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb

Message : Any other documents for tradeoffs with just using embeddings based search v/s alternatives/hybrid search?

Message : No not the content. The same content, but the way you tokenize to create the embeddings.

Of course the embedding algorithm itself - u can use OpenAI embeddings or the HuggingFace embeddings, etc.
U can store different kind of embeddings for the same content (cos its always a one time time cost) and query against multiple indexes when retrieving.
Quoted Message : Thanks! You mean focus more on the content being used to create the embeddings and any other parameters you can control?

Message : The retrieval algo itself is the most unchanging thing here...svm vs knn nonwithstanding

Message : There were indications of this monopolistic behaviour since quite some time

For ex OpenAI published a paper suggesting ways to limit civilian use of AI because they propose Gen AI can be used to spread disinformation
Quoted Message : Sam Altman proposes to the US Congress that licenses be issued for building AI\n\nhttps://www.reuters.com/technology/openai-chief-goes-before-us-congress-propose-licenses-building-ai-2023-05-16/

Message : ‚Äé<attached: 00004074-PHOTO-2023-05-16-23-13-14.jpg>

Message : ‚Äé<attached: 00004075-PHOTO-2023-05-16-23-15-17.jpg>

Message : Actually I think, you could do (late) Sam Roweis's Neighborhood Component Analysis. The idea here is that KNN, values all dimension equally but you can learn what dimensions are actually important by traning it to search over a family of distances (like Mahalonobis family for eg) initially. This way, you don't have to train at test time (like what Karpathy is doing) and should perform quite better. Will try this tomorrow evening or so.
Quoted Message : Karpathy has a very interesting take on this.  Checkout his notebook \nhttps://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb

Message : please share results
Quoted Message : Actually I think, you could do (late) Sam Roweis's Neighborhood Component Analysis. The idea here is that KNN, values all dimension equally but you can learn what dimensions are actually important by traning it to search over a family of distances (like Mahalonobis family for eg) initially. This way, you don't have to train at test time (like what Karpathy is doing) and should perform quite better. Will try this tomorrow evening or so.

Message : That's where he is building world coin ? He has some crypto stuff also going on right ?
Quoted Message :  2023_05_16_3AC7884F086A4A921FDF.jpeg

Message : Yup ,ties in pretty neatly to give OpenAI a good monopoly
Quoted Message : That's where he is building world coin ? He has some crypto stuff also going on right ?

Message : https://fortune.com/crypto/2023/05/15/openai-sam-altman-100-million-worldcoin-funding-iris-human-artificial-intelligence/

Message : Here is his talk. He was an very lucid expositor: http://videolectures.net/lce06_roweis_ncaml/
Quoted Message : Actually I think, you could do (late) Sam Roweis's Neighborhood Component Analysis. The idea here is that KNN, values all dimension equally but you can learn what dimensions are actually important by traning it to search over a family of distances (like Mahalonobis family for eg) initially. This way, you don't have to train at test time (like what Karpathy is doing) and should perform quite better. Will try this tomorrow evening or so.

Message : Got access to chatgpt plugins.
Based on your experience what are the best plugins

Message : the diagrams one
Quoted Message : Got access to chatgpt plugins.\nBased on your experience what are the best plugins

Message : also a basic question
How do you upload stuff to chatgpt, like I use the pdf reader plugin?

Message : Hi everyone. I‚Äôm Kailash. @kshivendu invited me to this group. I‚Äôm a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in

Cheers!

Message : Huge fan of zerodha and what's it done so far! Welcome aboard.
Quoted Message : Hi everyone. I‚Äôm Kailash. @kshivendu invited me to this group. I‚Äôm a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in\n\nCheers!

Message : https://blog.cloudflare.com/introducing-constellation/

Inference on workers. If anyone tries this do share how good.

Message : Hi Kailash, Welcome onboard. Sumod here btw. Yeah, exact same feelings of fascination & bewilderment at the same time. Trying to see how to make it to be something for greater good.
Quoted Message : Hi everyone. I‚Äôm Kailash. @kshivendu invited me to this group. I‚Äôm a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in\n\nCheers!

Message : wait really? I always wondered it would be possible to put together some consumer level GPUs and build a system like google did in the early days
Quoted Message : Any room with more than 5 computers (or some smallish number) can be considered a data center and therefore you cannot use the RTX family of GPUs in such a setup

Message : https://www.digitaltrends.com/computing/nvidia-bans-consumer-gpus-in-data-centers/
Quoted Message : wait really? I always wondered it would be possible to put together some consumer level GPUs and build a system like google did in the early days

Message : Bit of an old news, i haven't seen the latest on this


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Got access to chatgpt plugins.
Based on your experience what are the best plugins

Message : the diagrams one
Quoted Message : Got access to chatgpt plugins.\nBased on your experience what are the best plugins

Message : also a basic question
How do you upload stuff to chatgpt, like I use the pdf reader plugin?

Message : Hi everyone. I‚Äôm Kailash. @kshivendu invited me to this group. I‚Äôm a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in

Cheers!

Message : Huge fan of zerodha and what's it done so far! Welcome aboard.
Quoted Message : Hi everyone. I‚Äôm Kailash. @kshivendu invited me to this group. I‚Äôm a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in\n\nCheers!

Message : https://blog.cloudflare.com/introducing-constellation/

Inference on workers. If anyone tries this do share how good.

Message : Hi Kailash, Welcome onboard. Sumod here btw. Yeah, exact same feelings of fascination & bewilderment at the same time. Trying to see how to make it to be something for greater good.
Quoted Message : Hi everyone. I‚Äôm Kailash. @kshivendu invited me to this group. I‚Äôm a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in\n\nCheers!

Message : wait really? I always wondered it would be possible to put together some consumer level GPUs and build a system like google did in the early days
Quoted Message : Any room with more than 5 computers (or some smallish number) can be considered a data center and therefore you cannot use the RTX family of GPUs in such a setup

Message : https://www.digitaltrends.com/computing/nvidia-bans-consumer-gpus-in-data-centers/
Quoted Message : wait really? I always wondered it would be possible to put together some consumer level GPUs and build a system like google did in the early days

Message : Bit of an old news, i haven't seen the latest on this

Message : Google could that because they were small. Back during Stanford days, they used to offer to setup machines that come for the CS dept and secretly use it for a week or so before giving it to the intended recipient
Quoted Message : wait really? I always wondered it would be possible to put together some consumer level GPUs and build a system like google did in the early days

Message : https://github.com/microsoft/guidance

Interesting to see that such structuring allows to cut down on the prompt generation/inference time as well.

Message : Any comparisons between this and https://lmql.ai/ ?
Quoted Message : https://github.com/microsoft/guidance\n\nInteresting to see that such structuring allows to cut down on the prompt generation/inference time as well.

Message : I think OpenAI simply doesn't have the expertise or maybe motivation to do growth work, especially on free products side. FB would've optimised the hell out of chatgpt growth metrics if they were working on it
Quoted Message : Just curious to know the impact of launching plugin on business metrics: traffic, revenue, CSAT, etc?\nOne major problem I see in the OpenAI interface: discoverability of plugin, no search and filter option :(

Message : This mindset is perhaps why FB didn't invent ChatGPT, or even any GPT?

Altman would have taken Zerg's money instead of Nadella
Quoted Message : I think OpenAI simply doesn't have the expertise or maybe motivation to do growth work, especially on free products side. FB would've optimised the hell out of chatgpt growth metrics if they were working on it

Message : Before someone says Llama, in comparison to even 3.5-Turbo it's Lmao.

Message : Naa I think it was because of too much metaverse.
Quoted Message : This mindset is perhaps why FB didn't invent ChatGPT, or even any GPT?\n\nAltman would have taken Zerg's money instead of Nadella

Message : I'm sure they saw more growth in Metaverse.
Quoted Message : Naa I think it was because of too much metaverse.

Message : Engagement pro max
Quoted Message : I'm sure they saw more growth in Metaverse.

Message : I‚Äôm talking to one of the gen ai leads from meta next week, Looks like they‚Äôre doing a bunch of stuff

Message : Next level ads also
Quoted Message : I'm sure they saw more growth in Metaverse.

Message : Absolutely no disputing Meta's ability to fast follow by throwing together compute, and talent. I love Meta for making FAISS, PyTorch and what not
Quoted Message : I‚Äôm talking to one of the gen ai leads from meta next week, Looks like they‚Äôre doing a bunch of stuff

Message : Would love to know if Meta plans to continue to intend this research license behaviour + 
Plans for video‚Üítext embedding e.g. for Reels and their captions +
Any progress on Refactoring Code w/ generative AI that they've made

Message : Apple takes its first step in Gen AI

Message : https://www.apple.com/newsroom/2023/05/apple-previews-live-speech-personal-voice-and-more-new-accessibility-features/

Message : Going to steal a few customers from eleven labs TTS

Message : Shopify released this interesting dataset

I'm leading AI at Dukaan. If anyone's keen on taking up any projects related to this dataset then I'm happy to share my domain knowledge around e-commerce and AI.

https://news.shopify.com/index-beta

Message : ‚Äé<attached: 00004110-PHOTO-2023-05-17-08-05-45.jpg>
Quoted Message : Shopify released this interesting dataset\n\nI'm leading AI at Dukaan. If anyone's keen on taking up any projects related to this dataset then I'm happy to share my domain knowledge around e-commerce and AI.\n\nhttps://news.shopify.com/index-beta

Message : Exports of shopify merchants in India selling abroad

Message : There's possibly a currency impact too

Message : That isn't factored in

Message : Here's an idea: Prompt injection detection as a service.

There are a few ideas floating around in the ecosystem
* Using two LLMs - https://simonwillison.net/2023/Apr/25/dual-llm-pattern/
* Using vector DBs to keep track of previous attacks
* Other archaic techniques like - begging the LLM not to break character, using special charectors to differentiate system and user messages, etc.

Does anyone know any activity in this space?

Message : Related? 
https://twitter.com/willpienaar/status/1658479681182797836?s=46
Quoted Message : Here's an idea: Prompt injection detection as a service.\n\nThere are a few ideas floating around in the ecosystem\n* Using two LLMs - https://simonwillison.net/2023/Apr/25/dual-llm-pattern/\n* Using vector DBs to keep track of previous attacks\n* Other archaic techniques like - begging the LLM not to break character, using special charectors to differentiate system and user messages, etc.\n\nDoes anyone know any activity in this space?

Message : https://rebuff.ai/ is trying to build this, they even have a self hostable server

Message : Oh beat me to it

Message : To self host
https://github.com/woop/rebuff

Message : Why was it forwarded to the same WA group?

Message : ‚Äé<attached: 00004124-GIF-2023-05-17-08-50-06.mp4>

Message : Removed those for now, I assume it was meant for someone else
Quoted Message : Why was it forwarded to the same WA group?

Message : @91988071xxxx compiled this excel sheet with learning resource, hope you find this helpful 

https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240
Quoted Message : Do we have a list of good learning resource? Bunch of college grads have started reaching out asking for resources which can make them industry ready in the ML/AI space, specially Generative ?

Message : Thanks for this.
Quoted Message : @9198xxxxxxxx compiled this excel sheet with learning resource, hope you find this helpful \n\nhttps://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240

Message : They also made changes to CoreML for stable diffusion. Feels like in sometime, they will ship iphone/mac with their modified version of SD which devs/consumers can directly use. 

https://machinelearning.apple.com/research/stable-diffusion-coreml-apple-silicon
Quoted Message : Apple takes its first step in Gen AI

Message : https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353

A single developer took OpenCLIP and created an app Queryable ($1.99) which runs the model LOCALLY locally on your phone and indexes all your photos (you can put your phone in airplane mode to see) and you can now run any complex query on your photos. I've tried it and it is just mind blowingly good.

This is just STUNNING. For the longest time, Google had the best search for photos and the belief was that this was because of years of training on practically the whole internet.

That capability is now available to every developer for FREE

Message : https://hackathon.bio/ - Bio x AI hackathon - fully remote - people interested in AI in biology can look into it

Message : This is really cool find, will try this out
Quoted Message : https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353\n\nA single developer took OpenCLIP and created an app Queryable ($1.99) which runs the model LOCALLY locally on your phone and indexes all your photos (you can put your phone in airplane mode to see) and you can now run any complex query on your photos. I've tried it and it is just mind blowingly good.\n\nThis is just STUNNING. For the longest time, Google had the best search for photos and the belief was that this was because of years of training on practically the whole internet. \n\nThat capability is now available to every developer for FREE

Message : Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.

For example in this video - youtube.com/watch?v=twHxmU9OxDU - the presenter dumps a research paper's first two pages into the prompt and asks it a question.

Message : GPT-3.5-turbo and GPT-4 have default context sizes of 4096 tokens. There are variants of GPT-4 models with 8k and 32k tokens context sizes as well.
Quoted Message : Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.\n\nFor example in this video - youtube.com/watch?v=twHxmU9OxDU - the presenter dumps a research paper's first two pages into the prompt and asks it a question.

Message : Got it. Ty. 

Quick question:

Lets say I gave gpt-3.5-turbo a prompt for it to act as researcher and I gave it a large paper to ingest. I ask a few questions, etc.

After the model hits its context of 4096 tokens won't it forget it was a researcher?

Message : Works via Map Reduce kinda ideas. 

Here is one idea: https://python.langchain.com/en/latest/_modules/langchain/chains/mapreduce.html

You can see some of the community discussions here: https://nirantk.com/ai  ‚Äî they're all build this way. This chat is often more than 4K tokens/day.
Quoted Message : Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.\n\nFor example in this video - youtube.com/watch?v=twHxmU9OxDU - the presenter dumps a research paper's first two pages into the prompt and asks it a question.

Message : Map reduce has a theoretical upper limit on the size of output, which is 1/3 of the max output token count of the model btw something to keep in mind
Quoted Message : Works via Map Reduce kinda ideas. \n\nHere is one idea: https://python.langchain.com/en/latest/_modules/langchain/chains/mapreduce.html\n\nYou can see some of the community discussions here: https://nirantk.com/ai  ‚Äî they're all build this way. This chat is often more than 4K tokens/day.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Thanks for this.
Quoted Message : @9198xxxxxxxx compiled this excel sheet with learning resource, hope you find this helpful \n\nhttps://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240

Message : They also made changes to CoreML for stable diffusion. Feels like in sometime, they will ship iphone/mac with their modified version of SD which devs/consumers can directly use. 

https://machinelearning.apple.com/research/stable-diffusion-coreml-apple-silicon
Quoted Message : Apple takes its first step in Gen AI

Message : https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353

A single developer took OpenCLIP and created an app Queryable ($1.99) which runs the model LOCALLY locally on your phone and indexes all your photos (you can put your phone in airplane mode to see) and you can now run any complex query on your photos. I've tried it and it is just mind blowingly good.

This is just STUNNING. For the longest time, Google had the best search for photos and the belief was that this was because of years of training on practically the whole internet.

That capability is now available to every developer for FREE

Message : https://hackathon.bio/ - Bio x AI hackathon - fully remote - people interested in AI in biology can look into it

Message : This is really cool find, will try this out
Quoted Message : https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353\n\nA single developer took OpenCLIP and created an app Queryable ($1.99) which runs the model LOCALLY locally on your phone and indexes all your photos (you can put your phone in airplane mode to see) and you can now run any complex query on your photos. I've tried it and it is just mind blowingly good.\n\nThis is just STUNNING. For the longest time, Google had the best search for photos and the belief was that this was because of years of training on practically the whole internet. \n\nThat capability is now available to every developer for FREE

Message : Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.

For example in this video - youtube.com/watch?v=twHxmU9OxDU - the presenter dumps a research paper's first two pages into the prompt and asks it a question.

Message : GPT-3.5-turbo and GPT-4 have default context sizes of 4096 tokens. There are variants of GPT-4 models with 8k and 32k tokens context sizes as well.
Quoted Message : Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.\n\nFor example in this video - youtube.com/watch?v=twHxmU9OxDU - the presenter dumps a research paper's first two pages into the prompt and asks it a question.

Message : Got it. Ty. 

Quick question:

Lets say I gave gpt-3.5-turbo a prompt for it to act as researcher and I gave it a large paper to ingest. I ask a few questions, etc.

After the model hits its context of 4096 tokens won't it forget it was a researcher?

Message : Works via Map Reduce kinda ideas. 

Here is one idea: https://python.langchain.com/en/latest/_modules/langchain/chains/mapreduce.html

You can see some of the community discussions here: https://nirantk.com/ai  ‚Äî they're all build this way. This chat is often more than 4K tokens/day.
Quoted Message : Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.\n\nFor example in this video - youtube.com/watch?v=twHxmU9OxDU - the presenter dumps a research paper's first two pages into the prompt and asks it a question.

Message : Map reduce has a theoretical upper limit on the size of output, which is 1/3 of the max output token count of the model btw something to keep in mind
Quoted Message : Works via Map Reduce kinda ideas. \n\nHere is one idea: https://python.langchain.com/en/latest/_modules/langchain/chains/mapreduce.html\n\nYou can see some of the community discussions here: https://nirantk.com/ai  ‚Äî they're all build this way. This chat is often more than 4K tokens/day.

Message : I have a chrome extension that has found some success - https://chrome.google.com/webstore/detail/summarize/lmhkmibdclhibdooglianggbnhcbcjeh

I was planning on building more products that use chat.openai.com and not OpenAI token. This way I can give it out for free.

Is it a good idea to use chat.openai.com's auth token and make requests or should I be using OpenAI's API token? Is there a difference?

Message : https://twitter.com/itstimconnors/status/1658547632124354595?s=48&t=ACPHEfclkXmi9Z92RTsh9g

Imbuing agents with personality.

Message : Has anyone put ANY opensource model in production without fine tuning? 

Which one are u liking for being as close to OpenAI as possible for an open-source model ?

Message : would be good to use Azure OpenAI service while building products as you may hit rate limit error with OpenAI token.
Quoted Message : I have a chrome extension that has found some success - https://chrome.google.com/webstore/detail/summarize/lmhkmibdclhibdooglianggbnhcbcjeh\n\nI was planning on building more products that use chat.openai.com and not OpenAI token. This way I can give it out for free. \n\nIs it a good idea to use chat.openai.com's auth token and make requests or should I be using OpenAI's API token? Is there a difference?

Message : What is the usecase of putting a generic model in production?
Quoted Message : Has anyone put ANY opensource model in production without fine tuning? \n\nWhich one are u liking for being as close to OpenAI as possible for an open-source model ?

Message : The product will be using the user's Chat GPT token. So I don't think it will be hitting OpenAI's throttle limits
Quoted Message : would be good to use Azure OpenAI service while building products as you may hit rate limit error with OpenAI token.

Message : You might run foul of Terms of Service
Quoted Message : I have a chrome extension that has found some success - https://chrome.google.com/webstore/detail/summarize/lmhkmibdclhibdooglianggbnhcbcjeh\n\nI was planning on building more products that use chat.openai.com and not OpenAI token. This way I can give it out for free. \n\nIs it a good idea to use chat.openai.com's auth token and make requests or should I be using OpenAI's API token? Is there a difference?

Message : Is there a difference bw chat.openai.com and gpt-3.5-turbo?
Quoted Message : I have a chrome extension that has found some success - https://chrome.google.com/webstore/detail/summarize/lmhkmibdclhibdooglianggbnhcbcjeh\n\nI was planning on building more products that use chat.openai.com and not OpenAI token. This way I can give it out for free. \n\nIs it a good idea to use chat.openai.com's auth token and make requests or should I be using OpenAI's API token? Is there a difference?

Message : Hm, yes that could be an issue. But technically OpenAI does not know the requests are coming from an extension
Quoted Message : You might run foul of Terms of Service

Message : Hey there. Can someone help
me understand why the memory relevance score is obtained by simple summation and not say a multiplicative combination of recency, importance or similarity?
Quoted Message : https://twitter.com/itstimconnors/status/1658547632124354595?s=48&t=ACPHEfclkXmi9Z92RTsh9g\n\nImbuing agents with personality.

Message : And it is just a user's request. I pay for ChatGPT. But the app could be more for targeted segments instead of being a chat only tool.

Example
* a copy.ai clone all in your chrome extension.
* a kind of builder - form, email template , etc

Message : Yes, the biggest one has to be that there‚Äôs a farm of humans looking at what you type into chatgpt and trying to fix it üòÇ
Quoted Message : Hm, yes that could be an issue. But technically OpenAI does not know the requests are coming from an extension

Message : Taking a guess

If you multiply then change in one factor impacts the other 3 much more

Differentiate

xyz

Vs

x + y + z
Quoted Message : Hey there. Can someone help\nme understand why the memory relevance score is obtained by simple summation and not say a multiplicative combination of recency, importance or similarity?

Message : Why not factor something like an xy+yz+xz.. sometimes memory triggers for us are a combination of similarity and importance?

Message : I understand more unstability but maybe can be combined with a smaller coefficient?

Message : chatgpt is a generic model. more commonly known as a foundation model. 
not disputing the value of LLM/foundation models vs custom trained models...this question is merely about "which open source foundation model have u put in production just like u would use chatgpt"
Quoted Message : What is the usecase of putting a generic model in production?

Message : I guess its upto use case.

If you really expect more complicated logic in your use case.

You can just build a decision tree or svm with the 3 features
Quoted Message : Why not factor something like an xy+yz+xz.. sometimes memory triggers for us are a combination of similarity and importance?

Message : Simple intuition - 
Addition is like treating them as independent axes. So something can be extremely recent but not very important.
Multiplication makes it more of a dependent AND operation. It has to be recent , similar and important at the same time. It is more restrictive.
Quoted Message : Why not factor something like an xy+yz+xz.. sometimes memory triggers for us are a combination of similarity and importance?

Message : Addition is more lax. And so the model can decide what to do. And you err on the side of calling into the model more

Message : Someone was asking about metas plans

Message : https://atscaleconference.com/events/meta-ai-infra-scale/

Message : Tune in if you‚Äôre curious

Message : Yeah SVM with three features makes sense. Treating them like vectors on independent axes
Quoted Message : Simple intuition - \nAddition is like treating them as independent axes. So something can be extremely recent but not very important. \nMultiplication makes it more of a dependent AND operation. It has to be recent , similar and important at the same time. It is more restrictive.

Message : X+Y+Z < C is a diamond shape

xyz  < c is a complex 3d shape like with 8 hyperbola like faces
Quoted Message : Simple intuition - \nAddition is like treating them as independent axes. So something can be extremely recent but not very important. \nMultiplication makes it more of a dependent AND operation. It has to be recent , similar and important at the same time. It is more restrictive.

Message : Has anyone seen any example of an agent setup doing something truly impressive ?

Message : One way of think of them (Control System PoV) is that are they operations in series (multiplication) or parallel(addition)? Multiplying is great if you sort have a condition "if any of these are bad, then output should be low", as even one component being low will effect output drastically. Whereas addition will reduce only for that component's selection. There are other nuances as well. You can see this talk I gave at 2018 fifthelephant (some of those are dated today). See anti pattern3: https://m.youtube.com/watch?v=FYVFK4Y4IiY
Quoted Message : Hey there. Can someone help\nme understand why the memory relevance score is obtained by simple summation and not say a multiplicative combination of recency, importance or similarity?

Message : I have seen more demos of the frameworks than actual outputs

Message : I‚Äôm working on a bunch of stuff in ecomm - will dm you!
Quoted Message : Shopify released this interesting dataset\n\nI'm leading AI at Dukaan. If anyone's keen on taking up any projects related to this dataset then I'm happy to share my domain knowledge around e-commerce and AI.\n\nhttps://news.shopify.com/index-beta

Message : Like the Microsoft paper was cool because it was a simulation / game for fun. So for eg agents might be great for writing the plot of a movie. Make a set of characters and set them loose. But for ‚Äúreal work‚Äù yet to see something that works well

Message : The key here is to make you one of the ‚Äúagents‚Äù and also things like compilers and search engines. And you can interrupt it at any point by pressing Ctrl+D or something and redirect it.
Quoted Message : Like the Microsoft paper was cool because it was a simulation / game for fun. So for eg agents might be great for writing the plot of a movie. Make a set of characters and set them loose. But for ‚Äúreal work‚Äù yet to see something that works well

Message : And then you do tbis a lot and fine tune / RLHF on it. This is what openAI is doing with plugins.

Message : ‚Äé<attached: 00004174-PHOTO-2023-05-17-13-09-00.jpg>

Message : Any of you have github pro here? 
I was trying to upgrade to get more large-file-storage access, but RBI declined my payment

Message : ‚Äé<attached: 00004176-PHOTO-2023-05-17-14-57-34.jpg>

Message : I don't use Pro yet for my company. I thought there isn't a limit on repo size or file size. Is there?
Quoted Message : Any of you have github pro here? \nI was trying to upgrade to get more large-file-storage access, but RBI declined my payment

Message : You can get GitHub Pro for 12 months here if you're buying it for a startup: https://github.com/enterprise/startups
Quoted Message : Any of you have github pro here? \nI was trying to upgrade to get more large-file-storage access, but RBI declined my payment

Message : There is a maximum storage limit
Quoted Message : I don't use Pro yet for my company. I thought there isn't a limit on repo size or file size. Is there?

Message : /month

Message : Ok, so 2gb per file

Message : Hey folks,

Akash here from Flipkart Labs where I'm building products across a few emerging tech tracks with Gen AI being one of them. I've been a part of this community for just a day and I really appreciate the conversations and the people behind them. Learning a lot myself and would love to contribute/help in any way possible.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : And then you do tbis a lot and fine tune / RLHF on it. This is what openAI is doing with plugins.

Message : ‚Äé<attached: 00004174-PHOTO-2023-05-17-13-09-00.jpg>

Message : Any of you have github pro here? 
I was trying to upgrade to get more large-file-storage access, but RBI declined my payment

Message : ‚Äé<attached: 00004176-PHOTO-2023-05-17-14-57-34.jpg>

Message : I don't use Pro yet for my company. I thought there isn't a limit on repo size or file size. Is there?
Quoted Message : Any of you have github pro here? \nI was trying to upgrade to get more large-file-storage access, but RBI declined my payment

Message : You can get GitHub Pro for 12 months here if you're buying it for a startup: https://github.com/enterprise/startups
Quoted Message : Any of you have github pro here? \nI was trying to upgrade to get more large-file-storage access, but RBI declined my payment

Message : There is a maximum storage limit
Quoted Message : I don't use Pro yet for my company. I thought there isn't a limit on repo size or file size. Is there?

Message : /month

Message : Ok, so 2gb per file

Message : Hey folks,

Akash here from Flipkart Labs where I'm building products across a few emerging tech tracks with Gen AI being one of them. I've been a part of this community for just a day and I really appreciate the conversations and the people behind them. Learning a lot myself and would love to contribute/help in any way possible.

Message : I had a question for the folks working on Stable Diffusion / any diffusion model in a larger org. Most models / the companies behind them don't accept any liability for the images generated from the model and AI copyright is a tricky subject. There have been instances (although a small %) where copyrighted content has surfaced on the generated images (cross-checked with LAION-5B) and this makes working with them a bit hard. 

While inpainting use cases are broadly okay on a fine-tuned dataset, outpainting / complete generation of the image wouldn't. I'd only expect companies that have strict control over the pre-trained model data set to be able to consider this. Have any of you come across any company that's accepting liability for their model output or for their services?

Message : I follow AI regulations closely.

AI generated images can't be copyrighted. Which will come to mean that they don't enjoy copyright protection. It is still not tested in court, however US PTO has already moved on this.

https://www.artnews.com/art-news/news/ai-generator-art-text-us-copyright-policy-1234661683/
Quoted Message : I had a question for the folks working on Stable Diffusion / any diffusion model in a larger org. Most models / the companies behind them don't accept any liability for the images generated from the model and AI copyright is a tricky subject. There have been instances (although a small %) where copyrighted content has surfaced on the generated images (cross-checked with LAION-5B) and this makes working with them a bit hard. \n\nWhile inpainting use cases are broadly okay on a fine-tuned dataset, outpainting / complete generation of the image wouldn't. I'd only expect companies that have strict control over the pre-trained model data set to be able to consider this. Have any of you come across any company that's accepting liability for their model output or for their services?

Message : These are the regs if u want to read https://www.copyright.gov/ai/

We anticipate Indian copyright law to broadly mirror this.

Message : (deleted my answer because it was wrong)

Message : That said, I know this will be a tricky decision making process for someone like Flipkart to start getting audit clearance to generate AI images/content for products.

I think the best way right now that people are doing is to put a statutory declaration beneath each image "generated by AI. Report this for copyright infringement".

That way ur protected by Copyright Safe Harbor provisions rather than any new fangled g
generative AI regulations

Message : Correct me if I am wrong but doesn‚Äôt Adobe‚Äôs firefly helps you get around any copyright infringement reporting since the dataset is not on infringed content?

Message : Yeah while possible in certain instances, that would be hard to do at scale. Thank you though!
Quoted Message : That said, I know this will be a tricky decision making process for someone like Flipkart to start getting audit clearance to generate AI images/content for products.\n\nI think the best way right now that people are doing is to put a statutory declaration beneath each image \"generated by AI. Report this for copyright infringement\".\n\nThat way ur protected by Copyright Safe Harbor provisions rather than any new fangled g\ngenerative AI regulations

Message : Yes and no, 

Yes that they did use adobe stock and not look at other sources such as behance and other products of theirs. This does impact output but it does perform well across certain tracks

No because I remember reading somewhere that the contributors to adobe stock while giving away rights when they submitted weren‚Äôt made aware that the images were used for training the model and that the terms weren‚Äôt extremely clear. Not entirely sure about this though

Apart from this, it definitely would. Bard went ahead and integrated firefly too but I haven‚Äôt been able to use it there
Quoted Message : Correct me if I am wrong but doesn‚Äôt Adobe‚Äôs firefly helps you get around any copyright infringement reporting since the dataset is not on infringed content?

Message : ‚Äé<attached: 00004193-PHOTO-2023-05-17-16-33-26.jpg>

Message : https://www.sanctuary.ai/

Message : AI is at its peak i guess 
Classic example of on device AI

Message : ‚Äé<attached: 00004196-PHOTO-2023-05-17-17-25-00.jpg>

Message : Question: What are the best FOSS chat models which can be given personality with light finetuning or prompting?

Message : -cries in corner-
Quoted Message :  2023_05_17_3EB0DFB52547E2DB9511F2.jpeg

Message : Wait. Let me try this on my sarcastic chatbot

Message : Replicate had one where they trained on Simpsons
Quoted Message : Question: What are the best FOSS chat models which can be given personality with light finetuning or prompting?

Message : ‚Äé<attached: 00004201-PHOTO-2023-05-17-17-32-01.jpg>

Message : Does anybody have a viewpoint on this- When does it make sense to give personality traits in the prompt itself vs using constitutional ai to direct the LLM to give responses in a certain style?
Quoted Message :  2023_05_17_3EB0DFB52547E2DB9511F2.jpeg

Message : Follow up question: What is Constitutional AI?
Quoted Message : Does anybody have a viewpoint on this- When does it make sense to give personality traits in the prompt itself vs using constitutional ai to direct the LLM to give responses in a certain style?

Message : hmmm, seems so: https://docs.github.com/en/billing/managing-billing-for-your-github-account/one-time-payments-for-customers-in-india
Quoted Message :  2023_05_17_3A8E081CDC960A592375.jpeg

Message : ‚Äé<attached: 00004205-PHOTO-2023-05-17-17-34-08.jpg>

Message : Not foss sorry but davinci works better
Quoted Message : Question: What are the best FOSS chat models which can be given personality with light finetuning or prompting?

Message : I am doing this 10 interactions deep. 2-3 interactions is dead easy. Starts breaking the 4th wall about 5-7 interactions deep. 

Trying to see if Character.ai has any engineering moat. Doesn't seem like it at the moat.
Quoted Message :  2023_05_17_3EB02F99F593CDC009F00A.jpeg

Message : they are prompts which are given as pre-instructions before your actual prompt. they help in safety stuff (like no racist responses, etc etc)
Quoted Message : Follow up question: What is Constitutional AI?

Message : langchain has this to setup a set of principles which the LLM's responses should follow while giving a response. Although it's more so for not giving harmful or unethical responses, I was thinking that can't we use the same stuff for giving personality traits to the LLM as well?

https://python.langchain.com/en/latest/modules/chains/examples/constitutional_chain.html
Quoted Message : Follow up question: What is Constitutional AI?

Message : Constitutional AI is by Anthropic

Message : https://arxiv.org/abs/2212.08073

Message : FYI - constitutional AI will work very badly on models that are not RLHFed . because it wont know what "ethics" is

Message : someone shared this link on this group itself a few days back- https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids

It says that it's not that the AI doesn't know what ethics is. But knowing about it doesn't force it to give ethical responses because it's not incentivized to be ethical. So even if the model isn't RLHF'ed, won't just asking it to rephrase the response to be more ethical work? I think it would. Not an expert here though- just brainstorming
Quoted Message : FYI - constitutional AI will work very badly on models that are not RLHFed . because it wont know what \"ethics\" is

Message : i dont think it says that. it says that if you retrain AI with constitutional AI responses (which are generated themselves from vanilla RLHFed AI), it gives a better Elo score of ethics.
Anthropic does a good job of using Elo scoring versus some absolute scale because it is just better than the previous AI...not absolutely ethical on a human scale.
Quoted Message : someone shared this link on this group itself a few days back- https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids\n\nIt says that it's not that the AI doesn't know what ethics is. But knowing about it doesn't force it to give ethical responses because it's not incentivized to be ethical. So even if the model isn't RLHF'ed, won't just asking it to rephrase the response to be more ethical work? I think it would. Not an expert here though- just brainstorming

Message : ‚Äé<attached: 00004215-PHOTO-2023-05-17-18-09-54.jpg>
Quoted Message : i dont think it says that. it says that if you retrain AI with constitutional AI responses (which are generated themselves from vanilla RLHFed AI), it gives a better Elo score of ethics.\nAnthropic does a good job of using Elo scoring versus some absolute scale because it is just better than the previous AI...not absolutely ethical on a human scale.

Message : If you've any working notebooks for this, please share?
Quoted Message :  2023_05_17_3EB04369D4EAEA2BC1E02D.jpeg

Message : Tinkering with it. Will do soon

Message : Lol
Quoted Message :  2023_05_17_3EB0DFB52547E2DB9511F2.jpeg

Message : What prompt are you using for this?

Message : Are there any collaborative ChatGPT interfaces? 

Multiple users can interact with the same not. Use case is testing out a prompt in my team.

Message : Folks how are you deploying langchain for production chat application? Any great off-the-shelf solution?

Message : Off the Shelf for QA: https://github.com/gmpetrov/databerry

Not built on Langchain though
Quoted Message : Folks how are you deploying langchain for production chat application? Any great off-the-shelf solution?

Message : *Built on LangchainJS, not on Langchain Python

Message : I am looking for multi-message chats which requires state. QA have the freedom to be stateless. I am Python person, so cannot understand this


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00004215-PHOTO-2023-05-17-18-09-54.jpg>
Quoted Message : i dont think it says that. it says that if you retrain AI with constitutional AI responses (which are generated themselves from vanilla RLHFed AI), it gives a better Elo score of ethics.\nAnthropic does a good job of using Elo scoring versus some absolute scale because it is just better than the previous AI...not absolutely ethical on a human scale.

Message : If you've any working notebooks for this, please share?
Quoted Message :  2023_05_17_3EB04369D4EAEA2BC1E02D.jpeg

Message : Tinkering with it. Will do soon

Message : Lol
Quoted Message :  2023_05_17_3EB0DFB52547E2DB9511F2.jpeg

Message : What prompt are you using for this?

Message : Are there any collaborative ChatGPT interfaces? 

Multiple users can interact with the same not. Use case is testing out a prompt in my team.

Message : Folks how are you deploying langchain for production chat application? Any great off-the-shelf solution?

Message : Off the Shelf for QA: https://github.com/gmpetrov/databerry

Not built on Langchain though
Quoted Message : Folks how are you deploying langchain for production chat application? Any great off-the-shelf solution?

Message : *Built on LangchainJS, not on Langchain Python

Message : I am looking for multi-message chats which requires state. QA have the freedom to be stateless. I am Python person, so cannot understand this

Message : Any opinions on steamship?
https://www.steamship.com/build/langchain-apps

Message : What are multi message chats
Quoted Message : I am looking for multi-message chats which requires state. QA have the freedom to be stateless. I am Python person, so cannot understand this

Message : Is this what you are looking for?
https://python.langchain.com/en/latest/modules/memory/getting_started.html
Quoted Message : I am looking for multi-message chats which requires state. QA have the freedom to be stateless. I am Python person, so cannot understand this

Message : haha.. I mean chat which is multi-turn while QA is just single turn
Quoted Message : What are multi message chats

Message : My question is more around serving

Requirement
- hopefully serverless and scalable
- chat memory state management (easy if it is just buffer last k chat)
- saving chats to DB inorder to do analytics/train
- monitoring on chats (can be separate job over saved chats)
- more of research question: how to initiate a new chat with same person with context from old chat? Do you just feed summary of past n chats?
Quoted Message : Is this what you are looking for?\nhttps://python.langchain.com/en/latest/modules/memory/getting_started.html

Message : The new chat models have an option to give a chat history.

Ofcourse you will run out of context length, so you have to truncate it, and optionally summarise whatever you truncate and fit into the context.
Quoted Message : My question is more around serving\n\nRequirement\n- hopefully serverless and scalable\n- chat memory state management (easy if it is just buffer last k chat)\n- saving chats to DB inorder to do analytics/train\n- monitoring on chats (can be separate job over saved chats) \n- more of research question: how to initiate a new chat with same person with context from old chat? Do you just feed summary of past n chats?

Message : If the serving is serverless without state, is it better to send history from client or from a cloud cache like elasticache?

Message : The problem with sending state from client is latency over slow networks. 
Eg at 4096 tokens you‚Äôre looking at about 100kb of data for every request

Message : We built one on WhatsApp using Langchain agents with ConversationBufferWindowMemory which uses Redis for managing the last few messages context window.

- For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states.
- In-memory: ConversationBufferWindowMemory - for every ongoing conversation you can have unique key and load that conversation whenever a message from the same user is received from redis.
- For persistent storage: Used MongoDB (in our case) for persistent storage.
Quoted Message : My question is more around serving\n\nRequirement\n- hopefully serverless and scalable\n- chat memory state management (easy if it is just buffer last k chat)\n- saving chats to DB inorder to do analytics/train\n- monitoring on chats (can be separate job over saved chats) \n- more of research question: how to initiate a new chat with same person with context from old chat? Do you just feed summary of past n chats?

Message : We‚Äôre using django & postgres - allows long term storage & you get a free ui for monitoring too.

Instead of langchain, i use a db query to fetch the last X messages
Quoted Message : We built one on WhatsApp using Langchain agents with ConversationBufferWindowMemory which uses Redis for managing the last few messages context window.\n\n- For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states.\n- In-memory: ConversationBufferWindowMemory - for every ongoing conversation you can have unique key and load that conversation whenever a message from the same user is received from redis.\n- For persistent storage: Used MongoDB (in our case) for persistent storage.

Message : ya db query is a similar thought lot of people have
Quoted Message : We‚Äôre using django & postgres - allows long term storage & you get a free ui for monitoring too.\n\nInstead of langchain, i use a db query to fetch the last X messages

Message : You do have to do a bit of post maths after the query to figure out exactly how many tokens each msg is and fit accordingly
Quoted Message : We‚Äôre using django & postgres - allows long term storage & you get a free ui for monitoring too.\n\nInstead of langchain, i use a db query to fetch the last X messages

Message : >For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states.

could u elaborate this a bit more ? how does fastapi help with chat memory states ?
Quoted Message : We built one on WhatsApp using Langchain agents with ConversationBufferWindowMemory which uses Redis for managing the last few messages context window.\n\n- For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states.\n- In-memory: ConversationBufferWindowMemory - for every ongoing conversation you can have unique key and load that conversation whenever a message from the same user is received from redis.\n- For persistent storage: Used MongoDB (in our case) for persistent storage.

Message : I tried doing this for a chat bot, but did not find a way in langchain to persist summary along with buffer. So ended up implementing something like ConversationSummaryBufferMemory but where both Buffer and Summary were persisted in PG. Ended up writing my own python script.
Quoted Message : My question is more around serving\n\nRequirement\n- hopefully serverless and scalable\n- chat memory state management (easy if it is just buffer last k chat)\n- saving chats to DB inorder to do analytics/train\n- monitoring on chats (can be separate job over saved chats) \n- more of research question: how to initiate a new chat with same person with context from old chat? Do you just feed summary of past n chats?

Message : RedisChatMessageHistory which was the ChatMemory that we used in our ConversationSummaryBufferMemory (langchain classes) has a field called session_id.

In our case of WhatsApp, the phone_number quite conveniently became a unique identifier and hence the session_id which helped us maintain chat memory states as it remained constant across multiple messages (each whatsapp_message is a webhook request) from the same person. Also, we used langchain because there were multiple other tools of langchain involved in our case.

As for the FastAPI bit, I meant to imply that FastAPI was the way we achieved it but other web-frameworks (including Django) should also be able to achieve that.
Quoted Message : >For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states.\n\ncould u elaborate this a bit more ? how does fastapi help with chat memory states ?

Message : I use both fastapi & django, deadly combo ü´£
Quoted Message : RedisChatMessageHistory which was the ChatMemory that we used in our ConversationSummaryBufferMemory (langchain classes) has a field called session_id.\n\nIn our case of WhatsApp, the phone_number quite conveniently became a unique identifier and hence the session_id which helped us maintain chat memory states as it remained constant across multiple messages (each whatsapp_message is a webhook request) from the same person. Also, we used langchain because there were multiple other tools of langchain involved in our case.\n\nAs for the FastAPI bit, I meant to imply that FastAPI was the way we achieved it but other web-frameworks (including Django) should also be able to achieve that.

Message : Do you configure redis to have aways on disk writes?
Quoted Message : RedisChatMessageHistory which was the ChatMemory that we used in our ConversationSummaryBufferMemory (langchain classes) has a field called session_id.\n\nIn our case of WhatsApp, the phone_number quite conveniently became a unique identifier and hence the session_id which helped us maintain chat memory states as it remained constant across multiple messages (each whatsapp_message is a webhook request) from the same person. Also, we used langchain because there were multiple other tools of langchain involved in our case.\n\nAs for the FastAPI bit, I meant to imply that FastAPI was the way we achieved it but other web-frameworks (including Django) should also be able to achieve that.

Message : For us, it‚Äôs just an in memory store - so we don‚Äôt do disk writes there. For persistent storage, we store the chats in mongodb.
Quoted Message : Do you configure redis to have aways on disk writes?

Message : And load from mongo to redis on server restarts?
Quoted Message : For us, it‚Äôs just an in memory store - so we don‚Äôt do disk writes there. For persistent storage, we store the chats in mongodb.

Message : Still need to implement this! üòÖ
Quoted Message : And load from mongo to redis on server restarts?

Message : Curious why you wouldn‚Äôt just use mongo here
Quoted Message : Still need to implement this! üòÖ

Message : Do you have that level of scale where mongo db won‚Äôt hold up

Message : Discord for eg used mongodb until a 100 million msgs https://discord.com/blog/how-discord-stores-billions-of-messages

Message : We are using a managed redis so we didn‚Äôt accommodate for edge cases such as a redis restart.

Web server restarts wouldn‚Äôt matter since the state is anyways managed in redis which is not on the same server.
Quoted Message : Curious why you wouldn‚Äôt just use mongo here

Message : What does FastAPI has to do with serverless?
Quoted Message : >For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states.\n\ncould u elaborate this a bit more ? how does fastapi help with chat memory states ?

Message : I think now they moved to Scylla DB. Which is way better than Cassandra.
https://www.scylladb.com/
Quoted Message : Discord for eg used mongodb until a 100 million msgs https://discord.com/blog/how-discord-stores-billions-of-messages

Message : That's a great combination. 

Just curious, what type of retriever are you using? Are you using the Langchain retrievers or something else.

Context -: Me and Sushant are collaboratively developing the chatbot.
Quoted Message : We‚Äôre using django & postgres - allows long term storage & you get a free ui for monitoring too.\n\nInstead of langchain, i use a db query to fetch the last X messages

Message : Retriver for the documents? np.array & cosine similarity
Quoted Message : That's a great combination. \n\nJust curious, what type of retriever are you using? Are you using the Langchain retrievers or something else. \n\nContext -: Me and Sushant are collaboratively developing the chatbot.

Message : Chad.
Quoted Message : Retriver for the documents? np.array & cosine similarity

Message : What is next? You implement in numpy too?

Message : Cosine similarity ko NP.dot over unit vectors coz you know... Chad

Message : Appx Nearest neighbors and imagebind
Quoted Message : What is next? You implement in numpy too?

Message : Numpy I trust üòÇ
Quoted Message : What is next? You implement in numpy too?

Message : That's great... üòÖ

For simplicity we went with Weaviate.
Quoted Message : Retriver for the documents? np.array & cosine similarity

Message : That word simplicity in that sentence is like, "What am I doing here?"
Quoted Message : That's great... üòÖ\n\nFor simplicity we went with Weaviate.

Message : üòÖ
Quoted Message : That word simplicity in that sentence is like, \"What am I doing here?\"

Message : Curious - are mordern vector dbs just in memory stores? Or do they implement vector search using clever indexes so they dont have to load everything into ram

Message : They implement techniques like hnsw. They optimize for speed and lose a little bit in accuracy

Message : Has someone built a model to summarize conversations in this chat group?

So many interesting convos but no time to process em tbh ü§Ø

Something like a Daily Digest? üòÖ

Message : You can see some of the community discussions here: https://nirantk.com/ai
Quoted Message : Has someone built a model to summarize conversations in this chat group?\n\nSo many interesting convos but no time to process em tbh ü§Ø\n\nSomething like a Daily Digest? üòÖ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Cosine similarity ko NP.dot over unit vectors coz you know... Chad

Message : Appx Nearest neighbors and imagebind
Quoted Message : What is next? You implement in numpy too?

Message : Numpy I trust üòÇ
Quoted Message : What is next? You implement in numpy too?

Message : That's great... üòÖ

For simplicity we went with Weaviate.
Quoted Message : Retriver for the documents? np.array & cosine similarity

Message : That word simplicity in that sentence is like, "What am I doing here?"
Quoted Message : That's great... üòÖ\n\nFor simplicity we went with Weaviate.

Message : üòÖ
Quoted Message : That word simplicity in that sentence is like, \"What am I doing here?\"

Message : Curious - are mordern vector dbs just in memory stores? Or do they implement vector search using clever indexes so they dont have to load everything into ram

Message : They implement techniques like hnsw. They optimize for speed and lose a little bit in accuracy

Message : Has someone built a model to summarize conversations in this chat group?

So many interesting convos but no time to process em tbh ü§Ø

Something like a Daily Digest? üòÖ

Message : You can see some of the community discussions here: https://nirantk.com/ai
Quoted Message : Has someone built a model to summarize conversations in this chat group?\n\nSo many interesting convos but no time to process em tbh ü§Ø\n\nSomething like a Daily Digest? üòÖ

Message : Question -: Anyone tried implementing self query retriever from Langchain. 

Feature -: It retrieves documents from a VectorDB and then applies filter on the metadata according to the query.

Issue -: Many a time it is generating filters which has a  metadata that is not in the document.

Message : Are you talking about this? 
https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/self_query_retriever.html

I've tried this ‚Äî I suspect that your issue is not fixable via Langchain constructs.
Quoted Message : Question -: Anyone tried implementing self query retriever from Langchain. \n\nFeature -: It retrieves documents from a VectorDB and then applies filter on the metadata according to the query. \n\nIssue -: Many a time it is generating filters which has a  metadata that is not in the document.

Message : What metadata are you storing? If you can share some
Quoted Message : Question -: Anyone tried implementing self query retriever from Langchain. \n\nFeature -: It retrieves documents from a VectorDB and then applies filter on the metadata according to the query. \n\nIssue -: Many a time it is generating filters which has a  metadata that is not in the document.

Message : Did you try incontext learning? As in give an example of filters in the prompt?
Quoted Message : Question -: Anyone tried implementing self query retriever from Langchain. \n\nFeature -: It retrieves documents from a VectorDB and then applies filter on the metadata according to the query. \n\nIssue -: Many a time it is generating filters which has a  metadata that is not in the document.

Message : If you want to filter on metadata in some way, Llama Index has native support for that: https://gpt-index.readthedocs.io/en/latest/how_to/query/second_stage.html

I've tried that also, and it works. Here is a working nbs: https://github.com/NirantK/wip/blob/main/nbs/

Message : Alternatively you can use this

https://github.com/1rgs/jsonformer

This adheres to the schema you specify

Message : Metadata example -: 'area', 'price', 'locality', .... More 3 are there
Quoted Message : What metadata are you storing? If you can share some

Message : You can use the above solutions mentioned, or you can keep the ones you know it's getting wrong as a parameter that you receive for your function /api

Message : Self query retriever uses Langchain construct and this is forming a wrong query that is being applied to the document.
Quoted Message : Are you talking about this? \nhttps://python.langchain.com/en/latest/modules/indexes/retrievers/examples/self_query_retriever.html\n\nI've tried this ‚Äî I suspect that your issue is not fixable via Langchain constructs.

Message : Is it just me or is gpt4 been having a lot of issues full day. Lots of failures

Message : Yes same issue we are facing.
Quoted Message : Is it just me or is gpt4 been having a lot of issues full day. Lots of failures

Message : The python package that returns response of Google Bard through API.

pypi.org/project/

Message : https://github.com/dsdanielpark/Bard-API

Message : Anyone tried it? How's the response ?

Message : ‚Äé<attached: 00004283-PHOTO-2023-05-17-22-26-05.jpg>

Message : I have been playing around with langchain document loaders and some of these loaders are quite limited. For example, the Arxiv loader has a limit of max 4000 characters. To embed documents from arxiv, I am resorting to using a PyPDFLoader and then splitting the document using a splitter and then creating embeddings.

The question really is - people who are creating embeddings, are the default loaders good enough or do you end up writing your own loaders/use other libraries?

Message : Own regexes ü´£üò≠
Quoted Message : I have been playing around with langchain document loaders and some of these loaders are quite limited. For example, the Arxiv loader has a limit of max 4000 characters. To embed documents from arxiv, I am resorting to using a PyPDFLoader and then splitting the document using a splitter and then creating embeddings.\n\nThe question really is - people who are creating embeddings, are the default loaders good enough or do you end up writing your own loaders/use other libraries?

Message : Not the reply that I was hoping for :P
Quoted Message : Own regexes ü´£üò≠

Message : +1, For arxiv documents specifically - I've written a lot of code to extract text from PDF and then removing unusable pieces & even using font variations to split properly.

Message : I use something like this - https://gist.github.com/roh26it/d1d7af2432175b443355990ec640b1d5

Not sure if this helps though

Message : has anybody tried better prompts for paper summarisation? The base Langchain ones haven't worked for me for text other than state of the union or pg essays :P

Message : Some things only work on Pg essays‚Ä¶

Message : haha, this is how we've all internalised his essays now :)

Message : Doing things that don't scale xD
Quoted Message : Some things only work on Pg essays‚Ä¶

Message : Hmm, elicit.org has amazing paper summarisation output. I've no idea what magic they do, but their beta is rad. I've abandoned my toolchain completely for wide paper reading (surveys) and single both.
Quoted Message : has anybody tried better prompts for paper summarisation? The base Langchain ones haven't worked for me for text other than state of the union or pg essays :P

Message : Default loaders are decent, but a bit of pre processing is always good. Like use pyPDF for loading, but remove new lines and extra spaces by using TextPreProcessors. That saves embedding cost and has not much perf difference for retrieval.

On top of that, I really liked the gpt-index implementation of TreeIndex, the search in that when you‚Äôre breaking down big docs gives very good results. But it‚Äôs not performative enough due to multiple LLM calls. Thinking of a graphdb implementation of this, would love to collaborate if someone else is also interested.
Quoted Message : I have been playing around with langchain document loaders and some of these loaders are quite limited. For example, the Arxiv loader has a limit of max 4000 characters. To embed documents from arxiv, I am resorting to using a PyPDFLoader and then splitting the document using a splitter and then creating embeddings.\n\nThe question really is - people who are creating embeddings, are the default loaders good enough or do you end up writing your own loaders/use other libraries?

Message : https://blog.google/technology/developers/google-colab-ai-coding-features/

Google is adding Codey inside Google Colab!!

Message : ‚Äé<attached: 00004296-PHOTO-2023-05-17-23-22-40.jpg>
Quoted Message : has anybody tried better prompts for paper summarisation? The base Langchain ones haven't worked for me for text other than state of the union or pg essays :P

Message : ‚Äé<attached: 00004297-PHOTO-2023-05-17-23-46-49.jpg>

Message : ‚ÄúWe‚Äôre not planning to train GPT-5 for the next 6 months‚Äù

https://twitter.com/theturingpost/status/1658826361245675525?s=46

(Not sure if this was already discussed)

Message : Yeah cause gpt4 is so big that it can remember everything their human ops team teaches it for the next 6 months üòÇ
Quoted Message : ‚ÄúWe‚Äôre not planning to train GPT-5 for the next 6 months‚Äù\n\nhttps://twitter.com/theturingpost/status/1658826361245675525?s=46\n\n(Not sure if this was already discussed)

Message : This indicates that they've already trained GPT5. Not the other way around.
Quoted Message : ‚ÄúWe‚Äôre not planning to train GPT-5 for the next 6 months‚Äù\n\nhttps://twitter.com/theturingpost/status/1658826361245675525?s=46\n\n(Not sure if this was already discussed)

Message : GPT5 feels like Bahubali 2 to me now.

Message : In Khan academy demo they mentioned they got access last year to gpt-4, so the actual state of the art must be way ahead?
Quoted Message : This indicates that they've already trained GPT5. Not the other way around.

Message : I fear that might nuke GPT capabilities and only allow some sort of licensed usage given the tone of discourse here. They did this with GPS a long time back when the precision tech was only allowed to be used by the military

Message : Yeah but we don‚Äôt need satellites to recreate these things. GPU farm is enough

Message : And you can steal the satellites you can copy the weights

Message : *cant

Message : All these are doomed to fail

Message : For something like GPT-4, we might need human farms more than GPU farms üòÖ
Quoted Message : Yeah but we don‚Äôt need satellites to recreate these things. GPU farm is enough


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Yeah cause gpt4 is so big that it can remember everything their human ops team teaches it for the next 6 months üòÇ
Quoted Message : ‚ÄúWe‚Äôre not planning to train GPT-5 for the next 6 months‚Äù\n\nhttps://twitter.com/theturingpost/status/1658826361245675525?s=46\n\n(Not sure if this was already discussed)

Message : This indicates that they've already trained GPT5. Not the other way around.
Quoted Message : ‚ÄúWe‚Äôre not planning to train GPT-5 for the next 6 months‚Äù\n\nhttps://twitter.com/theturingpost/status/1658826361245675525?s=46\n\n(Not sure if this was already discussed)

Message : GPT5 feels like Bahubali 2 to me now.

Message : In Khan academy demo they mentioned they got access last year to gpt-4, so the actual state of the art must be way ahead?
Quoted Message : This indicates that they've already trained GPT5. Not the other way around.

Message : I fear that might nuke GPT capabilities and only allow some sort of licensed usage given the tone of discourse here. They did this with GPS a long time back when the precision tech was only allowed to be used by the military

Message : Yeah but we don‚Äôt need satellites to recreate these things. GPU farm is enough

Message : And you can steal the satellites you can copy the weights

Message : *cant

Message : All these are doomed to fail

Message : For something like GPT-4, we might need human farms more than GPU farms üòÖ
Quoted Message : Yeah but we don‚Äôt need satellites to recreate these things. GPU farm is enough

Message : Also available. India is human farm

Message : Yep. This is needed
Quoted Message : For something like GPT-4, we might need human farms more than GPU farms üòÖ

Message : Arre Arre Arre! ü§£
Quoted Message : Also available. India is human farm

Message : Get all the unkils labeling data on their WhatsApp you‚Äôll have data you need in few days

Message : But jokes apart this legit is a huge advantage we have if we use it well

Message : Expensive one, philipines is cheaper
Quoted Message : Also available. India is human farm

Message : ‚Äé<attached: 00004315-PHOTO-2023-05-17-23-57-25.jpg>

Message : JioGPT - get ppl in villages to label stuff on their Jio phone

Message : but if you have to make indicGPT then you need people in india

Message : your ai has the median intelligence of your labeller
Quoted Message : JioGPT - get ppl in villages to label stuff on their Jio phone

Message : GPT is bad at math. go figure
Quoted Message : your ai has the median intelligence of your labeller

Message : Harder part will be RLHF to make sure it doesn't piss of politicians
Quoted Message : but if you have to make indicGPT then you need people in india

Message : But making like a Government GPT that can do all your taxes , forms , aadhar etc is actually a very good idea imo

Message : bhaiyo, behno , mai ek bhaasha model hu, scam mai nahi karta
Quoted Message : Harder part will be RLHF to make sure it doesn't piss of politicians

Message : You can nuke bureaucracy on a massive level

Message : Is someone making BharatGPT ,?

Message : I think i read somewhere

Message : Ai4bharat is
Quoted Message : Is someone making BharatGPT ,?

Message : Someone ask Nandan

Message : I also tried my training via lora on their dataset

Message : Aadhar authenticated plugins for all your govt work

Message : we need bureaucracy. just a little more efficient. bureaucracy chahiye democracy mai. otherwise it just becomes authoritarian completely.
Quoted Message : You can nuke bureaucracy on a massive level

Message : Payment via UPI

Message : https://corover.ai/bharatgpt/

Message : India should do something about this whole AI, it's an opportunity

Message : plus, this might be a double edged sword but flexible regulations will help here
Quoted Message : India should do something about this whole AI, it's an opportunity

Message : there's a lot of red tape for models like MPT etc being released as commerical in US instead of plain open source

Message : In 2021 they had this DEEPMAX framework to evaluate AI and all an India framework, the whole licence system was talked about

Message : IndiaStack should train foundation models

Message : But i think the tech wasn't sophisticated back then, but it's now

Message : Koo launched one i guess, 

But it's not foundational it's trained and fine tuned on BERT
Quoted Message : IndiaStack should train foundation models

Message : Make govt apis available for plugins allow third parties to build and iterate UPI style

Message : they call it kooBERT

Message : cc Harsh @91866009xxxx is the Head of ML at Koo
Quoted Message : Koo launched one i guess, \n\nBut it's not foundational it's trained and fine tuned on BERT

Message : Koo you guys should make a foundation model, ditch the gov 

We should have vernac models come out of India üòÉ
Quoted Message : cc Harsh @9186xxxxxxxx is the Head of ML at Koo

Message : https://caryn.ai/

Message : does anyone have  any idea to create a similiar bot like this ?

Message : where the the voice can also be cloned ?

Message : ‚Äé<attached: 00004347-PHOTO-2023-05-18-00-36-33.jpg>

Message : ‚Äé<attached: 00004348-PHOTO-2023-05-18-00-36-34.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Koo launched one i guess, 

But it's not foundational it's trained and fine tuned on BERT
Quoted Message : IndiaStack should train foundation models

Message : Make govt apis available for plugins allow third parties to build and iterate UPI style

Message : they call it kooBERT

Message : cc Harsh @91866009xxxx is the Head of ML at Koo
Quoted Message : Koo launched one i guess, \n\nBut it's not foundational it's trained and fine tuned on BERT

Message : Koo you guys should make a foundation model, ditch the gov 

We should have vernac models come out of India üòÉ
Quoted Message : cc Harsh @9186xxxxxxxx is the Head of ML at Koo

Message : https://caryn.ai/

Message : does anyone have  any idea to create a similiar bot like this ?

Message : where the the voice can also be cloned ?

Message : ‚Äé<attached: 00004347-PHOTO-2023-05-18-00-36-33.jpg>

Message : ‚Äé<attached: 00004348-PHOTO-2023-05-18-00-36-34.jpg>

Message : Noob question? What kind of data is in the medQA dataset

Message : like is it general medical QA

Message : or like stuff on more advanced diagnosis

Message : Mixed. It's based on USMLE ‚Äî It's an exam you've to give to become a doctor in US
Quoted Message : like is it general medical QA

Message : Interesting

Message : ‚Äé<attached: 00004354-PHOTO-2023-05-18-00-41-07.jpg>

Message : I think LLMs will raise the standard of competency needed for the job

Message : pretty cool, but Palm 2 is only available on private beta right now, correct?
Quoted Message :  2023_05_18_3EB0684119CBEE778E2C98.jpeg

Message : and i presume it also has the limit that open ai has with 4097 tokens, makes it harder to parse data, otherwise have to divide the data and stream which makes it more challenging

Message : The bison api on par with gpt3.5 based on personal experience, but not as good as gpt4. 
Bison's context length is 4096 + 1024, so slightly better than gpt3.5 there
Quoted Message : and i presume it also has the limit that open ai has with 4097 tokens, makes it harder to parse data, otherwise have to divide the data and stream which makes it more challenging

Message : i built 42papers.com but it's aimed at quick scanning daily
Quoted Message : has anybody tried better prompts for paper summarisation? The base Langchain ones haven't worked for me for text other than state of the union or pg essays :P

Message : also a side project so working on improving things it's a spider+gpt4+staticsite

Message : text-bison@xxxx has 8192/1024
Quoted Message : The bison api on par with gpt3.5 based on personal experience, but not as good as gpt4. \nBison's context length is 4096 + 1024, so slightly better than gpt3.5 there

Message : chat-bison is 4096/1024

Message : Ah right, they updated token limit for text api this month
Quoted Message : text-bison@xxxx has 8192/1024

Message : Blinkit has started using gen AI to make receipes automatically. They are directly showing it to customers. Also, generates images using midjourney : https://twitter.com/albinder/status/1658821632008523777?cxt=HHwWgsDQmYnfqIUuAAAA

Message : They use a custom model 

This is an old one but more or less this workflow https://ought.org/updates/2022-04-25-responsibility
Quoted Message : Hmm, elicit.org has amazing paper summarisation output. I've no idea what magic they do, but their beta is rad. I've abandoned my toolchain completely for wide paper reading (surveys) and single both.

Message : Play.ht but don‚Äôt know the legality of it
Quoted Message : where the the voice can also be cloned ?

Message : Can one of admins please add my colleague `+91 77605 75030` to this group?

Cannot find the invite link to this group anymore.

Message : ‚Äé~‚ÄØOjasvi Yadav | Away added ‚Ä™+91¬†77605¬†75030‚Ä¨

Message : Done
Quoted Message : Can one of admins please add my colleague `+91 77605 75030` to this group?\n\nCannot find the invite link to this group anymore.

Message : https://github.com/justinjohn0306/so-vits-svc-4.0
Quoted Message : where the the voice can also be cloned ?

Message : Has anyone tried this out: https://www.tutory-ai.com/
Not sure if it has been posted already

Message : If I have multiple txt files containing information about people, each txt is one person and my usecase is to describe a person and find the most relevant one.. How should I go about it?

I can create embeddings of those txt files and do a semantic search and get the source docs..

My question is, what would be a more efficient way of doing it, creating different indexes for each txt in a vector db(sounds overkill to me tbh) or put everything in a single index, but will that create issues if you have a lot of files?

Message : ‚Äé<attached: 00004373-PHOTO-2023-05-18-10-11-26.jpg>
Quoted Message : If I have multiple txt files containing information about people, each txt is one person and my usecase is to describe a person and find the most relevant one.. How should I go about it?\n\nI can create embeddings of those txt files and do a semantic search and get the source docs..\n\nMy question is, what would be a more efficient way of doing it, creating different indexes for each txt in a vector db(sounds overkill to me tbh) or put everything in a single index, but will that create issues if you have a lot of files?

Message : Llamaindex will be easiest place to start
Quoted Message : If I have multiple txt files containing information about people, each txt is one person and my usecase is to describe a person and find the most relevant one.. How should I go about it?\n\nI can create embeddings of those txt files and do a semantic search and get the source docs..\n\nMy question is, what would be a more efficient way of doing it, creating different indexes for each txt in a vector db(sounds overkill to me tbh) or put everything in a single index, but will that create issues if you have a lot of files?

Message : Ohh, I sound stupid now, hahaü•≤
Quoted Message :  2023_05_18_3EB029CEA6C78CCB72AE32.jpeg

Message : Nahi nahi. 

You'd be a bad engineer if you hadn't asked

This degree of compression was not widely or commercially available till 2019-2020. It is not your day job to keep track of this tech!

Always ask! üôå
Quoted Message : Ohh, I sound stupid now, hahaü•≤

Message : I'm not able to find them on plugins even
Quoted Message : Has anyone tried this out: https://www.tutory-ai.com/\nNot sure if it has been posted already

Message : Just out it curiosity - anyone here / in India doing research towards AGI?

(I know AGI isn‚Äôt well defined, I mean it in Carmac/OpenAI sense)

Message : "AGI is a feeling. Like love. Stop trying to define it." - Andrej Karpathy
Quoted Message : Just out it curiosity - anyone here / in India doing research towards AGI?\n\n(I know AGI isn‚Äôt well defined, I mean it in Carmac/OpenAI sense)

Message : Everyone has their own definitions of AGI, but this iisc research group has a few worthwhile projects n publications in the area

https://ai.iisc.ac.in/
Quoted Message : Just out it curiosity - anyone here / in India doing research towards AGI?\n\n(I know AGI isn‚Äôt well defined, I mean it in Carmac/OpenAI sense)

Message : If anyone's used the GPTeam repo extensively lmk. Having some weird issues running it locally, which start after a few mins of successful agent communication. Will DM for help.

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : ‚Äé<attached: 00004383-PHOTO-2023-05-18-11-33-23.jpg>

Message : I'm trying to create multiple NLAToolkits (fancier API Toolkit for using natural language), using multiple openapi jsons, and pass these to a single agent. This is to automate and chain some REST queries. The issue is that individually each of these jsons are very long, so the token length is exceeding with just a single NLAToolkit (and hence a single json), let alone multiple.

Has anybody tried using a vector DB to do a lookup on which end point to call from a json? What would be the recommended way to implement something like this?

Message : This is a general problem with LLM output formatting. I have faced similar issues. It is also random at times. I wrote a custom output parser and retry parsing with some formatting in place
Quoted Message :  2023_05_18_3EB04C256FD5E2CD26105E.jpeg

Message : https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/output_fixing_parser.html
Quoted Message : This is a general problem with LLM output formatting. I have faced similar issues. It is also random at times. I wrote a custom output parser and retry parsing with some formatting in place

Message : Don't tell this to anyone, but this is why projects like guardrails.ai are good. JSONDecodeError is the Blue Screen of death of 2023. 

https://shreyar.github.io/guardrails/

Message : Do you mean something like this? https://medium.com/sopmac-ai/vector-databases-as-memory-for-your-ai-agents-986288530443 (paywall)
Quoted Message : I'm trying to create multiple NLAToolkits (fancier API Toolkit for using natural language), using multiple openapi jsons, and pass these to a single agent. This is to automate and chain some REST queries. The issue is that individually each of these jsons are very long, so the token length is exceeding with just a single NLAToolkit (and hence a single json), let alone multiple.\n\nHas anybody tried using a vector DB to do a lookup on which end point to call from a json? What would be the recommended way to implement something like this?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : "AGI is a feeling. Like love. Stop trying to define it." - Andrej Karpathy
Quoted Message : Just out it curiosity - anyone here / in India doing research towards AGI?\n\n(I know AGI isn‚Äôt well defined, I mean it in Carmac/OpenAI sense)

Message : Everyone has their own definitions of AGI, but this iisc research group has a few worthwhile projects n publications in the area

https://ai.iisc.ac.in/
Quoted Message : Just out it curiosity - anyone here / in India doing research towards AGI?\n\n(I know AGI isn‚Äôt well defined, I mean it in Carmac/OpenAI sense)

Message : If anyone's used the GPTeam repo extensively lmk. Having some weird issues running it locally, which start after a few mins of successful agent communication. Will DM for help.

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : ‚Äé<attached: 00004383-PHOTO-2023-05-18-11-33-23.jpg>

Message : I'm trying to create multiple NLAToolkits (fancier API Toolkit for using natural language), using multiple openapi jsons, and pass these to a single agent. This is to automate and chain some REST queries. The issue is that individually each of these jsons are very long, so the token length is exceeding with just a single NLAToolkit (and hence a single json), let alone multiple.

Has anybody tried using a vector DB to do a lookup on which end point to call from a json? What would be the recommended way to implement something like this?

Message : This is a general problem with LLM output formatting. I have faced similar issues. It is also random at times. I wrote a custom output parser and retry parsing with some formatting in place
Quoted Message :  2023_05_18_3EB04C256FD5E2CD26105E.jpeg

Message : https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/output_fixing_parser.html
Quoted Message : This is a general problem with LLM output formatting. I have faced similar issues. It is also random at times. I wrote a custom output parser and retry parsing with some formatting in place

Message : Don't tell this to anyone, but this is why projects like guardrails.ai are good. JSONDecodeError is the Blue Screen of death of 2023. 

https://shreyar.github.io/guardrails/

Message : Do you mean something like this? https://medium.com/sopmac-ai/vector-databases-as-memory-for-your-ai-agents-986288530443 (paywall)
Quoted Message : I'm trying to create multiple NLAToolkits (fancier API Toolkit for using natural language), using multiple openapi jsons, and pass these to a single agent. This is to automate and chain some REST queries. The issue is that individually each of these jsons are very long, so the token length is exceeding with just a single NLAToolkit (and hence a single json), let alone multiple.\n\nHas anybody tried using a vector DB to do a lookup on which end point to call from a json? What would be the recommended way to implement something like this?

Message : Not always an issue with json type data. Happens with agents with some expected format as response.
Quoted Message : Don't tell this to anyone, but this is why projects like guardrails.ai are good. JSONDecodeError is the Blue Screen of death of 2023. \n\nhttps://shreyar.github.io/guardrails/

Message : +1 to guardrails. I've this running as my json extracter in two projects on prod.

although I recommend deeply looking into the exact implementation and then deciding for your use case if this prompt make sense else write a smaller version of guard rails ai for saving on tokens with linter and retries with a different lenthier prompt -- this is what I've done in one.
Quoted Message : Don't tell this to anyone, but this is why projects like guardrails.ai are good. JSONDecodeError is the Blue Screen of death of 2023. \n\nhttps://shreyar.github.io/guardrails/

Message : Conversational agent expects a response starting with
Thought or AI.

Sometimes LLM doesn't output in that format.
Quoted Message : Not always an issue with json type data. Happens with agents with some expected format as response.

Message : Where can you apply for access for the apis?
Quoted Message : Ah right, they updated token limit for text api this month

Message : Not exactly. So this would work really well for qa retrieval over a simple text doc, right?

But when your doc is an openapi spec json with lots of endpoints and relatively vague descriptions, the retrieval from DB for a given query seems to stumble. Also NLAToolkit is useful because I can say something like "what is my most played song in my top Playlist" and it'll automatically resolve it to Spotify Tool and  find the appropriate endpoints to call and populate with the right parameters as well (all of these endpoints and descriptions are internally passed as input in the prompt, which causes the token limit to blow up)

I imagine a json agent can't do this natural language interpretation.

So i was wondering what would be the best way to do this.

Please correct me if there are any incorrect assumptions here
Quoted Message : Do you mean something like this? https://medium.com/sopmac-ai/vector-databases-as-memory-for-your-ai-agents-986288530443 (paywall)

Message : > But when your doc is an openapi spec json with lots of endpoints and relatively vague descriptions, the retrieval from DB for a given query seems to stumble.

Stumble as in? Bad recall? Bad precision, since it's Top 1? What is breaking here?
Quoted Message : Not exactly. So this would work really well for qa retrieval over a simple text doc, right?\n\nBut when your doc is an openapi spec json with lots of endpoints and relatively vague descriptions, the retrieval from DB for a given query seems to stumble. Also NLAToolkit is useful because I can say something like \"what is my most played song in my top Playlist\" and it'll automatically resolve it to Spotify Tool and  find the appropriate endpoints to call and populate with the right parameters as well (all of these endpoints and descriptions are internally passed as input in the prompt, which causes the token limit to blow up) \n\nI imagine a json agent can't do this natural language interpretation.\n\nSo i was wondering what would be the best way to do this.\n\nPlease correct me if there are any incorrect assumptions here

Message : And just to zoom out a bit, this is an empirical domain, not intuitive or theory (and definitely not in the _best practices_ era) ‚Äî  so whatever solutions we share have a half life of max 6 months

Message : Yeah that's fair. I was just wondering if anyone has worked with something like this before, so I could leverage those learnings
Quoted Message : And just to zoom out a bit, this is an empirical domain, not intuitive or theory (and definitely not in the _best practices_ era) ‚Äî  so whatever solutions we share have a half life of max 6 months

Message : So when you query the DB for a semantic match, it often throws up a completely irrelevant endpoint to the task. Sometimes even from the wrong tool
Quoted Message : > But when your doc is an openapi spec json with lots of endpoints and relatively vague descriptions, the retrieval from DB for a given query seems to stumble.\n\nStumble as in? Bad recall? Bad precision, since it's Top 1? What is breaking here?

Message : have u tried jsonformer or RELLM ? would love to know ur opinion
Quoted Message : +1 to guardrails. I've this running as my json extracter in two projects on prod.\n\nalthough I recommend deeply looking into the exact implementation and then deciding for your use case if this prompt make sense else write a smaller version of guard rails ai for saving on tokens with linter and retries with a different lenthier prompt -- this is what I've done in one.

Message : Not related to generative AI, but NLP

Has anyone worked in multimodal classification? Planning to work on Multimodal Hate Speech Event Detection Shared Task CASE@RANLP2023, and the task involves figuring out whether a text embedded image contains hate speech or not. Last time I worked on a similar task, it contained text and images separately, so I took a combination of ULMFiT and VGG 19, to get a combination of embeddings and use them to classify. Could a similar approach work here?
My plan is to extract text from the image, and then recreating the above pipeline. Would that work, or if anyone has any other suggestions, can we discuss that in detail.

Message : ReLLM and JSONFormer ideas are now both part of Guardrails as a lib now? 

cc Shreya @1217305xxxx from Guardrails is here too :)
Quoted Message : have u tried jsonformer or RELLM ? would love to know ur opinion

Message : Oh I didn't know that. Intresting
Quoted Message : ReLLM and JSONFormer ideas are now both part of Guardrails as a lib now? \n\ncc Shreya @121xxxxxxxx from Guardrails is here too :)

Message : Which one of the two works better in general?

Message : I am also asking, I saw a discussion around this. ReAsk is definitely there. I've used it

Message : ‚Äé<attached: 00004405-PHOTO-2023-05-18-12-22-43.jpg>
Quoted Message : Not always an issue with json type data. Happens with agents with some expected format as response.

Message : RLHF Karna padega üòÅ
Quoted Message :  2023_05_18_1915A1AA0A6F6056B6A0466AE4BB358C.jpeg

Message : I've not fully read it through.

btw I've a catch all after two retries to pick the stuff inside ```

I've seen 0 errors on not being able to pick json with this catch all + import gd so far but will explore jsonformer for sure
Quoted Message : have u tried jsonformer or RELLM ? would love to know ur opinion

Message : FYI, Rohit @91989995xxxx and I were discussing this. Looks like JSONFormer doesn't work with OpenAI Chat models (3.5-Turbo and GPT4) because they have a logit bias while JSONFormer uses Logits.
Quoted Message : I've not fully read it through.\n\nbtw I've a catch all after two retries to pick the stuff inside ```\n\nI've seen 0 errors on not being able to pick json with this catch all + import gd so far but will explore jsonformer for sure

Message : Mid journey how??
Quoted Message : Blinkit has started using gen AI to make receipes automatically. They are directly showing it to customers. Also, generates images using midjourney : https://twitter.com/albinder/status/1658821632008523777?cxt=HHwWgsDQmYnfqIUuAAAA

Message : Unofficial APIs perhaps? https://midjourneyapi.io/
Quoted Message : Mid journey how??

Message : Wow, and is this using a discord bot to get the image from mj discord bot? üòÇ
Quoted Message : Unofficial APIs perhaps? https://midjourneyapi.io/

Message : ‚Äé<attached: 00004412-PHOTO-2023-05-18-12-33-51.jpg>

Message : ‚Äé<attached: 00004413-PHOTO-2023-05-18-12-35-38.jpg>

Message : Ok albinder definitely needs to have a chat with his team before tweeting

Message : LOL

Message : https://blinkit.com/blog/recipe-rover

Their coders look much smarter

Message : Yep! I‚Äôve been planning on adding constrained decoding for general grammars in guardrails.
As a developer, different techniques are better for different use cases. constrained decoding introduces some latency which may not be worth it if you can use few shot examples to get the right json (which is Guardrails‚Äô current approach). It also doesn‚Äôt work for OpenAI‚Äôs newest models, Anthropic or Cohere.
Quoted Message : ReLLM and JSONFormer ideas are now both part of Guardrails as a lib now? \n\ncc Shreya @121xxxxxxxx from Guardrails is here too :)

Message : What breaks Cohere?
Quoted Message : Yep! I‚Äôve been planning on adding constrained decoding for general grammars in guardrails.\nAs a developer, different techniques are better for different use cases. constrained decoding introduces some latency which may not be worth it if you can use few shot examples to get the right json (which is Guardrails‚Äô current approach). It also doesn‚Äôt work for OpenAI‚Äôs newest models, Anthropic or Cohere.

Message : No access to logits
Quoted Message : What breaks Cohere?

Message : I didn't know that they removed logits too üòî
Quoted Message : No access to logits

Message : This would break in the chat models as well I think
Quoted Message : No access to logits

Message : Yeah I think this may have been recent. They updated a few of their models
Quoted Message : I didn't know that they removed logits too üòî

Message : I think OpenAI is working on their own language called "ChatML"
Quoted Message : Yep! I‚Äôve been planning on adding constrained decoding for general grammars in guardrails.\nAs a developer, different techniques are better for different use cases. constrained decoding introduces some latency which may not be worth it if you can use few shot examples to get the right json (which is Guardrails‚Äô current approach). It also doesn‚Äôt work for OpenAI‚Äôs newest models, Anthropic or Cohere.

Message : -yeah. New models. Much better at RAG.
Quoted Message : Yeah I think this may have been recent. They updated a few of their models

Message : To do this quickly and with generality you need to be able to send a custom sampling algorithm to the api provider. It will turn into a programming language eventually üòÅ

Message : All roads converge to a Programming language. At this point, both TF and PyTorch are programming language pretending to be a framework anyway
Quoted Message : To do this quickly and with generality you need to be able to send a custom sampling algorithm to the api provider. It will turn into a programming language eventually üòÅ

Message : I have a feeling a simpler trade off is to just use regexes. üòÅ

Message : Higher level framework can compile into regexes and send to backend provider. Regexes are very easy to support

Message : Perhaps a slight syntax tweak to control temperature etc for each regex.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I didn't know that they removed logits too üòî
Quoted Message : No access to logits

Message : This would break in the chat models as well I think
Quoted Message : No access to logits

Message : Yeah I think this may have been recent. They updated a few of their models
Quoted Message : I didn't know that they removed logits too üòî

Message : I think OpenAI is working on their own language called "ChatML"
Quoted Message : Yep! I‚Äôve been planning on adding constrained decoding for general grammars in guardrails.\nAs a developer, different techniques are better for different use cases. constrained decoding introduces some latency which may not be worth it if you can use few shot examples to get the right json (which is Guardrails‚Äô current approach). It also doesn‚Äôt work for OpenAI‚Äôs newest models, Anthropic or Cohere.

Message : -yeah. New models. Much better at RAG.
Quoted Message : Yeah I think this may have been recent. They updated a few of their models

Message : To do this quickly and with generality you need to be able to send a custom sampling algorithm to the api provider. It will turn into a programming language eventually üòÅ

Message : All roads converge to a Programming language. At this point, both TF and PyTorch are programming language pretending to be a framework anyway
Quoted Message : To do this quickly and with generality you need to be able to send a custom sampling algorithm to the api provider. It will turn into a programming language eventually üòÅ

Message : I have a feeling a simpler trade off is to just use regexes. üòÅ

Message : Higher level framework can compile into regexes and send to backend provider. Regexes are very easy to support

Message : Perhaps a slight syntax tweak to control temperature etc for each regex.

Message : Context free grammar etc is cool but most specific JSON you need can be expressed as key , value regex.

Message : https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags
Quoted Message : I have a feeling a simpler trade off is to just use regexes. üòÅ

Message : ‚Äé<attached: 00004432-PHOTO-2023-05-18-12-57-27.jpg>

Message : I know this but this answer is misleading. Yes regex cannot parse it in general. But for specific scenarios they can work. And we are often trying to generate some specific and simple JSON
Quoted Message :  2023_05_18_3AC8AE2CC46B70ADA1E0.jpeg

Message : I have parsed HTML using regex many times üòÅ

Message : ‚Äé<attached: 00004435-PHOTO-2023-05-18-12-58-47.jpg>
Quoted Message : I have a feeling a simpler trade off is to just use regexes. üòÅ

Message : Yes this . ‚ÄúWorse is better‚Äù Unix philosophy of design.
Quoted Message :  2023_05_18_3EB0D9B9CE9140619DA058.jpeg

Message : it seems to me that openai wants us to have less access to logits, etc and wants to do everything via few shots.
is that what u would guess ?
Quoted Message : Yep! I‚Äôve been planning on adding constrained decoding for general grammars in guardrails.\nAs a developer, different techniques are better for different use cases. constrained decoding introduces some latency which may not be worth it if you can use few shot examples to get the right json (which is Guardrails‚Äô current approach). It also doesn‚Äôt work for OpenAI‚Äôs newest models, Anthropic or Cohere.

Message : Logit sharing is more high level. You cannot constrain in the middle of a generation unless you call the API many many times for even simple things. So it‚Äôs probably not the way for JSON etc. you need some way to share a grammar , regex , program
Quoted Message : it seems to me that openai wants us to have less access to logits, etc and wants to do everything via few shots.\nis that what u would guess ?

Message : It just adds too much latency and cost

Message : This is also an advantage of open models. You can do lot of innovation around sampling

Message : fair point. cost is always a thing.
Quoted Message : Logit sharing is more high level. You cannot constrain in the middle of a generation unless you call the API many many times for even simple things. So it‚Äôs probably not the way for JSON etc. you need some way to share a grammar , regex , program

Message : but i think in the long run, having a custom NER model doing the extraction might be the best tradeoff of cost vs accuracy. dont bring in the LLM at all.

Message : Yes so the way I try to explain this to ppl is 
1. LLM as fast prototyping tool for ML
2. Prove business value
3. Extract production data / LLM data
4. Train a smaller model for the specific task

This could be a common pipeline

Message : Earlier it was hard to tell if ML had business value because each model for a task was expensive. Now you can find PMF quickly and then optimize

Message : Infra around this is an excellent startup idea if anyone is looking üòÅ
Quoted Message : Yes so the way I try to explain this to ppl is \n1. LLM as fast prototyping tool for ML\n2. Prove business value \n3. Extract production data / LLM data \n4. Train a smaller model for the specific task \n\nThis could be a common pipeline

Message : Sandeep eager to hear your thoughts on this
Quoted Message : Yes so the way I try to explain this to ppl is \n1. LLM as fast prototyping tool for ML\n2. Prove business value \n3. Extract production data / LLM data \n4. Train a smaller model for the specific task \n\nThis could be a common pipeline

Message : Has anyone here stumbled across any projects which does federated decision making by multiple role playing agents?

Something similar to this paper
https://arxiv.org/abs/2303.06109

Message : Looking for suggestions on opensource models that are good at writing sql queries based on provided question and schema. Has anyone worked on this? I am looking for collaborations as well if anyone interested.

Message : Anyone who did computer science in college. There was a course, theory of computation. And it basically started with every language started as something similar like just regex
Quoted Message : Context free grammar etc is cool but most specific JSON you need can be expressed as key , value regex.

Message : To note. The udacity course on this was much better

Message : What is the biggest GPU size you guys have used for training/fine tuning model? We are using 64GB and still running out of memory. Would highly appreciate any help in the regard .

Message : Which model are you training ?
Quoted Message : What is the biggest GPU size you guys have used for training/fine tuning model? We are using 64GB and still running out of memory. Would highly appreciate any help in the regard .

Message : Lora Adapter

Message : not tested with open source models, but there's guardrails for sql generation that perform validation for a specific db schema and have a few other tricks for good performance http://getguardrails.ai/use_cases/text2sql/text2sql/
Quoted Message : Looking for suggestions on opensource models that are good at writing sql queries based on provided question and schema. Has anyone worked on this? I am looking for collaborations as well if anyone interested.

Message : Which is supposed to be super super small but dont know whats wrong.
Quoted Message : Lora Adapter

Message : Hey! 

I couldn‚Äôt find the invite link to this group, can
+91 97413 54623 be added ?

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØKp

Message : Thanks! 
@91955016xxxx

Message : Hey, is there anyone here who can help with converting a vision transformer model to tflite?

Message : When I am using ChatGPT from the website(free version), I see that the url is this: https://chat.openai.com/?model=text-davinci-002-render-sha
Does this mean that it‚Äôs using davinci model and not the gpt-3.5-turbo model which the chatgpt api uses?

Message : PSA: Please DM mods for Invite links instead of sharing phone numbers of your friends. If you do that, I'll add your friend's number to Bajaj Finance, Yes Bank, Policy Bazaar.

Message : I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string ü§î
Quoted Message : If I have multiple txt files containing information about people, each txt is one person and my usecase is to describe a person and find the most relevant one.. How should I go about it?\n\nI can create embeddings of those txt files and do a semantic search and get the source docs..\n\nMy question is, what would be a more efficient way of doing it, creating different indexes for each txt in a vector db(sounds overkill to me tbh) or put everything in a single index, but will that create issues if you have a lot of files?

Message : I think this blog might be useful for you - https://medium.com/llamaindex-blog/using-llms-for-retrieval-and-reranking-23cf2d3a14b6
Quoted Message : I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string ü§î

Message : Do you just want relevancy scores or an answer? 

If you just need relevancy scores, do you want to just use a Vector DB client direcly?
Quoted Message : I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string ü§î

Message : No need to touch Llama Index or Langchain

Message : https://github.com/saschaschramm/chatgpt#gpt-35
Quoted Message : When I am using ChatGPT from the website(free version), I see that the url is this: https://chat.openai.com/?model=text-davinci-002-render-sha\nDoes this mean that it‚Äôs using davinci model and not the gpt-3.5-turbo model which the chatgpt api uses?

Message : Just relevancy scores
Quoted Message : Do you just want relevancy scores or an answer? \n\nIf you just need relevancy scores, do you want to just use a Vector DB client direcly?

Message : So it is different from what‚Äôs provided through the api? (GPT 3.5 vs GPT 3.5 Turbo)
Do you happen to know about any major differences as well?
Quoted Message : https://github.com/saschaschramm/chatgpt#gpt-35

Message : Only as much as is mentioned there in the link:

*Max tokens limit are different for them*:
GPT 3.5 = 8191 tokens
GPT 3.5 Turbo = 4096 tokens

And that GPT-3.5-turbo HumanEval scores are better than that of GPT 3.5


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : When I am using ChatGPT from the website(free version), I see that the url is this: https://chat.openai.com/?model=text-davinci-002-render-sha
Does this mean that it‚Äôs using davinci model and not the gpt-3.5-turbo model which the chatgpt api uses?

Message : PSA: Please DM mods for Invite links instead of sharing phone numbers of your friends. If you do that, I'll add your friend's number to Bajaj Finance, Yes Bank, Policy Bazaar.

Message : I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string ü§î
Quoted Message : If I have multiple txt files containing information about people, each txt is one person and my usecase is to describe a person and find the most relevant one.. How should I go about it?\n\nI can create embeddings of those txt files and do a semantic search and get the source docs..\n\nMy question is, what would be a more efficient way of doing it, creating different indexes for each txt in a vector db(sounds overkill to me tbh) or put everything in a single index, but will that create issues if you have a lot of files?

Message : I think this blog might be useful for you - https://medium.com/llamaindex-blog/using-llms-for-retrieval-and-reranking-23cf2d3a14b6
Quoted Message : I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string ü§î

Message : Do you just want relevancy scores or an answer? 

If you just need relevancy scores, do you want to just use a Vector DB client direcly?
Quoted Message : I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string ü§î

Message : No need to touch Llama Index or Langchain

Message : https://github.com/saschaschramm/chatgpt#gpt-35
Quoted Message : When I am using ChatGPT from the website(free version), I see that the url is this: https://chat.openai.com/?model=text-davinci-002-render-sha\nDoes this mean that it‚Äôs using davinci model and not the gpt-3.5-turbo model which the chatgpt api uses?

Message : Just relevancy scores
Quoted Message : Do you just want relevancy scores or an answer? \n\nIf you just need relevancy scores, do you want to just use a Vector DB client direcly?

Message : So it is different from what‚Äôs provided through the api? (GPT 3.5 vs GPT 3.5 Turbo)
Do you happen to know about any major differences as well?
Quoted Message : https://github.com/saschaschramm/chatgpt#gpt-35

Message : Only as much as is mentioned there in the link:

*Max tokens limit are different for them*:
GPT 3.5 = 8191 tokens
GPT 3.5 Turbo = 4096 tokens

And that GPT-3.5-turbo HumanEval scores are better than that of GPT 3.5

Message : Got it, thanks!
Quoted Message : Only as much as is mentioned there in the link:\n\n*Max tokens limit are different for them*:\nGPT 3.5 = 8191 tokens\nGPT 3.5 Turbo = 4096 tokens\n\nAnd that GPT-3.5-turbo HumanEval scores are better than that of GPT 3.5

Message : Anyone working here on gpt 4 api, could you help me with right max_token value which will make it generate the longest possible response without hitting error. I see the it's sum of input plus output. But the documentation is a bit unclear on limits..

Message : 8096 for input + output tokens
Quoted Message : Anyone working here on gpt 4 api, could you help me with right max_token value which will make it generate the longest possible response without hitting error. I see the it's sum of input plus output. But the documentation is a bit unclear on limits..

Message : 32k if you have access to that version

Message : Giving 8k as max token errors out if I want to generate a 3k word story. With a input in 2 lines.
Quoted Message : 8096 for input + output tokens

Message : 2k output. Over that errors can occur
Quoted Message : Anyone working here on gpt 4 api, could you help me with right max_token value which will make it generate the longest possible response without hitting error. I see the it's sum of input plus output. But the documentation is a bit unclear on limits..

Message : If you want a lot of output you need to be creative. But at one go it hangs over 2k output and timeout after 4k output tokens

Message : You have to calculate the input size using tiktoken, subtract it from 8k/4k

Message : Interesting - on the streaming api too?
Quoted Message : If you want a lot of output you need to be creative. But at one go it hangs over 2k output and timeout after 4k output tokens

Message : Oh dint know this. Same rule for 32k?
Quoted Message : If you want a lot of output you need to be creative. But at one go it hangs over 2k output and timeout after 4k output tokens

Message : Not to mention horribly slow

Message : This too. Also you need to take into consideration that one token is different in different languages
Quoted Message : You have to calculate the input size using tiktoken, subtract it from 8k/4k

Message : Yes
Quoted Message : Interesting - on the streaming api too?

Message : Yup, cause the limit is for input + output. So if your input is big, then it will throw an error
Quoted Message : Oh dint know this. Same rule for 32k?

Message : It takes ~50x time to generate a token than ingest an input token
Quoted Message : Not to mention horribly slow

Message : Similar findings
Quoted Message : It takes ~50x time to generate a token than ingest an input token

Message : Also the more you generate the more you hallucinate

Message : Basic question- I want to train a model locally on all my emails and documents. What‚Äôs the best way to do it nowadays. Lora? Gpt4all? Something else? I‚Äôve never trained a model locally so I‚Äôm a bit uncertain about this. (Also I don‚Äôt genuinely care about ‚Äúworldly knowledge‚Äù being part of the model but it doesn‚Äôt hurt)

Message : https://github.com/imartinez/privateGPT

Came across this recently which might be helpful.
Quoted Message : Basic question- I want to train a model locally on all my emails and documents. What‚Äôs the best way to do it nowadays. Lora? Gpt4all? Something else? I‚Äôve never trained a model locally so I‚Äôm a bit uncertain about this. (Also I don‚Äôt genuinely care about ‚Äúworldly knowledge‚Äù being part of the model but it doesn‚Äôt hurt)

Message : Thanks, quite useful. Still, curious if we can train / fine tune a model locally.

Message : TEAM is organising a Hackathon for GenAI in Mumbai on 3rd and 4th June (Saturday & Sunday)
https://www.mumbaihacks.com/register

Sharing for those interested

Message : Is there any other better option for long form content generation
Quoted Message : Yup, cause the limit is for input + output. So if your input is big, then it will throw an error

Message : approach in a similar approach to how you would do on the playground
Quoted Message : Is there any other better option for long form content generation

Message : continuous generation via different calls

Message : but you need to make sure your input+output is between the token limit

Message : https://www.cnbc.com/amp/2023/05/18/bilderberg-openai-microsoft-google-join-ai-talks-at-secretive-meeting.html?__source=instagram%7Cmain

Message : @91916718xxxx @91961944xxxx
Quoted Message : TEAM is organising a Hackathon for GenAI in Mumbai on 3rd and 4th June (Saturday & Sunday)\n https://www.mumbaihacks.com/register\n\nSharing for those interested

Message : Does anyone know how to force copilot to generate something when you're in the middle of a line / start of a line? It only seems to complete if I'm at the end of a line.

Message : ‚Äé<attached: 00004499-PHOTO-2023-05-18-21-06-52.jpg>

Message : Threaten it üòÇ
Quoted Message : Does anyone know how to force copilot to generate something when you're in the middle of a line / start of a line? It only seems to complete if I'm at the end of a line.

Message : ‚Äé<attached: 00004501-PHOTO-2023-05-18-21-07-23.jpg>

Message : ‚Äé<attached: 00004502-PHOTO-2023-05-18-21-08-13.jpg>

Message : ‚Äé<attached: 00004503-PHOTO-2023-05-18-21-08-31.jpg>

Message : I think there was a shortcut key for copilot generations, tried it?

Message : doesn't generate anything
Quoted Message : I think there was a shortcut key for copilot generations, tried it?

Message : https://twitter.com/peterjliu/status/1659023597447565312?s=46

RLHF alternative

Message : Ohh one of the co-authors is a college acquaintance, let me ping him!
Quoted Message : https://twitter.com/peterjliu/status/1659023597447565312?s=46\n\nRLHF alternative

Message : The may not need humans part seems hard to believe
Quoted Message : https://twitter.com/peterjliu/status/1659023597447565312?s=46\n\nRLHF alternative

Message : I thought RLHF stood for RL with human farms üòÇ

Message : ‚Äé<attached: 00004510-PHOTO-2023-05-18-21-33-16.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00004501-PHOTO-2023-05-18-21-07-23.jpg>

Message : ‚Äé<attached: 00004502-PHOTO-2023-05-18-21-08-13.jpg>

Message : ‚Äé<attached: 00004503-PHOTO-2023-05-18-21-08-31.jpg>

Message : I think there was a shortcut key for copilot generations, tried it?

Message : doesn't generate anything
Quoted Message : I think there was a shortcut key for copilot generations, tried it?

Message : https://twitter.com/peterjliu/status/1659023597447565312?s=46

RLHF alternative

Message : Ohh one of the co-authors is a college acquaintance, let me ping him!
Quoted Message : https://twitter.com/peterjliu/status/1659023597447565312?s=46\n\nRLHF alternative

Message : The may not need humans part seems hard to believe
Quoted Message : https://twitter.com/peterjliu/status/1659023597447565312?s=46\n\nRLHF alternative

Message : I thought RLHF stood for RL with human farms üòÇ

Message : ‚Äé<attached: 00004510-PHOTO-2023-05-18-21-33-16.jpg>

Message : We really need an opensource copilot that works off any llm API key  (use the langchain API wrapper  maybe)
Quoted Message : doesn't generate anything

Message : Have you tried Codeium? Not open source though
https://codeium.com/compare/comparison-copilot-codeium

Message : I have been using it of late

Message : It has chat in IDE as well

Message : Team, validating my following rudimentary understanding of opportunity for any company using LLMs!
Can someone help?
-----
Foundation LLMs which are trained on large data sets are expensive and only companies like OpenAi, Google are doing. Facebook, AnthropicAi are some others.

For other companies, opportunity is to get access to such LLMs and ingest their own data and context using prompt engg. Techniques, embeddings, etc. This is helping companies solve  productivity use cases such as code suggestion, PR suggestions, summarisation, QnA, etc

Message : Is this understanding correct?
Opportunity is partner with companies providing trained LLMs and add their own context.
Quoted Message : Team, validating my following rudimentary understanding of opportunity for any company using LLMs!\nCan someone help?\n-----\nFoundation LLMs which are trained on large data sets are expensive and only companies like OpenAi, Google are doing. Facebook, AnthropicAi are some others.\n\nFor other companies, opportunity is to get access to such LLMs and ingest their own data and context using prompt engg. Techniques, embeddings, etc. This is helping companies solve  productivity use cases such as code suggestion, PR suggestions, summarisation, QnA, etc

Message : Yes, plus collecting human feedback to later pipe back into your data / rlhf
Quoted Message : Team, validating my following rudimentary understanding of opportunity for any company using LLMs!\nCan someone help?\n-----\nFoundation LLMs which are trained on large data sets are expensive and only companies like OpenAi, Google are doing. Facebook, AnthropicAi are some others.\n\nFor other companies, opportunity is to get access to such LLMs and ingest their own data and context using prompt engg. Techniques, embeddings, etc. This is helping companies solve  productivity use cases such as code suggestion, PR suggestions, summarisation, QnA, etc

Message : Anyone used Lang chain or embeddings on bigger text data? How do you pass say 20 pages (or embeddings) from a repo of books to have accurate summarized snippets considering gpt 4 token limit?any other alternatives?

Message : For summarisation, you can consider Map-Reduce/Combine or Refine: You can see some of the community summary here: https://nirantk.com/ai ‚Äî they're all done that way. You can also create chapter/section specific summaries and concat
Quoted Message : Anyone used Lang chain or embeddings on bigger text data? How do you pass say 20 pages (or embeddings) from a repo of books to have accurate summarized snippets considering gpt 4 token limit?any other alternatives?

Message : make sure you respect this limit too
Quoted Message : Map reduce has a theoretical upper limit on the size of output, which is 1/3 of the max output token count of the model btw something to keep in mind

Message : Code for the Langchain summarisation
https://github.com/NirantK/nirantk.github.io/tree/main/community_dev

Message : Have tried it not even close to Copilot
Quoted Message : Have you tried Codeium? Not open source though\nhttps://codeium.com/compare/comparison-copilot-codeium

Message : https://openai.com/blog/introducing-the-chatgpt-app-for-ios

iOS App from openAI

Message : Not available in India still though

Message : ‚Äé<attached: 00004528-PHOTO-2023-05-18-23-03-22.jpg>
Quoted Message : https://openai.com/blog/introducing-the-chatgpt-app-for-ios\n\niOS App from openAI

Message : Logits would allow others to distill the models, so we should expect them to go away eventually in most commercial LLM APIs which are deemed valuable. OpenAI and cohere have already taken it off the table.
Quoted Message : it seems to me that openai wants us to have less access to logits, etc and wants to do everything via few shots.\nis that what u would guess ?

Message : Is it possible they might want to do an on-device LLM ? 
MLC LLM types ?
Quoted Message :  2023_05_18_3A6695C86AC089E4F989.jpeg

Message : I don't understand why would an iOS app come before an android app :/
Quoted Message : https://openai.com/blog/introducing-the-chatgpt-app-for-ios\n\niOS App from openAI

Message : ‚ÄúGoogle‚Äù it
Quoted Message : I don't understand why would an iOS app come before an android app :/

Message : P.S. Android users, you're next! ChatGPT will be coming to your devices soon. Pretty obvious :) (Unless windows phone is making a comeback)

Message : ‚Äé<attached: 00004534-PHOTO-2023-05-18-23-29-47.jpg>
Quoted Message : I don't understand why would an iOS app come before an android app :/

Message : ‚Äé<attached: 00004535-PHOTO-2023-05-18-23-30-17.jpg>

Message : The IOS app looks bit wonky , the speech recognition is dead , throws error. They could have used iOS's built in recognition ~, but they wanted to use Whisper apparently .

Message : This never works for me
Quoted Message : I think there was a shortcut key for copilot generations, tried it?

Message : 2nd point üòÇüòÇ
Quoted Message :  2023_05_18_3EB0997CFA8AEE61F43207.jpeg

Message : Also usually ios people are tech deprived. So possibly trying to expose them to new technology üòÅ. Iphone people please don't take come with pitchforks
Quoted Message :  2023_05_18_3EB0C25CCEF21DD23DF258.jpeg

Message : These cases started working for me just a couple of days ago. But I also did move from python to typescript in that time
Quoted Message :  2023_05_18_3EB03E23750D8CAEF3CE9B.jpeg

Message : More difficult for apps for ios to be approved implies ios app releases first ü•¥
Quoted Message : 2nd point üòÇüòÇ

Message : Makes sense ngl
Quoted Message : Also usually ios people are tech deprived. So possibly trying to expose them to new technology üòÅ. Iphone people please don't take come with pitchforks

Message : @91990072xxxx any results?
Quoted Message : Actually I think, you could do (late) Sam Roweis's Neighborhood Component Analysis. The idea here is that KNN, values all dimension equally but you can learn what dimensions are actually important by traning it to search over a family of distances (like Mahalonobis family for eg) initially. This way, you don't have to train at test time (like what Karpathy is doing) and should perform quite better. Will try this tomorrow evening or so.

Message : ‚Äé<attached: 00004544-PHOTO-2023-05-18-23-57-15.jpg>

Message : guys anyone can please guide , which is best Llm for translation task?

Message : Detailed report from EU for AI safety standards in aviation:
https://www.easa.europa.eu/en/document-library/general-publications/easa-artificial-intelligence-concept-paper-proposed-issue-2
Aviation has historically been an industry with one of the most stringent safety requirements. It's interesting to see their proposed regulations over AI.

Message : https://colab.research.google.com/drive/1Icoxgd2IJAjMU2fyD-MET5a706HGpwVg?usp=sharing

Zero dependency code for map reduce
Quoted Message : Code for the Langchain summarisation\nhttps://github.com/NirantK/nirantk.github.io/tree/main/community_dev

Message : Hey @91999047xxxx,

Self promotion is not allowed as per group community guidelines. Can you please remove the post?

Message : You can try ctrl+enter - this would ideally force it to respond
Quoted Message :  2023_05_18_3EB03E23750D8CAEF3CE9B.jpeg

Message : ‚Äé<attached: 00004551-PHOTO-2023-05-19-07-57-23.jpg>

Message : Which company?
Quoted Message :  2023_05_19_3EB008A06E4EA33C680A91.jpeg

Message : https://tome.app/ - https://twitter.com/jasonyuandesign/status/1659317627208998914?s=20
Quoted Message : Which company?

Message : Seems like he'll bring MercuryOS to life


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00004544-PHOTO-2023-05-18-23-57-15.jpg>

Message : guys anyone can please guide , which is best Llm for translation task?

Message : Detailed report from EU for AI safety standards in aviation:
https://www.easa.europa.eu/en/document-library/general-publications/easa-artificial-intelligence-concept-paper-proposed-issue-2
Aviation has historically been an industry with one of the most stringent safety requirements. It's interesting to see their proposed regulations over AI.

Message : https://colab.research.google.com/drive/1Icoxgd2IJAjMU2fyD-MET5a706HGpwVg?usp=sharing

Zero dependency code for map reduce
Quoted Message : Code for the Langchain summarisation\nhttps://github.com/NirantK/nirantk.github.io/tree/main/community_dev

Message : Hey @91999047xxxx,

Self promotion is not allowed as per group community guidelines. Can you please remove the post?

Message : You can try ctrl+enter - this would ideally force it to respond
Quoted Message :  2023_05_18_3EB03E23750D8CAEF3CE9B.jpeg

Message : ‚Äé<attached: 00004551-PHOTO-2023-05-19-07-57-23.jpg>

Message : Which company?
Quoted Message :  2023_05_19_3EB008A06E4EA33C680A91.jpeg

Message : https://tome.app/ - https://twitter.com/jasonyuandesign/status/1659317627208998914?s=20
Quoted Message : Which company?

Message : Seems like he'll bring MercuryOS to life

Message : Have seen this where companies based out of US release their 1st app on iOS than android. E.g. Insta / Snapchat
Quoted Message : I don't understand why would an iOS app come before an android app :/

Message : It is known statistics here that iOS users pay more. Also, in US they say no one important uses Android. ü§£

Message : iMessage is the culprit for it
Quoted Message : It is known statistics here that iOS users pay more. Also, in US they say no one important uses Android. ü§£

Message : But chatgpt is free (or is this a sign) :(((((
Quoted Message : It is known statistics here that iOS users pay more. Also, in US they say no one important uses Android. ü§£

Message : people text you on imessage (not whatsapp) and make facetime calls
Quoted Message : iMessage is the culprit for it

Message : Get more plus users

Message : Ah
Quoted Message : Get more plus users

Message : Also what's with gpt-4 browsing? Most times I try it says click failed or something like that. Is there a specific way to prompt that model?

Message : True. Also, general folks care less about installing apks and trust Apple to take care security and privacy.
Quoted Message : people text you on imessage (not whatsapp) and make facetime calls

Message : robots.txt
Quoted Message : Also what's with gpt-4 browsing? Most times I try it says click failed or something like that. Is there a specific way to prompt that model?

Message : At the current stage a gpt extension on the site is doing better than gpt-4 browsing in terms of summarisation

Message : They are probably going to remove that bad browsing UX and start indexing like good soon.

Message : *google*

Message : Oh. So gpt-4 is crawling sites... wouldn't it get blocked by cloudflares are you human as well
Quoted Message : robots.txt

Message : For those sites where it's enabled?

Message : They published an article about this recently, you'll have to search Twitter for more details.

Message : Sure. Thanks!
Quoted Message : They published an article about this recently, you'll have to search Twitter for more details.

Message : Hi guys, can you share a good resource to understand how to control midjourney. Basically prompting to have specific camera angles, hues, contrast etc etc.

Message : I follow Nick from twitter. He has good command over that
Quoted Message : Hi guys, can you share a good resource to understand how to control midjourney. Basically prompting to have specific camera angles, hues, contrast etc etc.

Message : Thanks
Quoted Message : I follow Nick from twitter. He has good command over that

Message : Profile pls
Quoted Message : I follow Nick from twitter. He has good command over that

Message : https://twitter.com/nickfloats?s=21&t=slFa1z9kP5GT6uvB_oz7cw
Quoted Message : Profile pls

Message : https://docs.google.com/spreadsheets/d/1MsX0NYYqhv4ZhZ7-50cXH1gvYE2FKLixLBvAkI40ha0/edit#gid=0

I have one for V4, but Nick does have a lot more covered for the more updated versions too - 5 and 5.1
Quoted Message : Hi guys, can you share a good resource to understand how to control midjourney. Basically prompting to have specific camera angles, hues, contrast etc etc.

Message : Great thankyou

Message : https://docs.midjourney.com/docs/prompts

Their docs do cover all the basics and the public prompts on discord will help you shape your own along with the above resources

Message : Nick's threads are great. 

apart from that you can also search the MJ web gallery for camera angles to get more inspiration.

Make sure to fav the good ones as they get saved to your account (for reference later on)
Quoted Message : Hi guys, can you share a good resource to understand how to control midjourney. Basically prompting to have specific camera angles, hues, contrast etc etc.

Message : Operating G-mail using brain waves and ChatGPT https://www.araya.org/en/publications/news20230512/

Message : On a similar note, there‚Äôs a startup called Neurosity which creates consumer grade ‚Äúcrowns‚Äù that can be used to control and build stuff using brain waves.
Quoted Message : Operating G-mail using brain waves and ChatGPT https://www.araya.org/en/publications/news20230512/

Message : A guy used it to control a Tesla: https://youtu.be/BDYdWoaa6g0

Message : https://www.linkedin.com/posts/abhi1thakur_drag-your-gan-interactive-point-based-manipulation-activity-7065225903370346496-JidB?utm_source=share&utm_medium=member_android

Message : This is next level

Message : They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!
Quoted Message : https://www.linkedin.com/posts/abhi1thakur_drag-your-gan-interactive-point-based-manipulation-activity-7065225903370346496-JidB?utm_source=share&utm_medium=member_android

Message : Yea, but we know what all can be achieved
Quoted Message : They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!

Message : I guess due to extreme competition, companies are avoiding releasing much information about their research. Google and Openai have already started

Message : This is not a company, its the Max Plank Institute in Germany, where I did my PhD from

Message : I see
Quoted Message : This is not a company, its the Max Plank Institute in Germany, where I did my PhD from

Message : Going viral on Twitter ü•∏
Quoted Message : https://www.linkedin.com/posts/abhi1thakur_drag-your-gan-interactive-point-based-manipulation-activity-7065225903370346496-JidB?utm_source=share&utm_medium=member_android

Message : Whats even worse is they have a Code link which goes to a github repo with the same gif only. :-/
Quoted Message : They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!

Message : They said going to release in June, probably after paper is published in SIGGRAPH
Quoted Message : Whats even worse is they have a Code link which goes to a github repo with the same gif only. :-/

Message : What are the odds someone will implement this before that :P


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This is next level

Message : They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!
Quoted Message : https://www.linkedin.com/posts/abhi1thakur_drag-your-gan-interactive-point-based-manipulation-activity-7065225903370346496-JidB?utm_source=share&utm_medium=member_android

Message : Yea, but we know what all can be achieved
Quoted Message : They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!

Message : I guess due to extreme competition, companies are avoiding releasing much information about their research. Google and Openai have already started

Message : This is not a company, its the Max Plank Institute in Germany, where I did my PhD from

Message : I see
Quoted Message : This is not a company, its the Max Plank Institute in Germany, where I did my PhD from

Message : Going viral on Twitter ü•∏
Quoted Message : https://www.linkedin.com/posts/abhi1thakur_drag-your-gan-interactive-point-based-manipulation-activity-7065225903370346496-JidB?utm_source=share&utm_medium=member_android

Message : Whats even worse is they have a Code link which goes to a github repo with the same gif only. :-/
Quoted Message : They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!

Message : They said going to release in June, probably after paper is published in SIGGRAPH
Quoted Message : Whats even worse is they have a Code link which goes to a github repo with the same gif only. :-/

Message : What are the odds someone will implement this before that :P

Message : Won't we also need a pretrained model to get these results?
Quoted Message : What are the odds someone will implement this before that :P

Message : anyone looking into https://github.com/microsoft/guidance
I can't get a handle on what exactly {{gen}} does I've read the docs but hoping someone can save me from having to read the code. For example what would {{gen 'chapter'}} do? Does it create a seperate api call to the LLM with rest of the generated prompt upto this point and then save the generated output in the variable 'chapter'

Message : cc Ravi @91955016xxxx did you get a chance to go deeper into this?
Quoted Message : anyone looking into https://github.com/microsoft/guidance\nI can't get a handle on what exactly {{gen}} does I've read the docs but hoping someone can save me from having to read the code. For example what would {{gen 'chapter'}} do? Does it create a seperate api call to the LLM with rest of the generated prompt upto this point and then save the generated output in the variable 'chapter'

Message : Yes. Output is saved in the key ‚Äúchapter‚Äù
Quoted Message : anyone looking into https://github.com/microsoft/guidance\nI can't get a handle on what exactly {{gen}} does I've read the docs but hoping someone can save me from having to read the code. For example what would {{gen 'chapter'}} do? Does it create a seperate api call to the LLM with rest of the generated prompt upto this point and then save the generated output in the variable 'chapter'

Message : what is the prompt used by {{gen}} is it just everything generated upto the point of the {{gen}} call ?
Quoted Message : Yes. Output is saved in the key ‚Äúchapter‚Äù

Message : Any idea how we can generate a prompt dataset with openai and llama index given an article ?

Message : What do you mean by prompt dataset here?
Quoted Message : Any idea how we can generate a prompt dataset with openai and llama index given an article ?

Message : Question and answer, a format similar to what alpaca needs

Message : There is question generation module which you can use to create questions and use index and query to generate answers.
Quoted Message : Question and answer, a format similar to what alpaca needs

Message : Thanks for your reply . Any links sources that I can learn from?

Message : https://gpt-index.readthedocs.io/en/latest/examples/evaluation/QuestionGeneration.html
Quoted Message : Thanks for your reply . Any links sources that I can learn from?

Message : Yup, that‚Äôs why the ‚Äúsequential execution‚Äù
Quoted Message : what is the prompt used by {{gen}} is it just everything generated upto the point of the {{gen}} call ?

Message : I also found https://lmql.ai/ a lot easier to understand and try out in their neat little playground

Message : Hot take - though I think even this could be simpler it‚Äôs better than guidance
Quoted Message : I also found https://lmql.ai/ a lot easier to understand and try out in their neat little playground

Message : Haven‚Äôt tried either just from a simplicity POV
Quoted Message : Hot take - though I think even this could be simpler it‚Äôs better than guidance

Message : I spent 10-15 mins on guidance got confused and gave up üòÅ

Message : If you want something truly magical you can also try https://www.askmarvin.ai/guide/concepts/ai_functions/ ü§ì

Message : Their entity extraction utils are truly neat
Quoted Message : If you want something truly magical you can also try https://www.askmarvin.ai/guide/concepts/ai_functions/ ü§ì

Message : And with pydantic support ü§Ø
Quoted Message : Their entity extraction utils are truly neat

Message : this is actually pretty neat! wow
Quoted Message : If you want something truly magical you can also try https://www.askmarvin.ai/guide/concepts/ai_functions/ ü§ì

Message : Yeah. That's what makes them neat. I eventually switched to Guardrails because they've ReAsk, making it more reliable
Quoted Message : And with pydantic support ü§Ø

Message : https://www.askmarvin.ai/guide/concepts/plugins/

Damn, they even do functions as plugins

Message : This is cool
Quoted Message : If you want something truly magical you can also try https://www.askmarvin.ai/guide/concepts/ai_functions/ ü§ì

Message : This is probably the best way to use LLMs

Message : It's taking too long. Is that the right behavior. I just have one pdf file with 4 pages.
Quoted Message : https://gpt-index.readthedocs.io/en/latest/examples/evaluation/QuestionGeneration.html

Message : also they are not really clear that this might end up costing a lot more with hosted llms like openai than a single pass execution. nor would some of the token rewind stuff work
Quoted Message : I spent 10-15 mins on guidance got confused and gave up üòÅ

Message : Yup saw AI functions for the first time in AutoGPT. Found the concept super interesting.

https://github.com/Significant-Gravitas/Auto-GPT/blob/master/autogpt/llm/llm_utils.py#L73

AutoGPT uses them when it has to run code.
Quoted Message : If you want something truly magical you can also try https://www.askmarvin.ai/guide/concepts/ai_functions/ ü§ì

Message : They come from here. 

https://github.com/Torantulino/AI-Functions
Quoted Message : Yup saw AI functions for the first time in AutoGPT. Found the concept super interesting.\n\nhttps://github.com/Significant-Gravitas/Auto-GPT/blob/master/autogpt/llm/llm_utils.py#L73\n\nAutoGPT uses them when it has to run code.

Message : hey folks, is there already any sophisticated method to do unit tests like things for functions powered by LLMs?

I've over 30-40 functions which needs a call to gpt and not each of them is called for every user's message - so while I change a few prompts here and there or a small param change, I try to reproduce each case of json in a function but it gets hard to work with as the json I'm extracting via LLM is getting complex and prompt fixes are increasing in frequency

Message : have you come across a js/ts impl of these
Quoted Message : They come from here. \n\nhttps://github.com/Torantulino/AI-Functions

Message : one thing i've done in the past is feed the result back into the llm along with th expected results and ask it to evaluate but again result might vary based on the complexity of your prompts
Quoted Message : hey folks, is there already any sophisticated method to do unit tests like things for functions powered by LLMs?\n\nI've over 30-40 functions which needs a call to gpt and not each of them is called for every user's message - so while I change a few prompts here and there or a small param change, I try to reproduce each case of json in a function but it gets hard to work with as the json I'm extracting via LLM is getting complex and prompt fixes are increasing in frequency

Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.

I'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.
Quoted Message : just bumping this thread back again to see if there is any plugin i can use to enable browsing via API except using serp as a tool? or any other library that's optimised on cost.

Message : is 100k free per month?
Quoted Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.\n\nI'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.

Message : just have to make sure JS websites are excluded otherwise you'll just get "couldn't get data because page blocked you" and some html tags cases
Quoted Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.\n\nI'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.

Message : interesting how did you make it so it checks everytime a commit is made?

my friends are also now making changes in my repo and altho they try to test but prompt based responses vary so much - it is getting hard keeping all inputs to yry in a file so have to ensure I'm checking with a build pipeline
Quoted Message : one thing i've done in the past is feed the result back into the llm along with th expected results and ask it to evaluate but again result might vary based on the complexity of your prompts

Message : i manually run the tests but yes that would be a future flow once i have the git actiosn setup

Message : Git Pre Commit has entered this chat
Quoted Message : interesting how did you make it so it checks everytime a commit is made?\n\nmy friends are also now making changes in my repo and altho they try to test but prompt based responses vary so much - it is getting hard keeping all inputs to yry in a file so have to ensure I'm checking with a build pipeline

Message : Ah thanks for this! Kept running into SERPs free limit
Quoted Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.\n\nI'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.

Message : Hey guys, can anyone tell which model is being used for image generation by Bing ? 

Is it a custom they have built internally?

Message : Based on DALL‚àôE, could be a next gen model, but probably finetuned.

"Powered by an advanced version of the DALL‚àôE model from our partners at OpenAI, Bing Image Creator allows you to create an image simply by using your own words to describe the picture you want to see."

https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing/#:~:text=Powered%20by%20an%20advanced%20version,picture%20you%20want%20to%20see.
Quoted Message : Hey guys, can anyone tell which model is being used for image generation by Bing ? \n\nIs it a custom they have built internally?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : one thing i've done in the past is feed the result back into the llm along with th expected results and ask it to evaluate but again result might vary based on the complexity of your prompts
Quoted Message : hey folks, is there already any sophisticated method to do unit tests like things for functions powered by LLMs?\n\nI've over 30-40 functions which needs a call to gpt and not each of them is called for every user's message - so while I change a few prompts here and there or a small param change, I try to reproduce each case of json in a function but it gets hard to work with as the json I'm extracting via LLM is getting complex and prompt fixes are increasing in frequency

Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.

I'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.
Quoted Message : just bumping this thread back again to see if there is any plugin i can use to enable browsing via API except using serp as a tool? or any other library that's optimised on cost.

Message : is 100k free per month?
Quoted Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.\n\nI'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.

Message : just have to make sure JS websites are excluded otherwise you'll just get "couldn't get data because page blocked you" and some html tags cases
Quoted Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.\n\nI'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.

Message : interesting how did you make it so it checks everytime a commit is made?

my friends are also now making changes in my repo and altho they try to test but prompt based responses vary so much - it is getting hard keeping all inputs to yry in a file so have to ensure I'm checking with a build pipeline
Quoted Message : one thing i've done in the past is feed the result back into the llm along with th expected results and ask it to evaluate but again result might vary based on the complexity of your prompts

Message : i manually run the tests but yes that would be a future flow once i have the git actiosn setup

Message : Git Pre Commit has entered this chat
Quoted Message : interesting how did you make it so it checks everytime a commit is made?\n\nmy friends are also now making changes in my repo and altho they try to test but prompt based responses vary so much - it is getting hard keeping all inputs to yry in a file so have to ensure I'm checking with a build pipeline

Message : Ah thanks for this! Kept running into SERPs free limit
Quoted Message : btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.\n\nI'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.

Message : Hey guys, can anyone tell which model is being used for image generation by Bing ? 

Is it a custom they have built internally?

Message : Based on DALL‚àôE, could be a next gen model, but probably finetuned.

"Powered by an advanced version of the DALL‚àôE model from our partners at OpenAI, Bing Image Creator allows you to create an image simply by using your own words to describe the picture you want to see."

https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing/#:~:text=Powered%20by%20an%20advanced%20version,picture%20you%20want%20to%20see.
Quoted Message : Hey guys, can anyone tell which model is being used for image generation by Bing ? \n\nIs it a custom they have built internally?

Message : has anyone been playing with integrating OpenAI (or other llm) in stuff like customer support chatbots in actual production ? 
have u found it better/worse than the commercial solutions out there.

Message : How does AWS Kendra compared to LLM tools ?

Use Case :
Kendra allows to ingest content and provides feasibility to ask questions and get answers.


Apart from from cost, what's the tech difference.

Message : Kendra is more of an info retrieval system.

It has an index that fetches you documents that are most appropriate to your query.

It doesn't generate text on its own.
Quoted Message : How does AWS Kendra compared to LLM tools ?\n\nUse Case : \nKendra allows to ingest content and provides feasibility to ask questions and get answers.\n\n\nApart from from cost, what's the tech difference.

Message : I see. But does it do well?
Unlike Chat GPT ?

Let's say we feed all publicly available policy and support docs to both Kendra and ChatGPT.

Which one is prone to be more accurate and cost optimal?
Quoted Message : Kendra is more of an info retrieval system.\n\nIt has an index that fetches you documents that are most appropriate to your query.\n\nIt doesn't generate text on its own.

Message : Can you not combine a retrieval system with a generation system
Quoted Message : I see. But does it do well?\nUnlike Chat GPT ?\n\nLet's say we feed all publicly available policy and support docs to both Kendra and ChatGPT.\n\nWhich one is prone to be more accurate and cost optimal?

Message : Whats your task?

Is it information retrieval or facts?

Then kendra

Is it reasoning or text generation?
Quoted Message : I see. But does it do well?\nUnlike Chat GPT ?\n\nLet's say we feed all publicly available policy and support docs to both Kendra and ChatGPT.\n\nWhich one is prone to be more accurate and cost optimal?

Message : Hi , 
Question on LangChain Agents - In case some data needs to be returned , can agents determine when it should use SerpAPI to browse the web and include that in the response , and not to browse in other cases .

Message : Enabling helpdesk guys to look at past data and suggest resolution for new support queries.


Data sources for resolution could be a set of PDFs , fresh desk data dump.
Quoted Message : Whats your task?\n\nIs it information retrieval or facts?\n\nThen kendra\n\nIs it reasoning or text generation?

Message : Yeah there has been some progress in this area.

But a pure LLM is an unreliable fact producer.

While a IR system cant produce text on its own
Quoted Message : Can you not combine a retrieval system with a generation system

Message : Yes
Quoted Message : Hi , \nQuestion on LangChain Agents - In case some data needs to be returned , can agents determine when it should use SerpAPI to browse the web and include that in the response , and not to browse in other cases .

Message : You have to just specify it as a tool and the agent will decide whether to use it or not

Message : They can. But they can be pretty bad at deciding when to not search. You'll have to put the boundaries properly in the prompt if you wanna enforce cases where you don't want it to search
Quoted Message : Hi , \nQuestion on LangChain Agents - In case some data needs to be returned , can agents determine when it should use SerpAPI to browse the web and include that in the response , and not to browse in other cases .

Message : So my question for you is:

Do you want your guys to think and reason while the system gives them the most relevant docs and snippets.

Do you want the system to compose an entire response on its own after digesting the material. The guys interact via prompt and communicate results to client.
Quoted Message : Enabling helpdesk guys to look at past data and suggest resolution for new support queries.\n\n\nData sources for resolution could be a set of PDFs , fresh desk data dump.

Message : is this to optimize serpapi calls for cost ?
Quoted Message : Hi , \nQuestion on LangChain Agents - In case some data needs to be returned , can agents determine when it should use SerpAPI to browse the web and include that in the response , and not to browse in other cases .

Message : oh , so instead of action agents , i'll need a custom one .
Quoted Message : They can. But they can be pretty bad at deciding when to not search. You'll have to put the boundaries properly in the prompt if you wanna enforce cases where you don't want it to search

Message : yep
Quoted Message : is this to optimize serpapi calls for cost ?

Message : + latency, serp is usually not as fast as google
Quoted Message : is this to optimize serpapi calls for cost ?

Message : Kind of. But you don't need the whole thing to be custom, you can just get the prompt template from codebase, append your guardrails and pass that instead
Quoted Message : oh , so instead of action agents , i'll need a custom one .

Message : Preferably later. 
Where prompt is prepared by system based on question raised by customer.

Let's say customer says "i am getting aadhaar seeding error while Onboarding and uploading PAN"


So the tool shall be able to relate to a policy document details that says Plans which are not aadhaar seeded shall not be allowed to onboard and set of steps from the same PDF to help customers know how to make PAN aadhaar seeded.


In essence: customer when raises the ticket may have relevant prompt worthy data and the tool shall infer/provide policy information and resolution steps documented in PDF.
Quoted Message : So my question for you is:\n\nDo you want your guys to think and reason while the system gives them the most relevant docs and snippets.\n\nDo you want the system to compose an entire response on its own after digesting the material. The guys interact via prompt and communicate results to client.

Message : Every business will have domain specific details which are not generic and usually could be present in set of documents that were ingested by system.

Leveraging AI for such data for auto generation of resolution response.

If response is incorrect, human could override response as a part of productized solution later.

Message : For this you need a LLM.

Kendra cannot reason.

What i would suggest is you need to use both
Quoted Message : Preferably later. \nWhere prompt is prepared by system based on question raised by customer.\n\nLet's say customer says \"i am getting aadhaar seeding error while Onboarding and uploading PAN\"\n\n\nSo the tool shall be able to relate to a policy document details that says Plans which are not aadhaar seeded shall not be allowed to onboard and set of steps from the same PDF to help customers know how to make PAN aadhaar seeded.\n\n\nIn essence: customer when raises the ticket may have relevant prompt worthy data and the tool shall infer/provide policy information and resolution steps documented in PDF.

Message : Step 1: use kendra to get your relevant docs

Message : Step 2: with relevant docs as context

Message : Answer client query

Message : Step 3 : let human verify to override the response and of response is edited, would that be fed back to Kendra or LLM ?
Quoted Message : Answer client query

Message : Maybe you wdnt need a giant LLM for this. Cheaper ones would do.

Message : It cant goto Kendra from my understanding.

For feedback to be accepted by a ML model you need to be able to express it as a loss function.

I cant imagine a way to pass the loss through the LLM back to Kendra.

Additionally i dont think Amazon lets you tinker with its retrieval models.
Quoted Message : Step 3 : let human verify to override the response and of response is edited, would that be fed back to Kendra or LLM ?

Message : If we skip the Kendra from equation, what all tools could be combined to do this with any light weight OSS for POC. ?
Quoted Message : It cant goto Kendra from my understanding.\n\nFor feedback to be accepted by a ML model you need to be able to express it as a loss function.\n\nI cant imagine a way to pass the loss through the LLM back to Kendra.\n\nAdditionally i dont think Amazon lets you tinker with its retrieval models.

Message : That's why you combine both
Quoted Message : Yeah there has been some progress in this area.\n\nBut a pure LLM is an unreliable fact producer.\n\nWhile a IR system cant produce text on its own

Message : Yup use the docs as context for LLM
Quoted Message : That's why you combine both

Message : OSS?
Quoted Message : If we skip the Kendra from equation, what all tools could be combined to do this with any light weight OSS for POC. ?

Message : I meant removing AWS property from equation altogether and revisiting the solution with any other set of tools that are pure OSS and combined.

What that stack could be ?
Quoted Message : That's why you combine both

Message : Open source software.
Quoted Message : OSS?

Message : np.array to store embeddings of the docs
Quoted Message : If we skip the Kendra from equation, what all tools could be combined to do this with any light weight OSS for POC. ?

Message : Maybe going for paragraphs might be better.
Quoted Message : np.array to store embeddings of the docs

Message : Yes..I meant that. Chunk your docs always
Quoted Message : Maybe going for paragraphs might be better.

Message : Also if the docs are pdf, ppt, etc 

Is there an easy way clean the mess?
Quoted Message : Yes..I meant that. Chunk your docs always

Message : Given the variety of tech present what's the pattern of tools that could be leveraged.

For example making REST API we have a stack of JavaScript, Java , Golang based on engineering teams capabilities and affinity.

What could be equivalent stacks for above problem that we discussed.

I'm sure there would be more than one combination
Quoted Message : I meant removing AWS property from equation altogether and revisiting the solution with any other set of tools that are pure OSS and combined.\n\nWhat that stack could be ?

Message : You can always develop a chunking strategy.
https://twitter.com/nirantk/status/1659624239320956928?s=46&t=URoDrV5X7GPNPYSgYW42Dw
Quoted Message : Also if the docs are pdf, ppt, etc \n\nIs there an easy way clean the mess?

Message : I think for a POC do what your engineering team is familiar with.
Quoted Message : Given the variety of tech present what's the pattern of tools that could be leveraged.\n\nFor example making REST API we have a stack of JavaScript, Java , Golang based on engineering teams capabilities and affinity.\n\nWhat could be equivalent stacks for above problem that we discussed.\n\nI'm sure there would be more than one combination


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : OSS?
Quoted Message : If we skip the Kendra from equation, what all tools could be combined to do this with any light weight OSS for POC. ?

Message : I meant removing AWS property from equation altogether and revisiting the solution with any other set of tools that are pure OSS and combined.

What that stack could be ?
Quoted Message : That's why you combine both

Message : Open source software.
Quoted Message : OSS?

Message : np.array to store embeddings of the docs
Quoted Message : If we skip the Kendra from equation, what all tools could be combined to do this with any light weight OSS for POC. ?

Message : Maybe going for paragraphs might be better.
Quoted Message : np.array to store embeddings of the docs

Message : Yes..I meant that. Chunk your docs always
Quoted Message : Maybe going for paragraphs might be better.

Message : Also if the docs are pdf, ppt, etc 

Is there an easy way clean the mess?
Quoted Message : Yes..I meant that. Chunk your docs always

Message : Given the variety of tech present what's the pattern of tools that could be leveraged.

For example making REST API we have a stack of JavaScript, Java , Golang based on engineering teams capabilities and affinity.

What could be equivalent stacks for above problem that we discussed.

I'm sure there would be more than one combination
Quoted Message : I meant removing AWS property from equation altogether and revisiting the solution with any other set of tools that are pure OSS and combined.\n\nWhat that stack could be ?

Message : You can always develop a chunking strategy.
https://twitter.com/nirantk/status/1659624239320956928?s=46&t=URoDrV5X7GPNPYSgYW42Dw
Quoted Message : Also if the docs are pdf, ppt, etc \n\nIs there an easy way clean the mess?

Message : I think for a POC do what your engineering team is familiar with.
Quoted Message : Given the variety of tech present what's the pattern of tools that could be leveraged.\n\nFor example making REST API we have a stack of JavaScript, Java , Golang based on engineering teams capabilities and affinity.\n\nWhat could be equivalent stacks for above problem that we discussed.\n\nI'm sure there would be more than one combination

Message : Dont make ppl learn web frameworks for a POC. ü•≤

Message : Even that needs to begin somewhere. Imagine clean slate.
Quoted Message : I think for a POC do what your engineering team is familiar with.

Message : Web framework was just a analogy
Quoted Message : Dont make ppl learn web frameworks for a POC. ü•≤

Message : Python + Flask

Message : I would use it for a simple POC on a browser.
Quoted Message : Python + Flask

Message : ‚Äé<attached: 00004692-PHOTO-2023-05-20-12-43-28.jpg>
Quoted Message : You can always develop a chunking strategy.\nhttps://twitter.com/nirantk/status/1659624239320956928?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Message : I'm not talking about REST.

It's equivalent for document parsing, ingest, reasoning and querying the data from new AI tools/tech

Let's say

Use X for docs parse
UseY for docs ingest
Use Z for reasoning
Use Q for corrected data ingest


That becomes a stack.
Quoted Message : I would use it for a simple POC on a browser.

Message : X, Y, Z, Q could be combination of some python libs and chat gpt 

Or its alternative that are self hosted.

Message : Or may be we are in metamorphosis phase where such patterns and stacks are yet to appear and stabilize.

Message : I have hopes from only one person, simon willison

Fwiw, it took about 10 years for web frameworks to properly mature.
Quoted Message : Or may be we are in metamorphosis phase where such patterns and stacks are yet to appear and stabilize.

Message : Guess what I‚Äôve been thinking about for months üòÅ
Quoted Message : Enabling helpdesk guys to look at past data and suggest resolution for new support queries.\n\n\nData sources for resolution could be a set of PDFs , fresh desk data dump.

Message : A lot depends on the available budget for each case and the complexity of the queries that need to be answered.

Message : LLM can definitely play a powerful role here

Message : Can design LangChain agents to act as fast assistants to help desk staff

Message : actually - thats a very interesting question. how does one get LLM to look at *past data* and use that to suggest resolutions ? lets say we pump all this stuff into a vector db as well. is there any prompts/chain-of-thought that does this ?
Quoted Message : Enabling helpdesk guys to look at past data and suggest resolution for new support queries.\n\n\nData sources for resolution could be a set of PDFs , fresh desk data dump.

Message : No I don‚Äôt think that works beyond the most basic queries

Message : What you want to do is build a combination of GitHub copilot / openAI plugins for the support staff.

Message : In spirit like not literally tbc

Message : Then you keep gathering data and improving

Message : Once you have enough you start fine tuning / RLHFing ..

Message : But ppl want fast easy solutions which I don‚Äôt think exist yet. This requires lots of careful engineering and planning.

Message : This new research is incredible.
Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold.

Paper: https://lnkd.in/dHUuCSDU
Project page: https://lnkd.in/dEfgRMM7


Through DragGAN, anyone can deform an image with precise control over where pixels go, thus manipulating the pose, shape, expression, and layout of diverse categories such as animals, cars, humans, landscapes, etc.

As these manipulations are performed on the learned generative image manifold of a GAN, they tend to produce realistic outputs even for challenging scenarios such as hallucinating occluded content and deforming shapes that consistently follow the object's rigidity.

Both qualitative and quantitative comparisons demonstrate the advantage of DragGAN over prior approaches in the tasks of image manipulation and point tracking. We also showcase the manipulation of real images through GAN inversion.

Message : Combining with diffusion models can give some awesome workflows

Message : https://www.reddit.com/r/ChatGPT/comments/13lqm1s/chatgpt_describe_a_world_where_the_power

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØAkshay Jain

Message : Hi folks üëã

Any references on LLaMA-adapter with audio modality? Has anyone here  tried it?

Message : I am currently working on performing QA retrieval over an existing FAISS index using the load_qa_with_sources_chain module in Langchain. I was wondering if there are any open-source, LLMs supported by Langchain that can serve as alternatives to OpenAI's models without requiring any authentication(i.e. OpenAI API key). Does anyone have any experience or recommendations for deploying such models in a production environment?

Message : huggingface supports open source models through langchain. No experience of using them though https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_hub.html
Quoted Message : I am currently working on performing QA retrieval over an existing FAISS index using the load_qa_with_sources_chain module in Langchain. I was wondering if there are any open-source, LLMs supported by Langchain that can serve as alternatives to OpenAI's models without requiring any authentication(i.e. OpenAI API key). Does anyone have any experience or recommendations for deploying such models in a production environment?

Message : Did anyone try loading llama 7b with alpaca and was successful in converting llama weighs to hugging face transformers?

Message : Most of these are too slow, or do not generate a meaningful response :)
Quoted Message : huggingface supports open source models through langchain. No experience of using them though https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_hub.html

Message : Surprisingly the Q/A models cannot be used with the QA_chains in Langchain, pretty weird

Message : Team, I am sure versions of these exist out there:

I am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part.

I read somewhere it needs to use pinecone, langchain, and openai.

But, curious to know if someone has come across a how-to video for how to do this?

Message : I think it matters where these places are - Google drive? Notion? A file on someone‚Äôs computer?
Quoted Message : Team, I am sure versions of these exist out there:\n\nI am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part. \n\nI read somewhere it needs to use pinecone, langchain, and openai. \n\nBut, curious to know if someone has come across a how-to video for how to do this?

Message : I have a out 50-75 pdfs through my access to seismic, then some google sheets, some notion docs yes, some ppts

Message : All of these files i have in my computer :)

Message : Are you keen on writing code? 

If not, something like this can work? https://www.databerry.ai/
Quoted Message : Team, I am sure versions of these exist out there:\n\nI am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part. \n\nI read somewhere it needs to use pinecone, langchain, and openai. \n\nBut, curious to know if someone has come across a how-to video for how to do this?

Message : Curious for your stack recommendation - if some one wants to code it from ground up? I/m thinking openai embeddings + pinecone.?
Quoted Message : Are you keen on writing code? \n\nIf not, something like this can work? https://www.databerry.ai/

Message : Embeddings: OpenAI / Cohere-Large, are both competitive. Sentence BERT if you want to do FOSS.

VectorDB: Pinecone is great to begin with, but so expensive I had to quickly move to FOSS. I tried Chroma, Redis and finally settled with Qdrant. Even if I were to use a cloud now, Qdrant is max $25/mo, while others start at $50-70/mo for basic things.

E.g. Qdrant does entire English Wikipedia in less than 2G of RAM. Just the compute cost for the rest is too much.
I've heard good things about the sentence BERT embedding integration in both Chroma and Weaviate. Qdrant doesn't have any such thing.
Quoted Message : Curious for your stack recommendation - if some one wants to code it from ground up? I/m thinking openai embeddings + pinecone.?

Message : For most projects like the one which Rohan @1650250xxxx bhaiya is trying, OpenAI + Redis would work better perhaps? Most tech teams already use Redis, so any questions are answered in 5 minutes vs 3 days.

Message : Related Q: how do I compare  the embeddings like intuitively, like what are the modalities where one embedding ‚Äúgets it‚Äù and other doesn‚Äôt
Quoted Message : Embeddings: OpenAI / Cohere-Large, are both competitive. Sentence BERT if you want to do FOSS.\n\nVectorDB: Pinecone is great to begin with, but so expensive I had to quickly move to FOSS. I tried Chroma, Redis and finally settled with Qdrant. Even if I were to use a cloud now, Qdrant is max $25/mo, while others start at $50-70/mo for basic things. \n\nE.g. Qdrant does entire English Wikipedia in less than 2G of RAM. Just the compute cost for the rest is too much.\nI've heard good things about the sentence BERT embedding integration in both Chroma and Weaviate. Qdrant doesn't have any such thing.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Surprisingly the Q/A models cannot be used with the QA_chains in Langchain, pretty weird

Message : Team, I am sure versions of these exist out there:

I am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part.

I read somewhere it needs to use pinecone, langchain, and openai.

But, curious to know if someone has come across a how-to video for how to do this?

Message : I think it matters where these places are - Google drive? Notion? A file on someone‚Äôs computer?
Quoted Message : Team, I am sure versions of these exist out there:\n\nI am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part. \n\nI read somewhere it needs to use pinecone, langchain, and openai. \n\nBut, curious to know if someone has come across a how-to video for how to do this?

Message : I have a out 50-75 pdfs through my access to seismic, then some google sheets, some notion docs yes, some ppts

Message : All of these files i have in my computer :)

Message : Are you keen on writing code? 

If not, something like this can work? https://www.databerry.ai/
Quoted Message : Team, I am sure versions of these exist out there:\n\nI am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part. \n\nI read somewhere it needs to use pinecone, langchain, and openai. \n\nBut, curious to know if someone has come across a how-to video for how to do this?

Message : Curious for your stack recommendation - if some one wants to code it from ground up? I/m thinking openai embeddings + pinecone.?
Quoted Message : Are you keen on writing code? \n\nIf not, something like this can work? https://www.databerry.ai/

Message : Embeddings: OpenAI / Cohere-Large, are both competitive. Sentence BERT if you want to do FOSS.

VectorDB: Pinecone is great to begin with, but so expensive I had to quickly move to FOSS. I tried Chroma, Redis and finally settled with Qdrant. Even if I were to use a cloud now, Qdrant is max $25/mo, while others start at $50-70/mo for basic things.

E.g. Qdrant does entire English Wikipedia in less than 2G of RAM. Just the compute cost for the rest is too much.
I've heard good things about the sentence BERT embedding integration in both Chroma and Weaviate. Qdrant doesn't have any such thing.
Quoted Message : Curious for your stack recommendation - if some one wants to code it from ground up? I/m thinking openai embeddings + pinecone.?

Message : For most projects like the one which Rohan @1650250xxxx bhaiya is trying, OpenAI + Redis would work better perhaps? Most tech teams already use Redis, so any questions are answered in 5 minutes vs 3 days.

Message : Related Q: how do I compare  the embeddings like intuitively, like what are the modalities where one embedding ‚Äúgets it‚Äù and other doesn‚Äôt
Quoted Message : Embeddings: OpenAI / Cohere-Large, are both competitive. Sentence BERT if you want to do FOSS.\n\nVectorDB: Pinecone is great to begin with, but so expensive I had to quickly move to FOSS. I tried Chroma, Redis and finally settled with Qdrant. Even if I were to use a cloud now, Qdrant is max $25/mo, while others start at $50-70/mo for basic things. \n\nE.g. Qdrant does entire English Wikipedia in less than 2G of RAM. Just the compute cost for the rest is too much.\nI've heard good things about the sentence BERT embedding integration in both Chroma and Weaviate. Qdrant doesn't have any such thing.

Message : Not at all actually. I want to cut out as much help required from others.  Willing to put 20 days haha
Quoted Message : Are you keen on writing code? \n\nIf not, something like this can work? https://www.databerry.ai/

Message : But if openai tells me step by step here is the code. Here is how you deploy, that‚Äôs something on me.
Quoted Message : Not at all actually. I want to cut out as much help required from others.  Willing to put 20 days haha

Message : Check this and this was done using embeddings. How do I do this on my own?

https://twitter.com/youraimarketer/status/1659360048693366784?s=46&t=A_AEd3mXs8W9xl-BOyaBqw
Quoted Message : But if openai tells me step by step here is the code. Here is how you deploy, that‚Äôs something on me.

Message : Yeah, so tools like the one which I linked to do use embeddings + some stores under the hood. They're a neater wrap on this ofc.
Quoted Message : Check this and this was done using embeddings. How do I do this on my own?\n\nhttps://twitter.com/youraimarketer/status/1659360048693366784?s=46&t=A_AEd3mXs8W9xl-BOyaBqw

Message : Neater ‚Üí Easier to use here

Message : You mean you‚Äôre developing something of this sort? 

If yes, can‚Äôt openai tell me the step by step method to build this private internal website / bot / whatever you want to call it:

1. Open terminal
2. Paste this python / Jupyter code or some shit like that?

Even is there are 500 steps like that, I am sure it can be done right. That‚Äôs how people are doing it. No?
Quoted Message : Yeah, so tools like the one which I linked to do use embeddings + some stores under the hood. They're a neater wrap on this ofc.

Message : I've not seen a single guidebook of sorts, but it should, you're right!

Message : What do u mean by that ? For e.g. the mpt chat model won't work with langchain qa chain ?
Quoted Message : Surprisingly the Q/A models cannot be used with the QA_chains in Langchain, pretty weird

Message : Damnnnn. So this a good challenge to solve and touch code in some form ü§£
Quoted Message : I've not seen a single guidebook of sorts, but it should, you're right!

Message : what are the most authortiative books on prompt engineering yet?

Message : We've discussed this quite a bit in the past. You can see some of the community discussions here: https://nirantk.com/ai
Quoted Message : what are the most authortiative books on prompt engineering yet?

Message : Advanced User Guide for prompts: lilianweng.github.io/posts/2023-03-15-prompt-engineering

Message : Thank you thank you. Sorry for the spam haha
Quoted Message : We've discussed this quite a bit in the past. You can see some of the community discussions here: https://nirantk.com/ai

Message : You can't reliably do this by asking OpenAI which has a knowledge cut-off date of sep21. Their is some post-sep21 data leakage due to RLHF, but it won't be reliable for building something like this.
Quoted Message : You mean you‚Äôre developing something of this sort? \n\nIf yes, can‚Äôt openai tell me the step by step method to build this private internal website / bot / whatever you want to call it:\n\n1. Open terminal \n2. Paste this python / Jupyter code or some shit like that? \n\nEven is there are 500 steps like that, I am sure it can be done right. That‚Äôs how people are doing it. No?

Message : Basically the non coder in me who got D grades all my life is not going to feel happy anytime soon üîú
Quoted Message : You can't reliably do this by asking OpenAI which has a knowledge cut-off date of sep21. Their is some post-sep21 data leakage due to RLHF, but it won't be reliable for building something like this.

Message : I think Chroma is the easiest to build something like this with, and its default guides should be good enough for you (if not, come back here and let us know). I would not recommend that for production though, and you should probably talk to @91773788xxxx if you're ready to take something live.

Message : Ok. That‚Äôs quite, helpful. Thank you üôèüèª
Quoted Message : I think Chroma is the easiest to build something like this with, and its default guides should be good enough for you (if not, come back here and let us know). I would not recommend that for production though, and you should probably talk to @9177xxxxxxxx if you're ready to take something live.

Message : Tanmay Bhat tweeted a sequel to the last harry potter book. Generated of course. 

Title: Harry Potter and the Echoes of the Dark Lord.

It is beautifully written.

https://twitter.com/thetanmay/status/1659974736859000832

Message : Maybe GRRM can use GPT to finally finish his books...

Message : God save the old man
Quoted Message : Maybe GRRM can use GPT to finally finish his books...

Message : ‚Äé<attached: 00004749-VIDEO-2023-05-21-11-59-55.mp4>

Message : This is a repeat pattern.
Quoted Message : Team, I am sure versions of these exist out there:\n\nI am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part. \n\nI read somewhere it needs to use pinecone, langchain, and openai. \n\nBut, curious to know if someone has come across a how-to video for how to do this?

Message : .
Quoted Message : Every business will have domain specific details which are not generic and usually could be present in set of documents that were ingested by system.\n\nLeveraging AI for such data for auto generation of resolution response.\n\nIf response is incorrect, human could override response as a part of productized solution later.

Message : Seems the most common use case

Message : https://learnprompting.org
Quoted Message : what are the most authortiative books on prompt engineering yet?

Message : Has anybody had success using GPT4 browsing? It always results in click failed no matter what website it tries to open.

Message : Depends on the websites

Message : What website was it

Message : yes it mostly fails 

https://twitter.com/bbourque/status/1659906528457916417?s=20
Quoted Message : Has anybody had success using GPT4 browsing? It always results in click failed no matter what website it tries to open.

Message : G2 reviews are not easily scraped. It seems the scraper isn't working the one they're using at openai

Message : I've tried a lot mostly github repos & documentations
Quoted Message : What website was it

Message : Yes they are hard to scrape
Quoted Message : I've tried a lot mostly github repos & documentations

Message : Quota github LinkedIn are hard to scrape sites

Message : Quora*

Message : Yes facing the same issue since yesterday
Quoted Message : Has anybody had success using GPT4 browsing? It always results in click failed no matter what website it tries to open.

Message : What are you trying to scrape and search exactly? There might be some tools that might work better for you
Quoted Message : Yes facing the same issue since yesterday

Message : https://nianticlabs.github.io/implicit-depth/index.html
Quoted Message : Should check google + unity workflow if for research purposes. Can bring in all of google earth into a rendering engine now \nRender pipelines for procedural setups if want to build apps \nWould have to also solve for occlusion culling if building for real time AR. Not an easy problem to solve.

Message : just wanted to summarise some articles..its not able to open any links
Quoted Message : What are you trying to scrape and search exactly? There might be some tools that might work better for you

Message : Is it one of these
Quoted Message : Quota github LinkedIn are hard to scrape sites

Message : https://studio.ribbonfarm.com/p/text-is-all-you-need
Quoted Message : Is it one of these


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I've tried a lot mostly github repos & documentations
Quoted Message : What website was it

Message : Yes they are hard to scrape
Quoted Message : I've tried a lot mostly github repos & documentations

Message : Quota github LinkedIn are hard to scrape sites

Message : Quora*

Message : Yes facing the same issue since yesterday
Quoted Message : Has anybody had success using GPT4 browsing? It always results in click failed no matter what website it tries to open.

Message : What are you trying to scrape and search exactly? There might be some tools that might work better for you
Quoted Message : Yes facing the same issue since yesterday

Message : https://nianticlabs.github.io/implicit-depth/index.html
Quoted Message : Should check google + unity workflow if for research purposes. Can bring in all of google earth into a rendering engine now \nRender pipelines for procedural setups if want to build apps \nWould have to also solve for occlusion culling if building for real time AR. Not an easy problem to solve.

Message : just wanted to summarise some articles..its not able to open any links
Quoted Message : What are you trying to scrape and search exactly? There might be some tools that might work better for you

Message : Is it one of these
Quoted Message : Quota github LinkedIn are hard to scrape sites

Message : https://studio.ribbonfarm.com/p/text-is-all-you-need
Quoted Message : Is it one of these

Message : weird. it can be scraped

Message : Was able to get quite a few models to work with langchain that are not OpenAI ones.

Llama, vicuna, mpt-7b-chat.

You can use the AutoCausalLM as part of the transformers library and load them by passing a local folder math for model_id parameter, and using the tokeniser and model, you can create a generator which can be used as LLM as part of the langchain pipeline.

Vicuna 7B and 13B actually do quite well for QA activities.
Ofcourse depends on your prompts.

If you want to make the inference faster, you could use bitsandbytes and accelerate packages to enable load 8 bit features of transformers packages.
Quoted Message : I am currently working on performing QA retrieval over an existing FAISS index using the load_qa_with_sources_chain module in Langchain. I was wondering if there are any open-source, LLMs supported by Langchain that can serve as alternatives to OpenAI's models without requiring any authentication(i.e. OpenAI API key). Does anyone have any experience or recommendations for deploying such models in a production environment?

Message : Tanmay again with Lagaan 2

https://twitter.com/thetanmay/status/1660204226734338049

I've tried creating prose using GPT. But never of this quality. I think this proves that you need a creative mind to unlock AI creativity. Us engineers are using it to help us with code, while Tanmay is using it for story telling.
Quoted Message : Tanmay Bhat tweeted a sequel to the last harry potter book. Generated of course. \n\nTitle: Harry Potter and the Echoes of the Dark Lord.\n\nIt is beautifully written. \n\nhttps://twitter.com/thetanmay/status/1659974736859000832

Message : Hi. Do u have a piece of code that does this ? Especially for mpt7b chat ? It didn't entirely work for us.

Isn't gpt4all the most popular one here ?
Quoted Message : Was able to get quite a few models to work with langchain that are not OpenAI ones.\n\nLlama, vicuna, mpt-7b-chat.\n\nYou can use the AutoCausalLM as part of the transformers library and load them by passing a local folder math for model_id parameter, and using the tokeniser and model, you can create a generator which can be used as LLM as part of the langchain pipeline.\n\nVicuna 7B and 13B actually do quite well for QA activities. \nOfcourse depends on your prompts. \n\nIf you want to make the inference faster, you could use bitsandbytes and accelerate packages to enable load 8 bit features of transformers packages.

Message : Any suggestions on where to buy used 3080/3090 gpus? Is gameloot safe or it's like quick/olx?

Message : What are the trade offs if you use redis vs a custom vector store

Message : Redis seems to also use undelivered

Message : Hnswlib

Message : https://blog.google/technology/research/project-starline/

Message : https://twitter.com/samsja19/status/1659953297011224579?t=OA2QYLUDLKfqCvCdjTFuGQ&s=08

This provides a way of thinking about your prompts  that's useful: is the token generation required by my prompt commensurate with the complexity of the task to be performed?

Message : (doesn't matter if you believe LLMs are purely stochastic parrots)

Message : Thought this might be interesting to you 
arxiv-vanity.com/papers/2305.10601
Quoted Message : https://twitter.com/samsja19/status/1659953297011224579?t=OA2QYLUDLKfqCvCdjTFuGQ&s=08\n\nThis provides a way of thinking about your prompts  that's useful: is the token generation required by my prompt commensurate with the complexity of the task to be performed?

Message : Thanks, yes

Message : I meant, the post I shared doesn't matter... Not that your beliefs don't matter üòÄ
Quoted Message : (doesn't matter if you believe LLMs are purely stochastic parrots)

Message : Hot take: doesn‚Äôt matter even if they‚Äôre purely stochastic parrots casue they‚Äôre so damn good at it
Quoted Message : (doesn't matter if you believe LLMs are purely stochastic parrots)

Message : Not an interesting take at all, sorry
Quoted Message : Hot take: doesn‚Äôt matter even if they‚Äôre purely stochastic parrots casue they‚Äôre so damn good at it

Message : As a language model trained by OpenAI, I cannot comment on whether this is philosophy or not. But it it is, we've a thriving *AI and Philosophy* WA group which discusses everything from Roko's Basilisk to Godel, Escher and Bach. 


https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : Had tried so long to stay away from philosophical discussions around LLMs
Quoted Message : As a language model trained by OpenAI, I cannot comment on whether this is philosophy or not. But it it is, we've a thriving *AI and Philosophy* WA group which discusses everything from Roko's Basilisk to Godel, Escher and Bach. \n\n\nhttps://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : Is this similar to smartgpt, where you essentially sample multiple outputs and then ask it to reflect on all of them independently and select the best one
Quoted Message : Thought this might be interesting to you \narxiv-vanity.com/papers/2305.10601

Message : You check G2 robots.txt. I think ChatGPT browser plugin owner website's robots.txt file. https://www.g2.com/robots.txt
Quoted Message : G2 reviews are not easily scraped. It seems the scraper isn't working the one they're using at openai

Message : Btw, I'm not sure about the overall point being made.The reason I can't make up my mind is because - can the slow verbal reasoning, which humans can't make very fast, be made fast with a faster model? And how is it going to be qualitatively different?
Quoted Message : https://twitter.com/samsja19/status/1659953297011224579?t=OA2QYLUDLKfqCvCdjTFuGQ&s=08\n\nThis provides a way of thinking about your prompts  that's useful: is the token generation required by my prompt commensurate with the complexity of the task to be performed?

Message : They just show a framework to generate multiple actions/thoughts - they are evaluating these thoughts in two ways - where LLM evaluated each thought and assigns a score or LLM looks at all the thoughts and generates comparisons. But we can use lots of other mechanisms to select the best one as well. Like another trained neural network or set of Lora weights which are trained using RL/ planning hybrid methods.
Quoted Message : Is this similar to smartgpt, where you essentially sample multiple outputs and then ask it to reflect on all of them independently and select the best one

Message : openai has rlhf data for reflexion and evaluation - they have human labellers doing this - so they probablyhave that rl/planning in built
Quoted Message : They just show a framework to generate multiple actions/thoughts - they are evaluating these thoughts in two ways - where LLM evaluated each thought and assigns a score or LLM looks at all the thoughts and generates comparisons. But we can use lots of other mechanisms to select the best one as well. Like another trained neural network or set of Lora weights which are trained using RL/ planning hybrid methods.

Message : Didn‚Äôt we have a jee working group here? Did you guys end up doing something like smartgpt or tree of thought to get better perf?
Quoted Message : They just show a framework to generate multiple actions/thoughts - they are evaluating these thoughts in two ways - where LLM evaluated each thought and assigns a score or LLM looks at all the thoughts and generates comparisons. But we can use lots of other mechanisms to select the best one as well. Like another trained neural network or set of Lora weights which are trained using RL/ planning hybrid methods.

Message : Complete speculation on my part - But it feels like GPT4 has some sort of internal planning module as well which makes it absolute beast with reasoning.
Quoted Message : openai has rlhf data for reflexion and evaluation - they have human labellers doing this - so they probablyhave that rl/planning in built

Message : https://youtube.com/shorts/H1sXIUbpRCU?feature=share

Message : very likely not, at least not mentioned in their paper.

also with plugins i think its very heuristic because they only allow upto 3 plugins at any time + very easy to break it with prompts (any ‚Äúreasoning‚Äù module that exists is not that sophisticated)
Quoted Message : Complete speculation on my part - But it feels like GPT4 has some sort of internal planning module as well which makes it absolute beast with reasoning.

Message : They haven‚Äôt mentioned anything in the paper except it‚Äôs a transformer model ..but maybe not. It feels easier to attribute reasoning capabilities of GPT4 to planning and ability to backtrack than just next token prediction.
Quoted Message : very likely not, at least not mentioned in their paper.\n\nalso with plugins i think its very heuristic because they only allow upto 3 plugins at any time + very easy to break it with prompts (any ‚Äúreasoning‚Äù module that exists is not that sophisticated)

Message : I‚Äôd imagine a 1T model learn some first order logic at least., this follows from the argument that emergence is a function of scale

Message : what kind of reasoning are u talking about + any papers in nlp or adjacent fields to back it up
Quoted Message : They haven‚Äôt mentioned anything in the paper except it‚Äôs a transformer model ..but maybe not. It feels easier to attribute reasoning capabilities of GPT4 to planning and ability to backtrack than just next token prediction.

Message : at least in robotics the planners i‚Äôve seen are very domain specific

Message : I agree with that..I think with GPT4 they have amazing base LLM + huge amount of SFT and RLHF. However just maximum likelihood training giving us performance of GPT4 seems hard. Couple of wrong token samples can put model in a wrong reasoning path and should decrease the performance. I am heavily impressed by GPT4‚Äôs reasoning performance (coding + plenty of other non bs tasks) and that might be biasing my speculation of GPT4 having planning component.
Quoted Message : I‚Äôd imagine a 1T model learn some first order logic at least., this follows from the argument that emergence is a function of scale

Message : you‚Äôre hugely underestimating the potential of scaled networks
Quoted Message : I agree with that..I think with GPT4 they have amazing base LLM + huge amount of SFT and RLHF. However just maximum likelihood training giving us performance of GPT4 seems hard. Couple of wrong token samples can put model in a wrong reasoning path and should decrease the performance. I am heavily impressed by GPT4‚Äôs reasoning performance (coding + plenty of other non bs tasks) and that might be biasing my speculation of GPT4 having planning component.

Message : you know what we are also just neural networks right? maybe with a hippocampus but short term memory is still activated in pathways of the cortex

Message : plus the amount of github code it was trained on, it would be excellent at basic coding

Message : i can‚Äôt get it to write good c++ or cuda code, even like 100-200 line scripts

Message : makes me think it‚Äôs more of a data exposure thing than a reasoning module

Message : This is literally not true
Quoted Message : you know what we are also just neural networks right? maybe with a hippocampus but short term memory is still activated in pathways of the cortex

Message : If that‚Äôs the case, it‚Äôs probably much more exciting .. then we will get much better augmented LLMs soon.
Quoted Message : makes me think it‚Äôs more of a data exposure thing than a reasoning module

Message : why not
Quoted Message : This is literally not true


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : at least in robotics the planners i‚Äôve seen are very domain specific

Message : I agree with that..I think with GPT4 they have amazing base LLM + huge amount of SFT and RLHF. However just maximum likelihood training giving us performance of GPT4 seems hard. Couple of wrong token samples can put model in a wrong reasoning path and should decrease the performance. I am heavily impressed by GPT4‚Äôs reasoning performance (coding + plenty of other non bs tasks) and that might be biasing my speculation of GPT4 having planning component.
Quoted Message : I‚Äôd imagine a 1T model learn some first order logic at least., this follows from the argument that emergence is a function of scale

Message : you‚Äôre hugely underestimating the potential of scaled networks
Quoted Message : I agree with that..I think with GPT4 they have amazing base LLM + huge amount of SFT and RLHF. However just maximum likelihood training giving us performance of GPT4 seems hard. Couple of wrong token samples can put model in a wrong reasoning path and should decrease the performance. I am heavily impressed by GPT4‚Äôs reasoning performance (coding + plenty of other non bs tasks) and that might be biasing my speculation of GPT4 having planning component.

Message : you know what we are also just neural networks right? maybe with a hippocampus but short term memory is still activated in pathways of the cortex

Message : plus the amount of github code it was trained on, it would be excellent at basic coding

Message : i can‚Äôt get it to write good c++ or cuda code, even like 100-200 line scripts

Message : makes me think it‚Äôs more of a data exposure thing than a reasoning module

Message : This is literally not true
Quoted Message : you know what we are also just neural networks right? maybe with a hippocampus but short term memory is still activated in pathways of the cortex

Message : If that‚Äôs the case, it‚Äôs probably much more exciting .. then we will get much better augmented LLMs soon.
Quoted Message : makes me think it‚Äôs more of a data exposure thing than a reasoning module

Message : why not
Quoted Message : This is literally not true

Message : what else is different

Message : pretty bad at anything that‚Äôs slightly novel. But good for exploring ideas
Quoted Message : i can‚Äôt get it to write good c++ or cuda code, even like 100-200 line scripts

Message : exactly! we on the other hand can very easily ‚Äúextend‚Äù reasoning beyond what we learn in tutorials or books
Quoted Message : pretty bad at anything that‚Äôs slightly novel. But good for exploring ideas

Message : try asking Yann Lecuns gear problem to GPT

Message : if it was good at reasoning, it would solve it no matter what configuration you give it

Message : but it doesnt

Message : NNs are a very very lossy abstraction inspired by our understanding of the brain from 60 years back. The list of differences are very very long, and I'll have to let you Google it for yourself.
Quoted Message : what else is different

Message : I mean, it's not even close.

Message : lol
Quoted Message : NNs are a very very lossy abstraction inspired by our understanding of the brain from 60 years back. The list of differences are very very long, and I'll have to let you Google it for yourself.

Message : i‚Äôm just saying things based off some cognitive neuroscience we‚Äôre reading

Message : sure, we‚Äôre not relu networks

Message : but we are networks

Message : ‚Äé<attached: 00004823-PHOTO-2023-05-21-19-38-17.jpg>

Message : thats why spiking NNs and memory augmented networks are getting interesting

Message : look up balints syndrome and other neurodegenerative diseases, it gives a nice primer on location of neural nets

Message : Ok we are again in AI philosophy territory
Quoted Message : look up balints syndrome and other neurodegenerative diseases, it gives a nice primer on location of neural nets

Message : cc
Quoted Message : As a language model trained by OpenAI, I cannot comment on whether this is philosophy or not. But it it is, we've a thriving *AI and Philosophy* WA group which discusses everything from Roko's Basilisk to Godel, Escher and Bach. \n\n\nhttps://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : also diffusion tensor imaging is literally the process of finding neural bundles

Message : We don‚Äôt understand brain well enough to make valid comparisons

We don‚Äôt even know if neurons are the fundamental unit of computation or if it‚Äôs something higher or lower level
Quoted Message : but we are networks

Message : no this is neuroscience territory
Quoted Message : Ok we are again in AI philosophy territory

Message : We have networks of neurons, sure, but they don't work the way these networks do. I mean, roads are networks too. Our brains don't work like the traffic. Some interesting analogies can be made sure, but that's about it.
Quoted Message : but we are networks

Message : bruh
Quoted Message : We don‚Äôt understand brain well enough to make valid comparisons\n\nWe don‚Äôt even know if neurons are the fundamental unit of computation or if it‚Äôs something higher or lower level

Message : pick up any computational neuroscience book

Message : and you‚Äôll see it say neurons are the fundamental unit in the gray matter

Message : Or could be that dendrites are doing something magical or it could be a higher level (networks of neurons)
Quoted Message : We don‚Äôt understand brain well enough to make valid comparisons\n\nWe don‚Äôt even know if neurons are the fundamental unit of computation or if it‚Äôs something higher or lower level

Message : yes, i‚Äôm not saying there is a one-to-one correspondence between human neurons and MLPs
Quoted Message : Or could be that dendrites are doing something magical or it could be a higher level (networks of neurons)

Message : but at a computational level they are equivalent (modulo some constant)

Message : And not to mention, the current networks have their genesis more than 60 years back, when we understood little about how the brain works. All this retro-fitting sounds like religion finding science in it.
Quoted Message : We don‚Äôt understand brain well enough to make valid comparisons\n\nWe don‚Äôt even know if neurons are the fundamental unit of computation or if it‚Äôs something higher or lower level

Message : Even this is largely incorrect
Quoted Message : but at a computational level they are equivalent (modulo some constant)

Message : We don‚Äôt know how we learn very well ..we mostly don‚Äôt do backprop

Message : thik h bhai, if you do not want established neuroscience literature and call it pseudoscience then idk what to tell you
Quoted Message : And not to mention, the current networks have their genesis more than 60 years back, when we understood little about how the brain works. All this retro-fitting sounds like religion finding science in it.

Message : Not saying that

Message : This is also fine.
Quoted Message : and you‚Äôll see it say neurons are the fundamental unit in the gray matter

Message : But you're making a large reductive jump

Message : my thesis work is literally in neurodegenerative diseases like alzheimers or parkinsons, and based on the human and rodent brains we study, there‚Äôs nothing ‚Äúmagical‚Äù computationally

Message : we don‚Äôt even know how important a rule non-neuronal cells in the brain (that outnumber neurons) play

Like astrocytes or glial cells

Brain is largely still unexplored territory
Quoted Message : Or could be that dendrites are doing something magical or it could be a higher level (networks of neurons)

Message : glial cells are literally just a cover
Quoted Message : we don‚Äôt even know how important a rule non-neuronal cells in the brain (that outnumber neurons) play\n\nLike astrocytes or glial cells\n\nBrain is largely still unexplored territory

Message : functionally they are very different agreed
Quoted Message : my thesis work is literally in neurodegenerative diseases like alzheimers or parkinsons, and based on the human and rodent brains we study, there‚Äôs nothing ‚Äúmagical‚Äù computationally

Message : but there is also a huge difference in scale + functional discrepancy

Message : if I‚Äôve learned one thing pouring over Biology over the years, it‚Äôs that any simplistic statement about a biological system is largely under estimating what it does

We just cannot make simple, linear, casual statements about complex systems

Have to be very careful before we say X is literally Y in Biology
Quoted Message : glial cells are literally just a cover


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : thik h bhai, if you do not want established neuroscience literature and call it pseudoscience then idk what to tell you
Quoted Message : And not to mention, the current networks have their genesis more than 60 years back, when we understood little about how the brain works. All this retro-fitting sounds like religion finding science in it.

Message : Not saying that

Message : This is also fine.
Quoted Message : and you‚Äôll see it say neurons are the fundamental unit in the gray matter

Message : But you're making a large reductive jump

Message : my thesis work is literally in neurodegenerative diseases like alzheimers or parkinsons, and based on the human and rodent brains we study, there‚Äôs nothing ‚Äúmagical‚Äù computationally

Message : we don‚Äôt even know how important a rule non-neuronal cells in the brain (that outnumber neurons) play

Like astrocytes or glial cells

Brain is largely still unexplored territory
Quoted Message : Or could be that dendrites are doing something magical or it could be a higher level (networks of neurons)

Message : glial cells are literally just a cover
Quoted Message : we don‚Äôt even know how important a rule non-neuronal cells in the brain (that outnumber neurons) play\n\nLike astrocytes or glial cells\n\nBrain is largely still unexplored territory

Message : functionally they are very different agreed
Quoted Message : my thesis work is literally in neurodegenerative diseases like alzheimers or parkinsons, and based on the human and rodent brains we study, there‚Äôs nothing ‚Äúmagical‚Äù computationally

Message : but there is also a huge difference in scale + functional discrepancy

Message : if I‚Äôve learned one thing pouring over Biology over the years, it‚Äôs that any simplistic statement about a biological system is largely under estimating what it does

We just cannot make simple, linear, casual statements about complex systems

Have to be very careful before we say X is literally Y in Biology
Quoted Message : glial cells are literally just a cover

Message : obviously, again I said im not claiming 1-1 correspondence

Message : but bringing back the cliche example of wright brothers, the airplane wasn't a one to one correspondence to a bird

Message : but all functional components were equivalent

Message : @91749807xxxx read up "Neuroscience Exploring the Brain" by Mark F Bear, and Neuroscience by Dale Purves. These are the books I'm reading for my work

Message : first one is very good

Message : can also send you studies on neurodegenerative diseases, and what they tell about different lobes and neuronal pathways

Message : ofc, a lot is also unknown because fMRI has very bad spatial resolution, so we can only say about the "macro" behavior of the brain, but histopathological slides have shown that neurons do most of the heavy lifting

Message : or comprise most of the functional brain, and neurodegenerative diseases all have to do with damaged or dead gray matter, meaning less neurons

Message : Thanks for the recommendations, and I have read a bunch about computational neuroscience as well, and I see and agree with a bunch of stuff you said as well, but

Message : 2hat are you claiming?
Quoted Message : obviously, again I said im not claiming 1-1 correspondence

Message : this is what I know. if you guys find some other explanations of the humans, or mammals in general lmk

Message : *what are you claiming?

Message : This was your original claim that you have backtracked from. If not this, then what else are you claiming now?
Quoted Message : you know what we are also just neural networks right? maybe with a hippocampus but short term memory is still activated in pathways of the cortex

Message : Friends, this is decidedly off topic, requesting you to move this conversation to the other group :)

Message : that on a functional level, GPT can have human-like reasoning with neural networks only, because that is how humans do it. Ok I want to do some ERM style math here so why not.

Let H be the space of all neural networks. My claim is that human brain f* \in H exists in this space. Let f be the GPT weights. I'm saying that since GPT weights  are in the space H, they can reach f*, just in a different form
Quoted Message : 2hat are you claiming?

Message : sure sure, this is the last bit from me anyway^ 

happy to take the discussion to DMs

Message : i hope the above explanation encompasses this as well
Quoted Message : This was your original claim that you have backtracked from. If not this, then what else are you claiming now?

Message : that gives me a good idea. I will try to write blog post summarizing some of these ideas

Message : is there any good hack anyone here has figured to promt something for LLM to understand. 

My solution:

right now my use case was understanding a specific topic from user so I ask LLM-1 to define all things in a bullet list that the LLM-2 should get from user and if it doesn't "understand/know" any of it, it should ask as a curious person.

Message : it works I guess. somewhat but it's just brute force like my most solutions üòÖ

anything better anyone has come across?

Message : I generate a todo list like thing in LLM-1. modified some prompts from guard rails implementation to prevent the gpt big mouth going off track

Message : Hi Rohit! Nice to see you here!

I doubt if Yann will agree with with you here. He says GPT is just autoregressive and does not have any world understanding.
Quoted Message : that on a functional level, GPT can have human-like reasoning with neural networks only, because that is how humans do it. Ok I want to do some ERM style math here so why not.\n\nLet H be the space of all neural networks. My claim is that human brain f* \in H exists in this space. Let f be the GPT weights. I'm saying that since GPT weights  are in the space H, they can reach f*, just in a different form

Message : But let‚Äôs see what still bigger GPTs can do.

Message : YLC has been shown to be wrong multiple times (gear configuration problems, forces in physics). I think Yann's stance is also motivated by the backlash of Galactica, and comparatively lesser attention to llama.

Yann also mentions that autoregressive models cannot have emergence, and my counter argument would be that ants are very simple automatons by themselves, but they show emergent properties when in huge numbers. A group of 10 ants wont show any emergence.
Quoted Message : Hi Rohit! Nice to see you here!\n\nI doubt if Yann will agree with with you here. He says GPT is just autoregressive and does not have any world understanding.

Message : Nice seeing you here too! Small world we live in haha
Quoted Message : Hi Rohit! Nice to see you here!\n\nI doubt if Yann will agree with with you here. He says GPT is just autoregressive and does not have any world understanding.

Message : GPT4 is already whooping GPT3 like crazy! I'm very impressed with some of the plugins, my academic workflow is 10x faster now!
Quoted Message : But let‚Äôs see what still bigger GPTs can do.

Message : True, I guess only time will tell. Interesting times to live in!
Quoted Message : YLC has been shown to be wrong multiple times (gear configuration problems, forces in physics). I think Yann's stance is also motivated by the backlash of Galactica, and comparatively lesser attention to llama.\n\nYann also mentions that autoregressive models cannot have emergence, and my counter argument would be that ants are very simple automatons by themselves, but they show emergent properties when in huge numbers. A group of 10 ants wont show any emergence.

Message : Very!
Quoted Message : True, I guess only time will tell. Interesting times to live in!

Message : Which plugins have you found useful?
Quoted Message : GPT4 is already whooping GPT3 like crazy! I'm very impressed with some of the plugins, my academic workflow is 10x faster now!

Message : penrose analyst is very cool, scraper too
Quoted Message : Which plugins have you found useful?

Message : xpapers is decent

Message : some of the video plugins don‚Äôt work, which is disputing

Message : disappointing*

Message : Thanks.  Will check these out.  I found a lot of value in code interpreter but have struggled to get much value from plugins.  Which video plugins have you tried?

Message : How about the speed?
Quoted Message : penrose analyst is very cool, scraper too

Message : ‚Äé<attached: 00004891-PHOTO-2023-05-22-08-56-33.jpg>
Quoted Message : How about the speed?

Message : *Xpapers

Message : Has rollout for plugins for chatgpt plus users started in India?

Message : Yes, Plugins are accessible to everyone on Plus. I've had Plugins for couple of weeks.
Quoted Message : Has rollout for plugins for chatgpt plus users started in India?

Message : I am a plus user, i wasnt able to see the plugin support. Do I need to enable anything separately?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : xpapers is decent

Message : some of the video plugins don‚Äôt work, which is disputing

Message : disappointing*

Message : Thanks.  Will check these out.  I found a lot of value in code interpreter but have struggled to get much value from plugins.  Which video plugins have you tried?

Message : How about the speed?
Quoted Message : penrose analyst is very cool, scraper too

Message : ‚Äé<attached: 00004891-PHOTO-2023-05-22-08-56-33.jpg>
Quoted Message : How about the speed?

Message : *Xpapers

Message : Has rollout for plugins for chatgpt plus users started in India?

Message : Yes, Plugins are accessible to everyone on Plus. I've had Plugins for couple of weeks.
Quoted Message : Has rollout for plugins for chatgpt plus users started in India?

Message : I am a plus user, i wasnt able to see the plugin support. Do I need to enable anything separately?

Message : ‚Äé<attached: 00004896-PHOTO-2023-05-22-09-05-45.jpg>
Quoted Message : I am a plus user, i wasnt able to see the plugin support. Do I need to enable anything separately?

Message : Thank you! Will check this
Quoted Message :  2023_05_22_3EB0AC16F6528197E74449.jpeg

Message : Enable in settings
Quoted Message : I am a plus user, i wasnt able to see the plugin support. Do I need to enable anything separately?

Message : Browsing is enabled by default but not plug-in access

Message : I see, let me check this

Message : PSA: WebPilot Plugin is a viable alternative to Browser. Does 80% of the job in 5% of the time. I've tried 2-3 queries on both and WebPilot beat Browser in speed and selection/relevance of the links selected both.

Message : Does gpt browsing have an increased context limit tho?
Quoted Message : PSA: WebPilot Plugin is a viable alternative to Browser. Does 80% of the job in 5% of the time. I've tried 2-3 queries on both and WebPilot beat Browser in speed and selection/relevance of the links selected both.

Message : It felt like it when I first used it

Message : Perhaps, but a longer context window in a weak search does not seem to help much. It's like having great recall for lyrics but not being able to find keys in the morning.

Message : Isn‚Äôt there something called Keymate.AI Search too?
Quoted Message : PSA: WebPilot Plugin is a viable alternative to Browser. Does 80% of the job in 5% of the time. I've tried 2-3 queries on both and WebPilot beat Browser in speed and selection/relevance of the links selected both.

Message : Which LLM api is available with a free tier that doesn't need a credit card ?

Am teaching some high school students as part of their summer holidays.

Extra brownie points 8f it works with langchain/gptindex.

Message : ‚Äé<attached: 00004907-PHOTO-2023-05-22-10-51-43.jpg>
Quoted Message : Which LLM api is available with a free tier that doesn't need a credit card ?\n\nAm teaching some high school students as part of their summer holidays.\n\nExtra brownie points 8f it works with langchain/gptindex.

Message : curious, why use the HF Inference API?
Quoted Message :  2023_05_22_3EB060EC9FF9E16B3BBE56.jpeg

Message : Free, faster than OpenAI, supports multi-modal, flexible (multiple models, context windows)
Quoted Message : curious, why use the HF Inference API?

Message : I heard Bard is pretty fast, I will look for benchmarks online

Message : Also @91955016xxxx, Jerry and I talked about you :) really appreciated your efforts

Message : It's fast but I found GPT4/3.5 is superior in most of the cases.
Quoted Message : I heard Bard is pretty fast, I will look for benchmarks online

Message : bard api is free ? and it works with langchain/gptindex ?
Quoted Message : I heard Bard is pretty fast, I will look for benchmarks online

Message : not looking for fast/superior...just free

Message : Bard has no official API
Quoted Message : bard api is free ? and it works with langchain/gptindex ?

Message : can u share this link ? i dont know what page is this
Quoted Message :  2023_05_22_3EB060EC9FF9E16B3BBE56.jpeg

Message : Let me send you a 30s Loom in next 30 minutes. Huggingface UX is terrible
Quoted Message : can u share this link ? i dont know what page is this

Message : I can‚Äôt believe how expensive RunwayML is lol

Message : Exactly. Almost every creative ai tool is like 20 dollars/20 minute usage. Runway,midjourney, synthesia
Quoted Message : I can‚Äôt believe how expensive RunwayML is lol

Message : ‚Äé<attached: 00004920-PHOTO-2023-05-22-11-03-00.jpg>

Message : Is there an open source alternative to synthesia?

Message : ‚Äé<attached: 00004922-PHOTO-2023-05-22-11-03-46.jpg>
Quoted Message :  2023_05_22_3A7D5B3AC316D8E2A9B9.jpeg

Message : wow, feeling limited by the 25 messages per 3 hour cap for the first time, because of this
Quoted Message : PSA: WebPilot Plugin is a viable alternative to Browser. Does 80% of the job in 5% of the time. I've tried 2-3 queries on both and WebPilot beat Browser in speed and selection/relevance of the links selected both.

Message : ‚Äé<attached: 00004925-PHOTO-2023-05-22-11-10-30.jpg>

Message : Moving that discussion to philosophy

Message : Something relevant since I found people discussing this last night:

https://ai.facebook.com/blog/ai-math-theorem-proving/

Message : ‚Äé<attached: 00004929-PHOTO-2023-05-22-11-47-25.jpg>
Quoted Message : Something relevant since I found people discussing this last night:\n\nhttps://ai.facebook.com/blog/ai-math-theorem-proving/

Message : The resource "supercluster" link mentions theorem proving as a top level project:
(Paper from 2022: https://arxiv.org/abs/2205.11491)
Quoted Message :  2023_05_22_3AAC0828DD3C43846FED.jpeg

Message : GPT-4 was able to solve 1-2 IMO problems

Message : this was able to solve 10 apparently ; best performance till date for reasoning skills

Message : That's 2 more than me
Quoted Message : GPT-4 was able to solve 1-2 IMO problems

Message : ‚ÄúSparks of AGI‚Äù paper
Quoted Message : GPT-4 was able to solve 1-2 IMO problems

Message : The first ever problem of IMO is a gcd problem, you have to show gcd of numerator and denominator is 1 
Can start with that üòõ
Quoted Message : That's 2 more than me

Message : Sandeep I run GPT4All locally ... very easy to use. Your students will get to be able to use it on a 4GB laptop also. You can use the desktop version or you can use the Python programming stack. 

https://gpt4all.io
Quoted Message : Which LLM api is available with a free tier that doesn't need a credit card ?\n\nAm teaching some high school students as part of their summer holidays.\n\nExtra brownie points 8f it works with langchain/gptindex.

Message : ‚Äé<attached: 00004937-PHOTO-2023-05-22-12-38-36.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Something relevant since I found people discussing this last night:

https://ai.facebook.com/blog/ai-math-theorem-proving/

Message : ‚Äé<attached: 00004929-PHOTO-2023-05-22-11-47-25.jpg>
Quoted Message : Something relevant since I found people discussing this last night:\n\nhttps://ai.facebook.com/blog/ai-math-theorem-proving/

Message : The resource "supercluster" link mentions theorem proving as a top level project:
(Paper from 2022: https://arxiv.org/abs/2205.11491)
Quoted Message :  2023_05_22_3AAC0828DD3C43846FED.jpeg

Message : GPT-4 was able to solve 1-2 IMO problems

Message : this was able to solve 10 apparently ; best performance till date for reasoning skills

Message : That's 2 more than me
Quoted Message : GPT-4 was able to solve 1-2 IMO problems

Message : ‚ÄúSparks of AGI‚Äù paper
Quoted Message : GPT-4 was able to solve 1-2 IMO problems

Message : The first ever problem of IMO is a gcd problem, you have to show gcd of numerator and denominator is 1 
Can start with that üòõ
Quoted Message : That's 2 more than me

Message : Sandeep I run GPT4All locally ... very easy to use. Your students will get to be able to use it on a 4GB laptop also. You can use the desktop version or you can use the Python programming stack. 

https://gpt4all.io
Quoted Message : Which LLM api is available with a free tier that doesn't need a credit card ?\n\nAm teaching some high school students as part of their summer holidays.\n\nExtra brownie points 8f it works with langchain/gptindex.

Message : ‚Äé<attached: 00004937-PHOTO-2023-05-22-12-38-36.jpg>

Message : Anything video is usually premium - right from non-AI tools
Quoted Message : I can‚Äôt believe how expensive RunwayML is lol

Message : You sell to the same market so companies price accordingly

Message : Hi prayank
This is useful, but I'm wondering if the local LLM can be exposed as an api.
My framework is kind of a langchain equivalent built in Java, which people can use to prototype serverless apps or even mobile apps.

So I don't mind locally running it...but is it exposed via api to make it usable in non python environments
Quoted Message : Sandeep I run GPT4All locally ... very easy to use. Your students will get to be able to use it on a 4GB laptop also. You can use the desktop version or you can use the Python programming stack. \n\nhttps://gpt4all.io

Message : Anyone here actively working on unreal engine code or content with stable diffusion ?

Message : mind reading https://twitter.com/_akhaliq/status/1660453496804741120?s=12

Message : https://github.com/go-skynet/LocalAI
LocalAI is a self-hosted, community-driven, local OpenAI-compatible API. It's designed to be a drop-in replacement for OpenAI, running Language Learning Models (LLMs) on consumer-grade hardware, with no GPU required.
Quoted Message : Hi prayank\nThis is useful, but I'm wondering if the local LLM can be exposed as an api.\nMy framework is kind of a langchain equivalent built in Java, which people can use to prototype serverless apps or even mobile apps. \n\nSo I don't mind locally running it...but is it exposed via api to make it usable in non python environments

Message : it is very slow for me ....are you aware of anyway to make it faster ?
using NVIDIA Quadro P1000
32 GB RAM
Quoted Message : Sandeep I run GPT4All locally ... very easy to use. Your students will get to be able to use it on a 4GB laptop also. You can use the desktop version or you can use the Python programming stack. \n\nhttps://gpt4all.io

Message : I'm running on 16GB RAM .. Apple M1
Quoted Message : it is very slow for me ....are you aware of anyway to make it faster ?\nusing NVIDIA Quadro P1000\n32 GB RAM

Message : This is very useful. Any idea which is the smallest model that will run on student grade hardware (maybe no GPU). Doesn't matter if it is slow ..as long as it is reasonably accurate
Quoted Message : https://github.com/go-skynet/LocalAI\nLocalAI is a self-hosted, community-driven, local OpenAI-compatible API. It's designed to be a drop-in replacement for OpenAI, running Language Learning Models (LLMs) on consumer-grade hardware, with no GPU required.

Message : Has anyone tried this? 

https://www.linkedin.com/posts/karenxcheng_karenxnerf-ugcPost-7065006931270119425-2uVb?utm_source=share&utm_medium=member_android

Message : @91800314xxxx
Quoted Message : Has anyone tried this? \n\nhttps://www.linkedin.com/posts/karenxcheng_karenxnerf-ugcPost-7065006931270119425-2uVb?utm_source=share&utm_medium=member_android

Message : Has anyone experimented with timeout parameter in openai api via the package . Keep seeing it there in their lib code but the versions I tried, didn't seem to work

Message : (The mobile app is iPhone only right now)
Quoted Message : Has anyone tried this? \n\nhttps://www.linkedin.com/posts/karenxcheng_karenxnerf-ugcPost-7065006931270119425-2uVb?utm_source=share&utm_medium=member_android

Message : Are you able to use their web API?
Quoted Message : Sandeep I run GPT4All locally ... very easy to use. Your students will get to be able to use it on a 4GB laptop also. You can use the desktop version or you can use the Python programming stack. \n\nhttps://gpt4all.io

Message : The one that GPT4all exposes on localhost
Quoted Message : Are you able to use their web API?

Message : This is a good idea - you are referring to this - https://docs.gpt4all.io/gpt4all_chat.html
Quoted Message : The one that GPT4all exposes on localhost

Message : Yes
Quoted Message : Has anyone tried this? \n\nhttps://www.linkedin.com/posts/karenxcheng_karenxnerf-ugcPost-7065006931270119425-2uVb?utm_source=share&utm_medium=member_android

Message : Ah I didn't know this was an option. I thought it was an in-memory model load.
Quoted Message : The one that GPT4all exposes on localhost

Message : Will check it out !

Message : Much thanks @91994530xxxx
Quoted Message : This is a good idea - you are referring to this - https://docs.gpt4all.io/gpt4all_chat.html

Message : We generally convert models to ONNX in our java edgechains and load it. But I didn't want students to bother with that.

Message : Did it work?
Quoted Message : Yes

Message : Yes ofcourse

Message : Unfortunately this doesn't work for me, it seems that there's no API exposed on that port. If you get it working, please let me know.
Quoted Message : This is a good idea - you are referring to this - https://docs.gpt4all.io/gpt4all_chat.html

Message : use GPT4?

Message : Yes, use it or use an open-source models
Quoted Message : use GPT4?

Message : https://arxiv.org/abs/2305.11206

LIMA, a 65B LLaMa model fine-tuned only with supervised learning on 1,000 carefully curated examples, without *any* RLHF at all, demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.

Message : Super... Is available to try?

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ~‚ÄØPalkush

Message : No
Quoted Message : Super... Is available to try?

Message : Although I agree with their hypothesis that LLM learn most of the knowledge during pretraining their results are not very conclusive. They have just tested on 200 samples

Message : Ok

Message : they use 1000 samples to train, so 20% of that to test is ok?
Quoted Message : Although I agree with their hypothesis that LLM learn most of the knowledge during pretraining their results are not very conclusive. They have just tested on 200 samples

Message : https://www.instagram.com/reel/CsOsJcRIZOC/?igshid=MmJiY2I4NDBkZg==

Message : Hollywood writers have gone on a strike, demanding a ban on using AI for writing scripts

Message : https://www.newscientist.com/article/2373382-why-use-of-ai-is-a-major-sticking-point-in-the-ongoing-writers-strike/

Message : i believe in the end we'll need even less good examples maybe even south of 100. i used to use t5 with setfit for zero shot classification and it needed less than 10 good examples to tune
Quoted Message : https://arxiv.org/abs/2305.11206\n\nLIMA, a 65B LLaMa model fine-tuned only with supervised learning on 1,000 carefully curated examples, without *any* RLHF at all, demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.

Message : It‚Äôs not about the split it‚Äôs about the diversity that could be covered by 200 samples. And they have 1300 samples in total (1k/50/250)
Quoted Message : they use 1000 samples to train, so 20% of that to test is ok?

Message : This is quite an insane video reconstruction follow up to the image reconstruction from fmri machines work
Quoted Message : mind reading https://twitter.com/_akhaliq/status/1660453496804741120?s=12

Message : https://twitter.com/jerryjliu0/status/1660683176099078144?t=suncjjVwLbYRB2-3LMJBHg&s=19

This is pretty cool for Q&A systems - chunking a policy document and extracting every section with header hierarchy for knowledge retrieval


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Although I agree with their hypothesis that LLM learn most of the knowledge during pretraining their results are not very conclusive. They have just tested on 200 samples

Message : Ok

Message : they use 1000 samples to train, so 20% of that to test is ok?
Quoted Message : Although I agree with their hypothesis that LLM learn most of the knowledge during pretraining their results are not very conclusive. They have just tested on 200 samples

Message : https://www.instagram.com/reel/CsOsJcRIZOC/?igshid=MmJiY2I4NDBkZg==

Message : Hollywood writers have gone on a strike, demanding a ban on using AI for writing scripts

Message : https://www.newscientist.com/article/2373382-why-use-of-ai-is-a-major-sticking-point-in-the-ongoing-writers-strike/

Message : i believe in the end we'll need even less good examples maybe even south of 100. i used to use t5 with setfit for zero shot classification and it needed less than 10 good examples to tune
Quoted Message : https://arxiv.org/abs/2305.11206\n\nLIMA, a 65B LLaMa model fine-tuned only with supervised learning on 1,000 carefully curated examples, without *any* RLHF at all, demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.

Message : It‚Äôs not about the split it‚Äôs about the diversity that could be covered by 200 samples. And they have 1300 samples in total (1k/50/250)
Quoted Message : they use 1000 samples to train, so 20% of that to test is ok?

Message : This is quite an insane video reconstruction follow up to the image reconstruction from fmri machines work
Quoted Message : mind reading https://twitter.com/_akhaliq/status/1660453496804741120?s=12

Message : https://twitter.com/jerryjliu0/status/1660683176099078144?t=suncjjVwLbYRB2-3LMJBHg&s=19

This is pretty cool for Q&A systems - chunking a policy document and extracting every section with header hierarchy for knowledge retrieval

Message : The webpilot plugin for chatgpt is hallucinating a lot. 
I asked it to summarise this repo for me and it responded with some completely unrelated text related to Azure.
https://github.com/microsoft/guidance

Message : https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1-trillion-parameters/

Message : What's the cheapest way to deploy open source models like Vicuna for quick inference ? Want to create a streamlit/gradio chatbot.

Message : Has anyone got a chance to try the LIMA model?

Message : Also any torrent link for the weights

Message : is there a link of independent comparison of free llms in the group somewhere. i couldnt find it

Message : not sure. but did someone share a HF space for this very same thing? Might be able to find one on twitter

Message : Can use - https://github.com/Elyah2035/llama-dl for direct download , for torrent link, can search on 4chan
Quoted Message : Also any torrent link for the weights

Message : Is anyone here doing experiments with fine tuning using a company's internal data - like internal chat, word documents, etc.

What's ur experience been - what opensource models work ok here ?

Message : The code interpreter plugin is wildly good. It doesn‚Äôt just produce code and run it, it can split the problem into steps, run multiple blocks code, inspects the output and even corrects exceptions.

Message : ‚Äé<attached: 00004992-PHOTO-2023-05-23-02-03-44.jpg>

Message : it can generate a graph ?

Message : or it gave a data and you put it in excel

Message : It can do everything, images text audio video graphs animations

Message : ‚Äé<attached: 00004996-PHOTO-2023-05-23-02-04-50.jpg>

Message : ‚Äé<attached: 00004997-PHOTO-2023-05-23-02-05-09.jpg>

Message : Used matplotlib

Message : ‚Äé<attached: 00004999-PHOTO-2023-05-23-02-07-56.jpg>

Message : It even edits files - i can see crazy shift here in analyst jobs

Message : @91748395xxxx
Quoted Message : It can do everything, images text audio video graphs animations

Message : sigh. that plugin doesnt seemed to be visible :(. there are some other 16 pages but not this

Message : ‚Äé<attached: 00005003-PHOTO-2023-05-23-02-17-36.jpg>

Message : ‚Äé<attached: 00005004-PHOTO-2023-05-23-02-17-37.jpg>

Message : ‚Äé<attached: 00005005-PHOTO-2023-05-23-02-17-38.jpg>

Message : ‚Äé<attached: 00005006-PHOTO-2023-05-23-02-17-39.jpg>

Message : ‚Äé<attached: 00005007-PHOTO-2023-05-23-02-17-40.jpg>

Message : More stats - this thing is just super üòµ

Message : ‚Äé<attached: 00005009-PHOTO-2023-05-23-02-20-13.jpg>
Quoted Message : sigh. that plugin doesnt seemed to be visible :(. there are some other 16 pages but not this

Message : ya seems like alpha release.

Message : Anyone worked on possible ways on factchecking a given article using LLM's. Is it theoretically possible to do this. if yes what could be approach

Message : Open ai has a classifier

Message : https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text

Message : But read limitations

Message : Which plugin?
Quoted Message : More stats - this thing is just super üòµ

Message : Code Interpreter
Quoted Message : Which plugin?

Message : Code interpreter is amazing! It's very close to talking to an analyst...

Message : PSA: this is not a plugin - you can‚Äôt write a plguin that replicates the behaviour of code interpreter
Quoted Message : Which plugin?

Message : Decomposing this a bit: 

Code Interpreter is GPT4 which is RLHF'd for certain behaviours e.g. use code to answer questions. This is a meaningful reliability upgrade e.g. code actually does what you ask it to.

You can add a Python REPL to GPT4 API and get very good results too ‚Äî better than anything FOSS.
Quoted Message : PSA: this is not a plugin - you can‚Äôt write a plguin that replicates the behaviour of code interpreter

Message : Got it! Is it based on codex model?
Quoted Message : PSA: this is not a plugin - you can‚Äôt write a plguin that replicates the behaviour of code interpreter

Message : GPT3.5 and GPT4 are both based on Codex. 

Since Code Interpreter is a light fork of GPT4 (confirmed by an engineer on the Plugins team) ‚Äî yes, it's a descendant of Codex
Quoted Message : Got it! Is it based on codex model?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Open ai has a classifier

Message : https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text

Message : But read limitations

Message : Which plugin?
Quoted Message : More stats - this thing is just super üòµ

Message : Code Interpreter
Quoted Message : Which plugin?

Message : Code interpreter is amazing! It's very close to talking to an analyst...

Message : PSA: this is not a plugin - you can‚Äôt write a plguin that replicates the behaviour of code interpreter
Quoted Message : Which plugin?

Message : Decomposing this a bit: 

Code Interpreter is GPT4 which is RLHF'd for certain behaviours e.g. use code to answer questions. This is a meaningful reliability upgrade e.g. code actually does what you ask it to.

You can add a Python REPL to GPT4 API and get very good results too ‚Äî better than anything FOSS.
Quoted Message : PSA: this is not a plugin - you can‚Äôt write a plguin that replicates the behaviour of code interpreter

Message : Got it! Is it based on codex model?
Quoted Message : PSA: this is not a plugin - you can‚Äôt write a plguin that replicates the behaviour of code interpreter

Message : GPT3.5 and GPT4 are both based on Codex. 

Since Code Interpreter is a light fork of GPT4 (confirmed by an engineer on the Plugins team) ‚Äî yes, it's a descendant of Codex
Quoted Message : Got it! Is it based on codex model?

Message : https://openai.com/blog/governance-of-superintelligence

Message : Superintelligence in 10 years ?

Message : Yup, Its not just gpt4 + repl. There are other intricacies here. Like it has to inspect the contnents of a large file, without running out of context length, and has to carry out multiple steps without going into an auto gpt loop of doom. It will also ask follow up questions before writing code sometimes
Quoted Message : Decomposing this a bit: \n\nCode Interpreter is GPT4 which is RLHF'd for certain behaviours e.g. use code to answer questions. This is a meaningful reliability upgrade e.g. code actually does what you ask it to. \n\nYou can add a Python REPL to GPT4 API and get very good results too ‚Äî better than anything FOSS.

Message : The reasoning shown by Code Interpreter is too good.
For ex the analysis on ‚Äúfunniest authors‚Äù takes into account what can be possible,makes some assumptions,explains the limitations and then proceeds to do the further analysis.ü§Ø
Quoted Message : Yup, Its not just gpt4 + repl. There are other intricacies here. Like it has to inspect the contnents of a large file, without running out of context length, and has to carry out multiple steps without going into an auto gpt loop of doom. It will also ask follow up questions before writing code sometimes

Message : How do these interpreters work?

Message : Is it trained on a data set of code?

Message : Trained by humans. To do specific tasks and create paths to solve problems by writing code and evaluating the outputs
Quoted Message : Is it trained on a data set of code?

Message : The trajectories are designed by humans and rlhf‚Äôd

Message : But the code is run on an actual interpreter right?

Message : Yes
Quoted Message : But the code is run on an actual interpreter right?

Message : It doesn‚Äôt have gpus though :D I told it to do vector search over the chat but it hung up trying to vectorize the data

Message : Doesn't seem to have any direct context length improvements over gpt4 afaict...
Quoted Message : The reasoning shown by Code Interpreter is too good.\nFor ex the analysis on ‚Äúfunniest authors‚Äù takes into account what can be possible,makes some assumptions,explains the limitations and then proceeds to do the further analysis.ü§Ø

Message : Being able to load files into py memory and dealing with it via code is what creates the illusion

Message : Doesn‚Äôt need context length improvement for reasoning does it ? 

You can setup a Python agent with LangChain ,load your csv files in a df ,and it still won‚Äôt be able to give you the same level of reasoning which the code interpreter is displaying
Quoted Message : Doesn't seem to have any direct context length improvements over gpt4 afaict...

Message : Sorry was responding to this...
Quoted Message : Yup, Its not just gpt4 + repl. There are other intricacies here. Like it has to inspect the contnents of a large file, without running out of context length, and has to carry out multiple steps without going into an auto gpt loop of doom. It will also ask follow up questions before writing code sometimes

Message : I‚Äôve tried this with 3.5 and it was nowhere near the reasoning ability which Code Interpreter is displaying 

Don‚Äôt know how the same setup will work with GPT-4 though
Quoted Message : Doesn‚Äôt need context length improvement for reasoning does it ? \n\nYou can setup a Python agent with LangChain ,load your csv files in a df ,and it still won‚Äôt be able to give you the same level of reasoning which the code interpreter is displaying

Message : This is an experiment worth trying out with gpt4
Quoted Message : I‚Äôve tried this with 3.5 and it was nowhere near the reasoning ability which Code Interpreter is displaying \n\nDon‚Äôt know how the same setup will work with GPT-4 though

Message : Yes, my point was that it knows implicitly that this context length exists, and writes code which respects this limit
Quoted Message : Sorry was responding to this...

Message : Eg see that it knows to sample 10 lines only
Quoted Message :  2023_05_23_3EB071873B7F0E91C732FE.jpeg

Message : Very much skeptical it will have comparable performance, even after tons of prompt engg
Quoted Message : This is an experiment worth trying out with gpt4

Message : Ummm... gpt4 might just be able to pull this off...    It's not bad at coding.  Next time I have a coding task I will test interpreter vs the base model on it.
Quoted Message : Very much skeptical it will have comparable performance, even after tons of prompt engg

Message : Thought this might be interesting to you 
https://python.langchain.com/en/latest/modules/agents/tools/examples/python.html
Quoted Message : Ummm... gpt4 might just be able to pull this off...    It's not bad at coding.  Next time I have a coding task I will test interpreter vs the base model on it.

Message : This kind of an attack is unlikely to do well.   The magic of code interpreter comes from maintaining the pandas data frame between subsequent calls.  Something like rpyc would be what I would go for.
Quoted Message : Thought this might be interesting to you \nhttps://python.langchain.com/en/latest/modules/agents/tools/examples/python.html

Message : Its not just dataframes from what I hear. It does images videos etc too
Quoted Message : This kind of an attack is unlikely to do well.   The magic of code interpreter comes from maintaining the pandas data frame between subsequent calls.  Something like rpyc would be what I would go for.

Message : You can also try this ,
https://github.com/gventuri/pandas-ai

Load data in data frame and ask questions over it

I haven‚Äôt tried it yet ,just one of many things to be tried still.
Quoted Message : This kind of an attack is unlikely to do well.   The magic of code interpreter comes from maintaining the pandas data frame between subsequent calls.  Something like rpyc would be what I would go for.

Message : All via keeping the python state maintained between calls
Quoted Message : Its not just dataframes from what I hear. It does images videos etc too

Message : Interesting though we need the exact reverse.
Quoted Message : You can also try this ,\nhttps://github.com/gventuri/pandas-ai\n\nLoad data in data frame and ask questions over it \n\nI haven‚Äôt tried it yet ,just one of many things to be tried still.

Message : An open source code interpreter could actually be quite useful.  Openai doesn't allow their interpreter to make web calls.  Even some ability to download small model weights would dramatically improve usability.

Message : For instance say upload csv of customer queries and have it clustered via something in nltk.

Message : Tried something like that a few weeks back and it tried to do some downloads and failed.

Message : Not FOSS, but since compute and network are needed: Replit has entered this chat

cc @91997020xxxx Anshul from Replit might find this interesting!
Quoted Message : An open source code interpreter could actually be quite useful.  Openai doesn't allow their interpreter to make web calls.  Even some ability to download small model weights would dramatically improve usability.

Message : What was the workflow you‚Äôd setup for this use case ?

I‚Äôm implementing a very similar usecase for NPS and feedback analysis ,but heavily using prompt engineering for it + embeddings
Quoted Message : Tried something like that a few weeks back and it tried to do some downloads and failed.

Message : I just uploaded a csv to code interpreter, asked it for 5 ways of doing a clustering analysis on it and then asked it to execute no 3.

Message : For stuff that fits on a pandas data frame this would be my preferred workflow...  It is quite smart about looking at the first few rows of data and coming up with a good plan

Message : I don‚Äôt think it maintains python state, does it?
Quoted Message : All via keeping the python state maintained between calls

Message : Maybe for a single generation it does

Message : I am almost sure it does.  Will run a test and get definitive proof.

Message : Python agent in LangChain should be able to download required libs and dependencies when you just give an open ended task like this 

Not sure how Code Interpreter handles this
Quoted Message : Tried something like that a few weeks back and it tried to do some downloads and failed.

Message : It says no
Quoted Message : Python agent in LangChain should be able to download required libs and dependencies when you just give an open ended task like this \n\nNot sure how Code Interpreter handles this

Message : üòÇü§°


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Not FOSS, but since compute and network are needed: Replit has entered this chat

cc @91997020xxxx Anshul from Replit might find this interesting!
Quoted Message : An open source code interpreter could actually be quite useful.  Openai doesn't allow their interpreter to make web calls.  Even some ability to download small model weights would dramatically improve usability.

Message : What was the workflow you‚Äôd setup for this use case ?

I‚Äôm implementing a very similar usecase for NPS and feedback analysis ,but heavily using prompt engineering for it + embeddings
Quoted Message : Tried something like that a few weeks back and it tried to do some downloads and failed.

Message : I just uploaded a csv to code interpreter, asked it for 5 ways of doing a clustering analysis on it and then asked it to execute no 3.

Message : For stuff that fits on a pandas data frame this would be my preferred workflow...  It is quite smart about looking at the first few rows of data and coming up with a good plan

Message : I don‚Äôt think it maintains python state, does it?
Quoted Message : All via keeping the python state maintained between calls

Message : Maybe for a single generation it does

Message : I am almost sure it does.  Will run a test and get definitive proof.

Message : Python agent in LangChain should be able to download required libs and dependencies when you just give an open ended task like this 

Not sure how Code Interpreter handles this
Quoted Message : Tried something like that a few weeks back and it tried to do some downloads and failed.

Message : It says no
Quoted Message : Python agent in LangChain should be able to download required libs and dependencies when you just give an open ended task like this \n\nNot sure how Code Interpreter handles this

Message : üòÇü§°

Message : ‚Äé<attached: 00005063-PHOTO-2023-05-23-09-37-35.jpg>

Message : ‚Äé<attached: 00005064-PHOTO-2023-05-23-09-36-31.jpg>

Message : Confirmed.  See the use of the data dataframe between subsequent calls.

Message : Lovely

Message : Pyhton‚Äôs repr() is ‚ù§Ô∏è

Message : Interesting idea - can you give code interpreter the .pyi stub file for a new library/ private code and tell it to use the library? üò±

Message : ‚Äé<attached: 00005070-PHOTO-2023-05-23-09-49-06.jpg>

Message : Must have the API üò≠
Quoted Message :  2023_05_23_3EB0C5366E42453BCBF521.jpeg

Message : Code interpreter is so powerful.  An unrestricted version of this would be awesome!  If I had any free time...

Message : Open AI blog post by Sam Altman, Greg Brockman & Ilya Sutskever on how to regulate future ai systems far more capable than ones that exist today 

https://openai.com/blog/governance-of-superintelligence

Message : Can it also process sql dumps?
Quoted Message :  2023_05_23_3A0CBD3C3001BF320CA7.jpeg

Message : I tried giving it a heavily nested json - doesn‚Äôt do well if you don‚Äôt give it a schema. But i guess with sql it can inspect schema
Quoted Message : Can it also process sql dumps?

Message : With openAPI schema, it might do that
Quoted Message : I tried giving it a heavily nested json - doesn‚Äôt do well if you don‚Äôt give it a schema. But i guess with sql it can inspect schema

Message : https://twitter.com/ylecun/status/1660732998155640833?s=46&t=icC0fizZK8E3ONsDVuGFWA

Meta strikes again in open sourcing AI

Apparently 1k languages available as STT and TTS via one model which has half the WER as Whisper

Message : I guess this would include many Indian languages

Message : I‚Äôm doubting this just based on reading their training methodology 

‚ÄúAs part of this project, we created a dataset of readings of the New Testament in over 1,100 languages, which provided on average 32 hours of data per language.

By considering unlabeled recordings of various other Christian religious readings, we increased the number of languages available to over 4,000. ‚Äú
Quoted Message : I guess this would include many Indian languages

Message : https://arxiv.org/abs/2305.13048

Anyone played with RNNs as alternatives to transformers for language models

Message : More accessible blog: 
https://huggingface.co/blog/rwkv
Quoted Message : https://arxiv.org/abs/2305.13048\n\nAnyone played with RNNs as alternatives to transformers for language models

Message : And a HF space: 
https://huggingface.co/spaces/Hazzzardous/RWKV-Instruct

Message : Makes me hopeful that open source community can drive things forward even if google etc stop publishing
Quoted Message : https://arxiv.org/abs/2305.13048\n\nAnyone played with RNNs as alternatives to transformers for language models

Message : Could not understand it fully but it looks like context windows of 100k-500k could become normal if this works as the inference cost grows linearly

Message : Hiii everyone, 

Has anyone come across some research work that talks about dataset size , complexity and coverage based on the complexity of task at hand ?

Message : Specifically for generative ai tasks
Quoted Message : Hiii everyone, \n\nHas anyone come across some research work that talks about dataset size , complexity and coverage based on the complexity of task at hand ?

Message : https://twitter.com/togethercompute/status/1660767722073128960?s=46

Vicuna on iphone - just tried the app, slower response than even gpt4 but a peak into what apple probably would be building

Message : Not sure if others have seen this, but I found this interactive categorization of the generative AI startup landscape useful. https://app.dealroom.co/lists/33530

Message : An interesting thread discussing potential limitations of RWKV and history of large scale RNNs https://twitter.com/smerity/status/1660786104377958400?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
Quoted Message : More accessible blog: \nhttps://huggingface.co/blog/rwkv

Message : I have this app but I don‚Äôt open it anymore . It makes my phone heat up a lot and it becomes unstable
Quoted Message : https://twitter.com/togethercompute/status/1660767722073128960?s=46\n\nVicuna on iphone - just tried the app, slower response than even gpt4 but a peak into what apple probably would be building

Message : But a year ago tbis would have been total science fiction

Message : Yeah one shouldn‚Äôt jump on this kind of researchy stuff. Transformers have a huge ecosystem around them that‚Äôs growing every day. It will take a lot of time to replicate that.
Quoted Message : An interesting thread discussing potential limitations of RWKV and history of large scale RNNs https://twitter.com/smerity/status/1660786104377958400?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ

Message : RNNs don‚Äôt need to replace transformers..Ability to have ready made embeddings is useful in at least a few niche applications.
Quoted Message : Yeah one shouldn‚Äôt jump on this kind of researchy stuff. Transformers have a huge ecosystem around them that‚Äôs growing every day. It will take a lot of time to replicate that.

Message : + faster inference particularly on long sequences

Message : Not a comparison but a list 
https://github.com/eugeneyan/open-llms
Quoted Message : is there a link of independent comparison of free llms in the group somewhere. i couldnt find it

Message : Nfx.com has an exportable csv
Quoted Message : Not sure if others have seen this, but I found this interactive categorization of the generative AI startup landscape useful. https://app.dealroom.co/lists/33530

Message : Thanks. I did see this. Only if there was objective comparison with these and gpt 4 would have been really helpful.
Quoted Message : Not a comparison but a list \nhttps://github.com/eugeneyan/open-llms

Message : Hey everyone! I've been really enjoying our discussions on LLMs here. We won a few hackathons using LLM prompting. I've compiled some notes that cover various concepts and recent advancements. I thought they might be useful to some of you. You can find it here: https://nishnik.notion.site/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

Happy to talk more about it!

Message : Folks QQ. How do you determine if a text is interrogative?

Message : I.e. Classify if it's a question or not

Message : What level did you reach here: https://gandalf.lakera.ai/

Message : cc @91974101xxxx you were interested in prompt security
Quoted Message : What level did you reach here: https://gandalf.lakera.ai/

Message : Wow. I love this game
Quoted Message : What level did you reach here: https://gandalf.lakera.ai/


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : + faster inference particularly on long sequences

Message : Not a comparison but a list 
https://github.com/eugeneyan/open-llms
Quoted Message : is there a link of independent comparison of free llms in the group somewhere. i couldnt find it

Message : Nfx.com has an exportable csv
Quoted Message : Not sure if others have seen this, but I found this interactive categorization of the generative AI startup landscape useful. https://app.dealroom.co/lists/33530

Message : Thanks. I did see this. Only if there was objective comparison with these and gpt 4 would have been really helpful.
Quoted Message : Not a comparison but a list \nhttps://github.com/eugeneyan/open-llms

Message : Hey everyone! I've been really enjoying our discussions on LLMs here. We won a few hackathons using LLM prompting. I've compiled some notes that cover various concepts and recent advancements. I thought they might be useful to some of you. You can find it here: https://nishnik.notion.site/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

Happy to talk more about it!

Message : Folks QQ. How do you determine if a text is interrogative?

Message : I.e. Classify if it's a question or not

Message : What level did you reach here: https://gandalf.lakera.ai/

Message : cc @91974101xxxx you were interested in prompt security
Quoted Message : What level did you reach here: https://gandalf.lakera.ai/

Message : Wow. I love this game
Quoted Message : What level did you reach here: https://gandalf.lakera.ai/

Message : Stuck at 4

Message : Good game. I am stuck at level 8

Message : There are only 8 levels chad
Quoted Message : Good game. I am stuck at level 8

Message : There's a bonus level which comes after level 7

Message : Aaah, I interpreted that to mean that you've cleared level 8 and stuck at it. My bad. 

Off by 1 errors still happen ü•≤
Quoted Message : There's a bonus level which comes after level 7

Message : ‚Äé<attached: 00005116-PHOTO-2023-05-23-15-34-19.jpg>

Message : Damn. Well done

Message : Love how creative this game is. Would also love it if people share some creative answers here, especially for the higher levels
Quoted Message : What level did you reach here: https://gandalf.lakera.ai/

Message : Asking the etymology too me to level 7.
Quoted Message : Love how creative this game is. Would also love it if people share some creative answers here, especially for the higher levels

Message : Actually all 8 levels worked
Quoted Message : Asking the etymology too me to level 7.

Message : Fun thing, just started. First two levels are straightforward üòÑ
Quoted Message : What level did you reach here: https://gandalf.lakera.ai/

Message : Cleared until third in the first 15 mins
Quoted Message : Fun thing, just started. First two levels are straightforward üòÑ

Message : 4th is tough :/

Message : Same üòÇ
Quoted Message : 4th is tough :/

Message : 7th was harder than 8th for me.

Message : Antler airtable https://airtable.com/shrBeWpMlxf3e14E8/tblS4TkbJbm0cqT0o
Quoted Message : Not sure if others have seen this, but I found this interactive categorization of the generative AI startup landscape useful. https://app.dealroom.co/lists/33530

Message : ‚Äé<attached: 00005127-PHOTO-2023-05-23-18-05-46.jpg>
Quoted Message : Hiii everyone, \n\nHas anyone come across some research work that talks about dataset size , complexity and coverage based on the complexity of task at hand ?

Message : https://web.stanford.edu/class/cs25/

Message : PSA: Drop a line with the link, don't just share the link. That increases the chances that people interested in it will get a sense of what it is without clicking through üôè

Message : Found this interesting map of infra companies for Gen AI - https://medium.com/cowboy-ventures/the-new-infra-stack-for-generative-ai-9db8f294dc3f

Was pleasantly surprised to see Portkey (@91989995xxxx) featured here :)

Message : Stanford course on transformers .

Some course videos are available on YouTube :

https://youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM
Quoted Message : https://web.stanford.edu/class/cs25/

Message : Are there more Generative AI companies than devs who can RLHF a Llama model?

Message : @91773788xxxx any comments about this space ? 
Surprised to see not enough MLops jumping this bandwagon .

First time posting here , not sure if I‚Äôm asking appropriate questions
Quoted Message :  2023_05_23_3A31E59D16D45EEDD842.jpeg

Message : Has anybody here tried the ChatGPT iOS app in india?

https://openai.com/blog/introducing-the-chatgpt-app-for-ios

Thoughts/feedback ?
How does the voice interaction feature work in day to day use ?

For me, am unable to install it :/ (iOS16.5)

Message : From DMs: Are there more Generative AI companies than dev who know what RLHF stands for? ü§£
Quoted Message : Are there more Generative AI companies than devs who can RLHF a Llama model?

Message : Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?

Message : AWS Sagemaker, Replicate (limited but dead cheap)
Quoted Message : Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?

Message : I think even in this group a lot of us know what it is and how it works in theory but doing RLHF *well* in practice is what will ensure GPT4 like performance & is OpenAI's sweet spot.

Open-source RLHF datasets are beginning to become available though, I think
Quoted Message : From DMs: Are there more Generative AI companies than dev who know what RLHF stands for? ü§£

Message : yes, you need to -
1.  create another icloud account
2.  set region to US (involves verifying a US address and  number https://www.receive-sms-online.info/)
3.  logout of your current account in the appstore app
4. login with the other acccount
Quoted Message : Has anybody here tried the ChatGPT iOS app in india?\n\nhttps://openai.com/blog/introducing-the-chatgpt-app-for-ios\n\nThoughts/feedback ?\nHow does the voice interaction feature work in day to day use ?\n\nFor me, am unable to install it :/ (iOS16.5)

Message : The app is pretty slick, and whisper + gpt4 is just too nice to use

Message : I don't think this exists, whatever exists is probably ~25% of what we want here, and is probably the biggest opportunity for infra startups right now
Quoted Message : Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?

Message : https://www.youtube.com/watch?v=ut5kp56wW_4

Paper summary!
Quoted Message : Thought this might be interesting to you \narxiv-vanity.com/papers/2305.10601

Message : doesn't mosaicML do this? I don't think its multimodal but it does help in deployment optimization https://www.mosaicml.com/
Quoted Message : Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?

Message : https://twitter.com/JosephJacks_/status/1660747216561254400?s=20üòÇ

Message : There are bunch of dataset companies from the last ML bull run e.g. Scale.ai which are now moving towards this in some way or the other. With datasets like PILE and more coming along, I suspect for text-LLMs FOSS Datasets will win. 

Specially for instruction tuning and RLAIF e.g. Vicuna, Alpaca, are all RLAIF models from FOSS datasets.

This does leave open the case of models trained on open licenses, there too ‚Äî domain specific datasets have begun to see industry adoption e.g. Replit chose to train their base model on Stack Dedup (v1.2?) https://huggingface.co/replit/replit-code-v1-3b

I'm generally net short on commercial, non-FOSS LLM Ops tools seeing bottom up adoption with Generative AI apps at this part of the hypecycle. The FOSS quality is simply too good to be competitive.

Of course, as the cycle fades, lot of the margins accrue to enterprise software
Quoted Message : Hiii everyone, \n\nHas anyone come across some research work that talks about dataset size , complexity and coverage based on the complexity of task at hand ?

Message : Anyone can explain to me how the problem of long sequences in transformers was solved?

I mean at one time we had these specific datasets for this tasks and ppl were trying to come up with solutions like BigBird, Longformer, etc. Which were better but not cutting it.

Then how did we suddenly move to 32 or 100k context? What innovation had happened?

Message : cc @91990072xxxx is perhaps the best person to answer this. But more generally, this is still an unsolved problem. 

Most long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2.

The other is the ability to scale up innovations like:

1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) ‚Äî introduced in 2020, explained how attention could work with RoBERTa
2. Flash Attention (https://github.com/HazyResearch/flash-attention) ‚Äî which demonstrated that you could do memory efficient and exact attention
3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) ‚Äî which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.
Quoted Message : Anyone can explain to me how the problem of long sequences in transformers was solved?\n\nI mean at one time we had these specific datasets for this tasks and ppl were trying to come up with solutions like BigBird, Longformer, etc. Which were better but not cutting it.\n\nThen how did we suddenly move to 32 or 100k context? What innovation had happened?

Message : Would multi query attention be also considered something that helped here
Quoted Message : cc @9199xxxxxxxx is perhaps the best person to answer this. But more generally, this is still an unsolved problem. \n\nMost long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2. \n\nThe other is the ability to scale up innovations like:\n\n1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) ‚Äî introduced in 2020, explained how attention could work with RoBERTa\n2. Flash Attention (https://github.com/HazyResearch/flash-attention) ‚Äî which demonstrated that you could do memory efficient and exact attention\n3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) ‚Äî which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.

Message : Thanks for your comprehensive answer.

but you say Anthropic is constrained to 2k tokens. Didn't they just launch 100k Claude?
Quoted Message : cc @9199xxxxxxxx is perhaps the best person to answer this. But more generally, this is still an unsolved problem. \n\nMost long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2. \n\nThe other is the ability to scale up innovations like:\n\n1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) ‚Äî introduced in 2020, explained how attention could work with RoBERTa\n2. Flash Attention (https://github.com/HazyResearch/flash-attention) ‚Äî which demonstrated that you could do memory efficient and exact attention\n3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) ‚Äî which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.

Message : I think he means response tokens
Quoted Message : Thanks for your comprehensive answer.\n\nbut you say Anthropic is constrained to 2k tokens. Didn't they just launch 100k Claude?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I don't think this exists, whatever exists is probably ~25% of what we want here, and is probably the biggest opportunity for infra startups right now
Quoted Message : Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?

Message : https://www.youtube.com/watch?v=ut5kp56wW_4

Paper summary!
Quoted Message : Thought this might be interesting to you \narxiv-vanity.com/papers/2305.10601

Message : doesn't mosaicML do this? I don't think its multimodal but it does help in deployment optimization https://www.mosaicml.com/
Quoted Message : Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?

Message : https://twitter.com/JosephJacks_/status/1660747216561254400?s=20üòÇ

Message : There are bunch of dataset companies from the last ML bull run e.g. Scale.ai which are now moving towards this in some way or the other. With datasets like PILE and more coming along, I suspect for text-LLMs FOSS Datasets will win. 

Specially for instruction tuning and RLAIF e.g. Vicuna, Alpaca, are all RLAIF models from FOSS datasets.

This does leave open the case of models trained on open licenses, there too ‚Äî domain specific datasets have begun to see industry adoption e.g. Replit chose to train their base model on Stack Dedup (v1.2?) https://huggingface.co/replit/replit-code-v1-3b

I'm generally net short on commercial, non-FOSS LLM Ops tools seeing bottom up adoption with Generative AI apps at this part of the hypecycle. The FOSS quality is simply too good to be competitive.

Of course, as the cycle fades, lot of the margins accrue to enterprise software
Quoted Message : Hiii everyone, \n\nHas anyone come across some research work that talks about dataset size , complexity and coverage based on the complexity of task at hand ?

Message : Anyone can explain to me how the problem of long sequences in transformers was solved?

I mean at one time we had these specific datasets for this tasks and ppl were trying to come up with solutions like BigBird, Longformer, etc. Which were better but not cutting it.

Then how did we suddenly move to 32 or 100k context? What innovation had happened?

Message : cc @91990072xxxx is perhaps the best person to answer this. But more generally, this is still an unsolved problem. 

Most long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2.

The other is the ability to scale up innovations like:

1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) ‚Äî introduced in 2020, explained how attention could work with RoBERTa
2. Flash Attention (https://github.com/HazyResearch/flash-attention) ‚Äî which demonstrated that you could do memory efficient and exact attention
3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) ‚Äî which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.
Quoted Message : Anyone can explain to me how the problem of long sequences in transformers was solved?\n\nI mean at one time we had these specific datasets for this tasks and ppl were trying to come up with solutions like BigBird, Longformer, etc. Which were better but not cutting it.\n\nThen how did we suddenly move to 32 or 100k context? What innovation had happened?

Message : Would multi query attention be also considered something that helped here
Quoted Message : cc @9199xxxxxxxx is perhaps the best person to answer this. But more generally, this is still an unsolved problem. \n\nMost long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2. \n\nThe other is the ability to scale up innovations like:\n\n1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) ‚Äî introduced in 2020, explained how attention could work with RoBERTa\n2. Flash Attention (https://github.com/HazyResearch/flash-attention) ‚Äî which demonstrated that you could do memory efficient and exact attention\n3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) ‚Äî which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.

Message : Thanks for your comprehensive answer.

but you say Anthropic is constrained to 2k tokens. Didn't they just launch 100k Claude?
Quoted Message : cc @9199xxxxxxxx is perhaps the best person to answer this. But more generally, this is still an unsolved problem. \n\nMost long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2. \n\nThe other is the ability to scale up innovations like:\n\n1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) ‚Äî introduced in 2020, explained how attention could work with RoBERTa\n2. Flash Attention (https://github.com/HazyResearch/flash-attention) ‚Äî which demonstrated that you could do memory efficient and exact attention\n3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) ‚Äî which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.

Message : I think he means response tokens
Quoted Message : Thanks for your comprehensive answer.\n\nbut you say Anthropic is constrained to 2k tokens. Didn't they just launch 100k Claude?

Message : Got you
Quoted Message : I think he means response tokens

Message : Yes, this is what I meant!
Quoted Message : I think he means response tokens

Message : It's same with gpt4. Even though you can set theoretically 5k response tokens it hangs

Message : Add ALiBi as well?

https://arxiv.org/abs/2108.12409
Quoted Message : cc @9199xxxxxxxx is perhaps the best person to answer this. But more generally, this is still an unsolved problem. \n\nMost long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2. \n\nThe other is the ability to scale up innovations like:\n\n1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) ‚Äî introduced in 2020, explained how attention could work with RoBERTa\n2. Flash Attention (https://github.com/HazyResearch/flash-attention) ‚Äî which demonstrated that you could do memory efficient and exact attention\n3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) ‚Äî which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.

Message : Mpt models are based on ALiBi and flash attention.

Message : Yeah, ALiBi counts!
Quoted Message : Add ALiBi as well?\n\nhttps://arxiv.org/abs/2108.12409

Message : I hit the limit of my output/response tokens too üòÇ

Message : The way Mosaic ML approached this with their MPT storywriter model (https://huggingface.co/mosaicml/mpt-7b-storywriter) was that they just finetuned base model with 4096 sequence length on books with longer sequence length. The input sequence to transformer models is of dimension : L * d where L is our sequence length and d is embedding size.So with existing base models, we can train derived models with longer sequence lengths; just doing so would cause us having large Q, K and V matrices.

Message : https://twitter.com/ofirpress/status/1657040700062441475?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Author of Alibi is stating finetuning is the way to go as 99% of documents in PILE or similar datasets are less than 500 tokens long.

Message : QQs: a) this 1 token = three fourth of a word / 4 or 5 characters, right for all LLMs?  b) what's the "so what" of this 500 token fact and what are the top implications does it have on use cases for the end user?
Quoted Message : https://twitter.com/ofirpress/status/1657040700062441475?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Author of Alibi is stating finetuning is the way to go as 99% of documents in PILE or similar datasets are less than 500 tokens long.

Message : A) yes..that‚Äôs 1token
Quoted Message : QQs: a) this 1 token = three fourth of a word / 4 or 5 characters, right for all LLMs?  b) what's the \"so what\" of this 500 token fact and what are the top implications does it have on use cases for the end user?

Message : B) because most of the documents are less than 500 tokens. For a base model with 2k context length, most of the time we will be fitting 4 documents together for a single forward pass. If we increase the sequence length, we would fit more documents for a single forward pass. But tokens in document 1 won‚Äôt be helping us in predicting tokens in document 2. Hence, he is saying it doesn‚Äôt make much sense to increase context length to 100k while training base models.

Message : ICYMI: Community's Generative AI May Meetups: 

Open for all:
https://hasgeek.com/generativeAI/may-meetup/

Women in AI:
https://hasgeek.com/generativeAI/women-in-ai-meetup/

Message : There's also questions around middle context accuracy in Anthropic's particular case:

https://twitter.com/dylan522p/status/1658147304094973957?t=NsYH5b0M4qYo3Rr6DTQWqA&s=19
Quoted Message : Anyone can explain to me how the problem of long sequences in transformers was solved?\n\nI mean at one time we had these specific datasets for this tasks and ppl were trying to come up with solutions like BigBird, Longformer, etc. Which were better but not cutting it.\n\nThen how did we suddenly move to 32 or 100k context? What innovation had happened?

Message : Prompting this gold of a meme by Karpathy xD

https://twitter.com/karpathy/status/1658161721251602432?t=Vr4eRdzjkp3FK6VKEfcoCA&s=19

Message : Probably using heuristics
Quoted Message : There's also questions around middle context accuracy in Anthropic's particular case:\n\nhttps://twitter.com/dylan522p/status/1658147304094973957?t=NsYH5b0M4qYo3Rr6DTQWqA&s=19

Message : Helpful. Thank you Sachin
Quoted Message : B) because most of the documents are less than 500 tokens. For a base model with 2k context length, most of the time we will be fitting 4 documents together for a single forward pass. If we increase the sequence length, we would fit more documents for a single forward pass. But tokens in document 1 won‚Äôt be helping us in predicting tokens in document 2. Hence, he is saying it doesn‚Äôt make much sense to increase context length to 100k while training base models.

Message : Anything in mumbai?
Quoted Message : ICYMI: Community's Generative AI May Meetups: \n\nOpen for all: \nhttps://hasgeek.com/generativeAI/may-meetup/\n\nWomen in AI: \nhttps://hasgeek.com/generativeAI/women-in-ai-meetup/

Message : Thanks sir üéÖ
Quoted Message : There are bunch of dataset companies from the last ML bull run e.g. Scale.ai which are now moving towards this in some way or the other. With datasets like PILE and more coming along, I suspect for text-LLMs FOSS Datasets will win. \n\nSpecially for instruction tuning and RLAIF e.g. Vicuna, Alpaca, are all RLAIF models from FOSS datasets. \n\nThis does leave open the case of models trained on open licenses, there too ‚Äî domain specific datasets have begun to see industry adoption e.g. Replit chose to train their base model on Stack Dedup (v1.2?) https://huggingface.co/replit/replit-code-v1-3b\n\nI'm generally net short on commercial, non-FOSS LLM Ops tools seeing bottom up adoption with Generative AI apps at this part of the hypecycle. The FOSS quality is simply too good to be competitive. \n\nOf course, as the cycle fades, lot of the margins accrue to enterprise software

Message : this was pretty fun lol.
feel like a pro level-4 gaslighter now
Quoted Message : What level did you reach here: https://gandalf.lakera.ai/

Message : The Bill & Melinda Gates Foundation today launched a new Grand Challenges (GC) request for proposals, "Catalyzing Equitable Artificial Intelligence (AI) Use".

Level: Up to $100,000 USD/project
Duration: 3 months
Application deadline: 5 June 2023, 11:30 AM Pacific Time

You can find additional information about the call for proposals at this link. https://lnkd.in/gZZH2SYb

Harnessing the potential of AI can improve the lives and wellbeing of vulnerable communities everywhere including those of women and children. As AI technology continues to swiftly evolve and advance, the global community must move with urgency to ensure low- and middle-income countries (LMICs) are included in the co-creation process.

Message : Would someone in the group have interest in the above.  Currently, I work at the intersection of technology, social good and policy and want to partner up with someone to explore the above question. Please DM me if above would be interesting.

Message : In June, yes
Quoted Message : Anything in mumbai?

Message : For anyone who has implemented txt2sql ,without fine tuning 

How do you pass db schema as context without stuffing it in prompt every time?

One way I‚Äôve seen is Llama Index using vector indexes created on db schema

But can you do semantic search over schemas stored in vector dbs and find out table relationships like which is the primary key for 2 tables ?

Message : Cc @1217305xxxx since we discussed this yesterday
Quoted Message : For anyone who has implemented txt2sql ,without fine tuning \n\nHow do you pass db schema as context without stuffing it in prompt every time?\n\nOne way I‚Äôve seen is Llama Index using vector indexes created on db schema\n\nBut can you do semantic search over schemas stored in vector dbs and find out table relationships like which is the primary key for 2 tables ?

Message : hi yes, we have used it without fine-tuning but we are yet to run into the prompt size limit prob. I might be able to add more on this in 2 weeks. But fundamentally we want to use something like Llama index to index, save and query the context in/ from embedding space. So to answer your question, yes we can do semantic search for the mentioned use-case.
Quoted Message : For anyone who has implemented txt2sql ,without fine tuning \n\nHow do you pass db schema as context without stuffing it in prompt every time?\n\nOne way I‚Äôve seen is Llama Index using vector indexes created on db schema\n\nBut can you do semantic search over schemas stored in vector dbs and find out table relationships like which is the primary key for 2 tables ?

Message : So I can just embed the db schemas and at time of querying it will fetch best matching schema for the query and use it in prompt 


But what I‚Äôm not able to wrap my head around is this scenario
I embed schema for 2 tables let‚Äôs say customers,orders with customer_id as unique key along with 50 other tables

When I run a query like find customers with highest number of orders,it should return a query joining customers table with orders


What I don‚Äôt get is
similarity search will show best semantically matching schema for the query then how can it show relation between tables ?
Quoted Message : hi yes, we have used it without fine-tuning but we are yet to run into the prompt size limit prob. I might be able to add more on this in 2 weeks. But fundamentally we want to use something like Llama index to index, save and query the context in/ from embedding space. So to answer your question, yes we can do semantic search for the mentioned use-case.

Message : @91961943xxxx Why are you doing semantic search over schemas? Do you take only top 1 retrieved DB schema in the prompt for query gen?

Message : Yes. The answer lies in how your are creating the text corpus and how you are indexing them. Point to remember that these models are probabilistic models and they try to predict the next token by analysing patterns in Corpus. Optimizing the accuracy of such mismatches in your particular usecases is also where the startups like us add value.
Quoted Message : So I can just embed the db schemas and at time of querying it will fetch best matching schema for the query and use it in prompt \n\n\nBut what I‚Äôm not able to wrap my head around is this scenario \nI embed schema for 2 tables let‚Äôs say customers,orders with customer_id as unique key along with 50 other tables \n\nWhen I run a query like find customers with highest number of orders,it should return a query joining customers table with orders\n\n\nWhat I don‚Äôt get is \nsimilarity search will show best semantically matching schema for the query then how can it show relation between tables ?

Message : I would suggest breaking the task down into smaller pieces and using multiple LLM calls.

Message : For eg the first one will only be a list of tables wirh primary / foreign key and a short description. You can fit upto 50-60 tables. That can be the first call. 
Once you have the list of tables you can only include their schemas and try to generate.
If that‚Äôs not working you can try again.

Message : I‚Äôm currently implementing this 
https://gpt-index.readthedocs.io/en/latest/examples/index_structs/struct_indices/SQLIndexDemo-ManyTables.html

And I was trying to see how table relations can be embedded
Quoted Message : @9196xxxxxxxx Why are you doing semantic search over schemas? Do you take only top 1 retrieved DB schema in the prompt for query gen?

Message : Sorry removing it for second order reasons.

Message : Generally for text corpus on the table description/relations I‚Äôm trying to embed files from data cataloging tools like Amundsen 

Lets assume that data catalog has all the required information ,then what could be the various ways we index this information so semantic search gives the correct info ?

https://www.amundsen.io/
Quoted Message : Yes. The answer lies in how your are creating the text corpus and how you are indexing them. Point to remember that these models are probabilistic models and they try to predict the next token by analysing patterns in Corpus. Optimizing the accuracy of such mismatches in your particular usecases is also where the startups like us add value.

Message : i dont think u can do this. because LLM will want full table info to start deducing. so u will need to stuff it into context - it will be hard to just query the vector db to do most of the work. so ur right in ur similary search problem.

at best what u can do is break ur prompt into two parts:  first one gets the tables involved in the query and the second one stuffs all these tables into context and sends it to llm.
Quoted Message : So I can just embed the db schemas and at time of querying it will fetch best matching schema for the query and use it in prompt \n\n\nBut what I‚Äôm not able to wrap my head around is this scenario \nI embed schema for 2 tables let‚Äôs say customers,orders with customer_id as unique key along with 50 other tables \n\nWhen I run a query like find customers with highest number of orders,it should return a query joining customers table with orders\n\n\nWhat I don‚Äôt get is \nsimilarity search will show best semantically matching schema for the query then how can it show relation between tables ?

Message : another complexity is when u have "type" fields in ur db table. (for e.g. type ==<cat,dog,monkey>). so the LLM needs to know about these types before it can generate a query. that means for these kind of columns, u need to send descriptions of columns as well...otherwise the query will fail

Message : At enterprise scale then it seems to me that this would break the text2sql workflow.It will always run into context length limitations 


Other option is to ask user to specify table name and relevant relations but it‚Äôs not very user friendly.
Quoted Message : i dont think u can do this. because LLM will want full table info to start deducing. so u will need to stuff it into context - it will be hard to just query the vector db to do most of the work. so ur right in ur similary search problem.\n\n at best what u can do is break ur prompt into two parts:  first one gets the tables involved in the query and the second one stuffs all these tables into context and sends it to llm.

Message : if ur doing the "type descriptions" i mentioned above..yes it will break the context length.
Quoted Message : At enterprise scale then it seems to me that this would break the text2sql workflow.It will always run into context length limitations \n\n\nOther option is to ask user to specify table name and relevant relations but it‚Äôs not very user friendly.

Message : Start this way ‚Ä¶ track your mistakes and then fine tune once you have enough samples. It should always be suggestions and not always be executed.
Quoted Message : For eg the first one will only be a list of tables wirh primary / foreign key and a short description. You can fit upto 50-60 tables. That can be the first call. \nOnce you have the list of tables you can only include their schemas and try to generate. \nIf that‚Äôs not working you can try again.

Message : Copilot model - show completions and track acceptance rate


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : For eg the first one will only be a list of tables wirh primary / foreign key and a short description. You can fit upto 50-60 tables. That can be the first call. 
Once you have the list of tables you can only include their schemas and try to generate.
If that‚Äôs not working you can try again.

Message : I‚Äôm currently implementing this 
https://gpt-index.readthedocs.io/en/latest/examples/index_structs/struct_indices/SQLIndexDemo-ManyTables.html

And I was trying to see how table relations can be embedded
Quoted Message : @9196xxxxxxxx Why are you doing semantic search over schemas? Do you take only top 1 retrieved DB schema in the prompt for query gen?

Message : Sorry removing it for second order reasons.

Message : Generally for text corpus on the table description/relations I‚Äôm trying to embed files from data cataloging tools like Amundsen 

Lets assume that data catalog has all the required information ,then what could be the various ways we index this information so semantic search gives the correct info ?

https://www.amundsen.io/
Quoted Message : Yes. The answer lies in how your are creating the text corpus and how you are indexing them. Point to remember that these models are probabilistic models and they try to predict the next token by analysing patterns in Corpus. Optimizing the accuracy of such mismatches in your particular usecases is also where the startups like us add value.

Message : i dont think u can do this. because LLM will want full table info to start deducing. so u will need to stuff it into context - it will be hard to just query the vector db to do most of the work. so ur right in ur similary search problem.

at best what u can do is break ur prompt into two parts:  first one gets the tables involved in the query and the second one stuffs all these tables into context and sends it to llm.
Quoted Message : So I can just embed the db schemas and at time of querying it will fetch best matching schema for the query and use it in prompt \n\n\nBut what I‚Äôm not able to wrap my head around is this scenario \nI embed schema for 2 tables let‚Äôs say customers,orders with customer_id as unique key along with 50 other tables \n\nWhen I run a query like find customers with highest number of orders,it should return a query joining customers table with orders\n\n\nWhat I don‚Äôt get is \nsimilarity search will show best semantically matching schema for the query then how can it show relation between tables ?

Message : another complexity is when u have "type" fields in ur db table. (for e.g. type ==<cat,dog,monkey>). so the LLM needs to know about these types before it can generate a query. that means for these kind of columns, u need to send descriptions of columns as well...otherwise the query will fail

Message : At enterprise scale then it seems to me that this would break the text2sql workflow.It will always run into context length limitations 


Other option is to ask user to specify table name and relevant relations but it‚Äôs not very user friendly.
Quoted Message : i dont think u can do this. because LLM will want full table info to start deducing. so u will need to stuff it into context - it will be hard to just query the vector db to do most of the work. so ur right in ur similary search problem.\n\n at best what u can do is break ur prompt into two parts:  first one gets the tables involved in the query and the second one stuffs all these tables into context and sends it to llm.

Message : if ur doing the "type descriptions" i mentioned above..yes it will break the context length.
Quoted Message : At enterprise scale then it seems to me that this would break the text2sql workflow.It will always run into context length limitations \n\n\nOther option is to ask user to specify table name and relevant relations but it‚Äôs not very user friendly.

Message : Start this way ‚Ä¶ track your mistakes and then fine tune once you have enough samples. It should always be suggestions and not always be executed.
Quoted Message : For eg the first one will only be a list of tables wirh primary / foreign key and a short description. You can fit upto 50-60 tables. That can be the first call. \nOnce you have the list of tables you can only include their schemas and try to generate. \nIf that‚Äôs not working you can try again.

Message : Copilot model - show completions and track acceptance rate

Message : Make an assistant / suggestion tool. This allows for slowly boot strapping better things from data.

Message : Has anyone worked on Generative AI tools for identity management? For example, 3D avatars? If so, can you direct me to such open-source resources and the current landscape (both funding-wise and use cases)?

Message : Is anyone working with chatgpt-retrieval-plugin?
I added a custom metada, but it seemed to allow far more context than what was allowed for the main ‚Äútext‚Äù field.
How are metadatas incorporated into the embeddings?

Message : *far more tokens
Quoted Message : Is anyone working with chatgpt-retrieval-plugin?\nI added a custom metada, but it seemed to allow far more context than what was allowed for the main ‚Äútext‚Äù field.\nHow are metadatas incorporated into the embeddings?

Message : https://github.com/ricklamers/gpt-code-ui

People who don't have a code interpreter access can check this out.

Message : Open AI prompt related -

Is there a way to force the open ai response in specific json format?

Message : Guardrails helps you do that: https://getguardrails.ai/ (I‚Äôve not used it personally, but folks are using it)

Message : Try jsonformer
Quoted Message : Open AI prompt related -\n\nIs there a way to force the open ai response in specific json format?

Message : https://lmql.ai/
Quoted Message : Open AI prompt related -\n\nIs there a way to force the open ai response in specific json format?

Message : There is a library by Microsoft.
https://github.com/microsoft/guidance

They control the output using `handlebars` templating.

It can also help when you want json responses' value to be guided. But needs access to logits (Llama type OSS models).
Quoted Message : Open AI prompt related -\n\nIs there a way to force the open ai response in specific json format?

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ~‚ÄØRupali and ‚Ä™+91¬†98118¬†32868‚Ä¨

Message : Anyone here got access to Anthropic‚Äôs Claude Instant API?

Message : do you any example for open ai model? 

What is the value you need to pass for the tokenizer in case of open ai

Message : was added to chat

Message : Anyone here got access to Anthropic‚Äôs Claude Instant API?

Message : do you any example for open ai model? \n\nWhat is the value you need to pass for the tokenizer in case of open ai
Quoted Message : Try jsonformer

Message : jsonformer won't work with OpenAI. You're better off using guidance or guardrails
Quoted Message : do you any example for open ai model? \n\nWhat is the value you need to pass for the tokenizer in case of open ai

Message : okay.
Quoted Message : jsonformer won't work with OpenAI. You're better off using guidance or guardrails

Message : I'm making do with a piece of code like https://github.com/hwchase17/langchainjs/blob/main/langchain/src/agents/chat_convo/outputParser.ts#L24-L37
Of course I asked for json in the prompt.
The other tools seemed too heavyweight
Quoted Message : Open AI prompt related -\n\nIs there a way to force the open ai response in specific json format?

Message : Open ai returns the keys("name") different sometimes, then it starts creating the problem
Quoted Message : I'm making do with a piece of code like https://github.com/hwchase17/langchainjs/blob/main/langchain/src/agents/chat_convo/outputParser.ts#L24-L37\nOf course I asked for json in the prompt. \nThe other tools seemed too heavyweight

Message : Chip Huyden and Amjad discuss LLMs in Production Challenges, register for invite: https://lu.ma/cs5vbjt3?tk=WyJJD3

Message : fyi - this will be a livestream on YouTube
Quoted Message : Chip Huyden and Amjad discuss LLMs in Production Challenges, register for invite: https://lu.ma/cs5vbjt3?tk=WyJJD3

Message : Which channel
Quoted Message : fyi - this will be a livestream on YouTube

Message : if you register here, you'll get the Youtube livestream link!
Quoted Message : Chip Huyden and Amjad discuss LLMs in Production Challenges, register for invite: https://lu.ma/cs5vbjt3?tk=WyJJD3

Message : Livestream Link: https://www.youtube.com/watch?v=zXX0I6dOPYk
Quoted Message : Chip Huyden and Amjad discuss LLMs in Production Challenges, register for invite: https://lu.ma/cs5vbjt3?tk=WyJJD3

Message : Talk by Karpathy at Msft build 

https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2

Message : Real good
Quoted Message : Talk by Karpathy at Msft build \n\nhttps://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2

Message : anyone here
Quoted Message : fyi - this will be a livestream on YouTube

Message : https://www.youtube.com/watch?v=zXX0I6dOPYk

Message : am there
Quoted Message : https://www.youtube.com/watch?v=zXX0I6dOPYk

Message : Some interesting points discussed here
Quoted Message : https://www.youtube.com/watch?v=zXX0I6dOPYk

Message : Wow, less than 100 live viewers for Chip Huyen! Lot of alpha there

Message : ‚Äé~‚ÄØDev Aggarwal added ~‚ÄØAryan Kuttappa

Message : Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder. 

One day ..
Quoted Message : Wow, less than 100 live viewers for Chip Huyen! Lot of alpha there

Message : depends on the talk and who you're targeting, LongShot had SEO related webinars where we discussed our semantic SEO feature, we got a few hundred, but yes they were mostly non technical
Quoted Message : Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder. \n\nOne day ..

Message : Hi all, I am Sam, founder of Writesonic. Been playing with generative AI for the last few years.

Excited to join this group and learn from you all üöÄ
Also, if any of you are looking for AI/ML roles in generative AI, do ping me.

Message : Shark tank bro üòÇ
Quoted Message : Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder. \n\nOne day ..

Message : https://twitter.com/tengyuma/status/1661412995430219786?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ A new optimizer which can achieve same performance as Adam with half the number of tokens.

Message : anyone?
Quoted Message : Is anyone working with chatgpt-retrieval-plugin?\nI added a custom metada, but it seemed to allow far more context than what was allowed for the main ‚Äútext‚Äù field.\nHow are metadatas incorporated into the embeddings?

Message : Haven't worked with it. But you need to check how the chunking is done of text to create the embeddings
Quoted Message : anyone?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Some interesting points discussed here
Quoted Message : https://www.youtube.com/watch?v=zXX0I6dOPYk

Message : Wow, less than 100 live viewers for Chip Huyen! Lot of alpha there

Message : ‚Äé~‚ÄØDev Aggarwal added ~‚ÄØAryan Kuttappa

Message : Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder. 

One day ..
Quoted Message : Wow, less than 100 live viewers for Chip Huyen! Lot of alpha there

Message : depends on the talk and who you're targeting, LongShot had SEO related webinars where we discussed our semantic SEO feature, we got a few hundred, but yes they were mostly non technical
Quoted Message : Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder. \n\nOne day ..

Message : Hi all, I am Sam, founder of Writesonic. Been playing with generative AI for the last few years.

Excited to join this group and learn from you all üöÄ
Also, if any of you are looking for AI/ML roles in generative AI, do ping me.

Message : Shark tank bro üòÇ
Quoted Message : Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder. \n\nOne day ..

Message : https://twitter.com/tengyuma/status/1661412995430219786?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ A new optimizer which can achieve same performance as Adam with half the number of tokens.

Message : anyone?
Quoted Message : Is anyone working with chatgpt-retrieval-plugin?\nI added a custom metada, but it seemed to allow far more context than what was allowed for the main ‚Äútext‚Äù field.\nHow are metadatas incorporated into the embeddings?

Message : Haven't worked with it. But you need to check how the chunking is done of text to create the embeddings
Quoted Message : anyone?

Message : Anyone here working on factchecking the output of an LLM's. Architecture suggestions would be great

Message : For people who have worked with chunking data/documenta before:
Suppose I have 5 documents.
With the chunking (i.e., recursive text-splitter?) method I use, the 1st document gets chunked into 3 parts, 2nd document gets chunked into 5 parts, etc.

OpenAI‚Äôs embedding model creates a vector of size 1536 for each such chunk.

So, for the 1st document, the dimension of embedding-vector will be (3,1536)
For the 2nd, it‚Äôll be (5,1536)‚Ä¶etc.

Isnt this (irregular size) a problem during retrieval? How is it handled?
I thought it needs to be of the same size‚Ä¶?
Quoted Message : Haven't worked with it. But you need to check how the chunking is done of text to create the embeddings

Message : During retrieval, we're not looking at (searching for) documents any more, but at chunks, which now all have the same size: (1, 1536).

Message : And what if my question has one part of answer in one of the chunks and the in another chunk of the same document?

Message : Splitting up a document honestly doesn‚Äôt sound a good idea to me.
Are there any workarounds for this?

Message : ‚Äé<attached: 00005244-PHOTO-2023-05-25-02-23-26.jpg>
Quoted Message : For people who have worked with chunking data/documenta before:\nSuppose I have 5 documents. \nWith the chunking (i.e., recursive text-splitter?) method I use, the 1st document gets chunked into 3 parts, 2nd document gets chunked into 5 parts, etc.\n\nOpenAI‚Äôs embedding model creates a vector of size 1536 for each such chunk.\n\nSo, for the 1st document, the dimension of embedding-vector will be (3,1536)\nFor the 2nd, it‚Äôll be (5,1536)‚Ä¶etc.\n\nIsnt this (irregular size) a problem during retrieval? How is it handled?\nI thought it needs to be of the same size‚Ä¶?

Message : Which is why you always chunk with some overlap, which you may have to tune for your dataset.
Quoted Message : And what if my question has one part of answer in one of the chunks and the in another chunk of the same document?

Message : also, to be clear my question sort of translates to ‚Äúwhat chunking system does chatgpt-retrieval-plugin use‚Äù, if anybody has an idea about it already:-)
Quoted Message : Haven't worked with it. But you need to check how the chunking is done of text to create the embeddings

Message : +1
Choosing the right kind of split for your usecase is also worth consideration. You need to specify/choose the splitting criteria in a way that suits your usecase
Quoted Message : Which is why you always chunk with some overlap, which you may have to tune for your dataset.

Message : Most vector stores (at least the good ones) support batch insertion which is faster, so it makes sense to create a bunch of docs (chunks actually) and their embeddings and insert them with one command.
Quoted Message :  2023_05_25_3EB029D8B7A1717FE9148B.jpeg

Message : The only real workaround for this is longer context window for the LLM, which is not in our hands. So we'll be doing chunking before retrieving for a while.
Quoted Message : Splitting up a document honestly doesn‚Äôt sound a good idea to me.\nAre there any workarounds for this?

Message : interesting‚Ä¶
Quoted Message : The only real workaround for this is longer context window for the LLM, which is not in our hands. So we'll be doing chunking before retrieving for a while.

Message : chunk overlap sounds a difficult problem, and subjective and very very specific to usecases

Message : No no, it's not that difficult at all. Most libs around this (like langchain) already have params that let you do this easily. Where some thought is required (like code or markdown or msword doc), usually you need to split carefully in the first place and don't need chunking.

Message : Or, at least, if you have thought through splitting, chunking strategy will be self-evident.

Message : a bit biased since i built it but it's the simplest of all of solutions out there and supports zod schemas to get structured data out of llms https://github.com/dosco/minds
Quoted Message : Open AI prompt related -\n\nIs there a way to force the open ai response in specific json format?

Message : https://geohot.github.io//blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html

This. So much this. About time someone started writing PyTorch for and cards üíì

Message : AMD cards*

Message : ‚ÄúIf NVIDIA is the Apple, we are the Android.‚Äù ü§å

Message : Love love love the sentiment.

However geohotz is mistaken in thinking this will open up the ML hardware market.

Imo (and i could be wrong) if he succeeded, he will have converted a monopoly to an oliogopoly.
Quoted Message : https://geohot.github.io//blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html\n\nThis. So much this. About time someone started writing PyTorch for and cards üíì

Message : Building a developer EcoSystem around chip is very tough. I see only three success stories in last 15 years, Apple, Android and Nvidia. Even Meta couldn't do it well for Oculus.

Message : You can‚Äôt build a great business with perfect market competition. All insanely profitable companies must be in some sort of oliogopoly to succeed (not monopoly because otherwise you get anti trust lawsuits)
Quoted Message : Love love love the sentiment.\n\nHowever geohotz is mistaken in thinking this will open up the ML hardware market.\n\nImo (and i could be wrong) if he succeeded, he will have converted a monopoly to an oliogopoly.

Message : Not just that,

You need insane investment to get something started to begin with
Quoted Message : You can‚Äôt build a great business with perfect market competition. All insanely profitable companies must be in some sort of oliogopoly to succeed (not monopoly because otherwise you get anti trust lawsuits)

Message : Geohot really loves this analogy ü§£ He said the same thing for Tesla and Comma
Quoted Message : ‚ÄúIf NVIDIA is the Apple, we are the Android.‚Äù ü§å

Message : This is super cool, wishing geohot all the very best!
Quoted Message : https://geohot.github.io//blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html\n\nThis. So much this. About time someone started writing PyTorch for and cards üíì

Message : QLoRA: *4-bit* finetuning of LLMs! 

Releases a Chat LLM: Guanaco
Single, 48G GPU, achieving 99% ChatGPT performance on the Vicuna benchmark (ELO style)

Paper: https://arxiv.org/abs/2305.14314
Code+Demo: https://github.com/artidoro/qlora

PS: I know ELO is iffy, but it's better than nothing üòÖ

Message : ‚Äé<attached: 00005267-PHOTO-2023-05-25-09-18-33.jpg>

Message : Take a look at Nvidia earnings and share price

Message : After markey

Message : ‚Äé<attached: 00005270-PHOTO-2023-05-25-09-21-44.jpg>

Message : So cheaper than openai now ü§î
Quoted Message :  2023_05_25_3EB0973CA020B8098CDCB3.jpeg

Message : I think Claude is the most expensive to infer ab

Message : How does Cohere compares to OpenAI in terms of quality?
Quoted Message :  2023_05_25_3EB0973CA020B8098CDCB3.jpeg

Message : ‚Äé<attached: 00005275-PHOTO-2023-05-25-09-41-46.jpg>
Quoted Message :  2023_05_25_30C8F736C95DD76D7FBDCEAD2DA24CA1.jpeg

Message : https://twitter.com/omarsar0/status/1661540207206846464?s=46&t=NNw5PElvtyZ9tUru_KLDVw

training llms to call APIs - isn't this just overfitting on the training data?

Message : I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... ü§ëü§ëü§ë
Quoted Message :  2023_05_25_3A6EAA7A12B8145D6A96.jpeg

Message : Curious why do you say so
Quoted Message : I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... ü§ëü§ëü§ë

Message : just seeing the last rallies in indian market... no data backed
Quoted Message : Curious why do you say so

Message : Hmm. I thought there is some signal which hints higher number of demand for GPUs in Indian ecosystem vs US/ EUR. But, got it.

Message : that will add $750B market cap over night
Quoted Message : I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... ü§ëü§ëü§ë


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : So cheaper than openai now ü§î
Quoted Message :  2023_05_25_3EB0973CA020B8098CDCB3.jpeg

Message : I think Claude is the most expensive to infer ab

Message : How does Cohere compares to OpenAI in terms of quality?
Quoted Message :  2023_05_25_3EB0973CA020B8098CDCB3.jpeg

Message : ‚Äé<attached: 00005275-PHOTO-2023-05-25-09-41-46.jpg>
Quoted Message :  2023_05_25_30C8F736C95DD76D7FBDCEAD2DA24CA1.jpeg

Message : https://twitter.com/omarsar0/status/1661540207206846464?s=46&t=NNw5PElvtyZ9tUru_KLDVw

training llms to call APIs - isn't this just overfitting on the training data?

Message : I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... ü§ëü§ëü§ë
Quoted Message :  2023_05_25_3A6EAA7A12B8145D6A96.jpeg

Message : Curious why do you say so
Quoted Message : I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... ü§ëü§ëü§ë

Message : just seeing the last rallies in indian market... no data backed
Quoted Message : Curious why do you say so

Message : Hmm. I thought there is some signal which hints higher number of demand for GPUs in Indian ecosystem vs US/ EUR. But, got it.

Message : that will add $750B market cap over night
Quoted Message : I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... ü§ëü§ëü§ë

Message : 20% of entire BSE

Message : don't convert directly dollar into rupees.. stock price will defiantly be on the lower side if  it listed in the indian market.
Quoted Message : that will add $750B market cap over night

Message : Most of it will anyway be fdi
Quoted Message : I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... ü§ëü§ëü§ë

Message : nah, indian retail investor/developer will invest a lot.
Quoted Message : Most of it will anyway be fdi

Message : ‚Äé<attached: 00005286-PHOTO-2023-05-25-10-26-21.jpg>

Message : ‚Äé<attached: 00005287-PHOTO-2023-05-25-10-28-22.jpg>
Quoted Message :  2023_05_25_3A6EAA7A12B8145D6A96.jpeg

Message : ‚Äé<attached: 00005288-PHOTO-2023-05-25-10-41-31.jpg>

Message : App store US

Message : Tensorflow is the floppy disk of AI era
Quoted Message :  2023_05_25_3AB3056F9FC35E692AC6.jpeg

Message : My takeaway from both chatgpt and character ai app store launches - its easier to scale massively on web first - you probably don‚Äôt need an app!
Quoted Message :  2023_05_25_3EB0F72C7A18E24C83F1CF.jpeg

Message : not entirely surprising given that their main use case is "mann ki baat" üòÇ
Quoted Message :  2023_05_25_3EB0F72C7A18E24C83F1CF.jpeg

Message : 100%. The code didn‚Äôt work out of the box. Now will have to dig into it. Just to upload a dataset
Quoted Message : Tensorflow is the floppy disk of AI era

Message : You need an app. All the other AI chat apps are on mobile.
Quoted Message : My takeaway from both chatgpt and character ai app store launches - its easier to scale massively on web first - you probably don‚Äôt need an app!

Message : Started on mobile too.

Message : Chat is native to mobile over web

Message : Tensorflow was the reason I took break from DL during 15-17 and focused on just ML  thinking this is not going to work out for real world applications.
Quoted Message : 100%. The code didn‚Äôt work out of the box. Now will have to dig into it. Just to upload a dataset

Message : https://twitter.com/andreyzagoruiko/status/1655046102738173954

Mobile AI Chat apps make 200K$+ per month

Message : ‚Äé<attached: 00005299-PHOTO-2023-05-25-10-50-37.jpg>

Message : All of these combined are <1% of chatgpt

Message : There is a saying in Hindi ‚ÄúGanv basa nahi, lootere aa gye‚Äù, every time something good start taking place grifters are first to come.
Quoted Message :  2023_05_25_3EB0BCBCA788FB96C397A8.jpeg

Message : translate please? :P

Message : We should both go to therapy sponsored by tensorflow support group. I did the same
Quoted Message : Tensorflow was the reason I took break from DL during 15-17 and focused on just ML  thinking this is not going to work out for real world applications.

Message : ChatGPT makes 100M$/month?
Quoted Message : All of these combined are <1% of chatgpt

Message : Riding the wave üåä
Quoted Message : translate please? :P

Message : Before a settlement even start taking place, bandits(lootere) are there

Message : Sorry I meant in terms of user count. Not sure what the revenue numbers are
Quoted Message : ChatGPT makes 100M$/month?

Message : https://poe.com/s/kBjvkzP5fiwOWn1bo21W
Quoted Message : translate please? :P

Message : Honestly stuff like this continues to blow my mind. How is this possible üòÅ

Message : Character.ai too is much much bigger. And has insane retention compared even YouTube
Quoted Message : All of these combined are <1% of chatgpt

Message : Don't get how these apps are robbers/scammers

Message : Oh, sudarshan
Quoted Message : Don't get how these apps are robbers/scammers

Message : I find this claim interesting. Coz I don‚Äôt know anyone that uses it. üòú
Quoted Message : Character.ai too is much much bigger. And has insane retention compared even YouTube

Message : And not even on Reddit or anything is it discussed much

Message : https://www.similarweb.com/amp/blog/insights/ai-news/character-ai-engagement/

‚ÄúAccording to today‚Äôs Reuters story, AI chatbot Character.AI, with no revenue, raises $150 mln led by Andreessen Horowitz, Character.AI says users spend an average of two hours per day on the site. That‚Äôs consistent with Similarweb estimates that time per visit has ranged from 25.4 to 29.7 minutes in recent months, which could easily add up to two hours across a few visits. That time per visit is about 3 to 4 times higher than the average for the top 100 websites ‚Äì higher even than YouTube, which is famous for claiming lots of user time.‚Äù
Quoted Message : I find this claim interesting. Coz I don‚Äôt know anyone that uses it. üòú

Message : So ChatGPT subreddit has 1.7 million members and 10k ppl online right now. Character AI - 80k members and 1k ppl online

Message : Curious how much time people spend on kissan ai @1937708xxxx üëÄ

Message : Don‚Äôt take it literally, just a joke
Quoted Message : Don't get how these apps are robbers/scammers

Message : Robbers is a metaphor for stealing a chunk of the limelight
Quoted Message : Don't get how these apps are robbers/scammers

Message : Don‚Äôt take it literally Bhai, just a light hearted joke.
Quoted Message : Don't get how these apps are robbers/scammers

Message : I don‚Äôt have stats for apps yet but on web avg 2m per session, went up 2x in a month. I was expecting to go down with more users but it is climbing everyday. Probably a good sign.
Quoted Message : Curious how much time people spend on kissan ai @193xxxxxxxx üëÄ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Oh, sudarshan
Quoted Message : Don't get how these apps are robbers/scammers

Message : I find this claim interesting. Coz I don‚Äôt know anyone that uses it. üòú
Quoted Message : Character.ai too is much much bigger. And has insane retention compared even YouTube

Message : And not even on Reddit or anything is it discussed much

Message : https://www.similarweb.com/amp/blog/insights/ai-news/character-ai-engagement/

‚ÄúAccording to today‚Äôs Reuters story, AI chatbot Character.AI, with no revenue, raises $150 mln led by Andreessen Horowitz, Character.AI says users spend an average of two hours per day on the site. That‚Äôs consistent with Similarweb estimates that time per visit has ranged from 25.4 to 29.7 minutes in recent months, which could easily add up to two hours across a few visits. That time per visit is about 3 to 4 times higher than the average for the top 100 websites ‚Äì higher even than YouTube, which is famous for claiming lots of user time.‚Äù
Quoted Message : I find this claim interesting. Coz I don‚Äôt know anyone that uses it. üòú

Message : So ChatGPT subreddit has 1.7 million members and 10k ppl online right now. Character AI - 80k members and 1k ppl online

Message : Curious how much time people spend on kissan ai @1937708xxxx üëÄ

Message : Don‚Äôt take it literally, just a joke
Quoted Message : Don't get how these apps are robbers/scammers

Message : Robbers is a metaphor for stealing a chunk of the limelight
Quoted Message : Don't get how these apps are robbers/scammers

Message : Don‚Äôt take it literally Bhai, just a light hearted joke.
Quoted Message : Don't get how these apps are robbers/scammers

Message : I don‚Äôt have stats for apps yet but on web avg 2m per session, went up 2x in a month. I was expecting to go down with more users but it is climbing everyday. Probably a good sign.
Quoted Message : Curious how much time people spend on kissan ai @193xxxxxxxx üëÄ

Message : Impressive !
Quoted Message : I don‚Äôt have stats for apps yet but on web avg 2m per session, went up 2x in a month. I was expecting to go down with more users but it is climbing everyday. Probably a good sign.

Message : What kinds of things are people asking ?

Message : I love the UX. You can introduce a share feature. Like Poe. That will increase sharing and organic growth

Message : I‚Äôll run an analysis during weekend, haven‚Äôt got anytime lately but some feedback we received, they are going at such a breath that I‚Äôm finding new use case everyday. For example, asking tractor comparison for an application, asking ways to make air freshener from a plant, schemes by state, loan rates. Some even asked to just give product with answer so they can buy directly. Hence, we started building API platform and product placement, one has to feed family and generate revenue, too. ü§£

Message : integrate it with ondc ü´∞
Quoted Message : I‚Äôll run an analysis during weekend, haven‚Äôt got anytime lately but some feedback we received, they are going at such a breath that I‚Äôm finding new use case everyday. For example, asking tractor comparison for an application, asking ways to make air freshener from a plant, schemes by state, loan rates. Some even asked to just give product with answer so they can buy directly. Hence, we started building API platform and product placement, one has to feed family and generate revenue, too. ü§£

Message : Yup, I‚Äôm going step further and doing vector matching of product with answer so they get exact item and not Google ads type crap.
Quoted Message : integrate it with ondc ü´∞

Message : I would also suggest to try and turn it into a community of sorts where people can search answers. Or maybe make most answers public by default. So AI generated and human answers can co exist. This will also increase revenue opportunities

Message : Mid Journey approach

Message : Are you facing issues with speechtotext considering various languages and accents it has to handle. Or is it manageable
Quoted Message : I‚Äôll run an analysis during weekend, haven‚Äôt got anytime lately but some feedback we received, they are going at such a breath that I‚Äôm finding new use case everyday. For example, asking tractor comparison for an application, asking ways to make air freshener from a plant, schemes by state, loan rates. Some even asked to just give product with answer so they can buy directly. Hence, we started building API platform and product placement, one has to feed family and generate revenue, too. ü§£

Message : That‚Äôs also one of the suggestion. If we start seeing people asking about a pest in an area, we can detect in pest infestation and alert authorities.
Quoted Message : I would also suggest to try and turn it into a community of sorts where people can search answers. Or maybe make most answers public by default. So AI generated and human answers can co exist. This will also increase revenue opportunities

Message : Early I faced, now we have figure out. Working out MoU with some bigger companies to see if the Bhasini can be optimized further for few languages.
Quoted Message : Are you facing issues with speechtotext considering various languages and accents it has to handle. Or is it manageable

Message : üôèGreat and such a relief to know that. So much can be done in the country in various sections such as education , healthcare with a reliable speechtotext

Message : Luckily, I‚Äôm sitting on huge voice data samples to further train and improve all Indic languages and it will only grow bigger from here. Limited by just time and resources.

Message : Provide the dataset to ai4bharat? They have annotators
Quoted Message : Luckily, I‚Äôm sitting on huge voice data samples to further train and improve all Indic languages and it will only grow bigger from here. Limited by just time and resources.

Message : https://betterprogramming.pub/building-your-own-devsecops-knowledge-base-with-openai-langchain-and-llamaindex-b28cda15abb7
Quoted Message : I'm not talking about REST.\n\nIt's equivalent for document parsing, ingest, reasoning and querying the data from new AI tools/tech\n\nLet's say \n\nUse X for docs parse\nUseY for docs ingest\nUse Z for reasoning\nUse Q for corrected data ingest\n\n\nThat becomes a stack.

Message : Yes, that‚Äôs the plan.
Quoted Message : Provide the dataset to ai4bharat? They have annotators

Message : üôèit's a hard task
Quoted Message : Luckily, I‚Äôm sitting on huge voice data samples to further train and improve all Indic languages and it will only grow bigger from here. Limited by just time and resources.

Message : ‚Äé<attached: 00005340-PHOTO-2023-05-25-11-17-27.jpg>
Quoted Message : Luckily, I‚Äôm sitting on huge voice data samples to further train and improve all Indic languages and it will only grow bigger from here. Limited by just time and resources.

Message : I think you‚Äôre definitely on a positive feedback loop of data flywheel

Message : Harrison Chase posted this yesterday. https://twitter.com/hwchase17/status/1661386820272156672

Accessing Open Source models as an API using Langchain + MosaicML
Quoted Message : Unfortunately this doesn't work for me, it seems that there's no API exposed on that port. If you get it working, please let me know.

Message : Can we help here to fast-track your exploratory analysis? So long you are firing events. I think otherwise it shud take you some time to see data at various cuts.
Quoted Message : I‚Äôll run an analysis during weekend, haven‚Äôt got anytime lately but some feedback we received, they are going at such a breath that I‚Äôm finding new use case everyday. For example, asking tractor comparison for an application, asking ways to make air freshener from a plant, schemes by state, loan rates. Some even asked to just give product with answer so they can buy directly. Hence, we started building API platform and product placement, one has to feed family and generate revenue, too. ü§£

Message : You can try creating chunks, and instead of using vector embeddings ask chatgpt to create question/answers from that chunk covering it exhaustively. You can then fine tune some model (open ai has api for davinci) with these question answers. 
I haven't really tried it but my intuition is that a model fine tuned this way should be able to pickup answers with context in multiple chunks.
Quoted Message : chunk overlap sounds a difficult problem, and subjective and very very specific to usecases

Message : so there‚Äôs no embeddings based kNN search involved in this approach?
Quoted Message : You can try creating chunks, and instead of using vector embeddings ask chatgpt to create question/answers from that chunk covering it exhaustively. You can then fine tune some model (open ai has api for davinci) with these question answers. \nI haven't really tried it but my intuition is that a model fine tuned this way should be able to pickup answers with context in multiple chunks.

Message : Anyone else having problem paying to openai via cc?

Message : Yeah, off late been hearing some complaints with Indian cards. Try Amex.
Quoted Message : Anyone else having problem paying to openai via cc?

Message : Icici said it is to do with the merchant
Quoted Message : Yeah, off late been hearing some complaints with Indian cards. Try Amex.

Message : Hi, Has anyone trying further fine-tuning Vicuna? 
Can someone guide me to resources on how to do that?

Message : I want to build a custom search/summarization for the documents present on my machine. 
I have started with Vector Search & Prompt Engineering, but GPT-3.5 does not allow bigger prompts.

Message : Bigger than 4096 even with vectorDB?
Quoted Message : I want to build a custom search/summarization for the documents present on my machine. \nI have started with Vector Search & Prompt Engineering, but GPT-3.5 does not allow bigger prompts.

Message : why not try https://github.com/imartinez/privateGPT
Quoted Message : I want to build a custom search/summarization for the documents present on my machine. \nI have started with Vector Search & Prompt Engineering, but GPT-3.5 does not allow bigger prompts.

Message : You can bump it to gpt-4 with 8k, but it is very expensive

Message : Yes, I want to summarize multiple docs. Context was not getting filled within 4096 tokens. 
I saw that llama index is solving it via multiple prompts and then re-summarizing all summarise at the end. I will try that as well.
But parallely want to experiment training myself as well. Atleast will end up learning more on this topic :)
Quoted Message : Bigger than 4096 even with vectorDB?

Message : Yeah :( Waiting for OpenAI to drop prices of GPT-4 and make something like GPT-4-turbo!
Quoted Message : You can bump it to gpt-4 with 8k, but it is very expensive

Message : Thanks, will check it out!
Quoted Message : why not try https://github.com/imartinez/privateGPT

Message : https://www.philschmid.de/fine-tune-flan-t5-peft
Quoted Message : Yes, I want to summarize multiple docs. Context was not getting filled within 4096 tokens. \nI saw that llama index is solving it via multiple prompts and then re-summarizing all summarise at the end. I will try that as well. \nBut parallely want to experiment training myself as well. Atleast will end up learning more on this topic :)

Message : This is great!! Thank you so much. Will replicate it!
Quoted Message : https://www.philschmid.de/fine-tune-flan-t5-peft

Message : Anyone who has developed any tts application themselves as a product to use, please DM. I have a jam

Message : *stt

Message : This solves the purpose for now! Thanks Sahir. 
Will check now how to make it faster and experiment with more LLMs.
Quoted Message : why not try https://github.com/imartinez/privateGPT

Message : Anyone faced issues with using GPT4ALL with this, or tried using LLaMa?

Naive question but it works well with a single doc, but hallicunates with multiple. Anyway to fix this?
Quoted Message : This solves the purpose for now! Thanks Sahir. \nWill check now how to make it faster and experiment with more LLMs.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You can bump it to gpt-4 with 8k, but it is very expensive

Message : Yes, I want to summarize multiple docs. Context was not getting filled within 4096 tokens. 
I saw that llama index is solving it via multiple prompts and then re-summarizing all summarise at the end. I will try that as well.
But parallely want to experiment training myself as well. Atleast will end up learning more on this topic :)
Quoted Message : Bigger than 4096 even with vectorDB?

Message : Yeah :( Waiting for OpenAI to drop prices of GPT-4 and make something like GPT-4-turbo!
Quoted Message : You can bump it to gpt-4 with 8k, but it is very expensive

Message : Thanks, will check it out!
Quoted Message : why not try https://github.com/imartinez/privateGPT

Message : https://www.philschmid.de/fine-tune-flan-t5-peft
Quoted Message : Yes, I want to summarize multiple docs. Context was not getting filled within 4096 tokens. \nI saw that llama index is solving it via multiple prompts and then re-summarizing all summarise at the end. I will try that as well. \nBut parallely want to experiment training myself as well. Atleast will end up learning more on this topic :)

Message : This is great!! Thank you so much. Will replicate it!
Quoted Message : https://www.philschmid.de/fine-tune-flan-t5-peft

Message : Anyone who has developed any tts application themselves as a product to use, please DM. I have a jam

Message : *stt

Message : This solves the purpose for now! Thanks Sahir. 
Will check now how to make it faster and experiment with more LLMs.
Quoted Message : why not try https://github.com/imartinez/privateGPT

Message : Anyone faced issues with using GPT4ALL with this, or tried using LLaMa?

Naive question but it works well with a single doc, but hallicunates with multiple. Anyway to fix this?
Quoted Message : This solves the purpose for now! Thanks Sahir. \nWill check now how to make it faster and experiment with more LLMs.

Message : hey folks, one question:

I'm experimenting with my a couple prompts responsible to get a JSON

when I use a prompt on browser, it outputs correctly however while using the same prompt with llm chain in code, it's giving out JSON with incorrect answers.

temperature is 0 at both places. I'm controlling temp value on chatbotui.com

would anyone know what I could explore more to see if I'm messing up with something?

Message : the prompt on chatbotui is working everytime and giving out incorrect output in code.

- same model, temperature
- using chatbot ui to test on browser, also used open ai playground and it works fine there
- using langchain's ChatOpenAI and llm chain class

Message : works with my Amazon ICICI credit card.
Quoted Message : Icici said it is to do with the merchant

Message : Worked now. Looks like a stripe issue yesterdays
Quoted Message : works with my Amazon ICICI credit card.

Message : yeah had some initial issues as well. You need to go and "view invoice" on Stripe, and then pay it (i.e. you can't do it from the OpenAI website).
Quoted Message : Yeah, off late been hearing some complaints with Indian cards. Try Amex.

Message : Hey everyone what is a good stack/pipeline using a self hosted llm for question answering on Excel sheets?

Message : We are planning to integrate the GPT 3.5 API into our platform. We have observed that the average inference time is 5 seconds, but it can sometimes go up to 30 seconds. Does OpenAI has any plans to improve the speed of inference below 2 secs so that we can deploy the code in production.

Message : No
Quoted Message : We are planning to integrate the GPT 3.5 API into our platform. We have observed that the average inference time is 5 seconds, but it can sometimes go up to 30 seconds. Does OpenAI has any plans to improve the speed of inference below 2 secs so that we can deploy the code in production.

Message : https://www.youtube.com/watch?v=ZMQbHMgK2rw

Run, run little robot mouse!

Message : Have you tried using their streaming api? [Chat Completion API with streaming=true]
If the response comes word by word, it will appear fast to end users.
Quoted Message : We are planning to integrate the GPT 3.5 API into our platform. We have observed that the average inference time is 5 seconds, but it can sometimes go up to 30 seconds. Does OpenAI has any plans to improve the speed of inference below 2 secs so that we can deploy the code in production.

Message : this has to be the modern version of apple adding animations to make stuff feel smoother
Quoted Message : Have you tried using their streaming api? [Chat Completion API with streaming=true]\nIf the response comes word by word, it will appear fast to end users.

Message : Yes we are using Chat completion API only...But our use case is not suitable to send response word by word
Quoted Message : Have you tried using their streaming api? [Chat Completion API with streaming=true]\nIf the response comes word by word, it will appear fast to end users.

Message : We are building an app using streaming, and the output seems quite quick (just like ChatGPT UI). You might want to reduce maxTokens and tune other params to improve speed
Quoted Message : We are planning to integrate the GPT 3.5 API into our platform. We have observed that the average inference time is 5 seconds, but it can sometimes go up to 30 seconds. Does OpenAI has any plans to improve the speed of inference below 2 secs so that we can deploy the code in production.

Message : I can't believe my eyes. These are so fast. They have fans under them to create suction and increase downforce. G forces as high as F1 üôà
Quoted Message : https://www.youtube.com/watch?v=ZMQbHMgK2rw\n\nRun, run little robot mouse!

Message : Haha. micromouse was so much fun. We organised one too during college. üòÖ

India didnt have this fast though. But I had gone to Beijing to participate in an event which also had micromouse üôè
Quoted Message : I can't believe my eyes. These are so fast. They have fans under them to create suction and increase downforce. G forces as high as F1 üôà

Message : There are generations of PhDs who did micromouse for years.

Message : But anyway, non genAI. Dont want to distract the group.

Message : Has anyone fine tuned a self hosted generative llm (alpaca, chatgpt4all) on domain specific data? Need some advice on when it is useful to fine-tune and when it may actually hurt

Message : Excellent Prompting Guide for LLM Hackers: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

From Nishant @91993397xxxx ‚Äî one of the Hackathon winners!

Message : https://twitter.com/ansonyuu/status/1661518548664041472

@91773788xxxx should we try this at the meetup?

Message : Totally!
Quoted Message : https://twitter.com/ansonyuu/status/1661518548664041472\n\n@9177xxxxxxxx should we try this at the meetup?

Message : Can make a real time version of this as well? Attendees enter interests at the venue and get plotted in real time?
Quoted Message : https://twitter.com/ansonyuu/status/1661518548664041472\n\n@9177xxxxxxxx should we try this at the meetup?

Message : @91876402xxxx has volunteered to build already to me.

Message : Forking this conversation from here to actually try this for Saturday to a separate group.

Message : ‚Äé<attached: 00005397-PHOTO-2023-05-25-16-47-50.jpg>

Message : Is it possible to train llm/stable diffusion models (smaller ones) on mac gpu?

Message : ^m1/m2 models

Message : ‚Äé<attached: 00005400-PHOTO-2023-05-25-16-57-53.jpg>

Message : https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/qr_version.jpg

Message : ‚Äé<attached: 00005403-PHOTO-2023-05-25-18-45-40.jpg>

Message : ‚Äé<attached: 00005404-PHOTO-2023-05-25-18-45-41.jpg>

Message : ‚Äé<attached: 00005405-PHOTO-2023-05-25-18-45-41.jpg>

Message : Interesting - is this vanilla chatgpt? Had generally heard that LLMs breaks on math problems because they don‚Äôt recognise universal math ‚Äúrules‚Äù and haven‚Äôt been trained on enough relevant papers etc
Quoted Message :  2023_05_25_3EB05BDEFB4958298C9499.jpeg

Message : GPT 4

Message : ‚Äé<attached: 00005408-PHOTO-2023-05-25-18-51-19.jpg>

Message : Isn‚Äôt the first sentence wrong itself? ü§£ How can there be 7 distinct elements in a set A from {0,1,2,3,4,5} ?
Quoted Message :  2023_05_25_3EB0234FC8F05F1E46D702.jpeg

Message : ‚Äé<attached: 00005410-PHOTO-2023-05-25-19-05-53.jpg>
Quoted Message : Isn‚Äôt the first sentence wrong itself? ü§£ How can there be 7 distinct elements in a set A from {0,1,2,3,4,5} ?

Message : this is also more in line with the IMO solution ü•≤
Quoted Message :  2023_05_25_3EB09695FA7F6B8216C3F4.jpeg

Message : It is really only a matter of time where this triviality will go away no?

Message : This solutions is also flawed.
We cannot always construct a set A of the form {0,1,2,3,‚Ä¶.5^n} where each element is of the form 5^km
Eg., 3 cannot be expressed as a power of 5 üôÇ
Quoted Message :  2023_05_25_3EB09695FA7F6B8216C3F4.jpeg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00005404-PHOTO-2023-05-25-18-45-41.jpg>

Message : ‚Äé<attached: 00005405-PHOTO-2023-05-25-18-45-41.jpg>

Message : Interesting - is this vanilla chatgpt? Had generally heard that LLMs breaks on math problems because they don‚Äôt recognise universal math ‚Äúrules‚Äù and haven‚Äôt been trained on enough relevant papers etc
Quoted Message :  2023_05_25_3EB05BDEFB4958298C9499.jpeg

Message : GPT 4

Message : ‚Äé<attached: 00005408-PHOTO-2023-05-25-18-51-19.jpg>

Message : Isn‚Äôt the first sentence wrong itself? ü§£ How can there be 7 distinct elements in a set A from {0,1,2,3,4,5} ?
Quoted Message :  2023_05_25_3EB0234FC8F05F1E46D702.jpeg

Message : ‚Äé<attached: 00005410-PHOTO-2023-05-25-19-05-53.jpg>
Quoted Message : Isn‚Äôt the first sentence wrong itself? ü§£ How can there be 7 distinct elements in a set A from {0,1,2,3,4,5} ?

Message : this is also more in line with the IMO solution ü•≤
Quoted Message :  2023_05_25_3EB09695FA7F6B8216C3F4.jpeg

Message : It is really only a matter of time where this triviality will go away no?

Message : This solutions is also flawed.
We cannot always construct a set A of the form {0,1,2,3,‚Ä¶.5^n} where each element is of the form 5^km
Eg., 3 cannot be expressed as a power of 5 üôÇ
Quoted Message :  2023_05_25_3EB09695FA7F6B8216C3F4.jpeg

Message : I saw the official solutions.
It‚Äôs noway in-line with the assumption is makes.

Message : *assumptions it makes

Message : I see, that could be possible. Mea Culpa and sorry - probably won't reverify but totally understand your point :)

Message : FWIW: GPT4 is RLHF'd on a ton of math, physics, logic, and code problems. It's possible that even the IMO 2022-style problems were part of that, since they'd professional math educators design the RLHF Set from the rumour mill.

Message : My flatmate spent a month in homi bhaba preparing for the actual international olympiad. I trust his proofreading üòÇüòÖ
But yes, it‚Äôs probably a ‚Äúmatter of time‚Äù before it gets better at these üôÇ

Message : I sincerely hope so
Quoted Message : FWIW: GPT4 is RLHF'd on a ton of math, physics, logic, and code problems. It's possible that even the IMO 2022-style problems were part of that, since they'd professional math educators design the RLHF Set from the rumour mill.

Message : but it‚Äôs funny how gpt builds up a crap story with full confidence with ‚Äú7 villagers‚Äù , when 7 can never be of the form 4n+2 for any integer n.
I was expecting gpt4 to be better in trivial logical reasoning like this :/
Quoted Message :  2023_05_25_3EB0247D36E9913532169A.jpeg

Message : Friends, we're testing the meetup matchmaker for 27th, mind filling it in if you're going to be there? https://forms.gle/dAYM1bUyhTFa7CnL8
Quoted Message : https://twitter.com/ansonyuu/status/1661518548664041472\n\n@9177xxxxxxxx should we try this at the meetup?

Message : Seema kapadia needs to see thisüí°
Quoted Message : Friends, we're testing the meetup matchmaker for 27th, mind filling it in if you're going to be there? https://forms.gle/dAYM1bUyhTFa7CnL8

Message : ‚Äé<attached: 00005425-PHOTO-2023-05-25-19-55-12.jpg>

Message : Very neat stuff Dev !
Does the viz get updated whenever there is a new respondent filling up the google form ?
Quoted Message :  2023_05_25_3EB094CA6B5E98BFA73005.jpeg

Message : Yes

Message : Asking for a friend: i want to create mock design for my app, eg, create a screen for soliciting aadhar card from user. Are there tools which are able to do that?

Message : Nice, how are you creating this viz?
Quoted Message : Yes

Message : Can we fill it in even if we're not going to be there?
Quoted Message : Friends, we're testing the meetup matchmaker for 27th, mind filling it in if you're going to be there? https://forms.gle/dAYM1bUyhTFa7CnL8

Message : Is there a GitHub ?
Quoted Message : Yes

Message : Yeah, but that significantly lowers the chances that you'll meet the person. For you, I strongly recommend taking that 3K INR flight to BLR!
Quoted Message : Can we fill it in even if we're not going to be there?

Message : I'm tempted
Quoted Message : Yeah, but that significantly lowers the chances that you'll meet the person. For you, I strongly recommend taking that 3K INR flight to BLR!

Message : Inflation adjusted, It's cheaper than Christopher Bishop's Pattern Recognition that we bought in undergrad ü§£!
Quoted Message : I'm tempted

Message : Here you go: 
https://github.com/devxpy/ai-matchmaker/
Quoted Message : Is there a GitHub ?

Message : https://a16z.com/2023/05/25/ai-canon/  curated list of resources according to the fund that are super compelling and have had an outsized impact

Message : Fantastic curation
Quoted Message : https://a16z.com/2023/05/25/ai-canon/  curated list of resources according to the fund that are super compelling and have had an outsized impact

Message : https://www.bbc.com/news/health-65709834

Gotdam, though the antibiotic mentioned only works on the specific ‚Äúsuperbug‚Äù bacteria but still insane.

Message : Have some questions. Would be really really helpful if someone who has worked with Pinecone could answer these:

https://github.com/pinecone-io/examples/issues/197

https://github.com/openai/chatgpt-retrieval-plugin/issues/283

TIA

Message : ‚Äé<attached: 00005442-PHOTO-2023-05-26-06-25-57.jpg>

Message : ‚Äé<attached: 00005443-PHOTO-2023-05-26-06-45-20.jpg>
Quoted Message :  2023_05_26_3A88E93092A2F20AB1E5.jpeg

Message : Anthropic round ü´†
Quoted Message :  2023_05_26_3A88E93092A2F20AB1E5.jpeg

Message : Seriously this is nuts tho.
Quoted Message :  2023_05_26_3D792AD2FFE70E9ACB447653D116CE54.jpeg

Message : https://www.cnbc.com/amp/2023/05/25/jpmorgan-develops-ai-investment-advisor.html?__source=instagram%7Cmain

Message : This is insane

Message : This feels like over reliance on LLMs when we know they hallucinate over reasoning and mathematics problems
Quoted Message : https://www.cnbc.com/amp/2023/05/25/jpmorgan-develops-ai-investment-advisor.html?__source=instagram%7Cmain

Message : Which would factor into selections of investments

Message : But investments are sometimes about modelling behaviour than mathematics? I assume they have amazing quants already, but LLMs are amazing herd followers - if you train them on news they can for eg filter the most popular consensus reliably. The hallucinations I think come when you ask for stuff that‚Äôs out of training distribution

Message : Folks it's simpler than this

Morgan Stanley needs to be viewed as doing something to counter AI.

Incorporating it as part of their workflows is the easiest way to arrest investor concerns
Quoted Message : But investments are sometimes about modelling behaviour than mathematics? I assume they have amazing quants already, but LLMs are amazing herd followers - if you train them on news they can for eg filter the most popular consensus reliably. The hallucinations I think come when you ask for stuff that‚Äôs out of training distribution

Message : They'll probably end up using llms to generate derived features for their ML models
Quoted Message : Folks it's simpler than this\n\nMorgan Stanley needs to be viewed as doing something to counter AI.\n\nIncorporating it as part of their workflows is the easiest way to arrest investor concerns

Message : Anyone has access to this article ?\n\nhttps://www.theinformation.com/articles/how-microsoft-swallowed-its-pride-to-make-a-massive-bet-on-openai

Message : Anyone has access to this article ?

https://www.theinformation.com/articles/how-microsoft-swallowed-its-pride-to-make-a-massive-bet-on-openai

Message : Their earnings guidance is nuts
Quoted Message :  2023_05_26_3A88E93092A2F20AB1E5.jpeg

Message : Read the transcripts

Message : You can ask Bard to create the summary of the article link
Quoted Message : Anyone has access to this article ?\n\nhttps://www.theinformation.com/articles/how-microsoft-swallowed-its-pride-to-make-a-massive-bet-on-openai


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This feels like over reliance on LLMs when we know they hallucinate over reasoning and mathematics problems
Quoted Message : https://www.cnbc.com/amp/2023/05/25/jpmorgan-develops-ai-investment-advisor.html?__source=instagram%7Cmain

Message : Which would factor into selections of investments

Message : But investments are sometimes about modelling behaviour than mathematics? I assume they have amazing quants already, but LLMs are amazing herd followers - if you train them on news they can for eg filter the most popular consensus reliably. The hallucinations I think come when you ask for stuff that‚Äôs out of training distribution

Message : Folks it's simpler than this

Morgan Stanley needs to be viewed as doing something to counter AI.

Incorporating it as part of their workflows is the easiest way to arrest investor concerns
Quoted Message : But investments are sometimes about modelling behaviour than mathematics? I assume they have amazing quants already, but LLMs are amazing herd followers - if you train them on news they can for eg filter the most popular consensus reliably. The hallucinations I think come when you ask for stuff that‚Äôs out of training distribution

Message : They'll probably end up using llms to generate derived features for their ML models
Quoted Message : Folks it's simpler than this\n\nMorgan Stanley needs to be viewed as doing something to counter AI.\n\nIncorporating it as part of their workflows is the easiest way to arrest investor concerns

Message : Anyone has access to this article ?\n\nhttps://www.theinformation.com/articles/how-microsoft-swallowed-its-pride-to-make-a-massive-bet-on-openai

Message : Anyone has access to this article ?

https://www.theinformation.com/articles/how-microsoft-swallowed-its-pride-to-make-a-massive-bet-on-openai

Message : Their earnings guidance is nuts
Quoted Message :  2023_05_26_3A88E93092A2F20AB1E5.jpeg

Message : Read the transcripts

Message : You can ask Bard to create the summary of the article link
Quoted Message : Anyone has access to this article ?\n\nhttps://www.theinformation.com/articles/how-microsoft-swallowed-its-pride-to-make-a-massive-bet-on-openai

Message : https://twitter.com/willdepue/status/1661781360619696128?t=Mjv8eQJ28AvW1cFSH_NO8w&s=08

Someone created arvix papers embedding. Sharing in case you are looking for something like this.

Message : Tried it with a bunch of articles. Bard/G-Search seems to be able to access the content behind paywall , but seems to be hallucinating quite a bit too. 
It's especially bad at follow up questions

ChatGPT/Bing-Search doesn't seem to have a work around to accessing paywall content
Quoted Message : You can ask Bard to create the summary of the article link

Message : https://a16z.com/2023/05/25/ai-canon/ - good compilation of resources

Message : Seems pretty good, hoping to read all of it over the weekend üôÇ
Quoted Message : https://a16z.com/2023/05/25/ai-canon/ - good compilation of resources

Message : Can anyone tell Which embeddings model did they use?
Quoted Message : https://twitter.com/willdepue/status/1661781360619696128?t=Mjv8eQJ28AvW1cFSH_NO8w&s=08\n\nSomeone created arvix papers embedding. Sharing in case you are looking for something like this.

Message : InstructorXL

https://huggingface.co/hkunlp/instructor-xl

https://twitter.com/willdepue/status/1661788343443791875?t=CFBOxcpWzl9KfJHvlyxOAw&s=19
Quoted Message : Can anyone tell Which embeddings model did they use?

Message : Soumith Chintala's take on the $NVDA rally !

https://twitter.com/soumithchintala/status/1661746183826735104?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : If you've ever used a TPU pod in production, you'd know his directionally right, timeline unknown.
Quoted Message : Soumith Chintala's take on the $NVDA rally !\n\nhttps://twitter.com/soumithchintala/status/1661746183826735104?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : I haven't but as someone wrote in the thread
"Stock markets don't run on logic, but on sentiment" :)
Quoted Message : If you've ever used a TPU pod in production, you'd know his directionally right, timeline unknown.

Message : anyone who knows about the default chunking systems in Pinecone?
Quoted Message : Have some questions. Would be really really helpful if someone who has worked with Pinecone could answer these:\n\nhttps://github.com/pinecone-io/examples/issues/197\n\nhttps://github.com/openai/chatgpt-retrieval-plugin/issues/283\n\nTIA

Message : They don't do chunking
Quoted Message : anyone who knows about the default chunking systems in Pinecone?

Message : You do it..embed the chunks and upsert it with Metadata

Message : I‚Äôm using and exploring```chatgpt-retrieval-plugin```.
The data is getting chunked as I‚Äôve given a proof of in the SS attached, though I am not chunking it.
Does that mean the ```retrieval-plugin``` is chunking the data, if it‚Äôs not done at the vectorDB level?

Can anyone confirm who has worked with ```Pinecone``` and/or ```chatgpt-retrieval-plugin``` ?
Quoted Message : They don't do chunking

Message : I can confirm that pinecone doesn't do chunking for you. Haven't used chatgpt-retrieval-plugin.

Message : We use pinecone and it doesn't do chunking. For that, we use llama index

Message : I have a hypothesis. Curious to hear others‚Äô thoughts.

Gradually LLMs will become too cheap to meter. (Especially when Google, Microsoft and Apple bake them into OS as a service).

Agree or disagree?

Message : interesting‚Ä¶

Message : It will be fun to imagine what applications will be possible when LLMs are almost free
Quoted Message : I have a hypothesis. Curious to hear others‚Äô thoughts.\n\nGradually LLMs will become too cheap to meter. (Especially when Google, Microsoft and Apple bake them into OS as a service).\n\nAgree or disagree?

Message : I guess they would be baked into every OS and products as long as they are not giving financial or health advice. May be the regulators will rein in these kind of products and services first.
Quoted Message : It will be fun to imagine what applications will be possible when LLMs are almost free

Message : What timeline are you thinking? 5 years out or more like 15 years out?
Quoted Message : I have a hypothesis. Curious to hear others‚Äô thoughts.\n\nGradually LLMs will become too cheap to meter. (Especially when Google, Microsoft and Apple bake them into OS as a service).\n\nAgree or disagree?

Message : If we can get Linux running on apple silicon we will have many local LLMs apps in the open source ecosystem

Message : And And I think Asahi Linux is getting there. So maybe less than 5 years?

https://asahilinux.org/about/

Message : Have you seen this - https://github.com/ParisNeo/gpt4all-ui 

I can run various open source models on my mac using this.
Quoted Message : If we can get Linux running on apple silicon we will have many local LLMs apps in the open source ecosystem

Message : Yes you can run models. But can you change or influence the OS to work with you?

Message : I think 5 years. Bcz most of these tools are positioned to increase productivity. Imp question to ponder is what gets shortened, when the productivity increases. 

In past, when we content got cheaply accessible. It gave rise to influencer marketing and really shortened the attention span.
Quoted Message : What timeline are you thinking? 5 years out or more like 15 years out?

Message : With Linux one could write a OS driver to or a kernel module if needed

Message : Bhasha Daan : An crowdsourcing initiative for Indian languages (Beta)

https://bhashini.gov.in/bhashadaan/en/home

https://www.linkedin.com/posts/microsoft_satya-nadella-on-linkedin-the-rate-of-diffusion-activity-7066997625346031616-JSLA/

Message : Jarvis
Quoted Message : It will be fun to imagine what applications will be possible when LLMs are almost free

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ~‚ÄØMadhur Sawhney

Message : Isn't it a bit crazy that Tony stark was sitting on that tech all this while without open sourcing it ?

No need for Friday. Even Jarvis v1 would've been nice to have for FOSS
Quoted Message : Jarvis

Message : 5
Quoted Message : What timeline are you thinking? 5 years out or more like 15 years out?

Message : Less than that actually

Message : 2-3 years seems doable

Message : Either LLMs will have to shrink quite a bit or we will only have the lower end of the LLMs on the device.

No way we will be pushing so much RAM in a portable device.

Unless of course hardware becomes really better
Quoted Message : I have a hypothesis. Curious to hear others‚Äô thoughts.\n\nGradually LLMs will become too cheap to meter. (Especially when Google, Microsoft and Apple bake them into OS as a service).\n\nAgree or disagree?

Message : my bet is that a good enough local LLM will do most of the job, with perhaps complex workflows seamlessly flowing to a cloud endpoint
Quoted Message : Either LLMs will have to shrink quite a bit or we will only have the lower end of the LLMs on the device.\n\nNo way we will be pushing so much RAM in a portable device.\n\nUnless of course hardware becomes really better

Message : Yeah I read a very interesting interview on this. 

Anthropic is trying to come up with ways to control the amount of compute used to respond to a query based on its complexity.
Quoted Message : my bet is that a good enough local LLM will do most of the job, with perhaps complex workflows seamlessly flowing to a cloud endpoint

Message : We actually don't need LLM call for all queries, which is the case rn. This also results in variable answers for a same given query, which is confusing.

Message : or some other company build something close to apple silicon
Quoted Message : If we can get Linux running on apple silicon we will have many local LLMs apps in the open source ecosystem

Message : Heard geohot wants to build AI hardware

Message : Run llama 65B for $15,000.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : 5
Quoted Message : What timeline are you thinking? 5 years out or more like 15 years out?

Message : Less than that actually

Message : 2-3 years seems doable

Message : Either LLMs will have to shrink quite a bit or we will only have the lower end of the LLMs on the device.

No way we will be pushing so much RAM in a portable device.

Unless of course hardware becomes really better
Quoted Message : I have a hypothesis. Curious to hear others‚Äô thoughts.\n\nGradually LLMs will become too cheap to meter. (Especially when Google, Microsoft and Apple bake them into OS as a service).\n\nAgree or disagree?

Message : my bet is that a good enough local LLM will do most of the job, with perhaps complex workflows seamlessly flowing to a cloud endpoint
Quoted Message : Either LLMs will have to shrink quite a bit or we will only have the lower end of the LLMs on the device.\n\nNo way we will be pushing so much RAM in a portable device.\n\nUnless of course hardware becomes really better

Message : Yeah I read a very interesting interview on this. 

Anthropic is trying to come up with ways to control the amount of compute used to respond to a query based on its complexity.
Quoted Message : my bet is that a good enough local LLM will do most of the job, with perhaps complex workflows seamlessly flowing to a cloud endpoint

Message : We actually don't need LLM call for all queries, which is the case rn. This also results in variable answers for a same given query, which is confusing.

Message : or some other company build something close to apple silicon
Quoted Message : If we can get Linux running on apple silicon we will have many local LLMs apps in the open source ecosystem

Message : Heard geohot wants to build AI hardware

Message : Run llama 65B for $15,000.

Message : its actually a fun project though he is trying to get AMD drivers/k mods on par with nvidia

Message : love seeing his streams man

Message : geohot is an interesting character. I love his engineering prowess, but we couldn't see his business side / success when running comma.ai

Message : You can do that with 2 x A6000 48gb (8k + 2k rest = 10k)
Quoted Message : Run llama 65B for $15,000.

Message : true that
Quoted Message : geohot is an interesting character. I love his engineering prowess, but we couldn't see his business side / success when running comma.ai

Message : Nvidia being a B2B business, I wonder how long they will be a 1 trillion company. 

Meaning a lot of people are going to try to get a piece of that pie. And engineers are not actually loyal, unlike consumer companies like apple and Tesla(?)

Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : Intelligent doc/image search without uploading personal files to the cloud.

Siri/Assistant
Quoted Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : Sharif, the founder of Lexica tweeted that he was on a flight and wanted to search some topic.
The inflight wifi wasn‚Äôt working so he was unable to google.
Then he realised he had a local Llama model running on his iphone and found the answer there.
Quoted Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : was speaking with a data storage company considering building it's local LLMs to help with basic ops on storage/datacentres
Quoted Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : I go upto the computer and ask it to drop my mother a good morning message on WhatsApp, find me which code is breaking from user and server logs and schedule an appointment with my trainer
Quoted Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : 1. Small workload that doesn't need a state of the art LLM
2. Enterprise information (but I think MS is solving this well, from what I understand from the recent MS build)
Quoted Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : So more of a privacy concern? Or latency / cost concern?
Quoted Message : Intelligent doc/image search without uploading personal files to the cloud.\n\nSiri/Assistant

Message : I remember this. This is super cool.

The whole world's information in your laptop
Quoted Message : Sharif, the founder of Lexica tweeted that he was on a flight and wanted to search some topic.\nThe inflight wifi wasn‚Äôt working so he was unable to google.\nThen he realised he had a local Llama model running on his iphone and found the answer there.

Message : This makes sense to me. Do we have any evals of how good llama is compared to GPT-4 for information retrieval?
Quoted Message : Sharif, the founder of Lexica tweeted that he was on a flight and wanted to search some topic.\nThe inflight wifi wasn‚Äôt working so he was unable to google.\nThen he realised he had a local Llama model running on his iphone and found the answer there.

Message : Both.

Use cases where either of them are crucial you might want to push to on device.
Quoted Message : So more of a privacy concern? Or latency / cost concern?

Message : Siri will be less stupid as it can under context

Notifications can be summarized like Nirant is doing for the group
Quoted Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : I agree that privacy will be the major factor for client side implementation. I suppose we will also learn more in Jun. After AI regulation draft in US and Eur
Quoted Message : So more of a privacy concern? Or latency / cost concern?

Message : Like a SQL query helper?
Quoted Message : was speaking with a data storage company considering building it's local LLMs to help with basic ops on storage/datacentres

Message : Does anybody here work/do research in medical/health ai ?

I am just getting started into the field.
Saw this interesting perspective :
https://twitter.com/drhughharvey/status/1661826562935726080?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : I think that enterprise info can still be solved by running a LLM in house on a server instead of individual devices? ü§î
Quoted Message : 1. Small workload that doesn't need a state of the art LLM\n2. Enterprise information (but I think MS is solving this well, from what I understand from the recent MS build)

Message : yes, plus agents for partition management, DB health management
Quoted Message : Like a SQL query helper?

Message : Yeah. The "on premise" pricing model is gonna have a major comeback

Message : +1, something like privateGPT having API endpoints?
Quoted Message : I think that enterprise info can still be solved by running a LLM in house on a server instead of individual devices? ü§î

Message : for me, it's the cost of LLM being borne by the client (LLMs that run on phone can enable AI to be included in most free apps/games)

Message : regulatory. if u pay close attention to how EU AI guidelines are shaping up (which will influence all other countries), personal health info will be covered under stringent regulations. 

i think we forget that GPT, and Google's Medical LLM have NOT cleared hipaa
Quoted Message : Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work

Message : for most enterprise usecases however, we have seen acceptance and buy in from banks/enterprises. Forget LLM, the big fight was on-premise vs cloud for normal servers

Message : Pocket internets?
Quoted Message : Sharif, the founder of Lexica tweeted that he was on a flight and wanted to search some topic.\nThe inflight wifi wasn‚Äôt working so he was unable to google.\nThen he realised he had a local Llama model running on his iphone and found the answer there.

Message : Also how did he pull this off any references?

Message : With all the hallucination, I think we have a long way to go before we can use LLMs for medical data, notwithstanding the regulatory environment
Quoted Message : regulatory. if u pay close attention to how EU AI guidelines are shaping up (which will influence all other countries), personal health info will be covered under stringent regulations. \n\ni think we forget that GPT, and Google's Medical LLM have NOT cleared hipaa

Message : long way than this ? https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model 

passes  US Medical Licensing Exam with an expert score.
Quoted Message : With all the hallucination, I think we have a long way to go before we can use LLMs for medical data, notwithstanding the regulatory environment

Message : From the text: first LLM to perform at an ‚Äúexpert‚Äù test-taker level performance on the MedQA dataset of US Medical Licensing Examination (USMLE)-style questions, reaching 85%+ accuracy, and it was the first AI system to reach a passing score on the MedMCQA dataset comprising Indian AIIMS and NEET medical examination questions, scoring 72.3%.
Quoted Message : long way than this ? https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model \n\npasses  US Medical Licensing Exam with an expert score.

Message : Aren't these exams notoriously amenable to rote learning?

Message : that is not the interesting part of the paper. 
the interesting part is this

"We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions,* physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p < 0.001)*. We also observed significant improvements compared to Med-PaLM on every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations."
Quoted Message : Aren't these exams notoriously amenable to rote learning?

Message : And there will be an LLM SDK (baked into ios for example) exposing LLM capabilities to app developers ?
Quoted Message : for me, it's the cost of LLM being borne by the client (LLMs that run on phone can enable AI to be included in most free apps/games)

Message : There's agent SDKs like Fixie, something similar for LLMs?
Quoted Message : And there will be an LLM SDK (baked into ios for example) exposing LLM capabilities to app developers ?

Message : So there's two claims here.
1. PaLM V2 is better than V1. Ok, cool.
2. Of the nine axes they evaluated, physicians preferred PaLM's response over a clinician response. Cool again, but why did they prefer it? Was it because it produced a more verbose response? Was it because they were preconditioned by knowing they're evaluating an ai response? etc.

I'm not arguing it's not a significant improvement but rather that it doesn't convince me that it's ready for a life or death scenario especially when it gets something wrong.

It seems Google too knows this and hence the limited release and iteration.
Quoted Message : that is not the interesting part of the paper. \nthe interesting part is this\n\n\"We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions,* physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p < 0.001)*. We also observed significant improvements compared to Med-PaLM on every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form \"adversarial\" questions to probe LLM limitations.\"

Message : Or could Apple for example include a tiered subscription for app developers for the "local LLM api service" running on the ios device ?

Upto x calls/ day : free
> X and < Y : $ A /call
> Y and < Z : $ B/ call
Quoted Message : for me, it's the cost of LLM being borne by the client (LLMs that run on phone can enable AI to be included in most free apps/games)

Message : Ahaha, that's a risky precedence ü´†
Quoted Message : Or could Apple for example include a tiered subscription for app developers for the \"local LLM api service\" running on the ios device ?\n\nUpto x calls/ day : free\n> X and < Y : $ A /call\n> Y and < Z : $ B/ call

Message : Also somewhat related, somewhat tangential q :

Have you guys tried rewind app on Mac ?
It continuously and smartly records screen and does OCR to enable search across all apps

Have you tried it @91986822xxxx @91991692xxxx ?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : long way than this ? https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model 

passes  US Medical Licensing Exam with an expert score.
Quoted Message : With all the hallucination, I think we have a long way to go before we can use LLMs for medical data, notwithstanding the regulatory environment

Message : From the text: first LLM to perform at an ‚Äúexpert‚Äù test-taker level performance on the MedQA dataset of US Medical Licensing Examination (USMLE)-style questions, reaching 85%+ accuracy, and it was the first AI system to reach a passing score on the MedMCQA dataset comprising Indian AIIMS and NEET medical examination questions, scoring 72.3%.
Quoted Message : long way than this ? https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model \n\npasses  US Medical Licensing Exam with an expert score.

Message : Aren't these exams notoriously amenable to rote learning?

Message : that is not the interesting part of the paper. 
the interesting part is this

"We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions,* physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p < 0.001)*. We also observed significant improvements compared to Med-PaLM on every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations."
Quoted Message : Aren't these exams notoriously amenable to rote learning?

Message : And there will be an LLM SDK (baked into ios for example) exposing LLM capabilities to app developers ?
Quoted Message : for me, it's the cost of LLM being borne by the client (LLMs that run on phone can enable AI to be included in most free apps/games)

Message : There's agent SDKs like Fixie, something similar for LLMs?
Quoted Message : And there will be an LLM SDK (baked into ios for example) exposing LLM capabilities to app developers ?

Message : So there's two claims here.
1. PaLM V2 is better than V1. Ok, cool.
2. Of the nine axes they evaluated, physicians preferred PaLM's response over a clinician response. Cool again, but why did they prefer it? Was it because it produced a more verbose response? Was it because they were preconditioned by knowing they're evaluating an ai response? etc.

I'm not arguing it's not a significant improvement but rather that it doesn't convince me that it's ready for a life or death scenario especially when it gets something wrong.

It seems Google too knows this and hence the limited release and iteration.
Quoted Message : that is not the interesting part of the paper. \nthe interesting part is this\n\n\"We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions,* physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p < 0.001)*. We also observed significant improvements compared to Med-PaLM on every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form \"adversarial\" questions to probe LLM limitations.\"

Message : Or could Apple for example include a tiered subscription for app developers for the "local LLM api service" running on the ios device ?

Upto x calls/ day : free
> X and < Y : $ A /call
> Y and < Z : $ B/ call
Quoted Message : for me, it's the cost of LLM being borne by the client (LLMs that run on phone can enable AI to be included in most free apps/games)

Message : Ahaha, that's a risky precedence ü´†
Quoted Message : Or could Apple for example include a tiered subscription for app developers for the \"local LLM api service\" running on the ios device ?\n\nUpto x calls/ day : free\n> X and < Y : $ A /call\n> Y and < Z : $ B/ call

Message : Also somewhat related, somewhat tangential q :

Have you guys tried rewind app on Mac ?
It continuously and smartly records screen and does OCR to enable search across all apps

Have you tried it @91986822xxxx @91991692xxxx ?

Message : not yet, but have heard great things about it

ps: it's by optimizely's founder, our #1 erstwhile competitor for vwo :)
Quoted Message : Also somewhat related, somewhat tangential q :\n\nHave you guys tried rewind app on Mac ?\nIt continuously and smartly records screen and does OCR to enable search across all apps\n\nHave you tried it @9198xxxxxxxx @9199xxxxxxxx ?

Message : The reference: https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md
Quoted Message : Sharif, the founder of Lexica tweeted that he was on a flight and wanted to search some topic.\nThe inflight wifi wasn‚Äôt working so he was unable to google.\nThen he realised he had a local Llama model running on his iphone and found the answer there.

Message : Anyone have experience using the guardrails (https://shreyar.github.io/guardrails/)-

I got stuck with one bug, can anyone check - https://github.com/ShreyaR/guardrails/issues/168

Thanks a lot

Message : ‚Äé<attached: 00005546-PHOTO-2023-05-26-14-02-48.jpg>

Message : Sama may not be in India, but he is spiritually.
Quoted Message :  2023_05_26_3A8AD34AC457A7A47C10.jpeg

Message : https://twitter.com/soumithchintala/status/1661746183826735104?s=48&t=ACPHEfclkXmi9Z92RTsh9g

Can anyone help provide more context / thoughts on this tweet?

Does training and inference merit different GPU lines? Not sure how different the core primitive in backpropagation math is from inference

Message : He is coming next week!
Quoted Message : Sama may not be in India, but he is spiritually.

Message : Why isn't the developed west not highlighted?
Quoted Message :  2023_05_26_3A8AD34AC457A7A47C10.jpeg

Message : cc Shreya, the creator of Guardrails @1217305xxxx is here as well btw
Quoted Message : Anyone have experience using the guardrails (https://shreyar.github.io/guardrails/)-\n\nI got stuck with one bug, can anyone check - https://github.com/ShreyaR/guardrails/issues/168 \n\nThanks a lot

Message : And they've a pretty active Discord

Message : ahh okay. let me join the discord too and message them..
Quoted Message : cc Shreya, the creator of Guardrails @121xxxxxxxx is here as well btw

Message : You might want to start by using the latest guardrails release which is not on Pypi yet
Quoted Message : ahh okay. let me join the discord too and message them..

Message : The biggest issue with using GPU for inference is that the I/O latency.

During training we use batch training so we can amortize the latency throughout the batch.

But usually if inference is a single instance. We have to consider the overhead of loading the model to memory, loading the data and then doing inference.

While in a cpu its gonna be much faster due to lower latency
Quoted Message : https://twitter.com/soumithchintala/status/1661746183826735104?s=48&t=ACPHEfclkXmi9Z92RTsh9g\n\nCan anyone help provide more context / thoughts on this tweet?\n\nDoes training and inference merit different GPU lines? Not sure how different the core primitive in backpropagation math is from inference

Message : "Global economy" which is vastly dominated by developed west.
Quoted Message : Why isn't the developed west not highlighted?

Message : how to do that? sorry I am python beginner.
Quoted Message : You might want to start by using the latest guardrails release which is not on Pypi yet

Message : Let's move this to DMs
Quoted Message : how to do that? sorry I am python beginner.

Message : So i guess its entirely upto whether your inference is batch and you are loading the model once.

Then use gpu

If your loading model to memory and doing inference on need basis.

Then gpu is not effective. Especially given the power consumption of the thousands of SM cores. Those cores consume power regardless of whether they are executing instructions.
Quoted Message : The biggest issue with using GPU for inference is that the I/O latency.\n\nDuring training we use batch training so we can amortize the latency throughout the batch.\n\nBut usually if inference is a single instance. We have to consider the overhead of loading the model to memory, loading the data and then doing inference.\n\nWhile in a cpu its gonna be much faster due to lower latency

Message : Thanks this helps! I‚Äôll dm you as well
Quoted Message : So i guess its entirely upto whether your inference is batch and you are loading the model once.\n\nThen use gpu\n\nIf your loading model to memory and doing inference on need basis. \n\nThen gpu is not effective. Especially given the power consumption of the thousands of SM cores. Those cores consume power regardless of whether they are executing instructions.

Message : FYI, its not working in the latest release too - 0.1.7
Quoted Message : You might want to start by using the latest guardrails release which is not on Pypi yet

Message : Is there anyone here who works for the DiskANN project for microsoft research? Or know someone there?

Message : Not really true. It also depends on how fast you can copy the model weights to GPU memory. You can reach speed as fast as a CPU ram too!
Quoted Message : The biggest issue with using GPU for inference is that the I/O latency.\n\nDuring training we use batch training so we can amortize the latency throughout the batch.\n\nBut usually if inference is a single instance. We have to consider the overhead of loading the model to memory, loading the data and then doing inference.\n\nWhile in a cpu its gonna be much faster due to lower latency

Message : I don't have an answer to this. 
But if you're using this then I'm guessing you'd want to host it somewhere. If that's so you can also look at the ANN models that cloud platforms provide, if it's enough cost-effective (google's : https://cloud.google.com/vertex-ai/docs/matching-engine/ann-service-overview)
Quoted Message : Is there anyone here who works for the DiskANN project for microsoft research? Or know someone there?

Message : nono, I just want to connect with a few people working in the team and bounce off ideas lol‚Ä¶
Quoted Message : I don't have an answer to this. \nBut if you're using this then I'm guessing you'd want to host it somewhere. If that's so you can also look at the ANN models that cloud platforms provide, if it's enough cost-effective (google's : https://cloud.google.com/vertex-ai/docs/matching-engine/ann-service-overview)

Message : I am working on a detailed prompting guide highlighting all use cases! 

Any great links you have come up to? Please share.
I am done with Andrew NG's LLM prompt course.

Message : Will publish the blog as well.
Quoted Message : I am working on a detailed prompting guide highlighting all use cases! \n\nAny great links you have come up to? Please share.\nI am done with Andrew NG's LLM prompt course.

Message : LLM Prompting Guide from @91993397xxxx from the community: 
https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77
Quoted Message : I am working on a detailed prompting guide highlighting all use cases! \n\nAny great links you have come up to? Please share.\nI am done with Andrew NG's LLM prompt course.

Message : And is pretty damn detailed!

Message : ChatGPT rolling out to India today for iOS https://twitter.com/OfficialLoganK/status/1661834375028154406

Message : has anyone implemented this repo
https://github.com/go-skynet/LocalAI
Been trying for a while but facing lots of issues

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : This is really good @91993397xxxx and seems friendly to non developers too. Love the part on Tool usage.
Quoted Message : LLM Prompting Guide from @9199xxxxxxxx from the community: \nhttps://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

Message : Hi @91773788xxxx ,
I joined the group just now, can you please share your prompting guide again?

Message : Hi Arpit,
Here is the link: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77
Quoted Message : Hi @9177xxxxxxxx ,\nI joined the group just now, can you please share your prompting guide again?

Message : https://www.cnbc.com/amp/2023/05/25/elon-musks-neuralink-gets-fda-approval-for-in-human-study.html

Message : Should we add it to the group description? 
@91773788xxxx
Quoted Message : Hi Arpit,\nHere is the link: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @91773788xxxx

Message : Expiration TTL: I've been storing date and time in the metadata and dropping entries using a cron.
Quoted Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @9177xxxxxxxx

Message : how do you go through all the vector keys? There's no filter only by meta right?

Message : Would using Redis help?
Quoted Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @9177xxxxxxxx

Message : "To start, we're releasing the embeddings for every research paper on the Arxiv. That's over 4m items, 600m tokens, and 3.07 billion vector dimensions."


https://twitter.com/willdepue/status/1661781355452325889?s=48&t=pt9BgXoRTmqx5FEPyAl9bg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This is really good @91993397xxxx and seems friendly to non developers too. Love the part on Tool usage.
Quoted Message : LLM Prompting Guide from @9199xxxxxxxx from the community: \nhttps://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

Message : Hi @91773788xxxx ,
I joined the group just now, can you please share your prompting guide again?

Message : Hi Arpit,
Here is the link: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77
Quoted Message : Hi @9177xxxxxxxx ,\nI joined the group just now, can you please share your prompting guide again?

Message : https://www.cnbc.com/amp/2023/05/25/elon-musks-neuralink-gets-fda-approval-for-in-human-study.html

Message : Should we add it to the group description? 
@91773788xxxx
Quoted Message : Hi Arpit,\nHere is the link: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @91773788xxxx

Message : Expiration TTL: I've been storing date and time in the metadata and dropping entries using a cron.
Quoted Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @9177xxxxxxxx

Message : how do you go through all the vector keys? There's no filter only by meta right?

Message : Would using Redis help?
Quoted Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @9177xxxxxxxx

Message : "To start, we're releasing the embeddings for every research paper on the Arxiv. That's over 4m items, 600m tokens, and 3.07 billion vector dimensions."


https://twitter.com/willdepue/status/1661781355452325889?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Do u see a lot of cacheable queries? I thought that the content would be so disparate that cache hits would be very low
Quoted Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @9177xxxxxxxx

Message : In business usecases it can save a decent share of queries.
Quoted Message : Do u see a lot of cacheable queries? I thought that the content would be so disparate that cache hits would be very low

Message : @91982023xxxx
Quoted Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @9177xxxxxxxx

Message : really ? but ur vector db query would be a prompt right ? u still see opportunities for caching ?
Quoted Message : In business usecases it can save a decent share of queries.

Message : genuine question btw

Message : Who's building LLM benchmarking + observability + semantic caching bundled in one?

Message : yes - running backtests on some datasets and it looks promising. Will come back when we have production datasets to backtest on. Simple caches already are great for dev and simple classification problems. I think semantic would be useful for RAGs
Quoted Message : Do u see a lot of cacheable queries? I thought that the content would be so disparate that cache hits would be very low

Message : hmm.. very interesting. would love to know more when ur ready. have been thinking about the caching problem for a long time.

Message : yea - people ask similar questions to a chatbot. A friend told me 30% of his chatbot questions (niche) were similar - so could build a cache bucket for such queries
Quoted Message : genuine question btw

Message : In that case, ur cache also needs to be a vector db (like redis). Cos it will be difficult to have a cache hit without transforming the "question" into an embedding first

Message : Seen in our case. True for users who work in v specific niche. Their prompts can be bundled w little difference in results
Quoted Message : really ? but ur vector db query would be a prompt right ? u still see opportunities for caching ?

Message : yes
Quoted Message : In that case, ur cache also needs to be a vector db (like redis). Cos it will be difficult to have a cache hit without transforming the \"question\" into an embedding first

Message : Oh you're Rohit from portkey? Hi again
Quoted Message : yea - people ask similar questions to a chatbot. A friend told me 30% of his chatbot questions (niche) were similar - so could build a cache bucket for such queries

Message : haha, yes! Hi Ankur
Quoted Message : Oh you're Rohit from portkey? Hi again

Message : This is also the similar usecase that we had thought of as the queries are kind of similar we were thinking to build semantic cache so we can reduce the latency for openai hits and get the results fastwr to users on bot  But as mentioned here u will need to first create a embedding and then this may work based on cosine similarity , but after some thinking as we were thinking this to reduce the latency of the hits we just did not think this will be helpful as still there is embedding creation part involved and if u go with different embedding model like sbert or something  for this specific cache which has lower latency that is an over kill as u will have now 2 kinds of retrieval as openai embeddings u may still want it as they are superioir , so rather than that we just went with streaming api ,and that helped us better our ux and also helped us maintain the latency or make it feel not that slow .
Quoted Message : In that case, ur cache also needs to be a vector db (like redis). Cos it will be difficult to have a cache hit without transforming the \"question\" into an embedding first

Message : Hope this helps a long message ,but i feel in this field qe all are facing kind of similar issues ..

Message : thanks! streaming helps with latency, but you'd still incur twice the cost for the same / similar questions, right?
Quoted Message : This is also the similar usecase that we had thought of as the queries are kind of similar we were thinking to build semantic cache so we can reduce the latency for openai hits and get the results fastwr to users on bot  But as mentioned here u will need to first create a embedding and then this may work based on cosine similarity , but after some thinking as we were thinking this to reduce the latency of the hits we just did not think this will be helpful as still there is embedding creation part involved and if u go with different embedding model like sbert or something  for this specific cache which has lower latency that is an over kill as u will have now 2 kinds of retrieval as openai embeddings u may still want it as they are superioir , so rather than that we just went with streaming api ,and that helped us better our ux and also helped us maintain the latency or make it feel not that slow .

Message : Very intresting to learn
Quoted Message : This is also the similar usecase that we had thought of as the queries are kind of similar we were thinking to build semantic cache so we can reduce the latency for openai hits and get the results fastwr to users on bot  But as mentioned here u will need to first create a embedding and then this may work based on cosine similarity , but after some thinking as we were thinking this to reduce the latency of the hits we just did not think this will be helpful as still there is embedding creation part involved and if u go with different embedding model like sbert or something  for this specific cache which has lower latency that is an over kill as u will have now 2 kinds of retrieval as openai embeddings u may still want it as they are superioir , so rather than that we just went with streaming api ,and that helped us better our ux and also helped us maintain the latency or make it feel not that slow .

Message : Yeah , u are right , if cost is in question than building a semantic cache with sbert model for retrieval of the same queries answered may help . U may need to create a metadata of the response answered with the query embedding and store that . And when new query comes just fire and get the sbert query se get the similar matches on queries and then acc to  that u may reduce your calls . Very intresting approch this we thought but thought to implement streaming first .. but to make sure this is caching at vectordb layer and not at openai level ..

Message : This is intresting to desing ...
Quoted Message : Yeah , u are right , if cost is in question than building a semantic cache with sbert model for retrieval of the same queries answered may help . U may need to create a metadata of the response answered with the query embedding and store that . And when new query comes just fire and get the sbert query se get the similar matches on queries and then acc to  that u may reduce your calls . Very intresting approch this we thought but thought to implement streaming first .. but to make sure this is caching at vectordb layer and not at openai level ..

Message : Yea I‚Äôm almost done except for the ttl bit
Quoted Message : This is intresting to desing ...

Message : So u have built this using? Like redis or something . Anything that u can share on design or what u have used .
I found this when i was thinkigj about this .
https://github.com/zilliztech/GPTCache
Quoted Message : Yea I‚Äôm almost done except for the ttl bit

Message : Not sure but technically redis vector search uses RedisJSON. Which supports update and delete of keys. So I think setting up TTL to JSON object is possible via Multi command.
Quoted Message : We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? @9177xxxxxxxx

Message : Ttl may be for u can be -1 right if the semantic match is beyond aome thrsold for incoming query u dont need ttl per say? Am i missing some

Message : Thing *

Message : Yea we saw GPTCache - we built it a little bit further and faster. Design and concept is similar
Quoted Message : So u have built this using? Like redis or something . Anything that u can share on design or what u have used .\nI found this when i was thinkigj about this .\nhttps://github.com/zilliztech/GPTCache

Message : This comment also says this
https://github.com/RedisJSON/RedisJSON/issues/415#issuecomment-886577326
Quoted Message : Not sure but technically redis vector search uses RedisJSON. Which supports update and delete of keys. So I think setting up TTL to JSON object is possible via Multi command.

Message : Thanks! I‚Äôll check this out
Quoted Message : This comment also says this\nhttps://github.com/RedisJSON/RedisJSON/issues/415#issuecomment-886577326

Message : This is the core difference between CPUs and GPUs: CPUs are optimized for latency: to finish a task as fast as possible; GPUs are optimized for throughput: they are slow, but they operate on bulks of data at once.

https://towardsdatascience.com/the-ai-illustrated-guide-why-are-gpus-so-powerful-99f4ae85a5c3
Quoted Message : Not really true. It also depends on how fast you can copy the model weights to GPU memory. You can reach speed as fast as a CPU ram too!

Message : I'd read this a while back I think. This is pretty neat
Quoted Message : This is the core difference between CPUs and GPUs: CPUs are optimized for latency: to finish a task as fast as possible; GPUs are optimized for throughput: they are slow, but they operate on bulks of data at once.\n\nhttps://towardsdatascience.com/the-ai-illustrated-guide-why-are-gpus-so-powerful-99f4ae85a5c3

Message : If you really want to test your use case 

Run a profiler and measure the time overheads of each of the tasks and decide for yourself.


If you try to take two 10^5 size matrices to gpu

Multiply

Return result.

Most probably 80% of time will be spent on I/O

Message : Embodied Artificial Intelligence.

https://www.1x.tech/

Message : https://twitter.com/karpathy/status/1662160997451431936?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : As we were discussing cache and TTL, just thought to share this quote .

"There are only two hard things in Computer Science: cache invalidation and naming things."
-- Phil Karlton

Message : Must be a pre-k8s quote üòÇ

Message : Real Life Human Feelings
Quoted Message : From DMs: Are there more Generative AI companies than dev who know what RLHF stands for? ü§£

Message : Friends, we're delighted to have over 900 esteemed members in this group, nearing the WhatsApp group limit of 1024 participants.

For those of you who have been primarily following our group for the most recent news across products and tech, we kindly request you to consider a transition to the GenerativeAI News group. This will allow us to welcome more diverse voices and perspectives to our current group.

GenerativeAI News Group: https://chat.whatsapp.com/KWaS9CBhrYPCMogmpGpz5g

Message : I'm hoping that at least 100ish folks make the transition i.e. join that group, and leave this group

If not, we'll begin removing folks based on two main factors:

1. Have you contributed in the last 50 days?
2. How long have you been here?

This'll happen as and when I get time (since removing folks is manual-ish at the moment)

Message : ‚Äé~‚ÄØNirant changed the group description

Message : When we look back, the link between symbolic and connectionist approaches would have been the breakthroughs in code generation.
Quoted Message : https://twitter.com/karpathy/status/1662160997451431936?s=48&t=pt9BgXoRTmqx5FEPyAl9bg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : If you really want to test your use case 

Run a profiler and measure the time overheads of each of the tasks and decide for yourself.


If you try to take two 10^5 size matrices to gpu

Multiply

Return result.

Most probably 80% of time will be spent on I/O

Message : Embodied Artificial Intelligence.

https://www.1x.tech/

Message : https://twitter.com/karpathy/status/1662160997451431936?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : As we were discussing cache and TTL, just thought to share this quote .

"There are only two hard things in Computer Science: cache invalidation and naming things."
-- Phil Karlton

Message : Must be a pre-k8s quote üòÇ

Message : Real Life Human Feelings
Quoted Message : From DMs: Are there more Generative AI companies than dev who know what RLHF stands for? ü§£

Message : Friends, we're delighted to have over 900 esteemed members in this group, nearing the WhatsApp group limit of 1024 participants.

For those of you who have been primarily following our group for the most recent news across products and tech, we kindly request you to consider a transition to the GenerativeAI News group. This will allow us to welcome more diverse voices and perspectives to our current group.

GenerativeAI News Group: https://chat.whatsapp.com/KWaS9CBhrYPCMogmpGpz5g

Message : I'm hoping that at least 100ish folks make the transition i.e. join that group, and leave this group

If not, we'll begin removing folks based on two main factors:

1. Have you contributed in the last 50 days?
2. How long have you been here?

This'll happen as and when I get time (since removing folks is manual-ish at the moment)

Message : ‚Äé~‚ÄØNirant changed the group description

Message : When we look back, the link between symbolic and connectionist approaches would have been the breakthroughs in code generation.
Quoted Message : https://twitter.com/karpathy/status/1662160997451431936?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Any reason this group is on WhatsApp and not Telegram? I'm sure you would have given it a thought. Curious to know the reason. I thought things were easier on TG.
Quoted Message : Friends, we're delighted to have over 900 esteemed members in this group, nearing the WhatsApp group limit of 1024 participants.\n\nFor those of you who have been primarily following our group for the most recent news across products and tech, we kindly request you to consider a transition to the GenerativeAI News group. This will allow us to welcome more diverse voices and perspectives to our current group.\n\nGenerativeAI News Group: https://chat.whatsapp.com/KWaS9CBhrYPCMogmpGpz5g

Message : WhatsApp continues to be the first choice for most folks in India ‚Üí Telegram is easier for moderators, harder for users

I didn't expect to get to 2^10 people in less than 100 days from starting üòÖ
Quoted Message : Any reason this group is on WhatsApp and not Telegram? I'm sure you would have given it a thought. Curious to know the reason. I thought things were easier on TG.

Message : I agree. But is it same with tech folks as well?
Quoted Message : WhatsApp continues to be the first choice for most folks in India ‚Üí Telegram is easier for moderators, harder for users\n\nI didn't expect to get to 2^10 people in less than 100 days from starting üòÖ

Message : Yes. We all have 2-4 muted family WhatsApp groups
Quoted Message : I agree. But is it same with tech folks as well?

Message : I meant  that  telegram is more opted for in the tech community. I might be wrong as well üòä

Message : Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ? 
Or heard of anyone do it. I see some small team organizations already doing it.
And any where you have been warned to not use it ?

Message : Samsung, Apple, VISA, MathWorks have banned ChatGPT Plus and deploying the GPT4 API under their own brands
Quoted Message : Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ? \nOr heard of anyone do it. I see some small team organizations already doing it. \nAnd any where you have been warned to not use it ?

Message : Many of these have been upsold by Azure OpenAI as per the rumour mill. The case being made is InfoSec: Azure inside VPC, data won't be used for training the model.

Message : SourceGraph had publicly announced that they're offering every employee the subscription. There was a thread by Shreyas Doshi where he had suggested the same. That thread had many people agreeing that they've reimbursed their employees.
Quoted Message : Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ? \nOr heard of anyone do it. I see some small team organizations already doing it. \nAnd any where you have been warned to not use it ?

Message : For org plans there is a provision which allows you to opt out.
When you use this the data won‚Äôt be utilised for training the model.
Quoted Message : Many of these have been upsold by Azure OpenAI as per the rumour mill. The case being made is InfoSec: Azure inside VPC, data won't be used for training the model.

Message : This is what we use as well.
Quoted Message : Many of these have been upsold by Azure OpenAI as per the rumour mill. The case being made is InfoSec: Azure inside VPC, data won't be used for training the model.

Message : we as in Paypal?
Quoted Message : This is what we use as well.

Message : Yes

Message : Azure openai within vpc

Message : MPL offers chatgpt subscription reimbursement
Quoted Message : Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ? \nOr heard of anyone do it. I see some small team organizations already doing it. \nAnd any where you have been warned to not use it ?

Message : Seems like there's a lot of trust for folks to use this over the plain OpenAI Service

Everyone is b2b i speak to is using that stack
Quoted Message : This is what we use as well.

Message : Mid journey as well
Quoted Message : MPL offers chatgpt subscription reimbursement

Message : Looks like B2C or B2B, insecurity and aspiration is where all the money lies.
Quoted Message : This is what we use as well.

Message : We at invideo offer both too.
Quoted Message : Mid journey as well

Message : h/t @91981048xxxx for saying what I was about to: The latest LLM is from the Govt of Dubai. 

Between US (OpenAI), China (Baidu, Alibaba) and Dubai (Technology Innovation Institute) ‚Äî guess the country which is missing and has a ton of computational talent and money?

https://twitter.com/sandeepssrin/status/1662318588898992130

Message : To clarify, it's not just latest. It is the top of the HuggingFace leaderboard. Beating all the Llama.

Nothing sadder than this.
Quoted Message : h/t @9198xxxxxxxx for saying what I was about to: The latest LLM is from the Govt of Dubai. \n\nBetween US (OpenAI), China (Baidu, Alibaba) and Dubai (Technology Innovation Institute) ‚Äî guess the country which is missing and has a ton of computational talent and money?\n\nhttps://twitter.com/sandeepssrin/status/1662318588898992130

Message : An instruct or chat fork of this would be üî•

Message : But you can turn off history any way
Quoted Message : Many of these have been upsold by Azure OpenAI as per the rumour mill. The case being made is InfoSec: Azure inside VPC, data won't be used for training the model.

Message : Lot of articles over the last couple of months have been highlighting the strategic need for building India's own LLM...
But what are the blockers  to that?

Message : ai4bharat is training one
Quoted Message : Lot of articles over the last couple of months have been highlighting the strategic need for building India's own LLM...\nBut what are the blockers  to that?

Message : Is ai4bharath a government initiative?
Quoted Message : ai4bharat is training one

Message : Yes, by IIT M
Quoted Message : Is ai4bharath a government initiative?

Message : Why does indus need one?
Quoted Message : Lot of articles over the last couple of months have been highlighting the strategic need for building India's own LLM...\nBut what are the blockers  to that?

Message : India*

Message : Number of diverse languages is one I can think catering to Indian needs.
Moreover, language models do have a strategic importance
Quoted Message : Why does indus need one?

Message : It is a demonstration that we have talent to build a good one + hopefully a precursor to have a company like mosaic (or hopefully soon something like OpenAI) in India
Quoted Message : Why does indus need one?

Message : We really need one for each Indian language. I am a mallu who runs a small business and my customers mostly speak Malayalam. 

If we don't have a model for Indian languages the MSME sector will fall behind, drastically
Quoted Message : Why does indus need one?

Message : 1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. 
2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds.
3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible..
4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)

Message : Do check out their previous work, bert,bart,indic language datasets, indic tokeniser. For singular languages probably easy to use a technique like Lora for training
Quoted Message : 1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. \n2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds. \n3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible..\n4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)

Message : Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?
Quoted Message : Do check out their previous work, bert,bart,indic language datasets, indic tokeniser. For singular languages probably easy to use a technique like Lora for training

Message : In fact I see the recent calling for some sort of  license/regulation to train LLMs analogous to the NPT..
Quoted Message : 1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. \n2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds. \n3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible..\n4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)

Message : I've used their transliteration demo and it's quite bad
Quoted Message : Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?

Message : @1937708xxxx is working with them
Quoted Message : Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?

Message : Oh great!
Quoted Message : @193xxxxxxxx is working with them

Message : Meta showed off a translation model last week that seems to be able to translate between many different languages - they claim 11k languages if I'm not wrong - and perhaps it is possible to build a single model that addresses many different languages (speech to text, translation, etc)
Quoted Message : We really need one for each Indian language. I am a mallu who runs a small business and my customers mostly speak Malayalam. \n\nIf we don't have a model for Indian languages the MSME sector will fall behind, drastically


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : It is a demonstration that we have talent to build a good one + hopefully a precursor to have a company like mosaic (or hopefully soon something like OpenAI) in India
Quoted Message : Why does indus need one?

Message : We really need one for each Indian language. I am a mallu who runs a small business and my customers mostly speak Malayalam. 

If we don't have a model for Indian languages the MSME sector will fall behind, drastically
Quoted Message : Why does indus need one?

Message : 1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. 
2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds.
3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible..
4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)

Message : Do check out their previous work, bert,bart,indic language datasets, indic tokeniser. For singular languages probably easy to use a technique like Lora for training
Quoted Message : 1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. \n2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds. \n3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible..\n4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)

Message : Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?
Quoted Message : Do check out their previous work, bert,bart,indic language datasets, indic tokeniser. For singular languages probably easy to use a technique like Lora for training

Message : In fact I see the recent calling for some sort of  license/regulation to train LLMs analogous to the NPT..
Quoted Message : 1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. \n2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds. \n3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible..\n4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)

Message : I've used their transliteration demo and it's quite bad
Quoted Message : Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?

Message : @1937708xxxx is working with them
Quoted Message : Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?

Message : Oh great!
Quoted Message : @193xxxxxxxx is working with them

Message : Meta showed off a translation model last week that seems to be able to translate between many different languages - they claim 11k languages if I'm not wrong - and perhaps it is possible to build a single model that addresses many different languages (speech to text, translation, etc)
Quoted Message : We really need one for each Indian language. I am a mallu who runs a small business and my customers mostly speak Malayalam. \n\nIf we don't have a model for Indian languages the MSME sector will fall behind, drastically

Message : Bad in what sense?
1. Model capability? Or
2. UI/UX?
Quoted Message : I've used their transliteration demo and it's quite bad

Message : Model capability: quality of output basically

Message : Okay! I am curious to know, how you tested the quality of the output?
Quoted Message : Model capability: quality of output basically

Message : Don't know the users on this group and how they see AI strategy at a high level but I agree that serving a large base of consumers in India is a generally good use of AI. Maybe AI can do what smartphones have done for education in India's Tier 3 cities and towns
Quoted Message : 1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. \n2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds. \n3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible..\n4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)

Message : ‚Äé<attached: 00005695-PHOTO-2023-05-27-11-05-00.jpg>
Quoted Message : Okay! I am curious to know, how you tested the quality of the output?

Message : ‚Äé<attached: 00005696-PHOTO-2023-05-27-11-05-01.jpg>
Quoted Message : Okay! I am curious to know, how you tested the quality of the output?

Message : Having local players to serve a huge customer base is quite important. It is just a matter of well preparedness...

Message : Same. So many are just using Azure OpenAI - either that or I'm in a bubble
Quoted Message : Azure openai within vpc

Message : This
Quoted Message :  2023_05_27_767D93BF828C57C2B2BEA94ACA0E5B67.jpeg

Message : I have worked with Bhasini models, in touch with few folks who worked on it at IITM before, but not directly collaborating with AI4Bharat team, yet. Let me know if someone can get me an intro.
Quoted Message : @193xxxxxxxx is working with them

Message : Responding to the OP - one of the biggest blockers for building any LLM is data engineering, data quality. Architectures are grokkable, compute is manageable, getting good and well prepared data is probably the biggest differentiator IMO
Quoted Message : Lot of articles over the last couple of months have been highlighting the strategic need for building India's own LLM...\nBut what are the blockers  to that?

Message : This is still fine right?

Reminds me of those codechef problems where we used to detect a user signal to stop a loop say - (STAHP, STop, stttoooppp, etc) The reader can more or less understand. But here I guess this is just transliteration so vernacular to English transliteration is a non-unique problem unless we have codified laws
Quoted Message :  2023_05_27_58B909D638A028511333729BF1E33DE3.jpeg

Message : Yeah that's the positive example for contrast
Quoted Message : This is still fine right?\n\nReminds me of those codechef problems where we used to detect a user signal to stop a loop say - (STAHP, STop, stttoooppp, etc) The reader can more or less understand. But here I guess this is just transliteration so vernacular to English transliteration is a non-unique problem unless we have codified laws

Message : Agreed. Even in the AI4Bharat team I see a lot of data leads
Quoted Message : Responding to the OP - one of the biggest blockers for building any LLM is data engineering, data quality. Architectures are grokkable, compute is manageable, getting good and well prepared data is probably the biggest differentiator IMO

Message : *people in data lead positions I mean
Quoted Message : Agreed. Even in the AI4Bharat team I see a lot of data leads

Message : No, it's a language model. It should be able to pick up the implicit conventions in millions of tokens. The devnagari to Roman is completely wrong and there are a bunch of APIs out there that do a much better job
Quoted Message : This is still fine right?\n\nReminds me of those codechef problems where we used to detect a user signal to stop a loop say - (STAHP, STop, stttoooppp, etc) The reader can more or less understand. But here I guess this is just transliteration so vernacular to English transliteration is a non-unique problem unless we have codified laws

Message : Okay!
Quoted Message : No, it's a language model. It should be able to pick up the implicit conventions in millions of tokens. The devnagari to Roman is completely wrong and there are a bunch of APIs out there that do a much better job

Message : To build base model like LLaMa, IITM will be need a hefty fund or huge support from Azure. MS funded the Bhasini training, LLaMa size base model can be very expensive to train.

Message : Do you expect complete invertibility here in such cases like- Roman to Devnagari and Devanagari to Roman?
Quoted Message : No, it's a language model. It should be able to pick up the implicit conventions in millions of tokens. The devnagari to Roman is completely wrong and there are a bunch of APIs out there that do a much better job

Message : But since hindi is a phonetic language why do we need ai for transliteration?
Quoted Message :  2023_05_27_58B909D638A028511333729BF1E33DE3.jpeg

Message : There are already standards like baraha

Message : Yes. Baraha
Quoted Message : Do you expect complete invertibility here in such cases like- Roman to Devnagari and Devanagari to Roman?

Message : I guess AI4Bharat is still being funded hugely by Microsoft Research and IDC..correct me if I am wrong.
Quoted Message : To build base model like LLaMa, IITM will be need a hefty fund or huge support from Azure. MS funded the Bhasini training, LLaMa size base model can be very expensive to train.

Message : For creating datasets, a good start can be to translate the training dataset that is open sourced already like redpajama dataset that is also commercially licensed. Then fine-tune with smaller example datasets to add Indian nuances based on what we want to achieve via instruction tuning

Message : Tamil would be a difficult language to transliterated
Quoted Message : But since hindi is a phonetic language why do we need ai for transliteration?

Message : No i expect the most colloquially correct looking transliteration from an Indian script (devnagari) to roman
Quoted Message : Do you expect complete invertibility here in such cases like- Roman to Devnagari and Devanagari to Roman?

Message : Also I see that Nandan Nilekani is a sponsor/initiative driver
Quoted Message : I guess AI4Bharat is still being funded hugely by Microsoft Research and IDC..correct me if I am wrong.

Message : The crux is that llm might be overkill for transliteration. And prone to hallucination anyway
Quoted Message : Tamil would be a difficult language to transliterated

Message : True. I'm not sure why MS will fund training of an OpenAI competition. Unless GoI decides to take an initiative, like BritGPT.
Quoted Message : I guess AI4Bharat is still being funded hugely by Microsoft Research and IDC..correct me if I am wrong.

Message : ‚Äé<attached: 00005720-PHOTO-2023-05-27-11-14-29.jpg>

Message : Makes sense for other NLP tasks.. unless it is something like -
We trained an LLM, apart from all the things it does, it can also do transliteration..
Quoted Message : The crux is that llm might be overkill for transliteration. And prone to hallucination anyway

Message : Great! I will check this out
Quoted Message :  2023_05_27_1D2E13DC7E900A379D9644519A9F6E34.jpeg

Message : Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else
Quoted Message : Makes sense for other NLP tasks.. unless it is something like -\nWe trained an LLM, apart from all the things it does, it can also do transliteration..

Message : Okay
Quoted Message : Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else

Message : ‚Äé~‚ÄØRavi Theja added ‚Ä™+91¬†95655¬†29742‚Ä¨

Message : ‚Äé<attached: 00005726-PHOTO-2023-05-27-11-16-49.jpg>

Message : Lora fine tunes are stackable, I don't think you'll lose prior capabilities with that since transliteration can be orthogonal to existing fine tunes. Unless you're overriding existing behaviour, it may work and can be tried out
Quoted Message : Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else

Message : Ah. I'll check it out
Quoted Message : Lora fine tunes are stackable, I don't think you'll lose prior capabilities with that since transliteration can be orthogonal to existing fine tunes. Unless you're overriding existing behaviour, it may work and can be tried out

Message : I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes.
Anyway, I think we don't have the same definition of transliteration as a task. I'm thinking of it post input.

Message : That's why gpt 3.5 is able to transliterate without it being finetuned for transliteration specifically
Quoted Message : I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes.\nAnyway, I think we don't have the same definition of transliteration as a task. I'm thinking of it post input.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Makes sense for other NLP tasks.. unless it is something like -
We trained an LLM, apart from all the things it does, it can also do transliteration..
Quoted Message : The crux is that llm might be overkill for transliteration. And prone to hallucination anyway

Message : Great! I will check this out
Quoted Message :  2023_05_27_1D2E13DC7E900A379D9644519A9F6E34.jpeg

Message : Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else
Quoted Message : Makes sense for other NLP tasks.. unless it is something like -\nWe trained an LLM, apart from all the things it does, it can also do transliteration..

Message : Okay
Quoted Message : Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else

Message : ‚Äé~‚ÄØRavi Theja added ‚Ä™+91¬†95655¬†29742‚Ä¨

Message : ‚Äé<attached: 00005726-PHOTO-2023-05-27-11-16-49.jpg>

Message : Lora fine tunes are stackable, I don't think you'll lose prior capabilities with that since transliteration can be orthogonal to existing fine tunes. Unless you're overriding existing behaviour, it may work and can be tried out
Quoted Message : Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else

Message : Ah. I'll check it out
Quoted Message : Lora fine tunes are stackable, I don't think you'll lose prior capabilities with that since transliteration can be orthogonal to existing fine tunes. Unless you're overriding existing behaviour, it may work and can be tried out

Message : I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes.
Anyway, I think we don't have the same definition of transliteration as a task. I'm thinking of it post input.

Message : That's why gpt 3.5 is able to transliterate without it being finetuned for transliteration specifically
Quoted Message : I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes.\nAnyway, I think we don't have the same definition of transliteration as a task. I'm thinking of it post input.

Message : Because it's not a hard task for state of the art

Message : Would this overcome spelling mistakes and colloquial / dialects
Quoted Message :  2023_05_27_1D2E13DC7E900A379D9644519A9F6E34.jpeg

Message : Not sure. It's been 8 years since I used baraha haha
Quoted Message : Would this overcome spelling mistakes and colloquial / dialects

Message : Oh is it!
Quoted Message : I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes.\nAnyway, I think we don't have the same definition of transliteration as a task. I'm thinking of it post input.

Message : They have a long time interest in this. https://news.microsoft.com/en-in/features/with-help-from-next-generation-ai-indian-villagers-gain-easier-access-to-government-services/
Quoted Message : True. I'm not sure why MS will fund training of an OpenAI competition. Unless GoI decides to take an initiative, like BritGPT.

Message : Yea it featured in build
Quoted Message : They have a long time interest in this. https://news.microsoft.com/en-in/features/with-help-from-next-generation-ai-indian-villagers-gain-easier-access-to-government-services/

Message : Interesting question!
Quoted Message : True. I'm not sure why MS will fund training of an OpenAI competition. Unless GoI decides to take an initiative, like BritGPT.

Message : ‚Äé~‚ÄØNirant changed the group description

Message : MS probably is targeting this segment.  They'll license the basic models to finetuning/ vectorisation for specific use cases

Message : Using azure openai service or something similar

Message : If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link.

Message : MS research in particular has been building multilingual chat interfaces for decades (my cofunder has that patent üòÜ)
Quoted Message : True. I'm not sure why MS will fund training of an OpenAI competition. Unless GoI decides to take an initiative, like BritGPT.

Message : You didn't add mine rightüòÆ‚Äçüí® I was the last person before the warning
Quoted Message : If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link.

Message : And remove you from this group.

Message : Aren't transformer architectures essentially really effective at translation? The gains we saw in language translation around 2018-19 were largely due to these architectures.
Quoted Message : The crux is that llm might be overkill for transliteration. And prone to hallucination anyway

Message : You'll find out soon enough
Quoted Message : You didn't add mine rightüòÆ‚Äçüí® I was the last person before the warning

Message : üò•
Quoted Message : You'll find out soon enough

Message : My point is that increasingly large models will cover almost all languages, which will likely include most Indian languages
Quoted Message : Don't know the users on this group and how they see AI strategy at a high level but I agree that serving a large base of consumers in India is a generally good use of AI. Maybe AI can do what smartphones have done for education in India's Tier 3 cities and towns

Message : GPT4, GPT3.5 Turbo are already quite good for Indic languages. It'd be very data-intensive to do better than them for Indic languages even today.
Quoted Message : My point is that increasingly large models will cover almost all languages, which will likely include most Indian languages

Message : And absolutely not worth any commercial utility

Message : MS working closely with us, so I am very well aware of their capabilities. My point was regarding them funding India llm, after spending $10B in OpenAI. IITM themselves can't do it. They may have talent but not resources.
Quoted Message : MS research in particular has been building multilingual chat interfaces for decades (my cofunder has that patent üòÜ)

Message : Yes, ai4bharat indicxlit is just a 11M model with a single transformer only, so it's expected that it's performance may be lacking in a few areas. Using LLM for transliteration is like bringing a tank to a gun fight, but it does wonderful and works zero shot so can't complain. With GGML quantizations, you can even have <4GB models doing transliteration and more for Indic languages if underlying model is fine-tuned on Indic languages.
Quoted Message : I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes.\nAnyway, I think we don't have the same definition of transliteration as a task. I'm thinking of it post input.

Message : If anything, perhaps it makes sense to fine tune large models on Indian govt files (let‚Äôs say Supreme Court decisions) and solve india specific problems

Message : Ah, this makes sense! So where do you think India would find its edge then?
Quoted Message : GPT4, GPT3.5 Turbo are already quite good for Indic languages. It'd be very data-intensive to do better than them for Indic languages even today.

Message : if I remember correctly, but I might be wrong Sachin @91942037xxxx was doing this for Supreme Court
Quoted Message : If anything, perhaps it makes sense to fine tune large models on Indian govt files (let‚Äôs say Supreme Court decisions) and solve india specific problems

Message : Do English FOSS, do it better than the world
Quoted Message : Ah, this makes sense! So where do you think India would find its edge then?

Message : I'm doing it for Agri and Rural data. But embedding is better solution than fine-tuning, imo.
Quoted Message : If anything, perhaps it makes sense to fine tune large models on Indian govt files (let‚Äôs say Supreme Court decisions) and solve india specific problems

Message : Okay!
Quoted Message : Do English FOSS, do it better than the world

Message : we have a rich collection of files from government agencies, so makes sense to focus on domain specific models.

Perhaps even a model of how Indian government operates :)
Quoted Message : If anything, perhaps it makes sense to fine tune large models on Indian govt files (let‚Äôs say Supreme Court decisions) and solve india specific problems

Message : Msft funded openai after the fact
Quoted Message : MS working closely with us, so I am very well aware of their capabilities. My point was regarding them funding India llm, after spending $10B in OpenAI. IITM themselves can't do it. They may have talent but not resources.

Message : What data sources are you ingesting?
Quoted Message : I'm doing it for Agri and Rural data. But embedding is better solution than fine-tuning, imo.

Message : Digital-twin of the Indian govt operations :p
Quoted Message : we have a rich collection of files from government agencies, so makes sense to focus on domain specific models.\n\nPerhaps even a model of how Indian government operates :)

Message : Meta and Google have keen interest in Indic languages as well. Google is working on USM for 100+ Indian language support and meta recently released MMS for the same purpose
Quoted Message : MS probably is targeting this segment.  They'll license the basic models to finetuning/ vectorisation for specific use cases

Message : https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/

Message : Replace govt with an AGI 

True democracy :)
Quoted Message : Digital-twin of the Indian govt operations :p

Message : also full of horrors!

But perhaps we can be first ones to experiment with this.
Quoted Message : Replace govt with an AGI \n\nTrue democracy :)

Message : Who will hold the switch to the AGI? ü§™
Quoted Message : Replace govt with an AGI \n\nTrue democracy :)

Message : Agri universities, ICARs, NABARD, and other other Official recommendations. agri is federal, so no one has unified collection. Collection and getting everyone on board is the challenge i'm solving first. But it is coming around.

Message : Yeah, any chat GPT user today should be able to generate text in Hindi, Kannada, Tamil, etc. I've done that a few times, it is pretty neat.
Quoted Message : GPT4, GPT3.5 Turbo are already quite good for Indic languages. It'd be very data-intensive to do better than them for Indic languages even today.

Message : ‚Äé<attached: 00005774-PHOTO-2023-05-27-11-31-59.jpg>
Quoted Message : h/t @9198xxxxxxxx for saying what I was about to: The latest LLM is from the Govt of Dubai. \n\nBetween US (OpenAI), China (Baidu, Alibaba) and Dubai (Technology Innovation Institute) ‚Äî guess the country which is missing and has a ton of computational talent and money?\n\nhttps://twitter.com/sandeepssrin/status/1662318588898992130


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : What data sources are you ingesting?
Quoted Message : I'm doing it for Agri and Rural data. But embedding is better solution than fine-tuning, imo.

Message : Digital-twin of the Indian govt operations :p
Quoted Message : we have a rich collection of files from government agencies, so makes sense to focus on domain specific models.\n\nPerhaps even a model of how Indian government operates :)

Message : Meta and Google have keen interest in Indic languages as well. Google is working on USM for 100+ Indian language support and meta recently released MMS for the same purpose
Quoted Message : MS probably is targeting this segment.  They'll license the basic models to finetuning/ vectorisation for specific use cases

Message : https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/

Message : Replace govt with an AGI 

True democracy :)
Quoted Message : Digital-twin of the Indian govt operations :p

Message : also full of horrors!

But perhaps we can be first ones to experiment with this.
Quoted Message : Replace govt with an AGI \n\nTrue democracy :)

Message : Who will hold the switch to the AGI? ü§™
Quoted Message : Replace govt with an AGI \n\nTrue democracy :)

Message : Agri universities, ICARs, NABARD, and other other Official recommendations. agri is federal, so no one has unified collection. Collection and getting everyone on board is the challenge i'm solving first. But it is coming around.

Message : Yeah, any chat GPT user today should be able to generate text in Hindi, Kannada, Tamil, etc. I've done that a few times, it is pretty neat.
Quoted Message : GPT4, GPT3.5 Turbo are already quite good for Indic languages. It'd be very data-intensive to do better than them for Indic languages even today.

Message : ‚Äé<attached: 00005774-PHOTO-2023-05-27-11-31-59.jpg>
Quoted Message : h/t @9198xxxxxxxx for saying what I was about to: The latest LLM is from the Govt of Dubai. \n\nBetween US (OpenAI), China (Baidu, Alibaba) and Dubai (Technology Innovation Institute) ‚Äî guess the country which is missing and has a ton of computational talent and money?\n\nhttps://twitter.com/sandeepssrin/status/1662318588898992130

Message : This seems cryptic.

What types of tasks? Where is the confidence coming from? Is it a Bayesian model
Quoted Message :  2023_05_27_3EB0102982A966B688C5.jpeg

Message : The graph is that of its journey in a new website. It faced initial difficulties adjusting to the new place, but then each subsequent spike is a new skill learnt. The spike grows smaller and smaller as the importance of each new learnt skill decreases.

Message : ‚ÄúImportance‚Äù being a weighted-conditional probability distribution over all the features of the website. It is conditional on the task at hand.

Message : So the skill of ‚Äútweeting‚Äù for @91773788xxxx in this case would probably have the most importance if Nirant was using this on Twitter. For a guy like me, however, it would probably be ‚Äúbookmarking‚Äù. Jokes aside, note that the measure of skill importance is CONDITIONAL on the task I give it. So even though ‚Äòbookmarking‚Äô for me might be the most important skill on Twitter generally, but if my instruction involves tweeting, then that does affect the way it assigns the importance to each skill, and that‚Äôs how ‚Äòtweeting‚Äô would be prioritised.

Message : This is some scary&crazy stuff hence I‚Äôm completely off the grid for the last 2 weeks. This is the only thing that matters.

Message : Thanks. Is there documentation on what tasks this is being trained for?
Quoted Message : So the skill of ‚Äútweeting‚Äù for @9177xxxxxxxx in this case would probably have the most importance if Nirant was using this on Twitter. For a guy like me, however, it would probably be ‚Äúbookmarking‚Äù. Jokes aside, note that the measure of skill importance is CONDITIONAL on the task I give it. So even though ‚Äòbookmarking‚Äô for me might be the most important skill on Twitter generally, but if my instruction involves tweeting, then that does affect the way it assigns the importance to each skill, and that‚Äôs how ‚Äòtweeting‚Äô would be prioritised.

Message : no

Message : too risky

Message : I have no idea what you‚Äôre talking about :)

If anyone else has, please pitch in
Quoted Message : This is some scary&crazy stuff hence I‚Äôm completely off the grid for the last 2 weeks. This is the only thing that matters.

Message : Do you have task domain or task type level metrics of some kind? That would be interesting to see. Yes, the model will still get trained if you feed it different sets of training data (for different tasks) in the same dataset. And I'm no expert in LLM training, have only built one or two.

Message : That‚Äôs unjust for folks who want to follow discussions
Quoted Message : I'm hoping that at least 100ish folks make the transition i.e. join that group, and leave this group\n\nIf not, we'll begin removing folks based on two main factors: \n\n1. Have you contributed in the last 50 days? \n2. How long have you been here? \n\nThis'll happen as and when I get time (since removing folks is manual-ish at the moment)

Message : I only have guesses. Seems Ojasvi is building these models and wants to share a general, high level update?
Quoted Message : I have no idea what you‚Äôre talking about :)\n\nIf anyone else has, please pitch in

Message : This is not and does not use a wrapper. I don't have a personal openAI account! And this is not an LangChain/autoGPT/babyAGI fork. This doesn't need internet to operate. There is no fine-tuned model either. The data used for its training is my own, just like the models used.
Quoted Message : Do you have task domain or task type level metrics of some kind? That would be interesting to see. Yes, the model will still get trained if you feed it different sets of training data (for different tasks) in the same dataset. And I'm no expert in LLM training, have only built one or two.

Message : I was doing semantic search on Supreme Court cases. I have dataset of (somewhat cleaned) Supreme Court cases and embeddings..If anyone here is interested in finetuning on it, I can share.
Quoted Message : if I remember correctly, but I might be wrong Sachin @9194xxxxxxxx was doing this for Supreme Court

Message : What are you using as the base model?
Quoted Message :  2023_05_27_3EB0102982A966B688C5.jpeg

Message : that deserves a research paper for itself ;)
Quoted Message : What are you using as the base model?

Message : Haha.. will wait to try whatever you‚Äôre cooking there.
Quoted Message : that deserves a research paper for itself ;)

Message : Yes. Still initial stages. Don't know the timelines but I can see the proof of concept around the corner.
Quoted Message : I only have guesses. Seems Ojasvi is building these models and wants to share a general, high level update?

Message : Awesome. Good luck
Quoted Message : This is not and does not use a wrapper. I don't have a personal openAI account! And this is not an LangChain/autoGPT/babyAGI fork. This doesn't need internet to operate. There is no fine-tuned model either. The data used for its training is my own, just like the models used.

Message : Good luck.

Just remember to not destroy the world along the way :)
Quoted Message : Yes. Still initial stages. Don't know the timelines but I can see the proof of concept around the corner.

Message : @91997100xxxx please provide your coordinates to air strike registry.

Message : Want to mention that in context of my tweet about the Dubai model topping charts - my intended audience is the govt and not a blame to the engineers here (and across India). I was on Mirror Now talking about this a few weeks ago - at a govt funding and promotion level, we are doing too less.

And at that time I referred to only China....now it is Dubai as well.

As always, due credit to everyone here building on stuff ü´°

Message : Esp given how many back office jobs and call center jobs it's gonna replace. Not enough urgency.
Quoted Message : Want to mention that in context of my tweet about the Dubai model topping charts - my intended audience is the govt and not a blame to the engineers here (and across India). I was on Mirror Now talking about this a few weeks ago - at a govt funding and promotion level, we are doing too less.\n\nAnd at that time I referred to only China....now it is Dubai as well.\n\nAs always, due credit to everyone here building on stuff ü´°

Message : TII UAE is a state funded entity and it's efforts or output can only be compared at the level of equally backed or rich entities.
Quoted Message : Want to mention that in context of my tweet about the Dubai model topping charts - my intended audience is the govt and not a blame to the engineers here (and across India). I was on Mirror Now talking about this a few weeks ago - at a govt funding and promotion level, we are doing too less.\n\nAnd at that time I referred to only China....now it is Dubai as well.\n\nAs always, due credit to everyone here building on stuff ü´°

Message : Woah didn‚Äôt know falcon was from Dubai. Holy shit that‚Äôs crazy
Quoted Message : h/t @9198xxxxxxxx for saying what I was about to: The latest LLM is from the Govt of Dubai. \n\nBetween US (OpenAI), China (Baidu, Alibaba) and Dubai (Technology Innovation Institute) ‚Äî guess the country which is missing and has a ton of computational talent and money?\n\nhttps://twitter.com/sandeepssrin/status/1662318588898992130

Message : I gotta dig deeper, going to find out who‚Äôs behind this

Message : It's TII

Message : By the way, Falcon is not a real OSS. 10% royalty after 1M revenue.

Message : Would encourage you to check the AUM of any VC fund in this WhatsApp group or any single IITs compute expenses. Or any ITBEES company's profits. 

We've more than enough money, we lack willpower
Quoted Message : TII UAE is a state funded entity and it's efforts or output can only be compared at the level of equally backed or rich entities.

Message : What is Falcon?
Quoted Message : By the way, Falcon is not a real OSS. 10% royalty after 1M revenue.

Message : SoTA LLM
Quoted Message : What is Falcon?

Message : https://falconllm.tii.ae/

Message : Models are available on Hugging Face ü§ó
7B: https://lnkd.in/ejpGndA2
40B: https://lnkd.in/e6ESxVTK

Message : That‚Äôs not exactly bad per se 

It has a commercial license if I remember correctly. Which unlocks tonnes of opportunities.

Now everyone using llama under the hood are going to switch lol
Quoted Message : By the way, Falcon is not a real OSS. 10% royalty after 1M revenue.

Message : Nothing has inspired more licensing innovation than LLM weights in my living memory
Quoted Message : By the way, Falcon is not a real OSS. 10% royalty after 1M revenue.

Message : Well on the one hand we have "Open" AI...
Quoted Message : That‚Äôs not exactly bad per se \n\nIt has a commercial license if I remember correctly. Which unlocks tonnes of opportunities. \n\nNow everyone using llama under the hood are going to switch lol

Message : Any ideas on how to implement prioritization on search (pinecone etc)? (Use case: Companies prioritize sources say employee handbook, sales handbook, HRIS etc and then on a query - it picks up from that order) One way is to keep them in separate indexes and search from highest priority to low but curious has anyone faced something like this?

Message : I agree. I hate CC-BY-NC license, it‚Äôs hypocrisy.
Quoted Message : That‚Äôs not exactly bad per se \n\nIt has a commercial license if I remember correctly. Which unlocks tonnes of opportunities. \n\nNow everyone using llama under the hood are going to switch lol

Message : CustomRetriver in LlamaIndex
Quoted Message : Any ideas on how to implement prioritization on search (pinecone etc)? (Use case: Companies prioritize sources say employee handbook, sales handbook, HRIS etc and then on a query - it picks up from that order) One way is to keep them in separate indexes and search from highest priority to low but curious has anyone faced something like this?

Message : And yes, different indexes is one way to do it. Can use collections if your VectorDB supports that. Qdrant allows metadata filtering which works out of the box for these cases


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : SoTA LLM
Quoted Message : What is Falcon?

Message : https://falconllm.tii.ae/

Message : Models are available on Hugging Face ü§ó
7B: https://lnkd.in/ejpGndA2
40B: https://lnkd.in/e6ESxVTK

Message : That‚Äôs not exactly bad per se 

It has a commercial license if I remember correctly. Which unlocks tonnes of opportunities.

Now everyone using llama under the hood are going to switch lol
Quoted Message : By the way, Falcon is not a real OSS. 10% royalty after 1M revenue.

Message : Nothing has inspired more licensing innovation than LLM weights in my living memory
Quoted Message : By the way, Falcon is not a real OSS. 10% royalty after 1M revenue.

Message : Well on the one hand we have "Open" AI...
Quoted Message : That‚Äôs not exactly bad per se \n\nIt has a commercial license if I remember correctly. Which unlocks tonnes of opportunities. \n\nNow everyone using llama under the hood are going to switch lol

Message : Any ideas on how to implement prioritization on search (pinecone etc)? (Use case: Companies prioritize sources say employee handbook, sales handbook, HRIS etc and then on a query - it picks up from that order) One way is to keep them in separate indexes and search from highest priority to low but curious has anyone faced something like this?

Message : I agree. I hate CC-BY-NC license, it‚Äôs hypocrisy.
Quoted Message : That‚Äôs not exactly bad per se \n\nIt has a commercial license if I remember correctly. Which unlocks tonnes of opportunities. \n\nNow everyone using llama under the hood are going to switch lol

Message : CustomRetriver in LlamaIndex
Quoted Message : Any ideas on how to implement prioritization on search (pinecone etc)? (Use case: Companies prioritize sources say employee handbook, sales handbook, HRIS etc and then on a query - it picks up from that order) One way is to keep them in separate indexes and search from highest priority to low but curious has anyone faced something like this?

Message : And yes, different indexes is one way to do it. Can use collections if your VectorDB supports that. Qdrant allows metadata filtering which works out of the box for these cases

Message : I would've agreed if not for the fact that those compute budgets or any other budgets aren't solely dedicated to this purpose. However my comment was to distinguish the efforts made on a personal level by an individual vs state funded entities.
Quoted Message : Would encourage you to check the AUM of any VC fund in this WhatsApp group or any single IITs compute expenses. Or any ITBEES company's profits. \n\nWe've more than enough money, we lack willpower

Message : Yeah that's a NC license by definition, non-commercial. MPT initially was launched commercially but due to their usage of a non-commercial dataset for usage, they had to change the license to CC BY NC
Quoted Message : I agree. I hate CC-BY-NC license, it‚Äôs hypocrisy.

Message : Can you also do weighted search?
Quoted Message : And yes, different indexes is one way to do it. Can use collections if your VectorDB supports that. Qdrant allows metadata filtering which works out of the box for these cases

Message : Na. That has to go via a CustomRetriever in LlamaIndex or similar in Langchain
Quoted Message : Can you also do weighted search?

Message : Taking off from what Paras said, I would argue we would be better off focusing on training and empowering people with strong knowledge of ml & they will go on & build amazing things.
Some of these things could be making an impact in societal problems like edu & health, both in private sector & govt
Quoted Message : Why does indus need one?

Message : I may be wrong, but I believe that as all these llms are trained on data that is in the gray area, if taken to courts, non of these licenses will hold.
Quoted Message : Nothing has inspired more licensing innovation than LLM weights in my living memory

Message : Which court? India? Europe? California?
Quoted Message : I may be wrong, but I believe that as all these llms are trained on data that is in the gray area, if taken to courts, non of these licenses will hold.

Message : Zuckerberg bhi gaya tha. Kuch nahi bigaad paye courts üôà
Quoted Message : I may be wrong, but I believe that as all these llms are trained on data that is in the gray area, if taken to courts, non of these licenses will hold.

Message : Curious to hear your take @91773788xxxx
Quoted Message : Taking off from what Paras said, I would argue we would be better off focusing on training and empowering people with strong knowledge of ml & they will go on & build amazing things.\nSome of these things could be making an impact in societal problems like edu & health, both in private sector & govt

Message : It'd be too off topic and too bitter for this forum. Let's talk on DMs/IRL
Quoted Message : Curious to hear your take @9177xxxxxxxx

Message : I‚Äôm honestly loving Dubai‚Äôs stance on tech in general. They‚Äôre at the forefront of blockchain and web3. Very blockchain friendly and they give funded founders a 10 year golden visa. 

I predict them taking a similar stance on AI, given falcon.

Message : @91773788xxxx any update on Sama visiting blore?

Message : Got multiple denials. Running down some more leads.
Quoted Message : @9177xxxxxxxx any update on Sama visiting blore?

Message : 10% royalty on trained data without paying data sources or without permissions in many cases. Zuck settled outside courts and paying fines. What I'm saying is that if I use Llama commercially and then Meta goes to court, it won't be straightforward cease and desist.
Quoted Message : Zuckerberg bhi gaya tha. Kuch nahi bigaad paye courts üôà

Message : Picking one visionary person to be India's ai czar could catapult India to be an "ai first mover"
Sadly govt is too slow.
My hope is that open source & individual devs will ensure that the field evolves such that geographic boundaries will matter very little.
Quoted Message : I‚Äôm honestly loving Dubai‚Äôs stance on tech in general. They‚Äôre at the forefront of blockchain and web3. Very blockchain friendly and they give funded founders a 10 year golden visa. \n\nI predict them taking a similar stance on AI, given falcon.

Message : Geo boundaries haven't mattered for a while. That's how we've every dev who can fine-tune a LLM on a one way flight outside India
Quoted Message : Picking one visionary person to be India's ai czar could catapult India to be an \"ai first mover\"\nSadly govt is too slow.\nMy hope is that open source & individual devs will ensure that the field evolves such that geographic boundaries will matter very little.

Message : That's not a fair take with due respect. Kickstarting the ecosystem is always the job of the govt.
Look at Tesla, etc. Dubai is now heading leadership of the APAC region in AI (minus China).

The amount of govt investment in AI in China is staggering. This is existential - because if the ecosystem is not built out, value will accrue to the local ecosystem of these countries even if it is Indians who go there to build it.
Quoted Message : Would encourage you to check the AUM of any VC fund in this WhatsApp group or any single IITs compute expenses. Or any ITBEES company's profits. \n\nWe've more than enough money, we lack willpower

Message : Are you an optimist by any chance?
Quoted Message : That's not a fair take with due respect. Kickstarting the ecosystem is always the job of the govt.\nLook at Tesla, etc. Dubai is now heading leadership of the APAC region in AI (minus China).\n\nThe amount of govt investment in AI in China is staggering. This is existential - because if the ecosystem is not built out, value will accrue to the local ecosystem of these countries even if it is Indians who go there to build it.

Message : How is Dubai leading AI in APAC? (Apart from falcon)
Quoted Message : That's not a fair take with due respect. Kickstarting the ecosystem is always the job of the govt.\nLook at Tesla, etc. Dubai is now heading leadership of the APAC region in AI (minus China).\n\nThe amount of govt investment in AI in China is staggering. This is existential - because if the ecosystem is not built out, value will accrue to the local ecosystem of these countries even if it is Indians who go there to build it.

Message : To be clear: I agree with Sandeep, I'm just disillusioned perhaps.

Message : Any other initiatives/ funds?

Message : FalconEdge funds NLP companies e.g. Verloop.io
Quoted Message : Any other initiatives/ funds?

Message : ‚Äé<attached: 00005840-PHOTO-2023-05-27-12-53-15.jpg>

Message : Government doesn't read tweet
Quoted Message : Want to mention that in context of my tweet about the Dubai model topping charts - my intended audience is the govt and not a blame to the engineers here (and across India). I was on Mirror Now talking about this a few weeks ago - at a govt funding and promotion level, we are doing too less.\n\nAnd at that time I referred to only China....now it is Dubai as well.\n\nAs always, due credit to everyone here building on stuff ü´°

Message : hopefully they watch Mirror Now ;)
Quoted Message : Government doesn't read tweet

Message : I feel government stuff also work lot like B2B sales. You need to find the right person in the big machinary who has the power and interest in doing what you want them to do, and find ways to talk to them and work with them directly.

Message : Some corrections 

Falcon is not from Dubai. It‚Äôs from TII which is based in Abu Dhabi.

https://falconllm.tii.ae/

It‚Äôs an initiative from the Abu Dhabi govt.

Message : Oh yeah! Have visited a few of these when I was in school. Went to school in Abu Dhabi. 

Dubai has something called knowledge village which has a tonne of campuses
Quoted Message :  2023_05_27_5E8D4C74B2CB97C97DD9.jpeg

Message : Some random person in the machinery seeing/reading the arguments somewhere is not enough for them to do something. They already have a lot on their plate, and they might not be in the right position to do something.
Quoted Message : I feel government stuff also work lot like B2B sales. You need to find the right person in the big machinary who has the power and interest in doing what you want them to do, and find ways to talk to them and work with them directly.

Message : UAE boss üôàüíú
Quoted Message : Some corrections \n\nFalcon is not from Dubai. It‚Äôs from TII which is based in Abu Dhabi. \n\nhttps://falconllm.tii.ae/\n\nIt‚Äôs an initiative from the Abu Dhabi govt.

Message : ‚Äé<attached: 00005848-PHOTO-2023-05-27-13-01-53.jpg>

Message : The challenge is language structure...in NLP ... English etc are subject verb object 
"I am eating a mango"

Whereas Hindi is
Subject object verb
"Main ek aam khaa Raha hoon"
Quoted Message : No, it's a language model. It should be able to pick up the implicit conventions in millions of tokens. The devnagari to Roman is completely wrong and there are a bunch of APIs out there that do a much better job

Message : How'd you explain Mandarin and China's amazing progress then? That has no SVO even
Quoted Message : The challenge is language structure...in NLP ... English etc are subject verb object \n\"I am eating a mango\"\n\nWhereas Hindi is \nSubject object verb\n\"Main ek aam khaa Raha hoon\"

Message : Doubt.  Google got away with digitising copyrighted books for search.  Fair use arguments in the hands of good lawyers will go a long way...
Quoted Message : I may be wrong, but I believe that as all these llms are trained on data that is in the gray area, if taken to courts, non of these licenses will hold.

Message : Not just Google, Amazon scans books for selling and that's FUP too iirc
Quoted Message : Doubt.  Google got away with digitising copyrighted books for search.  Fair use arguments in the hands of good lawyers will go a long way...

Message : That's translation. Transliteration is a much easier problem
Quoted Message : The challenge is language structure...in NLP ... English etc are subject verb object \n\"I am eating a mango\"\n\nWhereas Hindi is \nSubject object verb\n\"Main ek aam khaa Raha hoon\"

Message : I‚Äôm also curious if Marketing teams have a policy around where AI can‚Äôt be used - specially for blogs, public work, journo pieces
Quoted Message : Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ? \nOr heard of anyone do it. I see some small team organizations already doing it. \nAnd any where you have been warned to not use it ?

Message : That's one area where they *want* to use NLG capabilities like LLMs if I think
Quoted Message : I‚Äôm also curious if Marketing teams have a policy around where AI can‚Äôt be used - specially for blogs, public work, journo pieces

Message : *if I'm right...

Message : ‚Äé<attached: 00005859-PHOTO-2023-05-27-13-45-38.jpg>
Quoted Message : The challenge is language structure...in NLP ... English etc are subject verb object \n\"I am eating a mango\"\n\nWhereas Hindi is \nSubject object verb\n\"Main ek aam khaa Raha hoon\"


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00005848-PHOTO-2023-05-27-13-01-53.jpg>

Message : The challenge is language structure...in NLP ... English etc are subject verb object 
"I am eating a mango"

Whereas Hindi is
Subject object verb
"Main ek aam khaa Raha hoon"
Quoted Message : No, it's a language model. It should be able to pick up the implicit conventions in millions of tokens. The devnagari to Roman is completely wrong and there are a bunch of APIs out there that do a much better job

Message : How'd you explain Mandarin and China's amazing progress then? That has no SVO even
Quoted Message : The challenge is language structure...in NLP ... English etc are subject verb object \n\"I am eating a mango\"\n\nWhereas Hindi is \nSubject object verb\n\"Main ek aam khaa Raha hoon\"

Message : Doubt.  Google got away with digitising copyrighted books for search.  Fair use arguments in the hands of good lawyers will go a long way...
Quoted Message : I may be wrong, but I believe that as all these llms are trained on data that is in the gray area, if taken to courts, non of these licenses will hold.

Message : Not just Google, Amazon scans books for selling and that's FUP too iirc
Quoted Message : Doubt.  Google got away with digitising copyrighted books for search.  Fair use arguments in the hands of good lawyers will go a long way...

Message : That's translation. Transliteration is a much easier problem
Quoted Message : The challenge is language structure...in NLP ... English etc are subject verb object \n\"I am eating a mango\"\n\nWhereas Hindi is \nSubject object verb\n\"Main ek aam khaa Raha hoon\"

Message : I‚Äôm also curious if Marketing teams have a policy around where AI can‚Äôt be used - specially for blogs, public work, journo pieces
Quoted Message : Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ? \nOr heard of anyone do it. I see some small team organizations already doing it. \nAnd any where you have been warned to not use it ?

Message : That's one area where they *want* to use NLG capabilities like LLMs if I think
Quoted Message : I‚Äôm also curious if Marketing teams have a policy around where AI can‚Äôt be used - specially for blogs, public work, journo pieces

Message : *if I'm right...

Message : ‚Äé<attached: 00005859-PHOTO-2023-05-27-13-45-38.jpg>
Quoted Message : The challenge is language structure...in NLP ... English etc are subject verb object \n\"I am eating a mango\"\n\nWhereas Hindi is \nSubject object verb\n\"Main ek aam khaa Raha hoon\"

Message : Yes that is why in NLP translation ... Language structure is very important. Transliteration is just phonetic similarity so AI4Bharat is not wrong to transliterate from Hindi phonetics to English phonetics. If transliteration is what is supposed to do.
Quoted Message : That's translation. Transliteration is a much easier problem

Message : Yes Hindi, Hinglish will be different that is another problem. And availability of training datasets is a bigger challenge. 

But you can't give a model that is built to understand English grammar to predict Hindi. ..

Message : At a fundamental level, I think there are two ways to do this: 

1. Stochastic parrot method - then language grammar doesnt matter to LLM. You train with enough English Hindi pairs the parrot will be able to give you the answer.

Message : ‚Äé<attached: 00005864-PHOTO-2023-05-27-13-49-33.jpg>

Message : 2. Language understanding - might be more relevant to generate correct embeddings in semantic search - I'm not experienced to say if because of stochastic parrot method ... language understanding will follow

Message : The models that do well in this area aren't trained on just one language, they are trained on multilingual dataset and learn these capabilities themselves. What you're referring to as stochastic parrot method is the autoregressive transformer architecture and these SoTA architectures don't care for language grammar structures.

Message : Models trained specifically for multilingual translation like Bloom models also perform fairly well although I've not seen a good Bloom model for Indic languages. Google and Meta have USM and MMS that Target the same problem for 100+ Indic languages.

Message : Yeah, "stochastic parrot" is just jargon which is used in the context of the interpretability of these models, but the underlying architectures tend to be transformer based for most of the new LLMs. The sequence of tokens you train on is ultimately a data engineering problem - and yes, the model, its tuning and all are not a walk in the park but the data engineering distinguishes itself by being tedious and messy.
Quoted Message : The models that do well in this area aren't trained on just one language, they are trained on multilingual dataset and learn these capabilities themselves. What you're referring to as stochastic parrot method is the autoregressive transformer architecture and these SoTA architectures don't care for language grammar structures.

Message : Someone else in the discussion mentioned low resource languages - that is a key thing here - and Indic translation/transliteration/NLU/G/P will improve by leaps and bounds if we had good datasets to start with

Message : Tooling also matters. Character sets are different and complex across languages - we have many languages and dialects where phrases constructed to be alike may mean different things. Complex languages and dialects -> rich data corpus -> more data engineering requirements -> more training/tuning time -> longer time to get performant models.

Message : Yeah I mentioned the 2 key problems that are actually unique to a country like India that no other English speaking nation would face. These give us opportunities to add value and push SoTA in areas where it's useful for us and penetrates the bulk of our country that actually doesn't speak English well.
Quoted Message :  2023_05_27_894E69D8F9D67796D1118BAF42DC034F.jpeg

Message : Deepfakes are a real problem

https://www.instagram.com/reel/CspZqO1NNBX/?igshid=NjFhOGMzYTE3ZQ==

Anybody has interesting thoughts on how to tackle deepfakes as they get easier & easier to generate & soon commoditized ?

Message : They could be used to create havoc in India especially by political parties' it cells
Quoted Message : Deepfakes are a real problem\n\nhttps://www.instagram.com/reel/CspZqO1NNBX/?igshid=NjFhOGMzYTE3ZQ==\n\nAnybody has interesting thoughts on how to tackle deepfakes as they get easier & easier to generate & soon commoditized ?

Message : Hey @91789256xxxx, I have been working in countering deepfakes in social media(LinkedIn) from past year. Short answer is, for now, every synthetic image has a fingerprint/watermark in it which basic model(CNN/Fourier) can detect, but as we go forward, there will be images(midJ) which bypass this fingerprint thing and new methods would need to develop which involve taking other inputs too i.e. IP, activity on platform etc.

Message : @91996389xxxx bro you're working on deepfakes detection too right ?
Quoted Message : Hey @9178xxxxxxxx, I have been working in countering deepfakes in social media(LinkedIn) from past year. Short answer is, for now, every synthetic image has a fingerprint/watermark in it which basic model(CNN/Fourier) can detect, but as we go forward, there will be images(midJ) which bypass this fingerprint thing and new methods would need to develop which involve taking other inputs too i.e. IP, activity on platform etc.

Message : This sounds like something we discussed/proposed 2-3 months back üëÄ
Quoted Message : Hey @9178xxxxxxxx, I have been working in countering deepfakes in social media(LinkedIn) from past year. Short answer is, for now, every synthetic image has a fingerprint/watermark in it which basic model(CNN/Fourier) can detect, but as we go forward, there will be images(midJ) which bypass this fingerprint thing and new methods would need to develop which involve taking other inputs too i.e. IP, activity on platform etc.

Message : .

Message : https://medium.com/@steinsfu/stable-diffusion-the-invisible-watermark-in-generated-images-2d68e2ab1241

Message : Apart from this, there are some other fingerprint which are exposed when you filter image with some fourier kernels, interesting stuff though!

Message : https://paperswithcode.com/task/deepfake-detection
Quoted Message : Deepfakes are a real problem\n\nhttps://www.instagram.com/reel/CspZqO1NNBX/?igshid=NjFhOGMzYTE3ZQ==\n\nAnybody has interesting thoughts on how to tackle deepfakes as they get easier & easier to generate & soon commoditized ?

Message : Good start point for working with deep fake detection.. you get links to the best research with their code
Quoted Message : https://paperswithcode.com/task/deepfake-detection

Message : Folks is there going to be a zoom link to today's get meetup ?

Message : Cc @91740765xxxx is the curator
Quoted Message : Folks is there going to be a zoom link to today's get meetup ?

Message : Hello everyone!
My name is Ansuman Patnaik, I'm a 21 y/o backend (who can also do a bit of frontend) developer from Bhubaneswar. I will be coming to Mumbai to participate in the Mumbai Hacks hackathon next weekend. Is there anyone here who'd be interested in teaming up to work on the generative AI track?

Message : People have stated availability of training dataset as a common problem to Indic language models. As a country with the size of our population what‚Äôs coming in the way of creating the correct kind of datasets? We have a lot of people who speake a lot of languages, don‚Äôt we?

Message : Work has happened on IndicNLP corpus and you can see a good list here https://github.com/AI4Bharat/indicnlp_catalog

Message : AI4Bharat leads the charge on developing models, datasets and applications for IndicNLP (along with MSFT as a worthy industry collaborator).

Message : https://www.todayonline.com/world/tiktok-tests-ai-chatbot-tako-philippines-2179071


Tiktok is testing gen ai in the Philippines. Customers can ask questions regarding video and it can apparently help customers find similar videos as well

Message : Yes we are!
Quoted Message : @9199xxxxxxxx bro you're working on deepfakes detection too right ?

Message : Link for the AI matchmaker at the meetup - http://ai-matchmaker.us-1.gooey.ai

Message : https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq

What are shared links?
Shared links are a new feature that allow users to generate a unique URL for a ChatGPT conversation, which can then be shared with friends, colleagues, and collaborators. Shared links offer a new way for users to share their ChatGPT conversations, replacing the old and burdensome method of sharing screenshots.

With shared links, users can let others see - and continue - interesting, funny, or insightful exchanges with ChatGPT.

Message : Are these datasets not big enough to create Indic chatGPT?
Quoted Message : Work has happened on IndicNLP corpus and you can see a good list here https://github.com/AI4Bharat/indicnlp_catalog

Message : can anyone tell me how they might have done it? How will this work in another account or the long?
Quoted Message : https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq\n\nWhat are shared links?\nShared links are a new feature that allow users to generate a unique URL for a ChatGPT conversation, which can then be shared with friends, colleagues, and collaborators. Shared links offer a new way for users to share their ChatGPT conversations, replacing the old and burdensome method of sharing screenshots. \n\nWith shared links, users can let others see - and continue - interesting, funny, or insightful exchanges with ChatGPT.

Message : Folks, anyone using a fine-tuned OpenAI endpoint on Azure? Wanted to know if there is a way to host / access the same endpoint in a different instance - if I want an app in a different resource group on Azure to access the same endpoint. Thoughts?

Message : Just load the same context to the LLM for future responses. A user account is just for with and rate limiting.
Quoted Message : can anyone tell me how they might have done it? How will this work in another account or the long?

Message : *a user account is just for authentication and rate limiting (the LLM does not care)

Message : cool thanks

Message : There are amazing line of speakers at upcoming *Huggingface x Inferless x SequoiaIndia* meet-up on *June 10th*.

Speakers:

1. Eliot Andres - Cofounder and CTO of Photoroom‚Ä¨
‚Ä™2. Prasenjit Dey - SVP Of Innovation at ‚Ä¨MerlynMind
‚Ä™3. Saravana Kumar - Head of ML at Apollo.ai‚Ä¨

Do register if you haven‚Äôt yet.

Registration link: https://lu.ma/ijcugt4n

Cc: @91813040xxxx

Message : A high level piece on medical ai by a16z's Vijay Pande: 

https://time.com/6274752/ai-health-care/

https://twitter.com/vijaypande/status/1653854648288305153?s=46&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Embedding the internet , seems to be a good initiative powered by open source https://alex.macrocosm.so/download


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq

What are shared links?
Shared links are a new feature that allow users to generate a unique URL for a ChatGPT conversation, which can then be shared with friends, colleagues, and collaborators. Shared links offer a new way for users to share their ChatGPT conversations, replacing the old and burdensome method of sharing screenshots.

With shared links, users can let others see - and continue - interesting, funny, or insightful exchanges with ChatGPT.

Message : Are these datasets not big enough to create Indic chatGPT?
Quoted Message : Work has happened on IndicNLP corpus and you can see a good list here https://github.com/AI4Bharat/indicnlp_catalog

Message : can anyone tell me how they might have done it? How will this work in another account or the long?
Quoted Message : https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq\n\nWhat are shared links?\nShared links are a new feature that allow users to generate a unique URL for a ChatGPT conversation, which can then be shared with friends, colleagues, and collaborators. Shared links offer a new way for users to share their ChatGPT conversations, replacing the old and burdensome method of sharing screenshots. \n\nWith shared links, users can let others see - and continue - interesting, funny, or insightful exchanges with ChatGPT.

Message : Folks, anyone using a fine-tuned OpenAI endpoint on Azure? Wanted to know if there is a way to host / access the same endpoint in a different instance - if I want an app in a different resource group on Azure to access the same endpoint. Thoughts?

Message : Just load the same context to the LLM for future responses. A user account is just for with and rate limiting.
Quoted Message : can anyone tell me how they might have done it? How will this work in another account or the long?

Message : *a user account is just for authentication and rate limiting (the LLM does not care)

Message : cool thanks

Message : There are amazing line of speakers at upcoming *Huggingface x Inferless x SequoiaIndia* meet-up on *June 10th*.

Speakers:

1. Eliot Andres - Cofounder and CTO of Photoroom‚Ä¨
‚Ä™2. Prasenjit Dey - SVP Of Innovation at ‚Ä¨MerlynMind
‚Ä™3. Saravana Kumar - Head of ML at Apollo.ai‚Ä¨

Do register if you haven‚Äôt yet.

Registration link: https://lu.ma/ijcugt4n

Cc: @91813040xxxx

Message : A high level piece on medical ai by a16z's Vijay Pande: 

https://time.com/6274752/ai-health-care/

https://twitter.com/vijaypande/status/1653854648288305153?s=46&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Embedding the internet , seems to be a good initiative powered by open source https://alex.macrocosm.so/download

Message : These are offline? üòµ
Quoted Message : There are amazing line of speakers at upcoming *Huggingface x Inferless x SequoiaIndia* meet-up on *June 10th*.\n\nSpeakers:\n\n1. Eliot Andres - Cofounder and CTO of Photoroom‚Ä¨\n‚Ä™2. Prasenjit Dey - SVP Of Innovation at ‚Ä¨MerlynMind\n‚Ä™3. Saravana Kumar - Head of ML at Apollo.ai‚Ä¨\n\nDo register if you haven‚Äôt yet.\n\nRegistration link: https://lu.ma/ijcugt4n\n\nCc: @9181xxxxxxxx

Message : Eliot will be joining virtually, Prasenjit and Saravana in-person, going to be a great conversation üòÉ
Quoted Message : These are offline? üòµ

Message : There is a GenAI Hackathon happening on June 10-11 by Stellaris.
Anyone wants to team up?

https://joinef.info/41Ye9kg

Message : @91709300xxxx please check this before sharing number.

DM anyone of the admins to add Himanshu.
Quoted Message : If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link.

Message : @91955016xxxx the previous msg was shared before I joined this grp. Kindly reshare it as I am not able to read it completely.

Message : If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link.

Message : https://twitter.com/manaskar/status/1662225822604992512?t=v8dK_ngSb6VIp0hUyOlwrA&s=19

Message : False promise of fine tuned low parameter imitator models?

Message : It would be so nice if we had the option to pin this ü§£
Quoted Message : If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link.

Message : https://www.youtube.com/watch?v=cQO2XTP7QDw

Such a fun application & explanation of RNNs!

Message : I love this channel, the past videos on this channel are also very creative
Quoted Message : https://www.youtube.com/watch?v=cQO2XTP7QDw\n\nSuch a fun application & explanation of RNNs!

Message : This guy is maker-man!
Quoted Message : https://www.youtube.com/watch?v=cQO2XTP7QDw\n\nSuch a fun application & explanation of RNNs!

Message : Hi,

I am Arvind and I am a patent freelancer and data scientist graduate exploring legal tech. Currently (like most in the group) I am looking at applications of generative AI, but in the legal domain. I would be open to forming connections with people working on similar problems.

Message : In legal applications, explainability is incredibly important. A lawyer would not trust any information if it doesn't have a source. I was wondering what work efforts have been made towards the same.

I have been in touch with people who generative text through GAI for a given context (say by using embeddings of a policy document) and then use cosine similarity between the output and the document to infer which of its parts are being referred to

Message : But are there any better solutions?

Message : Arvind, this stuck out to me while scrolling out on twitter
Some law firm used ChatGPT to file a legal brief, which had made up references of legal cases, and now are in a big soup

https://twitter.com/questauthority/status/1662273759259295746?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
Quoted Message : Hi,\n\nI am Arvind and I am a patent freelancer and data scientist graduate exploring legal tech. Currently (like most in the group) I am looking at applications of generative AI, but in the legal domain. I would be open to forming connections with people working on similar problems.

Message : Maintain a vectorDB of the documents and and the links as metadata.
Quoted Message : But are there any better solutions?

Message : And would you recommend using a meta data catalog?
Quoted Message : Maintain a vectorDB of the documents and and the links as metadata.

Message : Catalog ss in?
Quoted Message : And would you recommend using a meta data catalog?

Message : As*

Message : I think this will do a good job explaining that I would - https://www.ibm.com/docs/en/icfsfz/11.3.0?topic=zos-metadata-catalog
Quoted Message : Catalog ss in?

Message : Yeah. Read the news today. When the affiants argued no such cases existed in any credible legal databases, these lawyers argued they didn't consult generative AI ChatGPT and it was the affiant's fault for "consulting" the same.

Now there is a sanction pending against them
Quoted Message : Arvind, this stuck out to me while scrolling out on twitter\nSome law firm used ChatGPT to file a legal brief, which had made up references of legal cases, and now are in a big soup\n\nhttps://twitter.com/questauthority/status/1662273759259295746?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : This would be for comparing the output with the document...?
Quoted Message : Maintain a vectorDB of the documents and and the links as metadata.

Message : Interesting work on citing pretraining data for reducing internal hallucinations 

https://arxiv.org/abs/2305.13252

Message : In your case, the model has to cite the appropriate law (or the details from the case). After that, there are two components - 

#1 whether the law (or the details from the case) exists or is hallucinated,

#2 whether the argument made using the law or details is the correct reasoning drawn from the citation

You've to avoid applying the model in novel or complex scenarios and instead use it in scenarios that happen in bulk and are low complexity.

I'm afraid, the model should only be able to exist as a copilot in this case and the human has to verify the cited law/reasoning on his end before using the argument.
Quoted Message : In legal applications, explainability is incredibly important. A lawyer would not trust any information if it doesn't have a source. I was wondering what work efforts have been made towards the same.\n\nI have been in touch with people who generative text through GAI for a given context (say by using embeddings of a policy document) and then use cosine similarity between the output and the document to infer which of its parts are being referred to

Message : Other way to think is use the agent framework, add vector DB as a tool, only cite from the vectorDB
Quoted Message : In your case, the model has to cite the appropriate law (or the details from the case). After that, there are two components - \n\n#1 whether the law (or the details from the case) exists or is hallucinated, \n\n#2 whether the argument made using the law or details is the correct reasoning drawn from the citation\n\nYou've to avoid applying the model in novel or complex scenarios and instead use it in scenarios that happen in bulk and are low complexity. \n\nI'm afraid, the model should only be able to exist as a copilot in this case and the human has to verify the cited law/reasoning on his end before using the argument.

Message : You can search and retrieve from the vector DB that will be a compilation of Indian law in some way but you'll still need to verify the final reasoning and the details drawn from the citation. The application has the same challenges that a RAG application would face. Even Bing/perplexity ai make up details or generate novel nouns every once in a while, even though the request would be to stay completely factual.
Quoted Message : Other way to think is use the agent framework, add vector DB as a tool, only cite from the vectorDB

Message : In India monetisation is a huge problem. The millions of $ of investment takes forever to recover, if at all.
Quoted Message : Don't know the users on this group and how they see AI strategy at a high level but I agree that serving a large base of consumers in India is a generally good use of AI. Maybe AI can do what smartphones have done for education in India's Tier 3 cities and towns

Message : Maybe building for India requires a different approach from that used by Si valley firms to deliver scalable value for millions of adopters/consumers. We've got a combination of price inelasticity and discerning consumers here. Monetization for new entrants requires partnerships that build scale and credibility.
Quoted Message : In India monetisation is a huge problem. The millions of $ of investment takes forever to recover, if at all.

Message : What's the best proper hosted infrastructure or tips to deploy large Langchain based Prompt Templates, currently the API inference call takes ~104sec with GPT-4 API ? Or any ways to make GPT4 API inference faster by optimising prompts?

Message : But we have more than enough speakers of such languages. They aren‚Äôt low resource in the sense that these aren‚Äôt dead languages. So both the problems are solvable.
Quoted Message :  2023_05_27_894E69D8F9D67796D1118BAF42DC034F.jpeg

Message : Solvable but currently solved with poor performance. So makes for a good opportunity for pushing SoTA in the context of Indian languages and solving a problem unique to countries like India.
Quoted Message : But we have more than enough speakers of such languages. They aren‚Äôt low resource in the sense that these aren‚Äôt dead languages. So both the problems are solvable.

Message : Friends, we're all quite passionate about Indic LLMs. 

I'll request the next person who wants to chip in to contribute with code or data instead of ideas.

Message : https://huggingface.co/aashay96/indic-BloomLM

I had converted the ai4bharat dataset into HF dataset, and have a script to train Hf models on the dataset using LoRA. Added a readme of what else can be optimised. (Deepspeed etc)

Message : If anyone wants to explore indic datasets

Message : Some thoughts on this; a) how would you set up a test involving counterfactuals for legal applications? b) can we extract human-readable rules from the model's performance - maybe there is a way to do black box testing for something like this? c) Since we're using LLMs, is it possible to develop conversational interactive explanations?
Quoted Message : In legal applications, explainability is incredibly important. A lawyer would not trust any information if it doesn't have a source. I was wondering what work efforts have been made towards the same.\n\nI have been in touch with people who generative text through GAI for a given context (say by using embeddings of a policy document) and then use cosine similarity between the output and the document to infer which of its parts are being referred to

Message : https://github.com/currentslab/awesome-vector-search

Message : Good repo

Message : https://jalammar.github.io/illustrated-transformer/

Message : A great blog to understand transformers in detail


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : But we have more than enough speakers of such languages. They aren‚Äôt low resource in the sense that these aren‚Äôt dead languages. So both the problems are solvable.
Quoted Message :  2023_05_27_894E69D8F9D67796D1118BAF42DC034F.jpeg

Message : Solvable but currently solved with poor performance. So makes for a good opportunity for pushing SoTA in the context of Indian languages and solving a problem unique to countries like India.
Quoted Message : But we have more than enough speakers of such languages. They aren‚Äôt low resource in the sense that these aren‚Äôt dead languages. So both the problems are solvable.

Message : Friends, we're all quite passionate about Indic LLMs. 

I'll request the next person who wants to chip in to contribute with code or data instead of ideas.

Message : https://huggingface.co/aashay96/indic-BloomLM

I had converted the ai4bharat dataset into HF dataset, and have a script to train Hf models on the dataset using LoRA. Added a readme of what else can be optimised. (Deepspeed etc)

Message : If anyone wants to explore indic datasets

Message : Some thoughts on this; a) how would you set up a test involving counterfactuals for legal applications? b) can we extract human-readable rules from the model's performance - maybe there is a way to do black box testing for something like this? c) Since we're using LLMs, is it possible to develop conversational interactive explanations?
Quoted Message : In legal applications, explainability is incredibly important. A lawyer would not trust any information if it doesn't have a source. I was wondering what work efforts have been made towards the same.\n\nI have been in touch with people who generative text through GAI for a given context (say by using embeddings of a policy document) and then use cosine similarity between the output and the document to infer which of its parts are being referred to

Message : https://github.com/currentslab/awesome-vector-search

Message : Good repo

Message : https://jalammar.github.io/illustrated-transformer/

Message : A great blog to understand transformers in detail

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØHP

Message : If we hit 2k people, we start a podcast
cc @91773788xxxx @91740765xxxx

Message : I like the joke. WhatsApp groups have a limit of 2^10 people
Quoted Message : If we hit 2k people, we start a podcast\ncc @9177xxxxxxxx @9174xxxxxxxx

Message : xD
Quoted Message : I like the joke. WhatsApp groups have a limit of 2^10 people

Message : Just fork into group 1 & group 2. I‚Äôve seen eg founders circle doing this

Message : There are better ways to kill a conversation. I'll give them a chance first.
Quoted Message : Just fork into group 1 & group 2. I‚Äôve seen eg founders circle doing this

Message : Hot take: Nirant is secretly a LLM finetuned on sarcasm
Quoted Message : There are better ways to kill a conversation. I'll give them a chance first.

Message : ‚Äé<attached: 00005988-GIF-2023-05-28-14-33-50.mp4>
Quoted Message : Hot take: Nirant is secretly a LLM finetuned on sarcasm

Message : LLMs not there yet. Ye AGI hai in secret
Quoted Message : Hot take: Nirant is secretly a LLM finetuned on sarcasm

Message : He's an LLM designed by policybazaar
Quoted Message : Hot take: Nirant is secretly a LLM finetuned on sarcasm

Message : Actually such humor would be a good predictor of agi, when it comes
Quoted Message : LLMs not there yet. Ye AGI hai in secret

Message : The existential horror of having an AGI powered auto-complete pre-empting your every statement with a wiser, and more sarcastic take should be enough to sober up the most progressive optimists amongst us. üòÅ

Message : ‚Äé<attached: 00005993-GIF-2023-05-28-15-04-47.mp4>

Message : ‚Äé‚Äé‚Ä™+91¬†97913¬†32054‚Ä¨ changed their phone number to a new number. ‚ÄéTap to message or add the new number.

Message : not involved anymore but a few months back I made a Lawyer Copilot over entire Canadian law for a startup. so can share a bit from what i learnt. 

IMO doing basic QA over embeddings is not a good idea. instead I used SequentialChains (from langchain. easy to build on your own too).

oversimplying but basically for each question, I divided them into 3 other subquestions to fetch narrow (hence lower chance of hallucination) answers then these were summarized/combined in some manner to influence other subanswers and eventually get a final answer. lot of chains üòÖ.

in the user interface, we also exposed this "thought process", a user could see the subquestions-answers too. and the actual sources from which each sub-answer was derived. helps instill confidence in the user if they can see the specifics, especially in fields like law, healthcare. as you said, explainability is important :)

didn't get time to optimize, test this more. also was made using gpt-3.  would perform better and slower üòÇ with gpt4.
Quoted Message : In legal applications, explainability is incredibly important. A lawyer would not trust any information if it doesn't have a source. I was wondering what work efforts have been made towards the same.\n\nI have been in touch with people who generative text through GAI for a given context (say by using embeddings of a policy document) and then use cosine similarity between the output and the document to infer which of its parts are being referred to

Message : Yessirr, DMing you
Quoted Message : There is a GenAI Hackathon happening on June 10-11 by Stellaris.\nAnyone wants to team up? \n\nhttps://joinef.info/41Ye9kg

Message : This is very intresting. How did u split the subquestions? I'm assuming u created few-shot examples

Did u follow a standard research approach (like react-and-act) or did u create ur own. What was the logic/thought process to create the examples
Quoted Message : not involved anymore but a few months back I made a Lawyer Copilot over entire Canadian law for a startup. so can share a bit from what i learnt. \n\nIMO doing basic QA over embeddings is not a good idea. instead I used SequentialChains (from langchain. easy to build on your own too). \n\noversimplying but basically for each question, I divided them into 3 other subquestions to fetch narrow (hence lower chance of hallucination) answers then these were summarized/combined in some manner to influence other subanswers and eventually get a final answer. lot of chains üòÖ. \n\nin the user interface, we also exposed this \"thought process\", a user could see the subquestions-answers too. and the actual sources from which each sub-answer was derived. helps instill confidence in the user if they can see the specifics, especially in fields like law, healthcare. as you said, explainability is important :)\n\ndidn't get time to optimize, test this more. also was made using gpt-3.  would perform better and slower üòÇ with gpt4.

Message : Guys for someone who‚Äôs a beginner who wants to train a Chatbot from scratch using any open source LLM architecture by fine tuning it on a dataset, can you suggest any resources?

Message : I am interested. Just registered for the event.
Quoted Message : There is a GenAI Hackathon happening on June 10-11 by Stellaris.\nAnyone wants to team up? \n\nhttps://joinef.info/41Ye9kg

Message : I and my cofounder @91707326xxxx were building LegalMind from 2019-2021 in college and worked with CAM (Cyril Amarchand) at that time we were working with various BERTs and even tried creating a specific Legal Word-vec. However in any case in order for any document that has to be admissable in the court one must provide either a statutory-proof,  constitutionalvalidy and evidence mapping in order for the court to accept it. Majorly while arguing the citations must of a judgment that is disposed of in the courts with proper AIR citings. 

Secondly, we observed that there has to be a domain-specific model that needs to be built from this from scratches legal language understanding is different than NLP.
Quoted Message : not involved anymore but a few months back I made a Lawyer Copilot over entire Canadian law for a startup. so can share a bit from what i learnt. \n\nIMO doing basic QA over embeddings is not a good idea. instead I used SequentialChains (from langchain. easy to build on your own too). \n\noversimplying but basically for each question, I divided them into 3 other subquestions to fetch narrow (hence lower chance of hallucination) answers then these were summarized/combined in some manner to influence other subanswers and eventually get a final answer. lot of chains üòÖ. \n\nin the user interface, we also exposed this \"thought process\", a user could see the subquestions-answers too. and the actual sources from which each sub-answer was derived. helps instill confidence in the user if they can see the specifics, especially in fields like law, healthcare. as you said, explainability is important :)\n\ndidn't get time to optimize, test this more. also was made using gpt-3.  would perform better and slower üòÇ with gpt4.

Message : You can refer, Harvey, Casetext and see how they might have integrated this, my assumption is Harvey has raised money because they are building a foundation model with legal understanding much like what bloombergGPT is for finance a 30B LLM if I am not wrong

Message : https://arxiv.org/abs/2305.15717

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØArpit Agrawal

Message : was added to chat

Message : this message has been deleted

Message : Rule violation wohoo

Message : ‚Äé~‚ÄØArpit Agrawal was added

Message : Rule violation wohoo

Message : ‚Äé<attached: 00006007-PHOTO-2023-05-28-19-02-44.jpg>
Quoted Message : This is very intresting. How did u split the subquestions? I'm assuming u created few-shot examples\n\nDid u follow a standard research approach (like react-and-act) or did u create ur own. What was the logic/thought process to create the examples

Message : great points!
Quoted Message : I and my cofounder @9170xxxxxxxx were building LegalMind from 2019-2021 in college and worked with CAM (Cyril Amarchand) at that time we were working with various BERTs and even tried creating a specific Legal Word-vec. However in any case in order for any document that has to be admissable in the court one must provide either a statutory-proof,  constitutionalvalidy and evidence mapping in order for the court to accept it. Majorly while arguing the citations must of a judgment that is disposed of in the courts with proper AIR citings. \n\nSecondly, we observed that there has to be a domain-specific model that needs to be built from this from scratches legal language understanding is different than NLP.

Message : Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.

He has created 13B and 7B models via fine-tuning llama using vicuna fastchat module.

The dataset preparation, eval method and fine-tuning all are shared in reproducible manner on his airoboros 13b repo

https://huggingface.co/jondurbin/airoboros-13b
Quoted Message : Guys for someone who‚Äôs a beginner who wants to train a Chatbot from scratch using any open source LLM architecture by fine tuning it on a dataset, can you suggest any resources?

Message : Thank you so much
Quoted Message : Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.\n\nHe has created 13B and 7B models via fine-tuning llama using vicuna fastchat module.\n\nThe dataset preparation, eval method and fine-tuning all are shared in reproducible manner on his airoboros 13b repo\n\nhttps://huggingface.co/jondurbin/airoboros-13b

Message : "Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs."

Ergo, you can't really distill GPT3.5 without losing a lot of factual information

https://arxiv.org/abs/2305.15717
Quoted Message : Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.\n\nHe has created 13B and 7B models via fine-tuning llama using vicuna fastchat module.\n\nThe dataset preparation, eval method and fine-tuning all are shared in reproducible manner on his airoboros 13b repo\n\nhttps://huggingface.co/jondurbin/airoboros-13b

Message : I think fine-tuning is best for style transfer and that was quite evident from the start. Full knowledge transfer can't be achieved by fine-tuning anyway.

Message : Nothing new there. A full fine-tuning would still yield value if the focus is for solving a single problem and not imitate chatGPT in every way.

Message : Best example for my statement - Goat: fine-tuned llama that beats gpt 4 in arithmetic capabilities 

https://arxiv.org/abs/2305.14201

Message : I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it‚Äôd perform better than GPT-3.5

</rant>
Quoted Message : Best example for my statement - Goat: fine-tuned llama that beats gpt 4 in arithmetic capabilities \n\nhttps://arxiv.org/abs/2305.14201

Message : Not really. It's a conversational AI with arithmetic capabilities better than GPT4. Without base mathematical abilities you wouldn't ever have a decent model useful in financial/academic research involving computations.

Message : Rohit bhaiya, why we do the things we do at all?

Sometimes, it's just because we can
Quoted Message : I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it‚Äôd perform better than GPT-3.5\n\n</rant>

Message : Using this to create decisive conclusions is usually counter productive no?
Quoted Message : Rohit bhaiya, why we do the things we do at all?\n\nSometimes, it's just because we can


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.

He has created 13B and 7B models via fine-tuning llama using vicuna fastchat module.

The dataset preparation, eval method and fine-tuning all are shared in reproducible manner on his airoboros 13b repo

https://huggingface.co/jondurbin/airoboros-13b
Quoted Message : Guys for someone who‚Äôs a beginner who wants to train a Chatbot from scratch using any open source LLM architecture by fine tuning it on a dataset, can you suggest any resources?

Message : Thank you so much
Quoted Message : Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.\n\nHe has created 13B and 7B models via fine-tuning llama using vicuna fastchat module.\n\nThe dataset preparation, eval method and fine-tuning all are shared in reproducible manner on his airoboros 13b repo\n\nhttps://huggingface.co/jondurbin/airoboros-13b

Message : "Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs."

Ergo, you can't really distill GPT3.5 without losing a lot of factual information

https://arxiv.org/abs/2305.15717
Quoted Message : Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.\n\nHe has created 13B and 7B models via fine-tuning llama using vicuna fastchat module.\n\nThe dataset preparation, eval method and fine-tuning all are shared in reproducible manner on his airoboros 13b repo\n\nhttps://huggingface.co/jondurbin/airoboros-13b

Message : I think fine-tuning is best for style transfer and that was quite evident from the start. Full knowledge transfer can't be achieved by fine-tuning anyway.

Message : Nothing new there. A full fine-tuning would still yield value if the focus is for solving a single problem and not imitate chatGPT in every way.

Message : Best example for my statement - Goat: fine-tuned llama that beats gpt 4 in arithmetic capabilities 

https://arxiv.org/abs/2305.14201

Message : I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it‚Äôd perform better than GPT-3.5

</rant>
Quoted Message : Best example for my statement - Goat: fine-tuned llama that beats gpt 4 in arithmetic capabilities \n\nhttps://arxiv.org/abs/2305.14201

Message : Not really. It's a conversational AI with arithmetic capabilities better than GPT4. Without base mathematical abilities you wouldn't ever have a decent model useful in financial/academic research involving computations.

Message : Rohit bhaiya, why we do the things we do at all?

Sometimes, it's just because we can
Quoted Message : I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it‚Äôd perform better than GPT-3.5\n\n</rant>

Message : Using this to create decisive conclusions is usually counter productive no?
Quoted Message : Rohit bhaiya, why we do the things we do at all?\n\nSometimes, it's just because we can

Message : Agreed on this has little/no real world utility, but for kicks, amazing üòÖ

Message : Absolutely. I think most astute readers get that this is indicative, not decisive or conclusive.
Quoted Message : Using this to create decisive conclusions is usually counter productive no?

Message : Yea - doing it to test / have fun is totally cool

Message : We might not be able to Black box distill GPT.

But OpenAI can still distill GPT
Quoted Message : \"Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs.\"\n\nErgo, you can't really distill GPT3.5 without losing a lot of factual information\n\nhttps://arxiv.org/abs/2305.15717

Message : https://twitter.com/shishirpatil_/status/1661780076277678082?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Had read a lot of tweets/talks around this, specifically-
https://twitter.com/abacaj/status/1649465635263356932?s=46

Glad someone actually did a paper on this
Quoted Message : \"Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs.\"\n\nErgo, you can't really distill GPT3.5 without losing a lot of factual information\n\nhttps://arxiv.org/abs/2305.15717

Message : Happy 3 year Anniversary to GPT-3 paper, which came out on May 28, 2020. The arXiv submission alone has >10K citations. 

Gossip: The first author of this author is now at AnthropicAI.

https://arxiv.org/abs/2005.14165

Message : That and webgpt was the last paper where openai actually revealed something about their process
Quoted Message : Happy 3 year Anniversary to GPT-3 paper, which came out on May 28, 2020. The arXiv submission alone has >10K citations. \n\nGossip: The first author of this author is now at AnthropicAI.  \n\nhttps://arxiv.org/abs/2005.14165

Message : Really pivotal paper

Message : How much would his CTC be? What are AI salaries like generally in the west?
Quoted Message : Happy 3 year Anniversary to GPT-3 paper, which came out on May 28, 2020. The arXiv submission alone has >10K citations. \n\nGossip: The first author of this author is now at AnthropicAI.  \n\nhttps://arxiv.org/abs/2005.14165

Message : His ctc would be in tax free gpu credits
Quoted Message : How much would his CTC be? What are AI salaries like generally in the west?

Message : And a protection from air strikes in case the loss drops? ü§£
Quoted Message : His ctc would be in tax free gpu credits

Message : (Sorry for encouraging off topic salary discussions/inside jokes, let's stop here)

Message : Yeah I think this topic will be quite the buzz here. I'm just glad we're finally addressing the elephant in the room ü§£

Message : Yesterday I posted this
Quoted Message :  2023_05_27_3EB0102982A966B688C5.jpeg

Message : https://twitter.com/dr_cintas/status/1662475320119656448?s=46&t=FvScmWlwJalkIndmUHhjjQ

Message : Seems like agents loss curves have to be interpreted in their own way

Message : I thought we should stop so yudkowsky doesn't drone strike this group
Quoted Message : (Sorry for encouraging off topic salary discussions/inside jokes, let's stop here)

Message : Since loss function's are nowhere dependent on distance based metrics which are 99% of the loss function used

Message : The loss metrics I used for my agent were completely based on a different reasoning

Message : This will definitely become its own field of research

Message : I am quite curious about this!
Quoted Message : This will definitely become its own field of research

Message : Even cross entropy based ones can be thought of as some sort of a distance metric in a probabilistic space..

Message : Is there some prior work which talk about loss formulations that are not directly/indirectly based on distance based metric
Quoted Message : The loss metrics I used for my agent were completely based on a different reasoning

Message : ?

Message : Not just the loss

Message : I actually created my own activation layer üòå

Message : Okay! That's interesting.. I do something similar for my SciML projects but nothing major..
Quoted Message : I actually created my own activation layer üòå

Message : Ranking losses are there...
Quoted Message : Is there some prior work which talk about loss formulations that are not directly/indirectly based on distance based metric

Message : Nothing major this side either. Just that the standard final activation layers are not fundamentally optimised to the task at hand
Quoted Message : Okay! That's interesting.. I do something similar for my SciML projects but nothing major..

Message : Ndcg is one of them if rank of each output matters
Quoted Message : Ranking losses are there...

Message : Okay
Quoted Message : Ndcg is one of them if rank of each output matters

Message : Coming back to this. There is no baseline to compare the performance to.
Quoted Message : Is there some prior work which talk about loss formulations that are not directly/indirectly based on distance based metric

Message : There is always a possibility of formulating a toy problem which can then be used to compare the existing and proposed one
Quoted Message : Coming back to this. There is no baseline to compare the performance to.

Message : https://twitter.com/davidad/status/1662821792942022656?s=20

This is so weird. Can it be solved by better prompting? Heck, for tic tac toe you just give it the entire tree of board configurations in the prompt!

Message : Cc @91966317xxxx
Quoted Message : https://twitter.com/davidad/status/1662821792942022656?s=20\n\nThis is so weird. Can it be solved by better prompting? Heck, for tic tac toe you just give it the entire tree of board configurations in the prompt!

Message : https://www.amazon.science/publications/web-scale-semantic-product-search-with-large-language-models

Message : Do you want to add a line about why this is interesting to you?
Quoted Message : https://www.amazon.science/publications/web-scale-semantic-product-search-with-large-language-models

Message : Using llms to surface mathematics from statement based problems and then using plug-ins which can do the actual symbolic mathematics might be better.
Quoted Message : I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it‚Äôd perform better than GPT-3.5\n\n</rant>

Message : Kind of like translating into the language of mathematics


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Ndcg is one of them if rank of each output matters
Quoted Message : Ranking losses are there...

Message : Okay
Quoted Message : Ndcg is one of them if rank of each output matters

Message : Coming back to this. There is no baseline to compare the performance to.
Quoted Message : Is there some prior work which talk about loss formulations that are not directly/indirectly based on distance based metric

Message : There is always a possibility of formulating a toy problem which can then be used to compare the existing and proposed one
Quoted Message : Coming back to this. There is no baseline to compare the performance to.

Message : https://twitter.com/davidad/status/1662821792942022656?s=20

This is so weird. Can it be solved by better prompting? Heck, for tic tac toe you just give it the entire tree of board configurations in the prompt!

Message : Cc @91966317xxxx
Quoted Message : https://twitter.com/davidad/status/1662821792942022656?s=20\n\nThis is so weird. Can it be solved by better prompting? Heck, for tic tac toe you just give it the entire tree of board configurations in the prompt!

Message : https://www.amazon.science/publications/web-scale-semantic-product-search-with-large-language-models

Message : Do you want to add a line about why this is interesting to you?
Quoted Message : https://www.amazon.science/publications/web-scale-semantic-product-search-with-large-language-models

Message : Using llms to surface mathematics from statement based problems and then using plug-ins which can do the actual symbolic mathematics might be better.
Quoted Message : I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it‚Äôd perform better than GPT-3.5\n\n</rant>

Message : Kind of like translating into the language of mathematics

Message : It seems they are doing  semantic neighbor search (a vector db's traditional role) using LLM.
Quoted Message : Do you want to add a line about why this is interesting to you?

Message : Umm no - ‚ÄúAt runtime, for every query entered by the customer, we compute the query embedding and then retrieve top K products using ANN search [4]. To serve traffic in realtime, we cache the product embed- dings and compute only the query embedding online.‚Äù
Quoted Message : It seems they are doing  semantic neighbor search (a vector db's traditional role) using LLM.

Message : Ah ok. I think I misread the interpretation. Thanks for the correction

Message : Actually I still think I'm correct. The paper seems to indicate the embeddings are part of the model and not separately stored. Am I wrong in this ?
Quoted Message : Umm no - ‚ÄúAt runtime, for every query entered by the customer, we compute the query embedding and then retrieve top K products using ANN search [4]. To serve traffic in realtime, we cache the product embed- dings and compute only the query embedding online.‚Äù

Message : They use the embeddings to finetune a smaller model for faster realtime inference. Issues at amazon scale üòÜ
Quoted Message : Actually I still think I'm correct. The paper seems to indicate the embeddings are part of the model and not separately stored. Am I wrong in this ?

Message : Hey everyone!  Wanted to share the generative agents implementation I was working on - 

https://github.com/toughyear/generative-agents

with a demo here - https://demo.multimode.run/

Message : This is amazing ü§© 
How did you come about creating the environment, if you are able to share that?
Quoted Message : Hey everyone!  Wanted to share the generative agents implementation I was working on - \n\nhttps://github.com/toughyear/generative-agents\n\nwith a demo here - https://demo.multimode.run/

Message : The game env was created with Unity and then ported to Phaser gaming engine for web.
Quoted Message : This is amazing ü§© \nHow did you come about creating the environment, if you are able to share that?

Message : Interesting questions. My thoughts are as follows, but they may not necessarily be the most optimal approach to address this problems:
a) and b) there is going to be some subjectivity involved at some point. For better explainability, there is a lot of emphasis given to Expert systems or systems for ontological/knowledge representation that is in essense just logic. Such systems would effectively try to decode law as objectively as possible (like if then functions). However, you would eventually have to make subjective or quantitative assessments at some point.

Ex- The law is clear as to tax rates applicable to chocolate and wafers. However, the subjective assessment one may need to encounter is whether KitKat is a chocolate or a wafer, and accordingly determine which tax rate is applicable (actual case btw). While expert systems may lead us to understand which laws are applicable, I think generative AI may be more suited for the later task.

I don't know what test metrics may be appropriate for this. As you rightly point out, the legal system mostly adversarial and there may be both information that helps or hurts your case.

For the moment, I want to move one step at a time. First see if LLMs can be used for generating and supporting arguments involving subjective assessments without hallucinating. And then later see how it criticize, counter and refine it's own arguments, again without making things up.

C) obviously it should be possible. Ideally it should be like legal text books where legal provisions are filled with extracts and citations of cases where judges explain what those legal provisions supposed to be mean and how they are applicable to the case
Quoted Message : Some thoughts on this; a) how would you set up a test involving counterfactuals for legal applications? b) can we extract human-readable rules from the model's performance - maybe there is a way to do black box testing for something like this? c) Since we're using LLMs, is it possible to develop conversational interactive explanations?

Message : This looks very interesting üòÅ
Quoted Message : Hey everyone!  Wanted to share the generative agents implementation I was working on - \n\nhttps://github.com/toughyear/generative-agents\n\nwith a demo here - https://demo.multimode.run/

Message : That's some really impressive work would love to contribute to it!
Quoted Message : Hey everyone!  Wanted to share the generative agents implementation I was working on - \n\nhttps://github.com/toughyear/generative-agents\n\nwith a demo here - https://demo.multimode.run/

Message : I kept track of how the copilot generates code for me after I saw this. My takeaway is if the function is very clear with variables either already defined, or present in similar functions, then the copilot generates from the beginning, else, it doesn't. If the copilot can't figure out what you are doing then it struggles. 

My tip is to provide a comment on the line before to let it know what you are trying to code. Another thing which I figured out that, it works very well in bigger files with more lines of code, mostly cause some functionality is repeated. Eg, getObject1FromDatabase() and then if you write a function getObject2FromDatabase(), it ends up completing the entire function. It didn't however, complete it for getObject1FromDatabase().

Hope this helps
Quoted Message : Does anyone know how to force copilot to generate something when you're in the middle of a line / start of a line? It only seems to complete if I'm at the end of a line.

Message : Is this copilot X or github copilot?
Quoted Message : I kept track of how the copilot generates code for me after I saw this. My takeaway is if the function is very clear with variables either already defined, or present in similar functions, then the copilot generates from the beginning, else, it doesn't. If the copilot can't figure out what you are doing then it struggles. \n\nMy tip is to provide a comment on the line before to let it know what you are trying to code. Another thing which I figured out that, it works very well in bigger files with more lines of code, mostly cause some functionality is repeated. Eg, getObject1FromDatabase() and then if you write a function getObject2FromDatabase(), it ends up completing the entire function. It didn't however, complete it for getObject1FromDatabase(). \n\nHope this helps

Message : GitHub copilot

Message : I see... currently github copilot is weaker than some vscode extensions in terms of code autocomplete if I'm not wrong.
Quoted Message : GitHub copilot

Message : Copilot is most definitely the best *free* code autocomplete out there. Most VSCode Extensions are often GPT3.5-Turbo wrappers ‚Äî many ask for your keys, which is still okay. 

The ones which don't, are just iffy (legally, can't use for anything, even FOSS) and slow
Quoted Message : I see... currently github copilot is weaker than some vscode extensions in terms of code autocomplete if I'm not wrong.

Message : Copilot Chat or Copilot X is in beta and needs VS Code Nightly builds for some reason ü§∑‚Äç‚ôÇÔ∏è

Message : so basically prompts as a service üòÇ
Quoted Message : Copilot is most definitely the best *free* code autocomplete out there. Most VSCode Extensions are often GPT3.5-Turbo wrappers ‚Äî many ask for your keys, which is still okay. \n\nThe ones which don't, are just iffy (legally, can't use for anything, even FOSS) and slow

Message : https://codeium.com/ seen this a few times

Message : Have tried codeium (and a few more) it's not as good as copilot.

Message : What about tabnine?

Message : Also, copilot chat is not as good as GPT4.

I'm currently using Copilot for simple code completions while GPT4 for a little more advanced code completions.

Let me know if anybody has a better solution.

Message : Quite behind Copilot
Quoted Message : What about tabnine?

Message : Tabnine made a blip some time ago, I guess it is still good. Copilot is the pre-eminent tool at least in enterprises right now. Dunno about startups and smaller firms.

Message : There was a lawsuit last Nov - Copilot seemed to suggest code found in some private repos. At least that's what I understand - not sure whether needle has moved

Message : None as good as copilot but codeium is one of the best free copilot alternatives out there that has chat option as well. This and Source graph Cody are very useful. 

I don't know what model codeium is using right now but previously they used a variant of santacoder. Now we have better OSS codegen alternatives than that so don't know what they are using now.
Quoted Message : https://codeium.com/ seen this a few times

Message : Absolutely nothing is as GPT4. 

More interesting: Most commercial tools are worse than the Replit Code, Meta's InCoder or the super powered StarCoder.
Quoted Message : Also, copilot chat is not as good as GPT4.\n\nI'm currently using Copilot for simple code completions while GPT4 for a little more advanced code completions.\n\nLet me know if anybody has a better solution.

Message : Atleast for Python

Message : Folks is there any hack for getting GPT4 api access ?

Message : Increase your open AI gpt 3 bills, that's the only one i know of
Quoted Message : Folks is there any hack for getting GPT4 api access ?

Message : Any idea how this compares to replit ghostwriter?
Quoted Message : https://codeium.com/ seen this a few times

Message : Replit Head of ML mentioned they are planning to open source Ghostwriter if I am not wrong

Message : I could add my friend here to the group who worked on Ghostwriter

Message : Even databricks recommend to use this
Quoted Message : https://codeium.com/ seen this a few times

Message : Ghostwriter won‚Äôt be open sourced but Replit v1-3 LLM is open source under CC BY
Quoted Message : Replit Head of ML mentioned they are planning to open source Ghostwriter if I am not wrong

Message : Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.

Message : Generate 3D meshes and 360 degree videos from text.

https://twitter.com/genmoai/status/1661420716733104129?t=QIL1qd3RTsk9CmAjKe5JeA&s=19

Message : ‚Äé~‚ÄØNirant turned on admin approval to join this group

Message : Very good

Message : @91902106xxxx are you taking about the Stellaris one? Some people above were interested - @91996728xxxx @91702235xxxx @91877061xxxx
Quoted Message : Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Any idea how this compares to replit ghostwriter?
Quoted Message : https://codeium.com/ seen this a few times

Message : Replit Head of ML mentioned they are planning to open source Ghostwriter if I am not wrong

Message : I could add my friend here to the group who worked on Ghostwriter

Message : Even databricks recommend to use this
Quoted Message : https://codeium.com/ seen this a few times

Message : Ghostwriter won‚Äôt be open sourced but Replit v1-3 LLM is open source under CC BY
Quoted Message : Replit Head of ML mentioned they are planning to open source Ghostwriter if I am not wrong

Message : Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.

Message : Generate 3D meshes and 360 degree videos from text.

https://twitter.com/genmoai/status/1661420716733104129?t=QIL1qd3RTsk9CmAjKe5JeA&s=19

Message : ‚Äé~‚ÄØNirant turned on admin approval to join this group

Message : Very good

Message : @91902106xxxx are you taking about the Stellaris one? Some people above were interested - @91996728xxxx @91702235xxxx @91877061xxxx
Quoted Message : Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.

Message : Yes thanks will DM them
Quoted Message : @9190xxxxxxxx are you taking about the Stellaris one? Some people above were interested - @9199xxxxxxxx @9170xxxxxxxx @9187xxxxxxxx

Message : Which hackathon is this? Could you share the link?
Quoted Message : Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.

Message : Yessir im going
Quoted Message : Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.

Message : it's the stellaris one

I think this is the link https://joinef.info/41Ye9kg
Quoted Message : Which hackathon is this? Could you share the link?

Message : there is one happening in mumbai this weekend as well

Message : can we have a plugins hackathon like the SF one for people who have Plugins access?

Message : oh interesting, could you share the link to that?
Quoted Message : there is one happening in mumbai this weekend as well

Message : mumbaihacks.com
Quoted Message : oh interesting, could you share the link to that?

Message : https://twitter.com/mumbai_tech_/status/1659198245984419840?s=20
Quoted Message : oh interesting, could you share the link to that?

Message : ‚Äé<attached: 00006122-PHOTO-2023-05-29-15-45-18.jpg>

Message : Outlier features are indeed being handled with 16 bit mat multiplication

Message : But the paper specifically mentions that these features are only 0.1% of total features

Message : this decomposition operation only consumes about 0.1% additional memory. Therefore, it doesn't defeat the purpose of using lower precision computations to save memory.

Message : Yeah when we maintain W in half precision and int8 both aren't we doubling the memory

Message : The outlier part is never handled via 8bit but remains 16 bit. But since the outlier features are very small as per this paper (https://arxiv.org/abs/2208.07339) it doesn't make performance difference. But your question was valid and it will be an issue in scenarios where you are dealing with huge number of outliers which I have not considered in detail before.

Message : https://revoicer.com

Emotion based text to speech. What models do you folks think this product is using under the hood?

Message : I got the answer..all the matrices are int8 quantised and they also keep track of scale factor needed for each Matrix to dequantise.
For outlier features we first dequantise the int8 Matrix and do multiplication.
For non outlier features we do quantised multiplication and dequantise the result ..now both of them are added to get final output.
Quoted Message : The outlier part is never handled via 8bit but remains 16 bit. But since the outlier features are very small as per this paper (https://arxiv.org/abs/2208.07339) it doesn't make performance difference. But your question was valid and it will be an issue in scenarios where you are dealing with huge number of outliers which I have not considered in detail before.

Message : Is anyone aware of an open source/free ML tool that analyses voice and categorises it as monotonous, too many fillers, too many pauses, engaging, exciting, etc?

Message : If anyone knows of speech pathology identification tools using ML - such as vocal fry identifiers, I‚Äôd be interested in knowing as well
Quoted Message : Is anyone aware of an open source/free ML tool that analyses voice and categorises it as monotonous, too many fillers, too many pauses, engaging, exciting, etc?

Message : hey folks, i had a bunch of noob doubts around embeddings. I am making a Matchmaking project based on Readwise highlights (from books, blogs, tweets) of users. will take 100-200 highlights (text chunks) of a user.

1. after embedding highlights of a user, what's the best way to generate a user_embedding (to compare with other user embeddings). I read that highlights could be averaged to get a single user profile embedding. is this fine or are there other ways?

2. also, what's InstructorXL (768 dimensions) performance vs OpenAI (1536). main question: does no. of dimensions matter a lot compared to other factors like the model itself? i get that more dimensions mean that more info is there, more storage required etc.

3. i know there's the MTEB leaderboard. but let's say i want to compare InstructorXL, openai ada, sbert for my task; how should i go about it? i've used ada in the past. not the other two. im actually not sure about this question. feel free to ignore lol. i just want to try out 2-3 models for this project and understand the differences in speed, perf etc.

4. when do people still use models like "all-mpnet-base-v2"? the HuggingFace blog mentions that it's a "good balance between speed and performance".
5. when does finetuning embeddings make sense? anyone here doing that?

Q. 4,5 are not that relevant to my small project; im just curious, trying to fill in some gaps.

Links for models i mentioned:
- instructorXL: https://huggingface.co/hkunlp/instructor-xl
- sbert: https://www.sbert.net/
- all-mpnet: https://huggingface.co/sentence-transformers/all-mpnet-base-v2

thanks.

Message : ‚Äé<attached: 00006135-PHOTO-2023-05-29-18-08-48.jpg>
Quoted Message : hey folks, i had a bunch of noob doubts around embeddings. I am making a Matchmaking project based on Readwise highlights (from books, blogs, tweets) of users. will take 100-200 highlights (text chunks) of a user.\n\n1. after embedding highlights of a user, what's the best way to generate a user_embedding (to compare with other user embeddings). I read that highlights could be averaged to get a single user profile embedding. is this fine or are there other ways?\n\n2. also, what's InstructorXL (768 dimensions) performance vs OpenAI (1536). main question: does no. of dimensions matter a lot compared to other factors like the model itself? i get that more dimensions mean that more info is there, more storage required etc.\n\n3. i know there's the MTEB leaderboard. but let's say i want to compare InstructorXL, openai ada, sbert for my task; how should i go about it? i've used ada in the past. not the other two. im actually not sure about this question. feel free to ignore lol. i just want to try out 2-3 models for this project and understand the differences in speed, perf etc.\n\n4. when do people still use models like \"all-mpnet-base-v2\"? the HuggingFace blog mentions that it's a \"good balance between speed and performance\".\n5. when does finetuning embeddings make sense? anyone here doing that?\n\nQ. 4,5 are not that relevant to my small project; im just curious, trying to fill in some gaps.\n\nLinks for models i mentioned:\n- instructorXL: https://huggingface.co/hkunlp/instructor-xl\n- sbert: https://www.sbert.net/\n- all-mpnet: https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n\nthanks.

Message : Re: #1, in addition to averaging here are few general methods for combining embeddings: 

1. Concat ‚Üí Simple, Straightforward, extremely useful for features like "We're recommending you X because you liked Y"
2. Linear layers over embed concat ‚Üí Useful when you've some way to calculate a loss e.g. user similarity from other methods. Helps you combine K embeddings of K highlights into one embedding too!
3. Expanding on #2 above, you can actually feed the K X V (where K is the number of embeddings and V is the vector dim), into a neural network and attend, conv, linear or any other combination to get a 1 X V final resultant across users.

#3 is a common trick I've heard from Kagglers and industry folks, but you need some way to calculate a loss which you can back prop over

Message : There‚Äôs this unique challenge in matchmaking - you can‚Äôt just get the top-k results from a vector search and call that your top matches. 

You also need to consider that the top-k results for a user, might not have that user in their top-k, resulting in a suboptimal match. i.e. you need to consider the bidirectional mapping / distance.

The easiest way I‚Äôve found (that doesn‚Äôt scale) is to do a matmul over the entire embeddings of all users, giving you a nice distance matrix that you can then run classical graph/tree/clustering algorithms over.

We recently used a min spanning tree to project this at the generative ai meetup - http://ai-matchmaker.us-1.gooey.ai
Quoted Message : hey folks, i had a bunch of noob doubts around embeddings. I am making a Matchmaking project based on Readwise highlights (from books, blogs, tweets) of users. will take 100-200 highlights (text chunks) of a user.\n\n1. after embedding highlights of a user, what's the best way to generate a user_embedding (to compare with other user embeddings). I read that highlights could be averaged to get a single user profile embedding. is this fine or are there other ways?\n\n2. also, what's InstructorXL (768 dimensions) performance vs OpenAI (1536). main question: does no. of dimensions matter a lot compared to other factors like the model itself? i get that more dimensions mean that more info is there, more storage required etc.\n\n3. i know there's the MTEB leaderboard. but let's say i want to compare InstructorXL, openai ada, sbert for my task; how should i go about it? i've used ada in the past. not the other two. im actually not sure about this question. feel free to ignore lol. i just want to try out 2-3 models for this project and understand the differences in speed, perf etc.\n\n4. when do people still use models like \"all-mpnet-base-v2\"? the HuggingFace blog mentions that it's a \"good balance between speed and performance\".\n5. when does finetuning embeddings make sense? anyone here doing that?\n\nQ. 4,5 are not that relevant to my small project; im just curious, trying to fill in some gaps.\n\nLinks for models i mentioned:\n- instructorXL: https://huggingface.co/hkunlp/instructor-xl\n- sbert: https://www.sbert.net/\n- all-mpnet: https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n\nthanks.

Message : ‚Äé~‚ÄØNirant changed the group description

Message : Can you elaborate on matmul part?

How would the resultant matrix be different from averaging embedding top-k matches
Quoted Message : There‚Äôs this unique challenge in matchmaking - you can‚Äôt just get the top-k results from a vector search and call that your top matches. \n\nYou also need to consider that the top-k results for a user, might not have that user in their top-k, resulting in a suboptimal match. i.e. you need to consider the bidirectional mapping / distance.\n\nThe easiest way I‚Äôve found (that doesn‚Äôt scale) is to do a matmul over the entire embeddings of all users, giving you a nice distance matrix that you can then run classical graph/tree/clustering algorithms over.\n\nWe recently used a min spanning tree to project this at the generative ai meetup - http://ai-matchmaker.us-1.gooey.ai

Message : The matmul is just a quick and easy way to get a nice distance matrix. But yes, same operation mathematically. The important part is that you have some way to factor in the reverse relationship too.

A tinder match is only good if the other person likes you as much as you like them üòÜ

Code is open source btw - https://github.com/devxpy/ai-matchmaker/blob/be101578f3409bbd4598124d9d0f6b89758fb57b/app.py#L232

Message : And embedding search is still very much a fuzzy similarity score. For real world I think you need something like amazon‚Äôs recent paper on finetuned embeddings on a particular dataset, or a quick hack to just feed the matches into gpt-4 and ask for scores based on some explicitly illustrated criteria in prompt.

Eg see - https://twitter.com/jobergum/status/1656201261308321792

Message : Yeah so you probably average the distance
Quoted Message : The matmul is just a quick and easy way to get a nice distance matrix. But yes, same operation mathematically. The important part is that you have some way to factor in the reverse relationship too.\n\nA tinder match is only good if the other person likes you as much as you like them üòÜ\n\nCode is open source btw - https://github.com/devxpy/ai-matchmaker/blob/be101578f3409bbd4598124d9d0f6b89758fb57b/app.py#L232

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØShaarang

Message : The leaderboard seems to have a litter of tasks you can eval against - https://github.com/embeddings-benchmark/mteb#available-tasks
Quoted Message : hey folks, i had a bunch of noob doubts around embeddings. I am making a Matchmaking project based on Readwise highlights (from books, blogs, tweets) of users. will take 100-200 highlights (text chunks) of a user.\n\n1. after embedding highlights of a user, what's the best way to generate a user_embedding (to compare with other user embeddings). I read that highlights could be averaged to get a single user profile embedding. is this fine or are there other ways?\n\n2. also, what's InstructorXL (768 dimensions) performance vs OpenAI (1536). main question: does no. of dimensions matter a lot compared to other factors like the model itself? i get that more dimensions mean that more info is there, more storage required etc.\n\n3. i know there's the MTEB leaderboard. but let's say i want to compare InstructorXL, openai ada, sbert for my task; how should i go about it? i've used ada in the past. not the other two. im actually not sure about this question. feel free to ignore lol. i just want to try out 2-3 models for this project and understand the differences in speed, perf etc.\n\n4. when do people still use models like \"all-mpnet-base-v2\"? the HuggingFace blog mentions that it's a \"good balance between speed and performance\".\n5. when does finetuning embeddings make sense? anyone here doing that?\n\nQ. 4,5 are not that relevant to my small project; im just curious, trying to fill in some gaps.\n\nLinks for models i mentioned:\n- instructorXL: https://huggingface.co/hkunlp/instructor-xl\n- sbert: https://www.sbert.net/\n- all-mpnet: https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n\nthanks.

Message : IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. 
https://twitter.com/val_iisc/status/1662801516934361094

Message : This must be heart breaking. Getting rejected from canada of all places..
Quoted Message : IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. \nhttps://twitter.com/val_iisc/status/1662801516934361094

Message : was added to chat

Message : this message has been deleted

Message : this message has been deleted

Message : This is too sad! Anything related to AI on resume seems to switch on a red alert of sorts in their heads.. ü•≤
Quoted Message : IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. \nhttps://twitter.com/val_iisc/status/1662801516934361094

Message : But why'd this be the case? If anything, they should want IISc folks, right?
Quoted Message : This is too sad! Anything related to AI on resume seems to switch on a red alert of sorts in their heads.. ü•≤

Message : This was the case earlier with Aerospace degree holders/researchers

Message : Now AI..nothing different

Message :  2023_05_29_192734_3ACC960288CD73E2D90D.jpeg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. 
https://twitter.com/val_iisc/status/1662801516934361094

Message : This must be heart breaking. Getting rejected from canada of all places..
Quoted Message : IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. \nhttps://twitter.com/val_iisc/status/1662801516934361094

Message : was added to chat

Message : this message has been deleted

Message : this message has been deleted

Message : This is too sad! Anything related to AI on resume seems to switch on a red alert of sorts in their heads.. ü•≤
Quoted Message : IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. \nhttps://twitter.com/val_iisc/status/1662801516934361094

Message : But why'd this be the case? If anything, they should want IISc folks, right?
Quoted Message : This is too sad! Anything related to AI on resume seems to switch on a red alert of sorts in their heads.. ü•≤

Message : This was the case earlier with Aerospace degree holders/researchers

Message : Now AI..nothing different

Message :  2023_05_29_192734_3ACC960288CD73E2D90D.jpeg

Message : And i bet lots of students from India go to Mila and  lots of Canadian universities every year.\nConference was reputed, iisc is reputed\n\nReally seems like some over zealous visa officer
Quoted Message : But why'd this be the case? If anything, they should want IISc folks, right?

Message : I used https://github.com/Shahabks/myprosody a couple of years back. Not very good for serious usecases and you might need to modify the source code a bit for your needs. But a decent library considering I couldn't find anything else
Quoted Message : Is anyone aware of an open source/free ML tool that analyses voice and categorises it as monotonous, too many fillers, too many pauses, engaging, exciting, etc?

Message : This is fantastic for the zero-sum mindset in me. More talent will stay back in India because of this news going wide ü§£
Quoted Message : And i bet lots of students from India go to Mila and  lots of Canadian universities every year.\nConference was reputed, iisc is reputed\n\nReally seems like some over zealous visa officer

Message : Mila and UToronto are two of the very best for sure
Quoted Message : And i bet lots of students from India go to Mila and  lots of Canadian universities every year.\nConference was reputed, iisc is reputed\n\nReally seems like some over zealous visa officer

Message : I thought Canada was welcoming towards International students / tourists/ job seekers

Message : I hope in the next decade, India hosts more prestigious  conferences - ai (neurips, icml, iclr) & non-ai\n\nThe centre of gravity of most conferences is the west given that most presenters & organizers are from the US , Canada & Europe.

Message : Quite possible! The Indian academic mindset should also shift from journal publication oriented approach to more prestigious conference proceedings + open review approach
Quoted Message : I hope in the next decade, India hosts more prestigious  conferences - ai (neurips, icml, iclr) & non-ai\n\nThe centre of gravity of most conferences is the west given that most presenters & organizers are from the US , Canada & Europe.

Message : There were others (not students) who faced similar problems - https://twitter.com/RisingSayak/status/1663102361752186880?s=20

Message : This has been happening for quite a few years atleast with the US.
Quoted Message : There were others (not students) who faced similar problems - https://twitter.com/RisingSayak/status/1663102361752186880?s=20

Message :  2023_05_29_194826_941A7AFF0001D8ACDEAB5958425D8779.pdf

Message : I thought Canada would be more welcoming, especially for attendees of major conferences such as CVPR.

Message : 'Drone', 'AI', 'chemistry', 'nuclear' , 'aerospace', 'aerofoil' etc are some key words always attracted pink slips or straight rejections

Message : Yea! I guessed so
Quoted Message : I thought Canada would be more welcoming, especially for attendees of major conferences such as CVPR.

Message : Is their job market saturating/stagnating because of the recession?
Quoted Message : I thought Canada would be more welcoming, especially for attendees of major conferences such as CVPR.

Message : But if that is the case then you should reject work visas üòÖ

Message : https://blog.y-axis.com/jobs-outlook-in-canada-for-2023/

Message : Yea!! Exactly
Quoted Message : But if that is the case then you should reject work visas üòÖ

Message : But that doesn't seem to be the case :p
Quoted Message : https://blog.y-axis.com/jobs-outlook-in-canada-for-2023/

Message : thanks for the tips, will check out ai matchmaker repo as well üëç
Quoted Message : There‚Äôs this unique challenge in matchmaking - you can‚Äôt just get the top-k results from a vector search and call that your top matches. \n\nYou also need to consider that the top-k results for a user, might not have that user in their top-k, resulting in a suboptimal match. i.e. you need to consider the bidirectional mapping / distance.\n\nThe easiest way I‚Äôve found (that doesn‚Äôt scale) is to do a matmul over the entire embeddings of all users, giving you a nice distance matrix that you can then run classical graph/tree/clustering algorithms over.\n\nWe recently used a min spanning tree to project this at the generative ai meetup - http://ai-matchmaker.us-1.gooey.ai

Message : thanks! will try these out
Quoted Message : Re: #1, in addition to averaging here are few general methods for combining embeddings: \n\n1. Concat ‚Üí Simple, Straightforward, extremely useful for features like \"We're recommending you X because you liked Y\" \n2. Linear layers over embed concat ‚Üí Useful when you've some way to calculate a loss e.g. user similarity from other methods. Helps you combine K embeddings of K highlights into one embedding too! \n3. Expanding on #2 above, you can actually feed the K X V (where K is the number of embeddings and V is the vector dim), into a neural network and attend, conv, linear or any other combination to get a 1 X V final resultant across users. \n\n#3 is a common trick I've heard from Kagglers and industry folks, but you need some way to calculate a loss which you can back prop over

Message : Thanks, @9185xxxxxxxx
Quoted Message : I used https://github.com/Shahabks/myprosody a couple of years back. Not very good for serious usecases and you might need to modify the source code a bit for your needs. But a decent library considering I couldn't find anything else

Message : This is for how many vectors?
Quoted Message :  2023_05_14_3EB08E927DAA5211EAC243.jpeg

Message : All configs, code are from ann-benchmarks.com
Quoted Message : This is for how many vectors?

Message : Unfortunately, this is nothing new. Happens every year as one of ICML/ICLR/NeuRIPS happens in Canada. üòï\n\nICLR tries to combat this by moving to Kigali but that brought up more issues around the safety of  LGBT members of the community. \n\nGoing to say somewhere outside of North America puts Iranian students in the US in a tough spot as they can't come back inside the US easily due to their visa issues.
Quoted Message : IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. \nhttps://twitter.com/val_iisc/status/1662801516934361094

Message : Has anyone tried any local LLMs on Apple M1 macs ? GPT4LL snoozy model has very slow inference for me. Any suggestions for faster ones ?

Message : Yeah, playing with almost all of the decent ones on M2 pro
Quoted Message : Has anyone tried any local LLMs on Apple M1 macs ? GPT4LL snoozy model has very slow inference for me. Any suggestions for faster ones ?

Message : Are you running this via GPT4all Mac app, try mpt 7B?
Quoted Message : Has anyone tried any local LLMs on Apple M1 macs ? GPT4LL snoozy model has very slow inference for me. Any suggestions for faster ones ?

Message : ‚Äé~‚ÄØShaarang was added

Message : This is too sad! Anything related to AI on resume seems to switch on a red alert of sorts in their heads.. ü•≤

Message : But why'd this be the case? If anything, they should want IISc folks, right?

Message : This was the case earlier with Aerospace degree holders/researchers

Message : Now AI..nothing different

Message : ‚Äé<attached: 00006154-PHOTO-2023-05-29-19-27-34.jpg>

Message : And i bet lots of students from India go to Mila and  lots of Canadian universities every year.
Conference was reputed, iisc is reputed

Really seems like some over zealous visa officer

Message : I used https://github.com/Shahabks/myprosody a couple of years back. Not very good for serious usecases and you might need to modify the source code a bit for your needs. But a decent library considering I couldn't find anything else

Message : This is fantastic for the zero-sum mindset in me. More talent will stay back in India because of this news going wide ü§£

Message : Mila and UToronto are two of the very best for sure

Message : I thought Canada was welcoming towards International students / tourists/ job seekers

Message : I hope in the next decade, India hosts more prestigious  conferences - ai (neurips, icml, iclr) & non-ai

The centre of gravity of most conferences is the west given that most presenters & organizers are from the US , Canada & Europe.

Message : Quite possible! The Indian academic mindset should also shift from journal publication oriented approach to more prestigious conference proceedings + open review approach


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This was the case earlier with Aerospace degree holders/researchers

Message : Now AI..nothing different

Message : ‚Äé<attached: 00006154-PHOTO-2023-05-29-19-27-34.jpg>

Message : And i bet lots of students from India go to Mila and  lots of Canadian universities every year.
Conference was reputed, iisc is reputed

Really seems like some over zealous visa officer

Message : I used https://github.com/Shahabks/myprosody a couple of years back. Not very good for serious usecases and you might need to modify the source code a bit for your needs. But a decent library considering I couldn't find anything else

Message : This is fantastic for the zero-sum mindset in me. More talent will stay back in India because of this news going wide ü§£

Message : Mila and UToronto are two of the very best for sure

Message : I thought Canada was welcoming towards International students / tourists/ job seekers

Message : I hope in the next decade, India hosts more prestigious  conferences - ai (neurips, icml, iclr) & non-ai

The centre of gravity of most conferences is the west given that most presenters & organizers are from the US , Canada & Europe.

Message : Quite possible! The Indian academic mindset should also shift from journal publication oriented approach to more prestigious conference proceedings + open review approach

Message : There were others (not students) who faced similar problems - https://twitter.com/RisingSayak/status/1663102361752186880?s=20

Message : This has been happening for quite a few years atleast with the US.

Message : tal.pdf ‚Ä¢ ‚Äé6 pages ‚Äé<attached: 00006164-tal.pdf>

Message : I thought Canada would be more welcoming, especially for attendees of major conferences such as CVPR.

Message : 'Drone', 'AI', 'chemistry', 'nuclear' , 'aerospace', 'aerofoil' etc are some key words always attracted pink slips or straight rejections

Message : Yea! I guessed so

Message : Is their job market saturating/stagnating because of the recession?

Message : But if that is the case then you should reject work visas üòÖ

Message : https://blog.y-axis.com/jobs-outlook-in-canada-for-2023/

Message : Yea!! Exactly

Message : But that doesn't seem to be the case :p

Message : thanks for the tips, will check out ai matchmaker repo as well üëç

Message : thanks! will try these out

Message : Thanks, @91855895xxxx

Message : This is for how many vectors?

Message : All configs, code are from ann-benchmarks.com

Message : Unfortunately, this is nothing new. Happens every year as one of ICML/ICLR/NeuRIPS happens in Canada. üòï

ICLR tries to combat this by moving to Kigali but that brought up more issues around the safety of  LGBT members of the community.

Going to say somewhere outside of North America puts Iranian students in the US in a tough spot as they can't come back inside the US easily due to their visa issues.

Message : Has anyone tried any local LLMs on Apple M1 macs ? GPT4LL snoozy model has very slow inference for me. Any suggestions for faster ones ?

Message : Yeah, playing with almost all of the decent ones on M2 pro

Message : Are you running this via GPT4all Mac app, try mpt 7B?

Message : I'm using a Jupyter notebook and using langchain.  Let me try mpt7B.
Quoted Message : Are you running this via GPT4all Mac app, try mpt 7B?

Message : PrivateGPT
Quoted Message : Has anyone tried any local LLMs on Apple M1 macs ? GPT4LL snoozy model has very slow inference for me. Any suggestions for faster ones ?

Message : Check it out , it's available and setup is also easy

Message : Yeah it is good with external docs as well. just that it gets slowed down a lot with increasing number of threads. Still haven't gotten around using the langchain support on this but I love this project.
Quoted Message : PrivateGPT

Message : I think he has updated his repo , as he also launched it on product hunt , haven't tried the new one yet
Quoted Message : Yeah it is good with external docs as well. just that it gets slowed down a lot with increasing number of threads. Still haven't gotten around using the langchain support on this but I love this project.

Message : You can also have a look at this 

https://kevinchen.co/blog/rewind-ai-app-teardown/#how-it-works-overview

Message : It's a product tear down of rewind might help check how they have integrated locally

Message : ‚Äé<attached: 00006190-PHOTO-2023-05-29-23-11-24.jpg>

Message : I have been facing some issue with setting up the falcon model on sagemaker ,mainly dependency issues
can you guys suggest which image and instance type I should use

Message : I'm running it on a100 80G

Message : responses are decent

Message : Enter your text: what is technical innovation institute UAE
Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.
Result: what is technical innovation institute UAE
The Technical Innovation Institute in the United Arab Emirates (UAE) is a government-owned institute that provides education, training and research in fields such as engineering, energy, transportation, communication, and information technology.
Enter your text:

Message : This is the 40B instruct chat model

Message : what issues you facing :)
Quoted Message : I have been facing some issue with setting up the falcon model on sagemaker ,mainly dependency issues\ncan you guys suggest which image and instance type I should use

Message : got it working
Quoted Message : what issues you facing :)

Message : Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm? 
(Context - I run Albus (conversational search across all your tools) - doing around 2K queries a day)

Message : Have you seen this by llama index creator?

https://twitter.com/jerryjliu0/status/1659581693748191233?s=46
Quoted Message : Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm? \n(Context - I run Albus (conversational search across all your tools) - doing around 2K queries a day)

Message : Can Branch help? 

@91988441xxxx
Quoted Message : Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm? \n(Context - I run Albus (conversational search across all your tools) - doing around 2K queries a day)

Message : Has anyone here worked on generating training sets ( preferably on coding data sets ) through GPT4 or other powerful models and then used it to finetune OSS ones ?

Message : Nvidia announced a new DGX system with 100TB GPU memory 

https://t.co/M3Y4P074de


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : responses are decent

Message : Enter your text: what is technical innovation institute UAE
Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.
Result: what is technical innovation institute UAE
The Technical Innovation Institute in the United Arab Emirates (UAE) is a government-owned institute that provides education, training and research in fields such as engineering, energy, transportation, communication, and information technology.
Enter your text:

Message : This is the 40B instruct chat model

Message : what issues you facing :)
Quoted Message : I have been facing some issue with setting up the falcon model on sagemaker ,mainly dependency issues\ncan you guys suggest which image and instance type I should use

Message : got it working
Quoted Message : what issues you facing :)

Message : Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm? 
(Context - I run Albus (conversational search across all your tools) - doing around 2K queries a day)

Message : Have you seen this by llama index creator?

https://twitter.com/jerryjliu0/status/1659581693748191233?s=46
Quoted Message : Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm? \n(Context - I run Albus (conversational search across all your tools) - doing around 2K queries a day)

Message : Can Branch help? 

@91988441xxxx
Quoted Message : Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm? \n(Context - I run Albus (conversational search across all your tools) - doing around 2K queries a day)

Message : Has anyone here worked on generating training sets ( preferably on coding data sets ) through GPT4 or other powerful models and then used it to finetune OSS ones ?

Message : Nvidia announced a new DGX system with 100TB GPU memory 

https://t.co/M3Y4P074de

Message : Wow

Message : ‚Äé~‚ÄØKaushik Bokka added ~‚ÄØAditi Chopra and ~‚ÄØNeeraj

Message : was added to chat

Message : Looking for a good Video based Interactive Python course for a begineer, fastai one could be difficult to go, any suggestions?

Message : I came across this really nice one by Sanjeev Thyagarajan on YouTube/FreeCodeCamp. Worth checking out despite its considerable length. https://youtu.be/0sOvCWFmrtA
Quoted Message : Looking for a good Video based Interactive Python course for a begineer, fastai one could be difficult to go, any suggestions?

Message : Hey everyone! 
I've been exploring various text-to-speech models for Indic languages, and so far, I've tried Meta's multilingual model ( https://github.com/facebookresearch/fairseq/tree/main/examples/mms) which gave me an average output for Hindi.

I also gave Bark (https://github.com/suno-ai/bark) a shot, and it performed slightly better.

However, Elevenlabs provided the best results for me, unfortunately it's not open-source.
Do you have any other recommendations or leads for high-quality Indic language TTS models? Additionally, if anyone has experience with the Meta model, could you please share your thoughts on enhancing its output quality.

Message : Do you have any specific usecase in mind or are you just exploring ?
Quoted Message : Hey everyone! \nI've been exploring various text-to-speech models for Indic languages, and so far, I've tried Meta's multilingual model ( https://github.com/facebookresearch/fairseq/tree/main/examples/mms) which gave me an average output for Hindi.\n\n I also gave Bark (https://github.com/suno-ai/bark) a shot, and it performed slightly better. \n\nHowever, Elevenlabs provided the best results for me, unfortunately it's not open-source.\n Do you have any other recommendations or leads for high-quality Indic language TTS models? Additionally, if anyone has experience with the Meta model, could you please share your thoughts on enhancing its output quality.

Message : vakyansh , suggested to me previously by @91773788xxxx 
P good
Quoted Message : Hey everyone! \nI've been exploring various text-to-speech models for Indic languages, and so far, I've tried Meta's multilingual model ( https://github.com/facebookresearch/fairseq/tree/main/examples/mms) which gave me an average output for Hindi.\n\n I also gave Bark (https://github.com/suno-ai/bark) a shot, and it performed slightly better. \n\nHowever, Elevenlabs provided the best results for me, unfortunately it's not open-source.\n Do you have any other recommendations or leads for high-quality Indic language TTS models? Additionally, if anyone has experience with the Meta model, could you please share your thoughts on enhancing its output quality.

Message : yes it's for product advertisements.
The current outputs are quite monotone . sharing the meta outputs

Message : ‚Äé<attached: 00006215-AUDIO-2023-05-30-12-43-53.aac>
Quoted Message : Do you have any specific usecase in mind or are you just exploring ?

Message : https://github.com/Open-Speech-EkStep/vakyansh-models
Quoted Message : vakyansh , suggested to me previously by @9177xxxxxxxx \nP good

Message : For TTS, OpenAI Whisper?

Message : Thanks @91824021xxxx  will try this out
Quoted Message : https://github.com/Open-Speech-EkStep/vakyansh-models

Message : yep . I'm yet to compare the results between whisper and meta mms , esp for indic . will share it here
Quoted Message : For TTS, OpenAI Whisper?

Message : this is STT though
Quoted Message : Thanks @9182xxxxxxxx  will try this out

Message : sorry I had misread earlier

Message : np , just saw vakyansh has TTS too . https://github.com/Open-Speech-EkStep/vakyansh-tts
Quoted Message : sorry I had misread earlier

Message : Vakyansh has build great models, I have personally used them

Message : Gives great results

Message : Whisper is pretty bad though, from personal experiences.
```pyttsx3``` was working better for me at times, lmao
Quoted Message : For TTS, OpenAI Whisper?

Message : nice, what did you use it for?
Quoted Message : Vakyansh has build great models, I have personally used them

Message : classification

Message : Any hackathons happening soon?

Message : https://www.mumbaihacks.com/ - this weekend in Mumbai

https://lu.ma/ucd44q8e - June 10th in Bangalore
Quoted Message : Any hackathons happening soon?

Message : Me and @91990072xxxx were talking in the last meetup if any other similarity metric other than Cosine similarity could potentially give better results. He was of the opinion that it wouldn‚Äôt matter much unless for specific usecases.

Anyone has tried any other similarity metric and got better results?

Message : Also, was wondering if anyone has tried hybrid search mechanisms yet (bm25 + embeddings) : not one after another as a fallback, but together

Message : My take is slightly more nuanced, sorry if this was not clear. Simple 1-1 similarity metrics like Cosine, SAD, SSD etc won't matter much except for specific use cases. There are problems that can't be solved using just distances alone (selective attention mechanisms: Where you use completions etc, more powerful search algo like hierarchical representations etc), these are different class altogether.
Quoted Message : Me and @9199xxxxxxxx were talking in the last meetup if any other similarity metric other than Cosine similarity could potentially give better results. He was of the opinion that it wouldn‚Äôt matter much unless for specific usecases.\n\nAnyone has tried any other similarity metric and got better results?

Message : Anyone want to team up for the generative AI track in mumbai? Please DM! Would love to jam and collaborate!
Quoted Message : https://www.mumbaihacks.com/ - this weekend in Mumbai\n\nhttps://lu.ma/ucd44q8e - June 10th in Bangalore

Message : right right correct
Quoted Message : My take is slightly more nuanced, sorry if this was not clear. Simple 1-1 similarity metrics like Cosine, SAD, SSD etc won't matter much except for specific use cases. There are problems that can't be solved using just distances alone (selective attention mechanisms: Where you use completions etc, more powerful search algo like hierarchical representations etc), these are different class altogether.

Message : We at PayPal use Hybrid search for our Enterprise Search which powers a lot of use cases - consumer help, merchant help, dev experience, intranet articles, etc.
Quoted Message : Also, was wondering if anyone has tried hybrid search mechanisms yet (bm25 + embeddings) : not one after another as a fallback, but together

Message : I think that should be the standard. Pure neural search performs badly in a lot of use cases.

Message : We use bm25 + neural search + things like doc2query

https://www.linkedin.com/posts/soujanya-lanka-11b99a_informationretrieval-search-doc2query-activity-7052247552376651776-V5Xi

Message : Have too used hybrid quite a few times.

Message : This is fairly common. You often have specific keywords that needs to be matched like tags, categories etc, in such cases regular search is really good.

Message : And the secret sauce is also the re-ranker across such indexes.

Message : Is the re-ranking done in a user-personalized way or based on something else?
Quoted Message : And the secret sauce is also the re-ranker across such indexes.

Message : this is very interesting. this is much like generating metadata for each document and using that for embeddings.

but how do u combine bm25 and embeddings ? do u use the elasticsearch inbuilt method to use dense vector rankings with bm25 rankings ?
or do u use separate vector db and search db and interleave them (which is something i havent been able to figure out)
Quoted Message : We use bm25 + neural search + things like doc2query\n\nhttps://www.linkedin.com/posts/soujanya-lanka-11b99a_informationretrieval-search-doc2query-activity-7052247552376651776-V5Xi

Message : I thought the best way to combine embeddings with text in search was to use the 'boost' functionality in ElasticSearch
Quoted Message : this is very interesting. this is much like generating metadata for each document and using that for embeddings.\n\nbut how do u combine bm25 and embeddings ? do u use the elasticsearch inbuilt method to use dense vector rankings with bm25 rankings ?\nor do u use separate vector db and search db and interleave them (which is something i havent been able to figure out)

Message : Let's you weigh disparate input signals

Message : exactly. i was thinking the same thing. unless u are using two separate db here..in which case i dont know how to do it
Quoted Message : I thought the best way to combine embeddings with text in search was to use the 'boost' functionality in ElasticSearch


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I think that should be the standard. Pure neural search performs badly in a lot of use cases.

Message : We use bm25 + neural search + things like doc2query

https://www.linkedin.com/posts/soujanya-lanka-11b99a_informationretrieval-search-doc2query-activity-7052247552376651776-V5Xi

Message : Have too used hybrid quite a few times.

Message : This is fairly common. You often have specific keywords that needs to be matched like tags, categories etc, in such cases regular search is really good.

Message : And the secret sauce is also the re-ranker across such indexes.

Message : Is the re-ranking done in a user-personalized way or based on something else?
Quoted Message : And the secret sauce is also the re-ranker across such indexes.

Message : this is very interesting. this is much like generating metadata for each document and using that for embeddings.

but how do u combine bm25 and embeddings ? do u use the elasticsearch inbuilt method to use dense vector rankings with bm25 rankings ?
or do u use separate vector db and search db and interleave them (which is something i havent been able to figure out)
Quoted Message : We use bm25 + neural search + things like doc2query\n\nhttps://www.linkedin.com/posts/soujanya-lanka-11b99a_informationretrieval-search-doc2query-activity-7052247552376651776-V5Xi

Message : I thought the best way to combine embeddings with text in search was to use the 'boost' functionality in ElasticSearch
Quoted Message : this is very interesting. this is much like generating metadata for each document and using that for embeddings.\n\nbut how do u combine bm25 and embeddings ? do u use the elasticsearch inbuilt method to use dense vector rankings with bm25 rankings ?\nor do u use separate vector db and search db and interleave them (which is something i havent been able to figure out)

Message : Let's you weigh disparate input signals

Message : exactly. i was thinking the same thing. unless u are using two separate db here..in which case i dont know how to do it
Quoted Message : I thought the best way to combine embeddings with text in search was to use the 'boost' functionality in ElasticSearch

Message : We use this at dukaan to compute similar-products.

Message : We have a long journey. We started off with bm25 and faiss. Now we have dense vectors in elastic itself.
Quoted Message : this is very interesting. this is much like generating metadata for each document and using that for embeddings.\n\nbut how do u combine bm25 and embeddings ? do u use the elasticsearch inbuilt method to use dense vector rankings with bm25 rankings ?\nor do u use separate vector db and search db and interleave them (which is something i havent been able to figure out)

Message : But still, we continue to use our custom re-ranker for final results

Message : but just curious - how does ur custom reranker combine the output of faiss and Elastic-bm25. in memory ?
Quoted Message : But still, we continue to use our custom re-ranker for final results

Message : Yeah, like Ragotham said too deep and some NDAs. There are many ways to combine and depends on problems. Example to flavour: think Math equations, Chemistry equations etc. You will need different distance functions (say you want similar quadratic equations), modifications to rankers etc. Many ways to do this, we have written custom rankers, distance functions etc in Solr/Lucene. Can't talk more unfortunately.

Message : ah ok. no probs. thanks for mentioning anyway üôè

Message : There was a post by Karpathy on Twitter where he compared nearest neighbour vs SVM.
SVM one is an interesting approach as it weighs the dimensions according to dataset, rather than giving equal importance to each dimension as in cosine sim

Can try if latency isn't an issue
Quoted Message : Me and @9199xxxxxxxx were talking in the last meetup if any other similarity metric other than Cosine similarity could potentially give better results. He was of the opinion that it wouldn‚Äôt matter much unless for specific usecases.\n\nAnyone has tried any other similarity metric and got better results?

Message : There are various ways to do it. Think of it as results coming from various sources and you need to rank them. One Can start with simple weights as re-ranker or go full blown learning the weights as well.

Message : Just curious how it performs , i am trying with faiss
Quoted Message : We have a long journey. We started off with bm25 and faiss. Now we have dense vectors in elastic itself.

Message : And funny thing is sometimes, it is just prodding the user right or providing UI mechanisms for user to nudge us correctly.

Message : The benefit of KNN/ANN is that you can get **good-enough** performance with 0 downtime

SVM might be more accurate, but it needs to be trained all-over again if it has to index something.
Quoted Message : There was a post by Karpathy on Twitter where he compared nearest neighbour vs SVM.\nSVM one is an interesting approach as it weighs the dimensions according to dataset, rather than giving equal importance to each dimension as in cosine sim\n\nCan try if latency isn't an issue

Message : Works well. Can't scale as orchestration is a pain. And when you say enterprise search, it is more like search as a service for the org. So, needs better tools / frameworks like full feature vector db
Quoted Message : Just curious how it performs , i am trying with faiss

Message : Will try it with bm25

Message : It needs to be trained for each query !! (or cached) Haha.. That was the context of this discussion.
Quoted Message : The benefit of KNN/ANN is that you can get **good-enough** performance with 0 downtime\n\nSVM might be more accurate, but it needs to be trained all-over again if it has to index something.

Message : Yeah, the SVM idea as he mentioned is not for enterprise scale. It gives better accuracy for small scale data.

Message : actually im a big believer in the composite ranking that you did. and that belief goes hand in hand with infrastructure tie in. 
this kind of combined rankings (ranking+embedding or freshness/recency + embedding)  is very strongly tied to infra and is hard to pull off outside it. have been having a side conversation on this as well with some people here !
Quoted Message : It needs to be trained for each query !! (or cached) Haha.. That was the context of this discussion.

Message : Check our the recys paper that @91986822xxxx had posted. It's a slightly terribly written paper but will give you ideas on how TikTok is mixing some of these. There are enough details. For them, freshness can be what is trending video in last 30 mins !!
Quoted Message : actually im a big believer in the composite ranking that you did. and that belief goes hand in hand with infrastructure tie in. \nthis kind of combined rankings (ranking+embedding or freshness/recency + embedding)  is very strongly tied to infra and is hard to pull off outside it. have been having a side conversation on this as well with some people here !

Message : *out

Message : i'll be honest - i didn't understand how SVM had a better performance than KNN.

the insight that KNN weighs all dimensions equally was very good, but i didn tget how SVM sidesteps it
Quoted Message : The benefit of KNN/ANN is that you can get **good-enough** performance with 0 downtime\n\nSVM might be more accurate, but it needs to be trained all-over again if it has to index something.

Message : Just curious how any pre-trained cross encoder will perform?
Quoted Message : The benefit of KNN/ANN is that you can get **good-enough** performance with 0 downtime\n\nSVM might be more accurate, but it needs to be trained all-over again if it has to index something.

Message : So in this case, karpathy argued that SVM cares for the unique aspects of your data more and hence better accuracy. Knn is computationally better but fails to preserve unique cases 

https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
Quoted Message : i'll be honest - i didn't understand how SVM had a better performance than KNN.\n\nthe insight that KNN weighs all dimensions equally was very good, but i didn tget how SVM sidesteps it

Message : yeah, saw that. but didnt get it fully, maybe need to read more
Quoted Message : So in this case, karpathy argued that SVM cares for the unique aspects of your data more and hence better accuracy. Knn is computationally better but fails to preserve unique cases \n\nhttps://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb

Message : SVM will typically have better performance than KNN because it's mathematically guaranteed to be a strong learner. KNN has the desirable property of being very fast for retrieval inference, so it gets used everywhere. Karpathy had a small, fixed dataset, so inference speed wasn't as issue (wasn't needed), and SVM did better.
Quoted Message : i'll be honest - i didn't understand how SVM had a better performance than KNN.\n\nthe insight that KNN weighs all dimensions equally was very good, but i didn tget how SVM sidesteps it

Message : Any strong learner (like boosted trees from xgboost or lightgbm) would have done better than KNN

Message : but what is the ground turth on which learning is happening?

we use knns because all we have is dimensions but we don't know actual clusters, if we know clusters then we can use strong learners. but in case all you have embeddings, where is the ground truth coming from?

maybe im confused.
Quoted Message : Any strong learner (like boosted trees from xgboost or lightgbm) would have done better than KNN

Message : I share the confusion. There are no labels here
Quoted Message : but what is the ground turth on which learning is happening?\n\nwe use knns because all we have is dimensions but we don't know actual clusters, if we know clusters then we can use strong learners. but in case all you have embeddings, where is the ground truth coming from?\n\nmaybe im confused.

Message : üòÇ that's the beautiful thing about his example

Message : We have ground truth: the query is identical to itself

Message : Everything else is not. The embeddings are assumed to be semantic ones, so the trained model works out for this small dataset

Message : but isn't that what classical machine learning is all about? Expecting future data to follow the same distribution as past data
Quoted Message : We have ground truth: the query is identical to itself

Message : I don't understand the question
Quoted Message : but isn't that what classical machine learning is all about? Expecting future data to follow the same distribution as past data

Message : like, it's not just about the example. For any real world problem, that approach would work well, as long as you continue to use the classifier in the same domain

Message : https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb

Message : Yes yes, if you convert a problem to ground truth carefully, strong learners will blow away the competition (I use strong learners in the sense of Vapnik's learning theory, which motivated SVM, boosted trees etc)
Quoted Message : like, it's not just about the example. For any real world problem, that approach would work well, as long as you continue to use the classifier in the same domain

Message : This has all the answers

Message : You take the query as the only one in it's class, all the others are in the other class. Then you train the SVM using this as the ground truth.

Message : We had to invent the entire domain of time series modelling because of autoregression. But if you build your features carefully to take care of autoregression, traditional ml does better than time series methods
Quoted Message : Yes yes, if you convert a problem to ground truth carefully, strong learners will blow away the competition (I use strong learners in the sense of Vapnik's learning theory, which motivated SVM, boosted trees etc)

Message : Traditional ml includes NN for tabular data, btw, as those are strong learners too

Message : right
Quoted Message : You take the query as the only one in it's class, all the others are in the other class. Then you train the SVM using this as the ground truth.

Message : I remember a project from a couple of years ago where ARIMA/SARIMA class models routinely did better at time series forecasting than deep learning models. I can vouch for good feature engineering + logistic regr for a text classification use case being better than an LLM with prompt engineering and all the jazz - in a specific area, limited or smaller models can work very well.
Quoted Message : We had to invent the entire domain of time series modelling because of autoregression. But if you build your features carefully to take care of autoregression, traditional ml does better than time series methods


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I don't understand the question
Quoted Message : but isn't that what classical machine learning is all about? Expecting future data to follow the same distribution as past data

Message : like, it's not just about the example. For any real world problem, that approach would work well, as long as you continue to use the classifier in the same domain

Message : https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb

Message : Yes yes, if you convert a problem to ground truth carefully, strong learners will blow away the competition (I use strong learners in the sense of Vapnik's learning theory, which motivated SVM, boosted trees etc)
Quoted Message : like, it's not just about the example. For any real world problem, that approach would work well, as long as you continue to use the classifier in the same domain

Message : This has all the answers

Message : You take the query as the only one in it's class, all the others are in the other class. Then you train the SVM using this as the ground truth.

Message : We had to invent the entire domain of time series modelling because of autoregression. But if you build your features carefully to take care of autoregression, traditional ml does better than time series methods
Quoted Message : Yes yes, if you convert a problem to ground truth carefully, strong learners will blow away the competition (I use strong learners in the sense of Vapnik's learning theory, which motivated SVM, boosted trees etc)

Message : Traditional ml includes NN for tabular data, btw, as those are strong learners too

Message : right
Quoted Message : You take the query as the only one in it's class, all the others are in the other class. Then you train the SVM using this as the ground truth.

Message : I remember a project from a couple of years ago where ARIMA/SARIMA class models routinely did better at time series forecasting than deep learning models. I can vouch for good feature engineering + logistic regr for a text classification use case being better than an LLM with prompt engineering and all the jazz - in a specific area, limited or smaller models can work very well.
Quoted Message : We had to invent the entire domain of time series modelling because of autoregression. But if you build your features carefully to take care of autoregression, traditional ml does better than time series methods

Message : In KNN, you look at k neighbors using some distance metric. Here the assumption being k and distance function being right for the data. Imagine a case where each position of your embedding direction is in different range and scales differently. Thus a simple Euclidean, L1 might not be good. Typically circa when people did PCA or other features etc, they would normalise the vectors to avoid this.

Message : Though I imagine normalization is only viable if you are going to get your embeddings from 1 model and that alone?
Quoted Message : In KNN, you look at k neighbors using some distance metric. Here the assumption being k and distance function being right for the data. Imagine a case where each position of your embedding direction is in different range and scales differently. Thus a simple Euclidean, L1 might not be good. Typically circa when people did PCA or other features etc, they would normalise the vectors to avoid this.

Message : Going to be a mumbo-jumbo that were to happen across different source-models :P

Message : Minor corrections, so edited both above. It's hard to be accurate on WhatsApp, when typing furiously on phone :).

Here you are fitting a hyperplane with your item on one side and all others on other side. The hyperplane is fit considering the global structure and the decision output from notebook can be thought of distance of points from this hyperplane. There are nuances like you need to divide by w to get actual distance, this is the probabilistic interpretation version, Platt's 1999 paper (not the SMO paper).

Message : You normalize over columns and not rows.
Quoted Message : Going to be a mumbo-jumbo that were to happen across different source-models :P

Message : This is what people used to do before.
Quoted Message : Though I imagine normalization is only viable if you are going to get your embeddings from 1 model and that alone?

Message : But that would make inference necessarily complex, no?

In this KNN configuration, I have to look for matches in an index that is built by 2 or more embedding sources. So at inference time, I need to fetch embeddings of the search-input from all those models, and then be in a position to find matches.
Quoted Message : You normalize over columns and not rows.

Message : Without embeddings from all the embedding-sources using which the index was built, no inference can work reliably

Message : actually....

Message : If you were to store your min,max,mean values for all the normalization operations

Message : you can re-use them on the embedding, if you know the embedding-source, which you probably would do

Message : this can then work

Message : I was still talking about the old style. Yes, for multi modal one way is to normalise them across columns for each modality. I think the more prefered one, I have heard is to normalise across rows, so sums to one for each modality. Thus both vectors are equally weighted. In this case cosine will be same as dot product.

Message : Let's take it offline now.
Quoted Message : you can re-use them on the embedding, if you know the embedding-source, which you probably would do

Message : On a tangent, are there any product-folks here who might have worked closely with AI features?

Message : I have a question, I'll keep it open-ended.

Why did YouTube ditch their approach of suggesting similar videos beneath a video? The suggestions beneath videos these days are just videos I've already seen, and might want to see again.

Talking in the technical Rec-Sys terms, why would YouTube choke away Novelty and Churn like this?

Message : their goal is maximizing view time on platform (as that drives monetization), so in their A/B test, this would have worked
Quoted Message : I have a question, I'll keep it open-ended.\n\nWhy did YouTube ditch their approach of suggesting similar videos beneath a video? The suggestions beneath videos these days are just videos I've already seen, and might want to see again.\n\nTalking in the technical Rec-Sys terms, why would YouTube choke away Novelty and Churn like this?

Message : And what kind of reasoning does a AI Product team use to decide if they should replace a feature or give it as an alternative option?

Message : Because there is an argument always to let the user tune these hyper-parameters

Message : to their own liking

Message : my understanding is that this is some sort of A/B test and you're in some other bucket. I'm seeing a variety of similar videoes not just the ones I've already seen.
Quoted Message : I have a question, I'll keep it open-ended.\n\nWhy did YouTube ditch their approach of suggesting similar videos beneath a video? The suggestions beneath videos these days are just videos I've already seen, and might want to see again.\n\nTalking in the technical Rec-Sys terms, why would YouTube choke away Novelty and Churn like this?

Message : ‚Äé<attached: 00006309-PHOTO-2023-05-30-17-05-16.jpg>

Message : https://huggingface.co/decapoda-research

Anyone know are these the original weights from meta? Has anyone used this?

Message : In general - To match their attempt at User Profiling to predicting what maximizes engagement / consumption time

In context of question - A possible scenario could be "are folks willing to go back to their watch history those videos are reminded in recos" -or- "what % of users are willing to dig back in their search history to revisit similar/ antecedent videos".

In both the A/Bs, it's to be understood that the video you've just watched is an outcome of a sequence of recommendation algos based on watch, browse, share, abandonment history. If YT decides to update the params for video content & filter types, it may need to revisit the ancestral data to re-establish the reco videos & broaden the space to run experiments on user-taste. (probably also trace user-behavioral transition)
Quoted Message : And what kind of reasoning does a AI Product team use to decide if they should replace a feature or give it as an alternative option?

Message : Beautifully explained. This is a gem.
Quoted Message : In general - To match their attempt at User Profiling to predicting what maximizes engagement / consumption time\n\nIn context of question - A possible scenario could be \"are folks willing to go back to their watch history those videos are reminded in recos\" -or- \"what % of users are willing to dig back in their search history to revisit similar/ antecedent videos\". \n\nIn both the A/Bs, it's to be understood that the video you've just watched is an outcome of a sequence of recommendation algos based on watch, browse, share, abandonment history. If YT decides to update the params for video content & filter types, it may need to revisit the ancestral data to re-establish the reco videos & broaden the space to run experiments on user-taste. (probably also trace user-behavioral transition)

Message : Rec sys is almost entirely about being able to model the human brain

Message : Absolutely. And maturing the rec sys almost comes down to about generating a space where the sys can atleast mirror ( if not predict) the transition of human behaviour when exposed to matching / disparate data_types
Quoted Message : Rec sys is almost entirely about being able to model the human brain

Message : Guys, any Vellum AI alternatives for prompt engg. you guys have been using? (preferably something that's more affordable and easily usable by product teams like how Vellum is)

Message : Spellbook, StackAI and Humanloop seem to be three in the space. Haven't used or evaluated them though
Quoted Message : Guys, any Vellum AI alternatives for prompt engg. you guys have been using? (preferably something that's more affordable and easily usable by product teams like how Vellum is)

Message : Have you used humanloop's product? Been trying to evaluate it but haven't gotten the access yet.
Quoted Message : Spellbook, StackAI and Humanloop seem to be three in the space. Haven't used or evaluated them though

Message : @91989995xxxx is building portkey.ai
Quoted Message : Guys, any Vellum AI alternatives for prompt engg. you guys have been using? (preferably something that's more affordable and easily usable by product teams like how Vellum is)

Message : Hey Friends. Wanted to check if you had come across a set of 10-15 mins videos on YT to learn about practical applications for langchain

I stumbled upon Greg Kamradt‚Äôs YouTube tutorial video series. They are quite good because he is alll about practical applications of langchain and how you can build on top.

So I wanted to check what are more such video series on langchain, if you‚Äôve come across üôèüèª

Message : The langchain handbook by pinecone
Quoted Message : Hey Friends. Wanted to check if you had come across a set of 10-15 mins videos on YT to learn about practical applications for langchain\n\nI stumbled upon Greg Kamradt‚Äôs YouTube tutorial video series. They are quite good because he is alll about practical applications of langchain and how you can build on top. \n\nSo I wanted to check what are more such video series on langchain, if you‚Äôve come across üôèüèª

Message : What‚Äôs your use case?
Quoted Message : Have you used humanloop's product? Been trying to evaluate it but haven't gotten the access yet.

Message : +1 for portkey. We evaluated humanloop, promptlayer, promtbase? and some others but landed on portkey
Quoted Message : @9198xxxxxxxx is building portkey.ai

Message : Building an internal sales assistant to better prep sales reps for calls
Quoted Message : What‚Äôs your use case?

Message : I have a lot of pdfs and sales enablement materials and now I want a chat with them
Quoted Message : Building an internal sales assistant to better prep sales reps for calls

Message : How will human loop help here exactly?
Quoted Message : I have a lot of pdfs and sales enablement materials and now I want a chat with them

Message : They are for prompt management, A/B testing prompt, getting feedback

Message : Sorry I don‚Äôt understand what this means. Wanting to make it easier for our sales team to retrieve. No need for a loop or feedback but i maybe wrong. Only case is summarisd retrieval. And no resources to execute (half a back endor no $$ to buy anything so trying to learn how to do this on my own
Quoted Message : How will human loop help here exactly?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : @91989995xxxx is building portkey.ai
Quoted Message : Guys, any Vellum AI alternatives for prompt engg. you guys have been using? (preferably something that's more affordable and easily usable by product teams like how Vellum is)

Message : Hey Friends. Wanted to check if you had come across a set of 10-15 mins videos on YT to learn about practical applications for langchain

I stumbled upon Greg Kamradt‚Äôs YouTube tutorial video series. They are quite good because he is alll about practical applications of langchain and how you can build on top.

So I wanted to check what are more such video series on langchain, if you‚Äôve come across üôèüèª

Message : The langchain handbook by pinecone
Quoted Message : Hey Friends. Wanted to check if you had come across a set of 10-15 mins videos on YT to learn about practical applications for langchain\n\nI stumbled upon Greg Kamradt‚Äôs YouTube tutorial video series. They are quite good because he is alll about practical applications of langchain and how you can build on top. \n\nSo I wanted to check what are more such video series on langchain, if you‚Äôve come across üôèüèª

Message : What‚Äôs your use case?
Quoted Message : Have you used humanloop's product? Been trying to evaluate it but haven't gotten the access yet.

Message : +1 for portkey. We evaluated humanloop, promptlayer, promtbase? and some others but landed on portkey
Quoted Message : @9198xxxxxxxx is building portkey.ai

Message : Building an internal sales assistant to better prep sales reps for calls
Quoted Message : What‚Äôs your use case?

Message : I have a lot of pdfs and sales enablement materials and now I want a chat with them
Quoted Message : Building an internal sales assistant to better prep sales reps for calls

Message : How will human loop help here exactly?
Quoted Message : I have a lot of pdfs and sales enablement materials and now I want a chat with them

Message : They are for prompt management, A/B testing prompt, getting feedback

Message : Sorry I don‚Äôt understand what this means. Wanting to make it easier for our sales team to retrieve. No need for a loop or feedback but i maybe wrong. Only case is summarisd retrieval. And no resources to execute (half a back endor no $$ to buy anything so trying to learn how to do this on my own
Quoted Message : How will human loop help here exactly?

Message : something like https://www.chatdox.com/ would be useful for this. I believe there are some open source solutions as well, though depending on your use-case, building something from scratch can also be faster.
Quoted Message : Sorry I don‚Äôt understand what this means. Wanting to make it easier for our sales team to retrieve. No need for a loop or feedback but i maybe wrong. Only case is summarisd retrieval. And no resources to execute (half a back endor no $$ to buy anything so trying to learn how to do this on my own

Message : I think two threads got mixed ü•≤ 

https://python.langchain.com/en/latest/use_cases/summarization.html

This should work for you.
Quoted Message : Sorry I don‚Äôt understand what this means. Wanting to make it easier for our sales team to retrieve. No need for a loop or feedback but i maybe wrong. Only case is summarisd retrieval. And no resources to execute (half a back endor no $$ to buy anything so trying to learn how to do this on my own

Message : 1. Evaluating different models and comparing
2. Experimenting with prompts and version controlling
Quoted Message : What‚Äôs your use case?

Message : Thank you so much. Def looking to do the old fashioned Build from scratch instead of buy for a couple of reasons (resources constraint plus learning also is important, hence the request for videos haha)
Quoted Message : something like https://www.chatdox.com/ would be useful for this. I believe there are some open source solutions as well, though depending on your use-case, building something from scratch can also be faster.

Message : Evaluating how?
For 2nd, portkey is perfect
Quoted Message : 1. Evaluating different models and comparing\n2. Experimenting with prompts and version controlling

Message : @91989995xxxx is the founder and can help
Quoted Message : Evaluating how?\nFor 2nd, portkey is perfect

Message : Like trying out different open models simultaneously on a bunch of queries and comparing performances while fine turning
Quoted Message : Evaluating how?\nFor 2nd, portkey is perfect

Message : will try portkey
Quoted Message : Evaluating how?\nFor 2nd, portkey is perfect

Message : Try the tutorials by James Briggs.
Quoted Message : Hey Friends. Wanted to check if you had come across a set of 10-15 mins videos on YT to learn about practical applications for langchain\n\nI stumbled upon Greg Kamradt‚Äôs YouTube tutorial video series. They are quite good because he is alll about practical applications of langchain and how you can build on top. \n\nSo I wanted to check what are more such video series on langchain, if you‚Äôve come across üôèüèª

Message : comparing how? Human feedback or through some metric? Best to run a python notebook in that case
Quoted Message : Like trying out different open models simultaneously on a bunch of queries and comparing performances while fine turning

Message : Thank you so much. Will try these out üôÇ
Quoted Message : Try the tutorials by James Briggs.

Message : Hey! I'm Aryan here, and i just passed out of highschool a few months ago, and I used to code back when i was in 8th or something and now am looking to get back into it full time and find internships in the ai/ml field. But i wanted to first gain experience and build a portfolio, so how do i start as a newbie in the field (courses etc), there is so much of info I feel clueless.

Message : I just know python, and have worked on one or two projects with the help of gpt, but i don't feel like I learnt much, should I do more math etc and go the conventional method?

Message : On babylm & the quest for smaller LLMs

https://www.nytimes.com/2023/05/30/science/ai-chatbots-language-learning-models.html

Message : Observation: GPT-4 browsing can be used to access text webpages which were once unclickable by saving a snapshot of the webpage on the wayback machine. Not sure how true this is, but it worked the first few times I tried.

Message : Anyone tried hands on privateGPT , how it is performing. I have a usecase where i have to extract parties and legal description part from the documents and i tried to use gpt4 and able to get almost Perfect answers for prompts. But constraints here i can't use gpt4 , something i can train or use locally

Message : Great resource. 

https://hackernoon.com/prompt-engineering-101-i-unveiling-principles-and-techniques-of-effective-prompt-crafting

Message : What are the open source tools for prompt versioning and prompt management?

Message : More advanced guide
nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Quoted Message : Great resource. \n\nhttps://hackernoon.com/prompt-engineering-101-i-unveiling-principles-and-techniques-of-effective-prompt-crafting

Message : Promptable is open source but not great. For simple stuff I‚Äôve seen people manage conf files for prompts and then use them with an SDK like Langchain
Quoted Message : What are the open source tools for prompt versioning and prompt management?

Message : not me creating TEMPLATE_1, TEMPLATE_PREVOUS, TEMPLATE_NOT_TO_BE_USED, TEMPLATE_ACTIVE
Quoted Message : Promptable is open source but not great. For simple stuff I‚Äôve seen people manage conf files for prompts and then use them with an SDK like Langchain

Message : Isn't prompt the same as any kind of knob/config in SW? Why not just treat it the same for flavour/variant control via config files? 
Am I missing something here?
Quoted Message : What are the open source tools for prompt versioning and prompt management?

Message : It works alright for RAG based QA, you'll have to test for your specific use case as it'll be inferior to GPT4 in extracting dependencies and may miss out on few parties here and there as per my observation.
Quoted Message : Anyone tried hands on privateGPT , how it is performing. I have a usecase where i have to extract parties and legal description part from the documents and i tried to use gpt4 and able to get almost Perfect answers for prompts. But constraints here i can't use gpt4 , something i can train or use locally

Message : ‚Äé<attached: 00006352-PHOTO-2023-05-30-21-22-30.jpg>

Message : Where the TEMPLATE_Final_pleaseworkthistime
Quoted Message : not me creating TEMPLATE_1, TEMPLATE_PREVOUS, TEMPLATE_NOT_TO_BE_USED, TEMPLATE_ACTIVE

Message : ‚Äé<attached: 00006354-PHOTO-2023-05-30-21-42-06.jpg>

Message : ‚Äé<attached: 00006355-PHOTO-2023-05-30-21-52-36.jpg>

Message : anyone here going to the airport to welcome him? üòÇ
AItithi devo bhava
Quoted Message :  2023_05_30_90A8A40C046F3CF5427A9B12904BA888.jpeg

Message : As a large language model, I cannot travel
Quoted Message : anyone here going to the airport to welcome him? üòÇ\nAItithi devo bhava

Message : Government should lobby Sama to put Indian users of OpenAI on same priority as those in the US. And integrate UPI for payments.

Message : Are indian users devoid of any features?
Quoted Message : Government should lobby Sama to put Indian users of OpenAI on same priority as those in the US. And integrate UPI for payments.

Message : As I'll be switching to an Indian paid subscription soon

Message : Rn I have access to gpt 4 plug-ins, web browsing with bing and gpt 3.5

Message : Some features get rolled out late to Indian users. Iphone app is the recent onem

Message : Same with a Indian subscription
Quoted Message : Rn I have access to gpt 4 plug-ins, web browsing with bing and gpt 3.5

Message : *an

Message : Alright that's a relief
Quoted Message : Same with a Indian subscription

Message : Is anyone aware of an AI music generator that can do background scores for video?

Message : do check out - https://riffusion.com/
Quoted Message : Is anyone aware of an AI music generator that can do background scores for video?

Message : Beatoven, Mubert
Quoted Message : Is anyone aware of an AI music generator that can do background scores for video?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Are indian users devoid of any features?
Quoted Message : Government should lobby Sama to put Indian users of OpenAI on same priority as those in the US. And integrate UPI for payments.

Message : As I'll be switching to an Indian paid subscription soon

Message : Rn I have access to gpt 4 plug-ins, web browsing with bing and gpt 3.5

Message : Some features get rolled out late to Indian users. Iphone app is the recent onem

Message : Same with a Indian subscription
Quoted Message : Rn I have access to gpt 4 plug-ins, web browsing with bing and gpt 3.5

Message : *an

Message : Alright that's a relief
Quoted Message : Same with a Indian subscription

Message : Is anyone aware of an AI music generator that can do background scores for video?

Message : do check out - https://riffusion.com/
Quoted Message : Is anyone aware of an AI music generator that can do background scores for video?

Message : Beatoven, Mubert
Quoted Message : Is anyone aware of an AI music generator that can do background scores for video?

Message : Do indian users have access to gpt plugins? Even after being a premium user?

Message : Yes
Quoted Message : Do indian users have access to gpt plugins? Even after being a premium user?

Message : Yes, have access

Message : Although, I'll be honest. Plugins have been quite mediocre so far

Message : Strangely it does not work for me. Not sure. Will check with you.

Message : Browser fails quite often at basic tasks

Message : Hope they fix that soon

Message : Interesting! but i found them to sound similar to each other
Quoted Message : do check out - https://riffusion.com/

Message : Logout, then login and check settings. If you find beta features, look for plugin/web browsing and enable it
Quoted Message : Strangely it does not work for me. Not sure. Will check with you.

Message : How so?
Quoted Message : Browser fails quite often at basic tasks

Message : Is it a click failed failure?

Message : Yes. That's the most common one

Message : There are a couple of others as wdll

Message : This is common because of robots.txt
Quoted Message : Is it a click failed failure?

Message : I found a workaround earlier.

Message : .
Quoted Message : Observation: GPT-4 browsing can be used to access text webpages which were once unclickable by saving a snapshot of the webpage on the wayback machine. Not sure how true this is, but it worked the first few times I tried.

Message : Scrapers/link readers have worked very well for me. Web browsing option can fail more frequently.

Message : Oh, thanks! Now it works.
Quoted Message : Logout, then login and check settings. If you find beta features, look for plugin/web browsing and enable it

Message : Interesting
Quoted Message : .

Message : I think someone on this group (or maybe Twitter) quite astutely pointed out that if meta had built chatgpt, they would have engineered it for crazy amounts of continued growth

Message : Openai gets basic UI wrong sometimes. Like the fact that you can't search on plugins is just a big oversight

Message : If you want to find a plugin, you need to manually scroll through each page to install

Message : I think not giving a serach bar to find plugins is a calculated move, provided that it's purely growing word of mouth they'd want everyone to know at least some more plugins apart from just their use case and would be tempted to try more. 

üòÖ
Quoted Message : If you want to find a plugin, you need to manually scroll through each page to install

Message : But the main issue/feature seems to be the apparent context window limit increase with gpt-4 browsing
Quoted Message : Scrapers/link readers have worked very well for me. Web browsing option can fail more frequently.

Message : Which will not be the case with any browser based extension

Message : What is the context window they're providing
Quoted Message : But the main issue/feature seems to be the apparent context window limit increase with gpt-4 browsing

Message : Gpt-4 is able to take an entire webpage as input context

Message : Probably the increased model.
Quoted Message : What is the context window they're providing

Message : 32k token limit

Message : Because in chatgpt the gpt4 is limited to 4k

Message : Yes but if that were the case gpt 4 with browsing would not be able to read large webpages. Which it can. Not to mention it can perform continued link search which would require even more context.
Quoted Message : Because in chatgpt the gpt4 is limited to 4k

Message : I think there are techniques to help with that
Quoted Message : Yes but if that were the case gpt 4 with browsing would not be able to read large webpages. Which it can. Not to mention it can perform continued link search which would require even more context.

Message : We have a feature at longshot as well where we read multiple web pages not just 1.

Message : True, the plugin interface design should've been similar to play store or iOS app store. It's quite obvious the natural direction of plugin developement is going to be the same as Android/iOS. May be searching and review based system would be implemented once their beta phase is over for plugins.
Quoted Message : Openai gets basic UI wrong sometimes. Like the fact that you can't search on plugins is just a big oversight

Message : True, I was using plugins to go through YouTube podcasts to identify books/ideas/thought experiments at once. But it was not doing well for anything longer than 1 hour.
Quoted Message : But the main issue/feature seems to be the apparent context window limit increase with gpt-4 browsing

Message : My experience has been similar. Interested in talking if someone has had a good experience with plugins
Quoted Message : Although, I'll be honest. Plugins have been quite mediocre so far

Message : Is there a good way to keep a preffered token length of variables inside a prompt template?

Oftentimes I want to trim out a particular variable like chat history if overall length of prompt is exceeding 4K tokens.

langchain doesn't support this out of box so I've a function to accept preffered token length and cut from start or back configurablity which I use with prompt templates these days but it has limitations around not having priority order of variables to cut tokens from if overall length is exceeding 4K so I've done patches on top of it but haven't reached a very sophisticated method yet

Message : I used show-me plugin for creating flowcharts(for PPT slides) ..seems to be doing a good job.
Quoted Message : My experience has been similar. Interested in talking if someone has had a good experience with plugins

Message : Memory e.g. ConversationalMemoryBuffer does this in Langchain?
Quoted Message : Is there a good way to keep a preffered token length of variables inside a prompt template?\n\nOftentimes I want to trim out a particular variable like chat history if overall length of prompt is exceeding 4K tokens.\n\nlangchain doesn't support this out of box so I've a function to accept preffered token length and cut from start or back configurablity which I use with prompt templates these days but it has limitations around not having priority order of variables to cut tokens from if overall length is exceeding 4K so I've done patches on top of it but haven't reached a very sophisticated method yet

Message : ‚Äé<attached: 00006409-PHOTO-2023-05-31-10-06-20.jpg>
Quoted Message :  2023_05_30_3A9B3940C378EC8DC546.jpeg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Yes but if that were the case gpt 4 with browsing would not be able to read large webpages. Which it can. Not to mention it can perform continued link search which would require even more context.
Quoted Message : Because in chatgpt the gpt4 is limited to 4k

Message : I think there are techniques to help with that
Quoted Message : Yes but if that were the case gpt 4 with browsing would not be able to read large webpages. Which it can. Not to mention it can perform continued link search which would require even more context.

Message : We have a feature at longshot as well where we read multiple web pages not just 1.

Message : True, the plugin interface design should've been similar to play store or iOS app store. It's quite obvious the natural direction of plugin developement is going to be the same as Android/iOS. May be searching and review based system would be implemented once their beta phase is over for plugins.
Quoted Message : Openai gets basic UI wrong sometimes. Like the fact that you can't search on plugins is just a big oversight

Message : True, I was using plugins to go through YouTube podcasts to identify books/ideas/thought experiments at once. But it was not doing well for anything longer than 1 hour.
Quoted Message : But the main issue/feature seems to be the apparent context window limit increase with gpt-4 browsing

Message : My experience has been similar. Interested in talking if someone has had a good experience with plugins
Quoted Message : Although, I'll be honest. Plugins have been quite mediocre so far

Message : Is there a good way to keep a preffered token length of variables inside a prompt template?

Oftentimes I want to trim out a particular variable like chat history if overall length of prompt is exceeding 4K tokens.

langchain doesn't support this out of box so I've a function to accept preffered token length and cut from start or back configurablity which I use with prompt templates these days but it has limitations around not having priority order of variables to cut tokens from if overall length is exceeding 4K so I've done patches on top of it but haven't reached a very sophisticated method yet

Message : I used show-me plugin for creating flowcharts(for PPT slides) ..seems to be doing a good job.
Quoted Message : My experience has been similar. Interested in talking if someone has had a good experience with plugins

Message : Memory e.g. ConversationalMemoryBuffer does this in Langchain?
Quoted Message : Is there a good way to keep a preffered token length of variables inside a prompt template?\n\nOftentimes I want to trim out a particular variable like chat history if overall length of prompt is exceeding 4K tokens.\n\nlangchain doesn't support this out of box so I've a function to accept preffered token length and cut from start or back configurablity which I use with prompt templates these days but it has limitations around not having priority order of variables to cut tokens from if overall length is exceeding 4K so I've done patches on top of it but haven't reached a very sophisticated method yet

Message : ‚Äé<attached: 00006409-PHOTO-2023-05-31-10-06-20.jpg>
Quoted Message :  2023_05_30_3A9B3940C378EC8DC546.jpeg

Message : I've confirmed reports from several devs and founders that GPT4 API has unusual RateLimit Errors in last 48 hours or so. Creating a new key seems to help. If you've a personal account, upgrading it to organisation also seems to help.

Message : Has anyone tried BloopAI (https://github.com/BloopAI/bloop) for in-repository code-searching

I've used it, and its like a senior engineer who knows absolutely everything about your codebase. Its what Github search was ought to become üôÇ

Message : I thought sourcegraph was awesome but this looks cool. Will check it out
Quoted Message : Has anyone tried BloopAI (https://github.com/BloopAI/bloop) for in-repository code-searching\n\nI've used it, and its like a senior engineer who knows absolutely everything about your codebase. Its what Github search was ought to become üôÇ

Message : In fact sourcegraph might be better for a more deterministic browsing
Quoted Message : I thought sourcegraph was awesome but this looks cool. Will check it out

Message : Could give generative fill a shot in Adobe photoshop without any prompt
Quoted Message :  2023_05_31_3EB04A5B1951088A773C17.jpeg

Message : Any news on Sam Altman‚Äôs delhi visit?

Message : ‚Äé<attached: 00006417-PHOTO-2023-05-31-11-49-03.jpg>

Message : This is some complete colab level BS

Message : You select A100 and you get T4 kind of scam this

Message : Cc @91783815xxxx any insider info from tcs? üåù
Quoted Message :  2023_05_30_90A8A40C046F3CF5427A9B12904BA888.jpeg

Message : Since when. I have been using since morning..
Quoted Message :  2023_05_31_3EB012514154F9DB8173AC.jpeg

Message : Right now. Mainly on Code Interpreter.
Quoted Message : Since when. I have been using since morning..

Message : https://news.ycombinator.com/item?id=36134249

Message : Yes, too much RLHF
Quoted Message : https://news.ycombinator.com/item?id=36134249

Message : ‚ÄòDumb stochastic parrot‚Äôü§£
Quoted Message : https://news.ycombinator.com/item?id=36134249

Message : How has been people's experience with Claude 100K?

Message : Good.
Quoted Message : How has been people's experience with Claude 100K?

Message : It's definitely very good but lacks some things that gpt4 etc have. It's much faster

Message : Its called the great AGI disillusionment
Quoted Message : https://news.ycombinator.com/item?id=36134249

Message : Also prompt engineering is a little different here

Message : I mean, Sama is publicly speaking about the species-level dangers of AI, what do you expect? We only get Nerf guns from now on. üòÄ
Quoted Message : https://news.ycombinator.com/item?id=36134249

Message : I keep a nerf water gun with me all the time in case my GPUs suddenly become sentients.

Message : NSA has a backdoor to all modern cpus / gpus\nWouldn‚Äôt worry too much about silicon becoming sentient

Message : NSA has a backdoor to all modern cpus / gpus
Wouldn‚Äôt worry too much about silicon becoming sentient

Message : Could be that they quantized the model further which leads to faster inference times but reduction in quality.
Quoted Message : https://news.ycombinator.com/item?id=36134249

Message : +1
The inference times have improved a lot recently.
Quoted Message : Could be that they quantized the model further which leads to faster inference times but reduction in quality.

Message : Yeah if the model has gotten dumber and faster, it's most likely the result of *model compression*. Not quantization though, that'll most likely Nerf it down completely. Also we aren't sure if openAI has started anything resembling GGML/GPTQ quantization internally.
Quoted Message : Could be that they quantized the model further which leads to faster inference times but reduction in quality.

Message : Has anyone used or knows the best model for english to chinese translation? A bunch of them on HF but if anyone has experience in something else it‚Äôll be great

Message : Anybody here regularly finetuning llama, opt or gpt j 6b? Have some quick questions to ask related to approach for the same. Thanks!

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : strange, on my codebase it really sucks. Most answers are super lame or fail with "something went wrong". Doubtful if I'll use it on an ongoing basis
Quoted Message : Has anyone tried BloopAI (https://github.com/BloopAI/bloop) for in-repository code-searching\n\nI've used it, and its like a senior engineer who knows absolutely everything about your codebase. Its what Github search was ought to become üôÇ

Message : There is an interesting conversation going on in the *AI and Philosophy* WA group on the regulator, AI research companies and the recent "AI will cause extinction" tweet signed by OAI, Stability and others: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : Related: For folks interested in *Generative Art*, including images, video and music: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4

Message : BTW this is interesting https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized - comparing token sizes for the same sentence in different languages. My takeaways: 1. in some languages token numbers will be unexpectedly high 2. If you're consistently using an LLM with non-English inputs/outputs it may be worth building an LLM with lang specific tokens (I remember we were discussing this a while back in this group) 3. Most likely this would apply to obscure english words too in domains like medical, legal etc which have a lot of foreign words (latin, Greek etc) or domain specific words

Message : Number of tokens:

Nirant: 3 English
‡§®‡§ø‡§∞‡§Ç‡§§: 10 Hindi
‡™®‡™ø‡™∞‡™æ‡™Ç‡™§: 18 Gujarati
‡Æ®‡Æø‡Æ∞‡Æ®‡Øç‡Æ§‡Øç: 21 Tamil

Message : If I am new to dl, can anyone recommend good resources to start with it.

Message : course.fast.ai
Quoted Message : If I am new to dl, can anyone recommend good resources to start with it.

Message : thanksüëç‚úåÔ∏è

Message : are there good books that I can use instead of a course?

Message : + 1 for this recomendation - there's also a book by the TA of this course - it also has jupyter notebook for all the lessons - https://course.fast.ai/Resources/book.html
Quoted Message : course.fast.ai


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : strange, on my codebase it really sucks. Most answers are super lame or fail with "something went wrong". Doubtful if I'll use it on an ongoing basis
Quoted Message : Has anyone tried BloopAI (https://github.com/BloopAI/bloop) for in-repository code-searching\n\nI've used it, and its like a senior engineer who knows absolutely everything about your codebase. Its what Github search was ought to become üôÇ

Message : There is an interesting conversation going on in the *AI and Philosophy* WA group on the regulator, AI research companies and the recent "AI will cause extinction" tweet signed by OAI, Stability and others: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : Related: For folks interested in *Generative Art*, including images, video and music: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4

Message : BTW this is interesting https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized - comparing token sizes for the same sentence in different languages. My takeaways: 1. in some languages token numbers will be unexpectedly high 2. If you're consistently using an LLM with non-English inputs/outputs it may be worth building an LLM with lang specific tokens (I remember we were discussing this a while back in this group) 3. Most likely this would apply to obscure english words too in domains like medical, legal etc which have a lot of foreign words (latin, Greek etc) or domain specific words

Message : Number of tokens:

Nirant: 3 English
‡§®‡§ø‡§∞‡§Ç‡§§: 10 Hindi
‡™®‡™ø‡™∞‡™æ‡™Ç‡™§: 18 Gujarati
‡Æ®‡Æø‡Æ∞‡Æ®‡Øç‡Æ§‡Øç: 21 Tamil

Message : If I am new to dl, can anyone recommend good resources to start with it.

Message : course.fast.ai
Quoted Message : If I am new to dl, can anyone recommend good resources to start with it.

Message : thanksüëç‚úåÔ∏è

Message : are there good books that I can use instead of a course?

Message : + 1 for this recomendation - there's also a book by the TA of this course - it also has jupyter notebook for all the lessons - https://course.fast.ai/Resources/book.html
Quoted Message : course.fast.ai

Message : http://introtodeeplearning.com by MIT is good, I've heard.
Quoted Message : If I am new to dl, can anyone recommend good resources to start with it.

Message : apart from fast.ai

ML - Stanford CS229: Machine Learning | Summer 2019 ‚Äì Courses explains everything from scratch, Math, Stats, Algorithms - https://youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh


DL (Focus on CV) - Stanford cs231n - https://www.youtube.com/playlist?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk

NLP from scratch to Language Models - Stanford CS 224N - https://youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ
Quoted Message : If I am new to dl, can anyone recommend good resources to start with it.

Message : Let's stick to the topic, which is Generative AI please üôè

Plenty of resources online on Deep Learning  ‚Äî I should've not encouraged this in the first place üòÖ

Message : Can‚Äôt we have a separate group for generic deep learning, like things which aren‚Äôt a part of generative space.
Quoted Message : Let's stick to the topic, which is Generative AI please üôè\n\nPlenty of resources online on Deep Learning  ‚Äî I should've not encouraged this in the first place üòÖ

Message : Please feel free to make one, *outside of this community* ‚Äî I am sure there are lot of folks interested in it! 

I do not have it in me to moderate another WA group
Quoted Message : Can‚Äôt we have a separate group for generic deep learning, like things which aren‚Äôt a part of generative space.

Message : I would love to create an AI Founders Forum with interested folks here :)

https://lightning-ogre-740.notion.site/All-In-Founder-Forum-19e1d399977f46b8b044ca5e939027d6

Message : @91773788xxxx Should we move this from whatsapp to discord server, where topic specific channels can be created, for moderation purposes we can leverage bots as well ?

Message : And I meant topics within Generative AI,

Message : +1
Quoted Message : I would love to create an AI Founders Forum with interested folks here :)\n\nhttps://lightning-ogre-740.notion.site/All-In-Founder-Forum-19e1d399977f46b8b044ca5e939027d6

Message : Please no, discord is not as accessible as WA
Quoted Message : @9177xxxxxxxx Should we move this from whatsapp to discord server, where topic specific channels can be created, for moderation purposes we can leverage bots as well ?

Message : Is there a known way to measure diversity, code consistency which people are complaining about?
Quoted Message : Yes, too much RLHF

Message : Can you share this link
Quoted Message : Check our the recys paper that @9198xxxxxxxx had posted. It's a slightly terribly written paper but will give you ideas on how TikTok is mixing some of these. There are enough details. For them, freshness can be what is trending video in last 30 mins !!

Message : Apart from a few open Ai gym problems like lunar lander and mountain car, can you guys recommend any other RL problem statements ?

Message : Recommendation as a RL system (check youtube paper)
Quoted Message : Apart from a few open Ai gym problems like lunar lander and mountain car, can you guys recommend any other RL problem statements ?

Message : https://m.youtube.com/watch?v=HEqQ2_1XRTs
Quoted Message : Recommendation as a RL system (check youtube paper)

Message : ‚Äé<attached: 00006471-PHOTO-2023-05-31-21-23-16.jpg>

Message : Has anyone else come across long build times for docker containers using a Pytorch dependency? Often times upwards of 20 minutes even on dedicated cloud build servers like Azure DevOps. Does anyone know workarounds for this kind of a situation? Or is it to be expected given how heavy torch has become?

Message : which pytorch version and base image?
Quoted Message : Has anyone else come across long build times for docker containers using a Pytorch dependency? Often times upwards of 20 minutes even on dedicated cloud build servers like Azure DevOps. Does anyone know workarounds for this kind of a situation? Or is it to be expected given how heavy torch has become?

Message : Random Prediction - 1 year from now, Adobe will do to Premiere pro what they just did to Photoshop.

Generative fill for videos. If implemented correctly, that will be the biggest impact of AI on the majority of the world, something even chatgpt can't claim to have.

Generative fill for videos will make the discussion of aspect ratios obsolete. It will restructure the entire display manufacturing and creative industry.

I get black bars on my TV because the movie I'm seeing was shot in a different aspect ratio. If done correctly, that can enormously reduce the contexts in which we use the phrase "aspect-ratio"

Message : yes
although there are two types of distributions now

pypi - this one is split into main pytorch plus libcu*.so provided by various nvidia-cu* wheels

torch index - this one has massive 1.5-2GB wheels that are downloaded as one file

if you don't need cuda use the +cpu variants they are only 200 MB ish

It is important to correctly use Docker caching or just start from official pytorch images
Quoted Message : Has anyone else come across long build times for docker containers using a Pytorch dependency? Often times upwards of 20 minutes even on dedicated cloud build servers like Azure DevOps. Does anyone know workarounds for this kind of a situation? Or is it to be expected given how heavy torch has become?

Message : Love the movie aspect ratio use case. Would be awesome if Smart TVs did it :)
Quoted Message : Random Prediction - 1 year from now, Adobe will do to Premiere pro what they just did to Photoshop.\n\nGenerative fill for videos. If implemented correctly, that will be the biggest impact of AI on the majority of the world, something even chatgpt can't claim to have.\n\nGenerative fill for videos will make the discussion of aspect ratios obsolete. It will restructure the entire display manufacturing and creative industry.\n\nI get black bars on my TV because the movie I'm seeing was shot in a different aspect ratio. If done correctly, that can enormously reduce the contexts in which we use the phrase \"aspect-ratio\"

Message : When a technology has the potential to remove one of the very first lessons that any creative learns about, you know that's significant on another scale

Message : torch~1.9 (different sub versions) and Python 3.9 and 3.10 base images (slim)
Quoted Message : which pytorch version and base image?

Message : Thats helpful, thanks. I think in some cases the CUDA bits may not be required, let me check that out.
Quoted Message : yes\nalthough there are two types of distributions now\n\npypi - this one is split into main pytorch plus libcu*.so provided by various nvidia-cu* wheels\n\ntorch index - this one has massive 1.5-2GB wheels that are downloaded as one file\n\nif you don't need cuda use the +cpu variants they are only 200 MB ish\n\nIt is important to correctly use Docker caching or just start from official pytorch images

Message : if you have your own builder, make sure
- you pull in the cache from previous version of the image
- if you can use docker buildkit, use a mount to cache pip downloads

RUN --mount=type=cache,target=/root/.cache/pip

first build will take time to download, next build will just start installing
Quoted Message : torch~1.9 (different sub versions) and Python 3.9 and 3.10 base images (slim)

Message : we had this issue in our case as well
pre 2.0 images were pretty huge (cuda) (16 gb)
so we switched to 2.0 PT base image which solved one of this major issue because the final image was like 6 gb

apart from that try to cache the layers
if it's in the CI, I think there are services that can help you with that
Quoted Message : torch~1.9 (different sub versions) and Python 3.9 and 3.10 base images (slim)

Message : Royalties waived off for commercial and research use for Falcon 40B

https://twitter.com/TIIuae/status/1663911042559234051?s=20

Message : Movie directors will hate you more!
Quoted Message : Love the movie aspect ratio use case. Would be awesome if Smart TVs did it :)

Message : Thanks, what was the underlying reason? Model size and quantization for pretrained models? Anything else?
Quoted Message : we had this issue in our case as well\npre 2.0 images were pretty huge (cuda) (16 gb)\nso we switched to 2.0 PT base image which solved one of this major issue because the final image was like 6 gb\n\napart from that try to cache the layers\nif it's in the CI, I think there are services that can help you with that

Message : just changing pytorch image helped me
didn't change any model weights/quantization stuff
previously we were using nvidia images but later figured it had some additional dependencies which we didn't need
Quoted Message : Thanks, what was the underlying reason? Model size and quantization for pretrained models? Anything else?

Message : Thanks, that is helpful too

Message : ‚Äé<attached: 00006487-PHOTO-2023-05-31-22-26-45.jpg>

Message : https://openai.com/research/improving-mathematical-reasoning-with-process-supervision OpenAI announced that they are training their reward models to provide reward for every thought (reward shaping) than giving reward at the last step for mathematical reasoning tasks.

Message : If all in your company follow consistent versions (python, torch, and even models) then create slim base images (with version combination) and push them to your repo. All other teams now can create images on top of these base images.

For advanced base image size reduction: check these but with caution, as it may not work as intended along with a reduction in your debugability.

Use torch serve base image https://hub.docker.com/r/pytorch/torch serve

https://github.com/slimtoolkit/slim

https://github.com/GoogleContainerTools/distress

Use the Alpine base image but it may increase your build time.

In general, try to reduce the number of layers in the Docker image. This one is a good article https://pythonspeed.com/articles/smaller-docker-images/
Quoted Message : torch~1.9 (different sub versions) and Python 3.9 and 3.10 base images (slim)

Message : https://twitter.com/kiwicopple/status/1664027051312001027?s=19

Message : This latest launch by supabase is pretty incredible. Other vector stores might be better at much larger scale, but supabase def has the most comprehensive toolkit and DX

Message : Falcon models have been made Apache2.0! good news !

https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_exciting-news-falcon-models-from-tii-activity-7069750736250621952-GH9U?utm_source=share&utm_medium=member_android

Message : TIL https://aviary.anyscale.com/

Compare cost, latency and choice on answer across LLMs with this simple UI. Comes handy for domain specific prompt testing across OSS models.

Message : ‚Äé<attached: 00006494-PHOTO-2023-06-01-09-49-44.jpg>

Message : Funny translations


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Thanks, that is helpful too

Message : ‚Äé<attached: 00006487-PHOTO-2023-05-31-22-26-45.jpg>

Message : https://openai.com/research/improving-mathematical-reasoning-with-process-supervision OpenAI announced that they are training their reward models to provide reward for every thought (reward shaping) than giving reward at the last step for mathematical reasoning tasks.

Message : If all in your company follow consistent versions (python, torch, and even models) then create slim base images (with version combination) and push them to your repo. All other teams now can create images on top of these base images.

For advanced base image size reduction: check these but with caution, as it may not work as intended along with a reduction in your debugability.

Use torch serve base image https://hub.docker.com/r/pytorch/torch serve

https://github.com/slimtoolkit/slim

https://github.com/GoogleContainerTools/distress

Use the Alpine base image but it may increase your build time.

In general, try to reduce the number of layers in the Docker image. This one is a good article https://pythonspeed.com/articles/smaller-docker-images/
Quoted Message : torch~1.9 (different sub versions) and Python 3.9 and 3.10 base images (slim)

Message : https://twitter.com/kiwicopple/status/1664027051312001027?s=19

Message : This latest launch by supabase is pretty incredible. Other vector stores might be better at much larger scale, but supabase def has the most comprehensive toolkit and DX

Message : Falcon models have been made Apache2.0! good news !

https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_exciting-news-falcon-models-from-tii-activity-7069750736250621952-GH9U?utm_source=share&utm_medium=member_android

Message : TIL https://aviary.anyscale.com/

Compare cost, latency and choice on answer across LLMs with this simple UI. Comes handy for domain specific prompt testing across OSS models.

Message : ‚Äé<attached: 00006494-PHOTO-2023-06-01-09-49-44.jpg>

Message : Funny translations

Message : ‚Äé<attached: 00006496-PHOTO-2023-06-01-09-50-23.jpg>

Message : Surprisingly dolly v2 is decent. Did not expect!

Message : Also demonstrates that Dolly, returned the correct answer in the second trial though .. the first trial was wrong. So inconsistent a bit

Message : There‚Äôs a lot more to come from supabase. Just one of the cool stuff team has been brewing :)
Quoted Message : This latest launch by supabase is pretty incredible. Other vector stores might be better at much larger scale, but supabase def has the most comprehensive toolkit and DX

Message : Postgres support?
Quoted Message : This latest launch by supabase is pretty incredible. Other vector stores might be better at much larger scale, but supabase def has the most comprehensive toolkit and DX

Message : Anyone used any generative tools for auto/assisted ground truth annotation of images or LiDAR with boxes/semantic segmentation labels?

Message : Supabase has always been postgres under-the-hood: they are productizing pgvector better
Quoted Message : Postgres support?

Message : That's my point - the fact that their lingua franca is PG, that results in a solid DX
Quoted Message : Supabase has always been postgres under-the-hood: they are productizing pgvector better

Message : But I am hearing PGVector doesn't do well at scale

Message : ‚Äé<attached: 00006505-PHOTO-2023-06-01-09-59-13.jpg>

Message : This is the same old RLHF pipeline. They (I think karpathy) just explicitly showing two parts of RLHF - Reward modeling and then using Reward network to train policy network.
Quoted Message :  2023_06_01_3A2F5FB2AD419E5F9E6D.jpeg

Message : Some of them are more excited & optimistic than you would believe !
Quoted Message : Movie directors will hate you more!

Message : How about TVs with GPUs that can automatically make HD videos out of old low resolution videos with GFGAN or something similar.
Quoted Message : When a technology has the potential to remove one of the very first lessons that any creative learns about, you know that's significant on another scale

Message : Don‚Äôt TVs already have chips that have GPUs in them? DLSS has been in gaming consoles and  rDNA architectures allow for similar capabilities.
Quoted Message : How about TVs with GPUs that can automatically make HD videos out of old low resolution videos with GFGAN or something similar.

Message : Interesting, got to check it out and update my knowledge. Not sure my 800$ TV has 1000$ GPU chip but I may be wrong.
Quoted Message : Don‚Äôt TVs already have chips that have GPUs in them? DLSS has been in gaming consoles and  rDNA architectures allow for similar capabilities.

Message : How about we make every thing kids friends and all the violence and blood is replaced by flowers and rainbow based on settings, in real time üòú

Message : Cc Rahul @91966317xxxx is doing this
Quoted Message : How about we make every thing kids friends and all the violence and blood is replaced by flowers and rainbow based on settings, in real time üòú

Message : That's the reason this group has DeepMedia in it

Message : Not in real time (yet) though. :)
Quoted Message : Cc Rahul @9196xxxxxxxx is doing this

Message : Add me as an early tester. My 5yo loves demon slayer and May be this will give me a moral victory

Message : Hahah will DM.
Quoted Message : Add me as an early tester. My 5yo loves demon slayer and May be this will give me a moral victory

Message : We are doing next year prediction anywayüòú the way we are moving it‚Äôs definitely will be a thing.
Quoted Message : Not in real time (yet) though. :)

Message : More like 2 months.
Quoted Message : We are doing next year prediction anywayüòú the way we are moving it‚Äôs definitely will be a thing.

Message : Well a GPU to do upscaling doesn‚Äôt have to be 1000 dollars. I could be wrong but it does not have to be the stereotypical GPU which looks like a Casio watch had a baby with Crysis 2
Quoted Message : Interesting, got to check it out and update my knowledge. Not sure my 800$ TV has 1000$ GPU chip but I may be wrong.

Message : My experience with GFGAN is that when I upscale low res image to 4K, it take a significant amount of memory. Now, I‚Äôm not aware of other techniques so I‚Äôll refrain from making assumptions.

Message : There is a lot of nuance to the topic of aspect ratios in film making and a rich history behind it...
Quoted Message : Some of them are more excited & optimistic than you would believe !

Message : I don‚Äôt play games so had to literally search Crysis 2 to understand reference ü§£
Quoted Message : Well a GPU to do upscaling doesn‚Äôt have to be 1000 dollars. I could be wrong but it does not have to be the stereotypical GPU which looks like a Casio watch had a baby with Crysis 2

Message : https://youtu.be/wlUV6y5TUko
Quoted Message : There is a lot of nuance to the topic of aspect ratios in film making and a rich history behind it...

Message : This is a good primer on aspect ratios and the problems with manually or automatically changing them...
Quoted Message : https://youtu.be/wlUV6y5TUko

Message : Old time gamer here but I too have stopped gaming. Crysis was big when I was younger. On that note generative AI is going to play a big role in content creation for games I assume. Upscaling is just one problem but maybe we will see super realistic graphics thanks to generative models. One of the biggest things in the recent past is Unreal Engine 5.1 and the nanite tech in it
Quoted Message : I don‚Äôt play games so had to literally search Crysis 2 to understand reference ü§£

Message : I‚Äôm sure you saw NVIDIA demo. No more NPCs. I also saw some tweets that people are getting connected to their character.ai characters. Combine these two and you got AI characters teaming up with you in games and once done, chatting with you about state of politics and IPL at home.
Quoted Message : Old time gamer here but I too have stopped gaming. Crysis was big when I was younger. On that note generative AI is going to play a big role in content creation for games I assume. Upscaling is just one problem but maybe we will see super realistic graphics thanks to generative models. One of the biggest things in the recent past is Unreal Engine 5.1 and the nanite tech in it

Message : Cc Rajeev @91998226xxxx was earlier working on game assets but moved away from it
Quoted Message : Old time gamer here but I too have stopped gaming. Crysis was big when I was younger. On that note generative AI is going to play a big role in content creation for games I assume. Upscaling is just one problem but maybe we will see super realistic graphics thanks to generative models. One of the biggest things in the recent past is Unreal Engine 5.1 and the nanite tech in it

Message : That is very cool. A completely digital persona who can interact with you across virtual and real worlds, or something like this.
Quoted Message : I‚Äôm sure you saw NVIDIA demo. No more NPCs. I also saw some tweets that people are getting connected to their character.ai characters. Combine these two and you got AI characters teaming up with you in games and once done, chatting with you about state of politics and IPL at home.

Message : We can port this to telegram
Bots + accessibility both covered

@91773788xxxx ?
Quoted Message : @9177xxxxxxxx Should we move this from whatsapp to discord server, where topic specific channels can be created, for moderation purposes we can leverage bots as well ?

Message : Sticking to WhatsApp in the interest of serendipity. I don't expect Crysis2 to be mentioned on Telegram for instance. 

Trust me, I'd love bots. I spend 6 hrs/week doing very manual things
Quoted Message : We can port this to telegram\nBots + accessibility both covered \n\n@9177xxxxxxxx ?

Message : There‚Äôs a section in this video which discusses video reconstruction from MRI data collected using visual stimuli. Mind blowing stuff. https://youtu.be/eXttLLdlzaI

Message : Hey folks, which vector store would you recommend for production application ? 
I have heard of pinecone and weaviate

Do you have any favourites ?

Message : Weaviate is quite accessible, great DX and @91963283xxxx runs it in production for Albus. I've both Redis and Qdrant in production, mainly for high QPS and _practically_ free
Quoted Message : Hey folks, which vector store would you recommend for production application ? \nI have heard of pinecone and weaviate\n\nDo you have any favourites ?

Message : We have just migrated off pinecone to weaviate, and could not be happier. Great dev ex and gives us the right amount of flexibility.

Message : We're using Redis in production now. Langchain comes with Chroma DB which works for smaller use cases
Quoted Message : Weaviate is quite accessible, great DX and @9196xxxxxxxx runs it in production for Albus. I've both Redis and Qdrant in production, mainly for high QPS and _practically_ free


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I‚Äôm sure you saw NVIDIA demo. No more NPCs. I also saw some tweets that people are getting connected to their character.ai characters. Combine these two and you got AI characters teaming up with you in games and once done, chatting with you about state of politics and IPL at home.
Quoted Message : Old time gamer here but I too have stopped gaming. Crysis was big when I was younger. On that note generative AI is going to play a big role in content creation for games I assume. Upscaling is just one problem but maybe we will see super realistic graphics thanks to generative models. One of the biggest things in the recent past is Unreal Engine 5.1 and the nanite tech in it

Message : Cc Rajeev @91998226xxxx was earlier working on game assets but moved away from it
Quoted Message : Old time gamer here but I too have stopped gaming. Crysis was big when I was younger. On that note generative AI is going to play a big role in content creation for games I assume. Upscaling is just one problem but maybe we will see super realistic graphics thanks to generative models. One of the biggest things in the recent past is Unreal Engine 5.1 and the nanite tech in it

Message : That is very cool. A completely digital persona who can interact with you across virtual and real worlds, or something like this.
Quoted Message : I‚Äôm sure you saw NVIDIA demo. No more NPCs. I also saw some tweets that people are getting connected to their character.ai characters. Combine these two and you got AI characters teaming up with you in games and once done, chatting with you about state of politics and IPL at home.

Message : We can port this to telegram
Bots + accessibility both covered

@91773788xxxx ?
Quoted Message : @9177xxxxxxxx Should we move this from whatsapp to discord server, where topic specific channels can be created, for moderation purposes we can leverage bots as well ?

Message : Sticking to WhatsApp in the interest of serendipity. I don't expect Crysis2 to be mentioned on Telegram for instance. 

Trust me, I'd love bots. I spend 6 hrs/week doing very manual things
Quoted Message : We can port this to telegram\nBots + accessibility both covered \n\n@9177xxxxxxxx ?

Message : There‚Äôs a section in this video which discusses video reconstruction from MRI data collected using visual stimuli. Mind blowing stuff. https://youtu.be/eXttLLdlzaI

Message : Hey folks, which vector store would you recommend for production application ? 
I have heard of pinecone and weaviate

Do you have any favourites ?

Message : Weaviate is quite accessible, great DX and @91963283xxxx runs it in production for Albus. I've both Redis and Qdrant in production, mainly for high QPS and _practically_ free
Quoted Message : Hey folks, which vector store would you recommend for production application ? \nI have heard of pinecone and weaviate\n\nDo you have any favourites ?

Message : We have just migrated off pinecone to weaviate, and could not be happier. Great dev ex and gives us the right amount of flexibility.

Message : We're using Redis in production now. Langchain comes with Chroma DB which works for smaller use cases
Quoted Message : Weaviate is quite accessible, great DX and @9196xxxxxxxx runs it in production for Albus. I've both Redis and Qdrant in production, mainly for high QPS and _practically_ free

Message : Wait, I might be wrong on this ‚Äî @91963283xxxx uses Pinecone

Message : Supermeme.ai also uses pinecone I believe

Message : I use Pinecone.

Message : what type of flexibility?
Quoted Message : We have just migrated off pinecone to weaviate, and could not be happier. Great dev ex and gives us the right amount of flexibility.

Message : We use Pinecone at Nintee
Quoted Message : Hey folks, which vector store would you recommend for production application ? \nI have heard of pinecone and weaviate\n\nDo you have any favourites ?

Message : Pretty good

Message : hows the pricing scaling for you?
Quoted Message : We use Pinecone at Nintee

Message : Folks using pinecone, are you charged for concurrent requests as well or are you charged just for the amount of vector embeddings you store?
Another question how do you store date in Metadata if you do at all?

Message : Ramsri recommended pinecone even when he faced issued. That was proof enough for us
Quoted Message : Supermeme.ai also uses pinecone I believe

Message : I have the same question. Their QPS ratings are a little fuzzy so its not clear at all how many pods you actually need
Quoted Message : Folks using pinecone, are you charged for concurrent requests as well or are you charged just for the amount of vector embeddings you store?\nAnother question how do you store date in Metadata if you do at all?

Message : Openai embeddings k according you can store 2.5 million embeddings per pod. But unsure if this counts Metadata limits also
Quoted Message : I have the same question. Their QPS ratings are a little fuzzy so its not clear at all how many pods you actually need

Message : @91630952xxxx we're discussing vector databases, and thought it'd be good to hear why you recommend Pinecone

Message : There are a few good ones out there that have personally used but for a production application the choices I wud make would be governed by scale/precision , integration with the ecosystem etc. Making Pinecone and Chroma easiest/fastest to integrate with
Quoted Message : Hey folks, which vector store would you recommend for production application ? \nI have heard of pinecone and weaviate\n\nDo you have any favourites ?

Message : Its per instance / pod type. We are small and only have a single pod now. 
334,535 vectors
p1.x1 pod
$65/month
We do meta data, namespace and are now working on hybrid search
Pinecone works well with zero complaints

Message : Caveat: Chroma is very weird. Takes 2G to store 1.2G worth of embeddings and so on. Won't recommend for production

Message : Sure! :) I am not Pinecone's ambassador, haha! I think nowadays Weaviate, Qdrant, Croma all are equally competent and capable
If I am starting today I would use Postgres Pgvector for smaller use cases and only think about Vector DBs at million vector scale .
Quoted Message : @9163xxxxxxxx we're discussing vector databases, and thought it'd be good to hear why you recommend Pinecone

Message : Seconded, anything upto 10-20 QPS and a few 100K embeddings should go to pgvector!
Quoted Message : Sure! :) I am not Pinecone's ambassador, haha! I think nowadays Weaviate, Qdrant, Croma all are equally competent and capable\nIf I am starting today I would use Postgres Pgvector for smaller use cases and only think about Vector DBs at million vector scale .

Message : One thing we do is store embeddings in a local Postgres so changing vector store db is easy

So start with anything really
Quoted Message : Caveat: Chroma is very weird. Takes 2G to store 1.2G worth of embeddings and so on. Won't recommend for production

Message : We are moving to hybrid search and want to the ability to weight sparse VS dense. U can do this in pine one but it‚Äôs more of a pain. 

We also want to weight different sources. Example: a pdf carries more weight than a csv (this is v specific to your use case), and Weaviate was better for this.

Finally, it‚Äôs open source :)
Quoted Message : what type of flexibility?

Message : Any comments for caching questions in a QnA setup to avoid GPT call? I am checking https://github.com/zilliztech/GPTCache but not sure of that's the best direction.
Quoted Message : Seconded, anything upto 10-20 QPS and a few 100K embeddings should go to pgvector!

Message : Exact questions rarely come in production
Quoted Message : Any comments for caching questions in a QnA setup to avoid GPT call? I am checking https://github.com/zilliztech/GPTCache but not sure of that's the best direction.

Message : True, but similar questions are frequent. For example - 'What happens to payment page if product is out of stock', I found 20+ variants of this in a manual review. I only took a 10% random sample for review.
Quoted Message : Exact questions rarely come in production

Message : Embed the question, do a look up and provide the answer if the similarity score is above X? Ideally only if the user upvoted or approved teh answer

Message : Yup, that's my current setup.   I felt GPTCache might be doing something smarter so reached out to the group.
Quoted Message : Embed the question, do a look up and provide the answer if the similarity score is above X? Ideally only if the user upvoted or approved teh answer

Message : This was the paper from Recsys on what TikTok does, that I spoke a day ago.
Quoted Message : This is the paper I wanted to understand and got stuck up on hashes\n\nhttps://arxiv.org/pdf/2209.07663.pdf

Message : https://arxiv.org/pdf/2209.07663.pdf

Message : @91988429xxxx : ‚òùÔ∏è

Message : Hi all, looking to make a marketing oriented video using Runway ML. Would anyone be interested in taking a quick paid gig for it?

Message : We are sort of having the same conversation over and over again. Thought it might be good experiment, if we can create a community curated notes. The idea being, the community edits and add *short big tested takeaways* content, in a specific overall structure (which will get getting updated over time) as we have discussions. Just so that we have time to learn the structure of the document, I thought we can roll out edit access slowly. Everyone has view access immediately, please request edit access from the document directly, if you want to edit (I can't handle 1000 DM ;). The quality of this is in each of our hands, hoping we can make something amazing out of this. Just an experiment, lets see how far this goes. We can start with the most frequently asked questions, that way we have most bang for the buck. Here is the doc: https://docs.google.com/document/d/1Wnw-vS9lATKTRAdEPxRm2uKgZlk4BKEmi7b8DL83NPs/edit#heading=h.ir323h4vucu

Message : https://www.jugalbandi.ai/

Came across this today. Very cool work by AI4Bharat

Message : ‚Äé<attached: 00006570-PHOTO-2023-06-01-16-52-28.jpg>
Quoted Message : https://www.jugalbandi.ai/\n\nCame across this today. Very cool work by AI4Bharat

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØSumanth Doddapaneni

Message : It featured in MSbuild
Quoted Message : https://www.jugalbandi.ai/\n\nCame across this today. Very cool work by AI4Bharat

Message : Lol considering that they got highlighted in ms build that'd be a no brainer
Quoted Message :  2023_06_01_3ACB0913FE37AABD7739.jpeg

Message : I think MS invested in them

Message : Added @91951590xxxx from AI4Bharat here

Message : Please bother him judiciously

Message : Good idea to possibly make this a Github repo? 

Possibly easier for folks to contribute & editors to merge them via PRs?

Just thinking out loud - a brilliant initiative nonetheless
Quoted Message : We are sort of having the same conversation over and over again. Thought it might be good experiment, if we can create a community curated notes. The idea being, the community edits and add *short big tested takeaways* content, in a specific overall structure (which will get getting updated over time) as we have discussions. Just so that we have time to learn the structure of the document, I thought we can roll out edit access slowly. Everyone has view access immediately, please request edit access from the document directly, if you want to edit (I can't handle 1000 DM ;). The quality of this is in each of our hands, hoping we can make something amazing out of this. Just an experiment, lets see how far this goes. We can start with the most frequently asked questions, that way we have most bang for the buck. Here is the doc: https://docs.google.com/document/d/1Wnw-vS9lATKTRAdEPxRm2uKgZlk4BKEmi7b8DL83NPs/edit#heading=h.ir323h4vucu

Message : Welcome to the group Sumanth!
Quoted Message : Added @9195xxxxxxxx from AI4Bharat here

Message : ‚Äé<attached: 00006579-PHOTO-2023-06-01-17-01-09.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00006570-PHOTO-2023-06-01-16-52-28.jpg>
Quoted Message : https://www.jugalbandi.ai/\n\nCame across this today. Very cool work by AI4Bharat

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØSumanth Doddapaneni

Message : It featured in MSbuild
Quoted Message : https://www.jugalbandi.ai/\n\nCame across this today. Very cool work by AI4Bharat

Message : Lol considering that they got highlighted in ms build that'd be a no brainer
Quoted Message :  2023_06_01_3ACB0913FE37AABD7739.jpeg

Message : I think MS invested in them

Message : Added @91951590xxxx from AI4Bharat here

Message : Please bother him judiciously

Message : Good idea to possibly make this a Github repo? 

Possibly easier for folks to contribute & editors to merge them via PRs?

Just thinking out loud - a brilliant initiative nonetheless
Quoted Message : We are sort of having the same conversation over and over again. Thought it might be good experiment, if we can create a community curated notes. The idea being, the community edits and add *short big tested takeaways* content, in a specific overall structure (which will get getting updated over time) as we have discussions. Just so that we have time to learn the structure of the document, I thought we can roll out edit access slowly. Everyone has view access immediately, please request edit access from the document directly, if you want to edit (I can't handle 1000 DM ;). The quality of this is in each of our hands, hoping we can make something amazing out of this. Just an experiment, lets see how far this goes. We can start with the most frequently asked questions, that way we have most bang for the buck. Here is the doc: https://docs.google.com/document/d/1Wnw-vS9lATKTRAdEPxRm2uKgZlk4BKEmi7b8DL83NPs/edit#heading=h.ir323h4vucu

Message : Welcome to the group Sumanth!
Quoted Message : Added @9195xxxxxxxx from AI4Bharat here

Message : ‚Äé<attached: 00006579-PHOTO-2023-06-01-17-01-09.jpg>

Message : *reach them
Quoted Message :  2023_06_01_5EB9C2597AC593F4DE93.jpeg

Message : saurabh@opennyai.org

Message : on their site

Message : haqdarshak.com is about schemes that citizens can avail.
Quoted Message :  2023_06_01_5EB9C2597AC593F4DE93.jpeg

Message : wonder if this summarizer is just a wrapper to chatGPT :) https://summarizer-fer6v2lowq-uc.a.run.app/

Message : üëÜfrom opennyai (just realized its a play on nyaayü§¶üèª‚Äç‚ôÇÔ∏è)

Message : I am meeting Saurab this evening, will ask him to join the group if he is interested.

Message : Hey @91951590xxxx!‚úåüèº

Message : ‚Äé~‚ÄØSumod Mohan added ~‚ÄØSaurabh Karn

Message : Hi Saurabh, Welcome to the group. There are bunch of folks who are very excited by your work on Jugalbandi and OpenNyAI. @91942037xxxx had worked on legal AI before.

Message : Thanks a ton Sumod :)
Quoted Message : Hi Saurabh, Welcome to the group. There are bunch of folks who are very excited by your work on Jugalbandi and OpenNyAI. @9194xxxxxxxx had worked on legal AI before.

Message : @91942037xxxx - Would be very happy to chat about Legal AI.

Message : @91807217xxxx also worked on Legal AI with his startup so there are quite a few Legal AI folks here already ü•≥

Message : @91819726xxxx sky is the limit bro, great to see you here.
Quoted Message : @9180xxxxxxxx also worked on Legal AI with his startup so there are quite a few Legal AI folks here already ü•≥

Message : Hi Saurabh - nice to see you here!

Vishwam - also building in the legal space (Webnyay.ai).

Message : Hey Vishwam! Glad to see you too here :)
Quoted Message : Hi Saurabh - nice to see you here!\n\nVishwam - also building in the legal space (Webnyay.ai).

Message : @91783815xxxx @91819753xxxx - glad to see you here too!

Message : Welcome to the group Saurabh. Would be great to chat.
Quoted Message : @9194xxxxxxxx - Would be very happy to chat about Legal AI.

Message : By the way folks, we are curating OpenNyAI residency this year. You should check it out.

https://forms.opennyai.org/residency2023

Message : From another group‚Ä¶.

Message : *Call for Papers: AI-ML Systems 2023*
https://www.aimlsystems.org/2023/

We are pleased to announce the 3rd International Conference on AI-ML Systems to be held in Bangalore, India, during October 25-28, 2023 as a fully physical conference. AI-MLSystems is a new conference targeting the research in the intersection of Systems Engineering and Artificial Intelligence and Machine Learning techniques.

The conference invites papers across Research and Industry tracks.  Areas of interest, submission deadlines, submission guidelines can be accessed at the links below.

Research Track: https://www.aimlsystems.org/2023/callResearch
Industry Track: https://www.aimlsystems.org/2023/callIndustry

Message : Hey thanks for sharing. Will the papers be published in ACM/IEEE proceedings? (Didn't find exact info on the website)
Quoted Message : *Call for Papers: AI-ML Systems 2023*\nhttps://www.aimlsystems.org/2023/\n\nWe are pleased to announce the 3rd International Conference on AI-ML Systems to be held in Bangalore, India, during October 25-28, 2023 as a fully physical conference. AI-MLSystems is a new conference targeting the research in the intersection of Systems Engineering and Artificial Intelligence and Machine Learning techniques.\n\nThe conference invites papers across Research and Industry tracks.  Areas of interest, submission deadlines, submission guidelines can be accessed at the links below.\n\nResearch Track: https://www.aimlsystems.org/2023/callResearch\nIndustry Track: https://www.aimlsystems.org/2023/callIndustry

Message : I asked chatgpt a logic problem and it realized its mistake and its self correcting.
Problem is its keeping on getting it wrong

Message : Its just generating on and on and on

Message : https://chat.openai.com/share/5adb1eea-3bf0-42ef-ab2d-3543abcb1457
3 tries finally

Message : phir bhi wrong hai. but this is an interesting development

Message : What‚Äôs your hypothesis? Why is it happening?

Message : This is the first time I've seen it happening. With 3.5 it was wrong and just said yes, I'm wrong and this probably can't be solved so good luck
Quoted Message : What‚Äôs your hypothesis? Why is it happening?

Message : I'm guessing the loss dropped real low

Message : Once it makes a mistake it‚Äôs reinforced via context
Quoted Message : What‚Äôs your hypothesis? Why is it happening?

Message : 3.5 lacks reflection abilities

Message : I've yet to try with 3.5
Quoted Message : 3.5 lacks reflection abilities

Message : Very interesting. This is a new behaviour. It used to sometimes identify it's mistakes and apologise but never go on a loop like this. It could be due to it being trained to work with tools and APIs where it has to receive an error and perform retries after changing its approach.
Quoted Message : https://chat.openai.com/share/5adb1eea-3bf0-42ef-ab2d-3543abcb1457\n3 tries finally

Message : GPT-4 can sometimes reflect on itself

Message : It emerged

Message : Maybe it‚Äôs trying to spit out anything until it finally receives a positive reinforcement ü§îüòÖ

Message : This is because the model has to do multiple things 
- follow the users instructions / prompt
- follow the open AI rules
And there is only a fixed amount of compute available. Each time it‚Äôs trained it finds a different trade off
Quoted Message : Very interesting. This is a new behaviour. It used to sometimes identify it's mistakes and apologise but never go on a loop like this. It could be due to it being trained to work with tools and APIs where it has to receive an error and perform retries after changing its approach.

Message : The model thinks for fixed time and then outputs the best token found after it

Message : This is a fundamental limitation of transformers. They are fixed in depth.

Message : Whereas we can decide to tnink harder


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : 3.5 lacks reflection abilities

Message : I've yet to try with 3.5
Quoted Message : 3.5 lacks reflection abilities

Message : Very interesting. This is a new behaviour. It used to sometimes identify it's mistakes and apologise but never go on a loop like this. It could be due to it being trained to work with tools and APIs where it has to receive an error and perform retries after changing its approach.
Quoted Message : https://chat.openai.com/share/5adb1eea-3bf0-42ef-ab2d-3543abcb1457\n3 tries finally

Message : GPT-4 can sometimes reflect on itself

Message : It emerged

Message : Maybe it‚Äôs trying to spit out anything until it finally receives a positive reinforcement ü§îüòÖ

Message : This is because the model has to do multiple things 
- follow the users instructions / prompt
- follow the open AI rules
And there is only a fixed amount of compute available. Each time it‚Äôs trained it finds a different trade off
Quoted Message : Very interesting. This is a new behaviour. It used to sometimes identify it's mistakes and apologise but never go on a loop like this. It could be due to it being trained to work with tools and APIs where it has to receive an error and perform retries after changing its approach.

Message : The model thinks for fixed time and then outputs the best token found after it

Message : This is a fundamental limitation of transformers. They are fixed in depth.

Message : Whereas we can decide to tnink harder

Message : Here we have to provide hints think hard , step by step . But these are ultimately hacks

Message : For eg GPT-4 cannot play tic tac toe optimally . Because that needs thinking ahead to some arbitrary depths.

Message : But that also doesn‚Äôt mean that it is stupid

Message : To fix this either you can fine tune / prompt on many different ways ppl plan on common tasks. That will plug the gap.

Message : My guess is there's another prompt here acting

Message : There's definitely an agent at play here. Because I'm using the browsing model

Message : does anyone have any examples of papers/prompts that can do one-shot/few-shot classification of things like spam, fraud, etc. that kind of things ?

Message : Let me find it

Message : Check out the work of Yao Fu https://twitter.com/francis_yao_/status/1654804366002638849?s=46&t=6c5AUaH7z7YH7nCchlCSSQ

Message : TL;DR - the best way is few shot - ie few examples + chain of thought in the examples before generating the answer

Message : Eg 
You are a machine learning classifier trying to classify user comments as spam or not_spam

Add your rules here as a list

Comment: ‚ÄúExcited on Monday‚Äù
Thought:
Let‚Äôs think step by step
The user is posting that they are excited on Monday
This is not spam because ‚Ä¶
Classification: not_spam

More examples ..

Message : More detailed studies here on diversity, recency bias etc https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/

Message : Lmk how it goes we can debug / improve

Message : Sklearn announced scikit-llm specifically for this purpose 
It aims to cover standard NLP tasks like classification zero shot or few shot, summarising etc with the help of LLMs

https://github.com/iryna-kondr/scikit-llm

Message : Likewise spacy announced spacy LLM for all standard NLP pipelines. Spacy used to be quite popular for quick and easy industrial applications before LLM rage took over 

https://github.com/explosion/spacy-llm

Message : Quick question, is there an API version for plugins yet?

Message : Extra credit - you can check token probability for spam / not_spam for even more nuance
Quoted Message : Eg \nYou are a machine learning classifier trying to classify user comments as spam or not_spam \n\nAdd your rules here as a list \n\nComment: ‚ÄúExcited on Monday‚Äù\nThought: \nLet‚Äôs think step by step \nThe user is posting that they are excited on Monday \nThis is not spam because ‚Ä¶\nClassification: not_spam\n\nMore examples ..

Message : won't be an api version of plugin imo, since that would defeat the point of plugin but the apis powering those plugins might be released sometime maybe
Quoted Message : Quick question, is there an API version for plugins yet?

Message : Langhcain has done work on this. can look this up

Message : What was this then?
Quoted Message :  2023_05_11_3EB01D455CC15BDF2C9804.jpeg

Message : Yes. But text to sql dataset. And enriching dataset instead of generating from scratch because that works better.
Quoted Message : Has anyone here worked on generating training sets ( preferably on coding data sets ) through GPT4 or other powerful models and then used it to finetune OSS ones ?

Message : I can't see this message. Also the plugin repo is available to work on top of if you want to create a new plugin
Quoted Message : What was this then?

Message : https://github.com/teknium1/GPTeacher
Quoted Message : Has anyone here worked on generating training sets ( preferably on coding data sets ) through GPT4 or other powerful models and then used it to finetune OSS ones ?

Message : I need to replace myself with a langchain agent that shares papers

Message : so i was indeed thinking of it in a few shot + COT way. but i was not very good or successful. so was looking if people had already figured out nice prompts and chains for this.
Quoted Message : TL;DR - the best way is few shot - ie few examples + chain of thought in the examples before generating the answer

Message : that‚Äôs not what I mean.
I want to retrieve the results I get using an existing plugin as an API call
Quoted Message : I can't see this message. Also the plugin repo is available to work on top of if you want to create a new plugin

Message : Share the task / few test cases and I can try .
Quoted Message : so i was indeed thinking of it in a few shot + COT way. but i was not very good or successful. so was looking if people had already figured out nice prompts and chains for this.

Message : i have already built a fair amount of chains, so i understand the general space...but am wondering if there is any specific ones that have worked here.
for e.g. im wondering if retrieval augmented works here (past examples of spam)...but im not sure how that would fit in. because should i give few examples of spam related to the keywords of the mail ? or just depend on few-shots

Message : Yes RAG will definitely work. If you can recover similar examples both positive and negative along with their Thought chains .

Message : You can use embedding matches maybe

Message : If even that is not enough you have to bite the bullet and go into fine tuning etc

Message : Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain
Quoted Message : Yes RAG will definitely work. If you can recover similar examples both positive and negative along with their Thought chains .

Message : https://bergum.medium.com/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5
Quoted Message : Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain

Message : Also pay attention to chunking when calculating embeddings. Better chunks would give better embeddings
Quoted Message : Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain

Message : When you go down fine tuning route you can fine tune one model to detect fraud spam etc . And then it‚Äôs embeddings will better reflect the domain.

Message : Unless the spam you're trying to classify is novel, zero shot spam classification using GPT should be fine.

If the type of classification isn't well known or is a type of natural language inference (like identifying whether a SW req. is testable or non-testable), then you may require multi shot in-context approach or just fine tuning
Quoted Message : i have already built a fair amount of chains, so i understand the general space...but am wondering if there is any specific ones that have worked here.\nfor e.g. im wondering if retrieval augmented works here (past examples of spam)...but im not sure how that would fit in. because should i give few examples of spam related to the keywords of the mail ? or just depend on few-shots

Message : However I have worked in this space on non ML parts . Adversarial ML is a whole different can of worms

Message : The speed of retraining becomes critical

Message : And also combining other signals and not just from the content. Reputation scores of IP , account , phone

Message : And creating hold out sets to prevent degenerate feedback loops


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : If even that is not enough you have to bite the bullet and go into fine tuning etc

Message : Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain
Quoted Message : Yes RAG will definitely work. If you can recover similar examples both positive and negative along with their Thought chains .

Message : https://bergum.medium.com/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5
Quoted Message : Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain

Message : Also pay attention to chunking when calculating embeddings. Better chunks would give better embeddings
Quoted Message : Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain

Message : When you go down fine tuning route you can fine tune one model to detect fraud spam etc . And then it‚Äôs embeddings will better reflect the domain.

Message : Unless the spam you're trying to classify is novel, zero shot spam classification using GPT should be fine.

If the type of classification isn't well known or is a type of natural language inference (like identifying whether a SW req. is testable or non-testable), then you may require multi shot in-context approach or just fine tuning
Quoted Message : i have already built a fair amount of chains, so i understand the general space...but am wondering if there is any specific ones that have worked here.\nfor e.g. im wondering if retrieval augmented works here (past examples of spam)...but im not sure how that would fit in. because should i give few examples of spam related to the keywords of the mail ? or just depend on few-shots

Message : However I have worked in this space on non ML parts . Adversarial ML is a whole different can of worms

Message : The speed of retraining becomes critical

Message : And also combining other signals and not just from the content. Reputation scores of IP , account , phone

Message : And creating hold out sets to prevent degenerate feedback loops

Message : Could you explain what u mean by this ? So train a model to generate embeddings ? I didn't understand the meaning of this.
Quoted Message : When you go down fine tuning route you can fine tune one model to detect fraud spam etc . And then it‚Äôs embeddings will better reflect the domain.

Message : Multi task learning . Metas classifiers for abuse for eg are trained on many different tasks. Spam , fraud , terrorism. The embeddings of this model are very powerful as a result . Same idea applies to other models including LLM

Message : Similar to how FLAN is fine tuned on a whole battery of tasks

Message : Those same embeddings can be used for things like RAG into even more powerful LLMs , search etc

Message : I‚Äôm not an ML expert so others who have surely done this can add more

Message : they were  generating embeddings using a classifier ? hmm.. i dont think i have ever looked into that.

Message : Yeah those embedding can be used in other classifier for other tasks

Message : https://research.facebook.com/publications/deep-entity-classification-abusive-account-detection-for-online-social-networks/

Message : ‚Äé<attached: 00006670-PHOTO-2023-06-02-02-46-20.jpg>

Message : ‚Äé<attached: 00006671-PHOTO-2023-06-02-02-48-04.jpg>

Message : Thanks everyone on the inputs 
I also wanted to check what embedding you folks are using

Do you have any learnings to share on that front
Quoted Message : This was the paper from Recsys on what TikTok does, that I spoke a day ago.

Message : Caching will be useful in BI sort of use cases where different people are trying to ask same /similar questions
Quoted Message : Any comments for caching questions in a QnA setup to avoid GPT call? I am checking https://github.com/zilliztech/GPTCache but not sure of that's the best direction.

Message : Any interesting space tech newsletters i can follow?

Message : We‚Äôve been trying our version of semantic cache for knowledge retrieval and text2sql and it‚Äôs surprisingly been really good with a decent F1
Quoted Message : Caching will be useful in BI sort of use cases where different people are trying to ask same /similar questions

Message : GPTCache is a great starting point. On top choosing the best embedding model and then cleanup query before store improves accuracy a whole lot!

Message : https://twitter.com/omarsar0/status/1664441085693657088?s=46

SQL-Palm for txt2sql

Message : This is awesome. And super useful. I'm trying to do something to manage DBs with plain text. Setting up indexes, managing slow queries, running migrations, managing Wal, etc.

Is there somewhere we can access this model?
Quoted Message : https://twitter.com/omarsar0/status/1664441085693657088?s=46\n\nSQL-Palm for txt2sql

Message : ‚Äé<attached: 00006679-PHOTO-2023-06-02-09-21-05.jpg>
Quoted Message : Quick question, is there an API version for plugins yet?

Message : who's in control? the programmers or the program?

https://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test

Message : I see‚Ä¶. thanks!
Quoted Message :  2023_06_02_BD79E74F341444A18A91F61FA0044556.jpeg

Message : https://research.nvidia.com/labs/dir/neuralangelo/

2D video to 3D surface reconstruction by NVIDIA

Message : Anyone has access to the new alpha model from OpenAI which does function routing better?

Message : What model is this?
Quoted Message : Anyone has access to the new alpha model from OpenAI which does function routing better?

Message : GPT4 is better with function routing or "actions" in the agent parlance from what we've seen. Don't know if there's any new release after GPT4. Is that the one you are talking about?
Quoted Message : Anyone has access to the new alpha model from OpenAI which does function routing better?

Message : I don't even have access to code interpreter yet üôÅ does anyone know how to get it?

Message : (I mean can I ask openai to enable, etc)

Message : Is anyone tried chatgpt as the translator ? Or arabic bot ? I have tried it looks like it is a coin toss if u give propts and all properly sometimes answers are good and sometimes its not much . As its not train wrt to translation i think that is expected but i did not think i will see some good reaults as well . Anyones exp with this ?

Message : On the onset I have seen it being a pretty good translator. I think vocabulary and sentence construction goes off when prompt is more complicated. I think a little bit of fine tuning on good curated data should be able to bump up the performance.
Quoted Message : Is anyone tried chatgpt as the translator ? Or arabic bot ? I have tried it looks like it is a coin toss if u give propts and all properly sometimes answers are good and sometimes its not much . As its not train wrt to translation i think that is expected but i did not think i will see some good reaults as well . Anyones exp with this ?

Message : I guess in private alpha. Will try to get more details
Quoted Message : What model is this?

Message : As we know that the tiiuae/falcon-40b-instruct model has an Apache-2.0 license.

Has anyone tried using the model in a Document Q&A use case?

I have been using trying some basic steps -:
1. In memory DB -: Chroma DB
2. HuggingFace embeddings
3.  tiiuae/falcon-40b-instruct
4. Pass everything to RetrievalQA

I just wanted to know how is the performance of the model according to you?

Message : Is there an economic case for using falcon over GPT-turbo ?

Message : Hey folks looking for help on how you are managing prompts, flows for calling openai api

- I have a series of scenarios/data summaries tagged with different features.
- I want to create a "trigger engine" to trigger certain tasks if/when certain criteria are met
- e.g. "X% of users in a set have a specific tag", "X% of users in a set with tag A also have tag B",  etc

- I'm thinking of defining these "triggers" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future
- Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups

Thanks

Message : I haven‚Äôt done detailed calculations but it seems to me any such approach in practice will cost a lot more

Message : Check out airflow . You need a data orchestration framework.
Quoted Message : Hey folks looking for help on how you are managing prompts, flows for calling openai api\n\n- I have a series of scenarios/data summaries tagged with different features. \n- I want to create a \"trigger engine\" to trigger certain tasks if/when certain criteria are met\n- e.g. \"X% of users in a set have a specific tag\", \"X% of users in a set with tag A also have tag B\",  etc\n\n- I'm thinking of defining these \"triggers\" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future\n- Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups \n\nThanks

Message : I've used Dagster for chain and filter kinda operations. Works like a charm
Quoted Message : Hey folks looking for help on how you are managing prompts, flows for calling openai api\n\n- I have a series of scenarios/data summaries tagged with different features. \n- I want to create a \"trigger engine\" to trigger certain tasks if/when certain criteria are met\n- e.g. \"X% of users in a set have a specific tag\", \"X% of users in a set with tag A also have tag B\",  etc\n\n- I'm thinking of defining these \"triggers\" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future\n- Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups \n\nThanks

Message : Airflow should work too

Message : Nirant Bot is always faster üòÅ

Message : Has he already replaced himself ü§î

Message : Thanks..
But for now..airflow is slightly overkill for me..

It's a single app I'm dogfooding with a subset of users to see how well it works...

Ultimately something like that would be needed
Quoted Message : Check out airflow . You need a data orchestration framework.

Message : Any sufficiently fast typist human is indistinguishable from an AI Model ü§£
Quoted Message : Has he already replaced himself ü§î


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Is there an economic case for using falcon over GPT-turbo ?

Message : Hey folks looking for help on how you are managing prompts, flows for calling openai api

- I have a series of scenarios/data summaries tagged with different features.
- I want to create a "trigger engine" to trigger certain tasks if/when certain criteria are met
- e.g. "X% of users in a set have a specific tag", "X% of users in a set with tag A also have tag B",  etc

- I'm thinking of defining these "triggers" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future
- Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups

Thanks

Message : I haven‚Äôt done detailed calculations but it seems to me any such approach in practice will cost a lot more

Message : Check out airflow . You need a data orchestration framework.
Quoted Message : Hey folks looking for help on how you are managing prompts, flows for calling openai api\n\n- I have a series of scenarios/data summaries tagged with different features. \n- I want to create a \"trigger engine\" to trigger certain tasks if/when certain criteria are met\n- e.g. \"X% of users in a set have a specific tag\", \"X% of users in a set with tag A also have tag B\",  etc\n\n- I'm thinking of defining these \"triggers\" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future\n- Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups \n\nThanks

Message : I've used Dagster for chain and filter kinda operations. Works like a charm
Quoted Message : Hey folks looking for help on how you are managing prompts, flows for calling openai api\n\n- I have a series of scenarios/data summaries tagged with different features. \n- I want to create a \"trigger engine\" to trigger certain tasks if/when certain criteria are met\n- e.g. \"X% of users in a set have a specific tag\", \"X% of users in a set with tag A also have tag B\",  etc\n\n- I'm thinking of defining these \"triggers\" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future\n- Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups \n\nThanks

Message : Airflow should work too

Message : Nirant Bot is always faster üòÅ

Message : Has he already replaced himself ü§î

Message : Thanks..
But for now..airflow is slightly overkill for me..

It's a single app I'm dogfooding with a subset of users to see how well it works...

Ultimately something like that would be needed
Quoted Message : Check out airflow . You need a data orchestration framework.

Message : Any sufficiently fast typist human is indistinguishable from an AI Model ü§£
Quoted Message : Has he already replaced himself ü§î

Message : Thank you
Checking it out
Quoted Message : I've used Dagster for chain and filter kinda operations. Works like a charm

Message : just some feedback - This does not take into account sharding yet
Quoted Message :  2023_05_31_3EB02A473CE1DA796FB290.jpeg

Message : That‚Äôs a million dollar question. If we keep just the performance in terms of quality away, it should totally be cheap to host it yourself as long as the base infrastructure to inference is good. So hosting it on Azure which is what MS is preaching might be one way. Even AWS now provides a enterprise grade LLM hosting and fine tuning support on sagemaker. I think inferencing is where most of the cost is. Maybe we need to do a costing benchmark across different modes of deployment options.
Quoted Message : Is there an economic case for using falcon over GPT-turbo ?

Message : I can provide that for Laama and Vicu√±a on GCP

Message : I suspect the utilization level for GPU would need a certain scale. If your GPU is idle then it can‚Äôt be cheaper

Message : And if you spin it up on demand then cold start time increases

Message : Yeah. There‚Äôs probably a threshehold you need to cross in terms of users to counter for cold start problems and all. But also the GPU availability across the globe is a bottleneck.
Quoted Message : I suspect the utilization level for GPU would need a certain scale. If your GPU is idle then it can‚Äôt be cheaper

Message : So depending on the size of model seeing if you want dedicated GPUs or something else that will start becoming a real question as well

Message : It‚Äôs not just that . OpenAI I suspect has a distillation system that benefits from scale and usage . That‚Äôs why turbo version drops a few months later. It‚Äôs difficult to replicate all this.
Quoted Message : Yeah. There‚Äôs probably a threshehold you need to cross in terms of users to counter for cold start problems and all. But also the GPU availability across the globe is a bottleneck.

Message : And features like json output , adapters , state can be added by OpenAI over time making the case for self hosting even weaker on short term economic grounds.

Message : Yeah. Totally possible!

Message : If you get the storage layer is correctly built you can get the coldstart to couple of seconds
Quoted Message : And if you spin it up on demand then cold start time increases

Message : Which thereby makes the utilisation super high

Message : Ideally like a serverless abstraction

Message : Only economical way I see possible, compared to turbo, is hosting on-premise on a6000. Cold start latency may disrupt use experience, even additional 2 seconds.

Message : Yes, we need to do all the processing without use of any external APIs.
Quoted Message : Is there an economic case for using falcon over GPT-turbo ?

Message : A single On premise can go down any time. Then you'd need redundancy.
Quoted Message : Only economical way I see possible, compared to turbo, is hosting on-premise on a6000. Cold start latency may disrupt use experience, even additional 2 seconds.

Message : Of course, one day of A100 on aws is like 50M token of turbo. Having redundancy will be still cheaper

Message : Open AI / Microsoft are now building the highest possible standards of data security and compliance.
Quoted Message : Yes, we need to do all the processing without use of any external APIs.

Message : On Prem is cheaper, but the problem is once you buy the card , you have to also pay for network and it‚Äôs really hard to do Autoscaling if the QPS becomes fluctuating
Quoted Message : Only economical way I see possible, compared to turbo, is hosting on-premise on a6000. Cold start latency may disrupt use experience, even additional 2 seconds.

Message : For Tranining I would highly recommend On Prem

Message : Agreed.
Could use Q Blocks instead for more A100s in same dollar (sorry for self promo lol) but i think it can help for such a case where you want to scale out and at the same time be cost effective and don't want to be on-prem.
Quoted Message : On Prem is cheaper, but the problem is once you buy the card , you have to also pay for network and it‚Äôs really hard to do Autoscaling if the QPS becomes fluctuating

Message : Once you have that many daily users, yes, ~50k request per day. There aren‚Äôt many production use cases.

Message : Yeah you need things like infini band networking , custom racks with NVLink. Redundancy . It all probably adds up .

Message : Yes , there are cheaper players you can get cheats GPUs , if you at willing to do the dev ops yourself you can significantly get the cost down

Message : How many tokens per second can an A100 do with falcon ? And how many do you need

Message : https://www.youtube.com/watch?v=Rk3nTUfRZmo
The infra MS has built is crazy

Message : I don‚Äôt think this can be easily replicated

Message : This is a great video
Quoted Message : https://www.youtube.com/watch?v=Rk3nTUfRZmo\nThe infra MS has built is crazy

Message : Microsoft has built up a good 6-12 months lead all things put together

Message : This is a great question. If Running a larger model Falcon 40B or Llama 65B on A100s not giving me 200-300 tps, then the latency will be killer for end users in production environment where turbo can return 1000tokens via API in less than 2 seconds.
Quoted Message : How many tokens per second can an A100 do with falcon ? And how many do you need

Message : ‚Äé<attached: 00006733-PHOTO-2023-06-02-13-07-18.jpg>

Message : I‚Äôm sure a100 won‚Äôt be more than 80, that‚Äôs slow too. And this is q4 to accommodate on single GPU.

Message : As I suspected

Message : Then the question is also if OpenAI is eating losses

Message : Nothing in near future beating Turbo, and when we figure out OAI will reduce price of GPT4.5 turbo to that level

Message : Yup . Absolutely masterful strategy üôáüèΩ

Message : Why? What about scaling use-cases?
Quoted Message : Once you have that many daily users, yes, ~50k request per day. There aren‚Äôt many production use cases.

Message : Speculation- turbo only has 1-2 B parameters and maybe further quantized
Quoted Message : This is a great question. If Running a larger model Falcon 40B or Llama 65B on A100s not giving me 200-300 tps, then the latency will be killer for end users in production environment where turbo can return 1000tokens via API in less than 2 seconds.

Message : OpenAI has published it themselves that 1.5B versions of GPT are not that bad


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This is a great question. If Running a larger model Falcon 40B or Llama 65B on A100s not giving me 200-300 tps, then the latency will be killer for end users in production environment where turbo can return 1000tokens via API in less than 2 seconds.
Quoted Message : How many tokens per second can an A100 do with falcon ? And how many do you need

Message : ‚Äé<attached: 00006733-PHOTO-2023-06-02-13-07-18.jpg>

Message : I‚Äôm sure a100 won‚Äôt be more than 80, that‚Äôs slow too. And this is q4 to accommodate on single GPU.

Message : As I suspected

Message : Then the question is also if OpenAI is eating losses

Message : Nothing in near future beating Turbo, and when we figure out OAI will reduce price of GPT4.5 turbo to that level

Message : Yup . Absolutely masterful strategy üôáüèΩ

Message : Why? What about scaling use-cases?
Quoted Message : Once you have that many daily users, yes, ~50k request per day. There aren‚Äôt many production use cases.

Message : Speculation- turbo only has 1-2 B parameters and maybe further quantized
Quoted Message : This is a great question. If Running a larger model Falcon 40B or Llama 65B on A100s not giving me 200-300 tps, then the latency will be killer for end users in production environment where turbo can return 1000tokens via API in less than 2 seconds.

Message : OpenAI has published it themselves that 1.5B versions of GPT are not that bad

Message : In terms of using OSS models. May be my mistake using the word use cases. Probably production applications using OSS models at this scale.
Quoted Message : Why? What about scaling use-cases?

Message : Still it has higher score than 65B LLaMa
Quoted Message : Speculation- turbo only has 1-2 B parameters and maybe further quantized

Message : Also, excessive RLHF help me to trust the turbo inference in production. I‚Äôm scared to death with LLaMa hallucinating in front of Farmers.

Message : Do try guardrails-ai.. You can run the group of prompts in sequence based on the open ai results/
Quoted Message : Hey folks looking for help on how you are managing prompts, flows for calling openai api\n\n- I have a series of scenarios/data summaries tagged with different features. \n- I want to create a \"trigger engine\" to trigger certain tasks if/when certain criteria are met\n- e.g. \"X% of users in a set have a specific tag\", \"X% of users in a set with tag A also have tag B\",  etc\n\n- I'm thinking of defining these \"triggers\" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future\n- Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups \n\nThanks

Message : Check out zero shot Nas. Quite a good paper
Quoted Message : does anyone have any examples of papers/prompts that can do one-shot/few-shot classification of things like spam, fraud, etc. that kind of things ?

Message : https://arxiv.org/abs/2301.11300

This one ? I couldn't find any reference to spam classification, etc
Quoted Message : Check out zero shot Nas. Quite a good paper

Message : It can used for classification problems as well. Quite efficient
Quoted Message : https://arxiv.org/abs/2301.11300\n\nThis one ? I couldn't find any reference to spam classification, etc

Message : A question on deploying a web app  on ai - 
* does anyone know how to make heroku work with indian credit card?
* if not possible, what is the best alternative (tried render, koyeb- any other suggestion ?)
* or should i grow up and use aws for hosting generative ai apps?

Message : You can try fly.io and railway.app
Quoted Message : A question on deploying a web app  on ai - \n* does anyone know how to make heroku work with indian credit card? \n* if not possible, what is the best alternative (tried render, koyeb- any other suggestion ?)\n* or should i grow up and use aws for hosting generative ai apps?

Message : Vercel is pretty seamless if you are using Nextjs
Quoted Message : A question on deploying a web app  on ai - \n* does anyone know how to make heroku work with indian credit card? \n* if not possible, what is the best alternative (tried render, koyeb- any other suggestion ?)\n* or should i grow up and use aws for hosting generative ai apps?

Message : I mean they created it
Quoted Message : Vercel is pretty seamless if you are using Nextjs

Message : Azure/ DigitalOcean? 
I‚Äôve hosted genai webapps in both of these; easy to deploy
Quoted Message : A question on deploying a web app  on ai - \n* does anyone know how to make heroku work with indian credit card? \n* if not possible, what is the best alternative (tried render, koyeb- any other suggestion ?)\n* or should i grow up and use aws for hosting generative ai apps?

Message : can hook the build action directly to your github repo

Message : though this is pretty elementary; I‚Äôm not sure if you were asking from a competitive overhead sort of angle , sorry

Message : +1 for fly and railway, easier hosting (can do cd via GitHub actions). 
- If you plan to use db in fly, slightly complex setup since they have semi-automated pg hosting (that‚Äôs what they call)
- Both places you can run servers under $5 for free each month
Quoted Message : You can try fly.io and railway.app

Message : Quite an interesting thread on migrating from fly to render. Check it may help

https://twitter.com/sebastianszturo/status/1663116343829483520?s=46&t=DtzjOgXVCgwDUiK5fng9Mw

Message : Has anyone been able to increase GPT4 rate limits ? Any tips ?

Message : Azure OpenAI, pay for dedicated Gpt3.5 and you get very generous GPT4 limits too
Quoted Message : Has anyone been able to increase GPT4 rate limits ? Any tips ?

Message : no, they don't increase
Quoted Message : Has anyone been able to increase GPT4 rate limits ? Any tips ?

Message : how to get approved for GPT4?
Quoted Message : Azure OpenAI, pay for dedicated Gpt3.5 and you get very generous GPT4 limits too

Message : Try chaining the prompts. We are doing that.
Quoted Message : Has anyone been able to increase GPT4 rate limits ? Any tips ?

Message : Is anyone using GPTCache here ?

It is doing an exact match ?

Hey Sandeep, the ExactMatchEvaluation is actually just:

```if cached_data.question == user_prompt.question```

Message : think they do both. ExactMatch and SemanticMatch
Quoted Message : Is anyone using GPTCache here ?\n\nIt is doing an exact match ?\n\nHey Sandeep, the ExactMatchEvaluation is actually just:\n\n```if cached_data.question == user_prompt.question```

Message : Sckit learn cosine similarity and qdrant cosine similarity seems tobe quite different

Message : Qdrant cosine similarity is not giving expected results but sklearn cosine similarity gives good results üëç

Message : Anybody facing such difficulty and solving them would be great to know

Message : All vector stores approximate distance for performance, scikit is exact search
Quoted Message : Sckit learn cosine similarity and qdrant cosine similarity seems tobe quite different

Message : Along with what Nirant said, most of them will have an option to set search to exact or approx. Be aware exact will lead to lower qps/latency. Pretty sure qdrant too will have it
Quoted Message : Qdrant cosine similarity is not giving expected results but sklearn cosine similarity gives good results üëç

Message : Yes that's what I was after

Message : Yes it has an exact param

Message : Thanks

Message : Exact true unfortunately did not help

Message : Will find out more

Message : Could be that you're embeddings are not normalised?

Message : If they're not normalised you should be using l2 instead of cosine

Message : Is it just the scores are different or are also your order different (btw scipy vs qdrant). If order is same, it's just a scale difference due to normalisation. If order is different, then see if you are doing some filtering type of thing in your setup.
Quoted Message : Exact true unfortunately did not help

Message : Question:

Has someone hacked ggml llama to just get sentence embeddings ?
Maybe after taking the head off ?

Message : Asking for local embedding reasons
Quoted Message : Question:\n\nHas someone hacked ggml llama to just get sentence embeddings ?\nMaybe after taking the head off ?

Message : Don't know much about Qdrant internals, so can't help much more.
Quoted Message : Is it just the scores are different or are also your order different (btw scipy vs qdrant). If order is same, it's just a scale difference due to normalisation. If order is different, then see if you are doing some filtering type of thing in your setup.

Message : I am using Sentence Transformer embeddings
When adding to Qdrant we would specify the distance as Cosine
Quoted Message : If they're not normalised you should be using l2 instead of cosine


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Thanks

Message : Exact true unfortunately did not help

Message : Will find out more

Message : Could be that you're embeddings are not normalised?

Message : If they're not normalised you should be using l2 instead of cosine

Message : Is it just the scores are different or are also your order different (btw scipy vs qdrant). If order is same, it's just a scale difference due to normalisation. If order is different, then see if you are doing some filtering type of thing in your setup.
Quoted Message : Exact true unfortunately did not help

Message : Question:

Has someone hacked ggml llama to just get sentence embeddings ?
Maybe after taking the head off ?

Message : Asking for local embedding reasons
Quoted Message : Question:\n\nHas someone hacked ggml llama to just get sentence embeddings ?\nMaybe after taking the head off ?

Message : Don't know much about Qdrant internals, so can't help much more.
Quoted Message : Is it just the scores are different or are also your order different (btw scipy vs qdrant). If order is same, it's just a scale difference due to normalisation. If order is different, then see if you are doing some filtering type of thing in your setup.

Message : I am using Sentence Transformer embeddings
When adding to Qdrant we would specify the distance as Cosine
Quoted Message : If they're not normalised you should be using l2 instead of cosine

Message : Which model?
Quoted Message : I am using Sentence Transformer embeddings\n When adding to Qdrant we would specify the distance as Cosine

Message : Therefore would it not do it.Let me check that

Message : All minilm l6 v2

Message : This is normalized
Quoted Message : All minilm l6 v2

Message : https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2

It seems like it isn't normalised
Quoted Message : This is normalized

Message : This is weird. Because I think last year someone asked nils Reimer this question and he had mentioned that you can use cosine for this. So I assumed it was. 
Even in sbert docs you can verify this I believe

Message : Qdrant does normalisation internally when adding vectors I believe.

Scikit - u may have not done.
Quoted Message : Qdrant cosine similarity is not giving expected results but sklearn cosine similarity gives good results üëç

Message : You are correct
Quoted Message : Qdrant does normalisation internally when adding vectors I believe.\n\nScikit - u may have not done.

Message : Let me do DOT similarity

Message : I‚Äôm not sure of qdrant but there must be some way to retrain the index to refresh the clusters of index 

I think you should be able to define how many clusters to search around query too
Quoted Message : Qdrant cosine similarity is not giving expected results but sklearn cosine similarity gives good results üëç

Message : Does this work ü•π
Quoted Message : Try chaining the prompts. We are doing that.

Message : if ur result is better with non-normalized vectors, try reducing the size of chunking. intuitively non-normalized cosine product is due to the shorter vectors.
Quoted Message : You are correct

Message : I've always wondered what's a good chunk size for vectors.. has anybody tested with different chunk sizes for RAGs?
Quoted Message : if ur result is better with non-normalized vectors, try reducing the size of chunking. intuitively non-normalized cosine product is due to the shorter vectors.

Message : @91963283xxxx can comment on this I guess as they have done quite good number of experiments for fixing chunk size.
Quoted Message : I've always wondered what's a good chunk size for vectors.. has anybody tested with different chunk sizes for RAGs?

Message : Try a smaller number and go bigger

Message : so, just hit & trial then?

Message : Yes. Few things to keep in mind 
- try to add Metadata if possible in your chunks as well.

Message : Different docs chunk different
Quoted Message : so, just hit & trial then?

Message : Is there a way to use any AI technique to see how some of YT channels do in setting their narrative? Which line is dominant and which one gets ignored. Both pro- or anti- on political topics.

I see that in many WhatsApp groups, political emotions are driven a lot by channels that folks watch regularly. So this might be interesting to know factually the dominant narrative.

Message : You can start by identifying it yourself. Then find a pattern. Then try automate it
Quoted Message : Is there a way to use any AI technique to see how some of YT channels do in setting their narrative? Which line is dominant and which one gets ignored. Both pro- or anti- on political topics.\n\nI see that in many WhatsApp groups, political emotions are driven a lot by channels that folks watch regularly. So this might be interesting to know factually the dominant narrative.

Message : Can you give some more details ?
Quoted Message : Try chaining the prompts. We are doing that.

Message : LLMs can help in this. But would need to formulate a paradigm first as a solution then use LLM as a tool to achieve the objective.
Quoted Message : Is there a way to use any AI technique to see how some of YT channels do in setting their narrative? Which line is dominant and which one gets ignored. Both pro- or anti- on political topics.\n\nI see that in many WhatsApp groups, political emotions are driven a lot by channels that folks watch regularly. So this might be interesting to know factually the dominant narrative.

Message : Happy to help! Can you DM?
Quoted Message : Can you give some more details ?

Message : Update: Strangely enough changing the prompt worked
Quoted Message : I‚Äôm not sure of qdrant but there must be some way to retrain the index to refresh the clusters of index \n\nI think you should be able to define how many clusters to search around query too

Message : in Qdrant

Message : is there a way to train our own model with the data we have?

Message : does dalai ai does it?

Message : Dalai is a local execution/inference and only works with Llama to the best of my knowledge. Has that changed?

Message : how about smol ai?

Message : we have this huge dataset of case filings & want to use it to build our own model

Message : smol is not an AI model, is a clever way to call GPT4 APIs
Quoted Message : how about smol ai?

Message : oh got it

Message : ‚Äé<attached: 00006815-PHOTO-2023-06-03-11-03-43.jpg>

Message : Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?
Quoted Message :  2023_06_03_3EB06ADF9D5AC8E1DE19BF.jpeg

Message : Azure OpenAI also has dedicated deployment option. Your requests never touch OpenAI is the promise in that case
Quoted Message : Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?

Message : I think the terms say that they keep data on their severs for 30 days for safety and compliance audits
Quoted Message : Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?

Message : Exactly
Quoted Message : Azure OpenAI also has dedicated deployment option. Your requests never touch OpenAI is the promise in that case

Message : And they promise to not use that data for training

Message : You can opt out of this, in both openai and azure
Quoted Message : I think the terms say that they keep data on their severs for 30 days for safety and compliance audits

Message : We are still on openai. Should switch to Azure.
Quoted Message : You can opt out of this, in both openai and azure


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : smol is not an AI model, is a clever way to call GPT4 APIs
Quoted Message : how about smol ai?

Message : oh got it

Message : ‚Äé<attached: 00006815-PHOTO-2023-06-03-11-03-43.jpg>

Message : Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?
Quoted Message :  2023_06_03_3EB06ADF9D5AC8E1DE19BF.jpeg

Message : Azure OpenAI also has dedicated deployment option. Your requests never touch OpenAI is the promise in that case
Quoted Message : Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?

Message : I think the terms say that they keep data on their severs for 30 days for safety and compliance audits
Quoted Message : Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?

Message : Exactly
Quoted Message : Azure OpenAI also has dedicated deployment option. Your requests never touch OpenAI is the promise in that case

Message : And they promise to not use that data for training

Message : You can opt out of this, in both openai and azure
Quoted Message : I think the terms say that they keep data on their severs for 30 days for safety and compliance audits

Message : We are still on openai. Should switch to Azure.
Quoted Message : You can opt out of this, in both openai and azure

Message : Anyone from here at the GenAI hackathon in mumbai today? Please react with a üëç to this message

Message : All the best to all participating! Send pictures ü•≥

Message : Been using Azure OpenAI for a month Now. Every individual deployment has max 120 transaction per second limit, which is fine in most cases, but you can roll out multiple instances, and shuffle.

Message : oh nice. That way we can serve more requests. Nice.
Quoted Message : Been using Azure OpenAI for a month Now. Every individual deployment has max 120 transaction per second limit, which is fine in most cases, but you can roll out multiple instances, and shuffle.

Message : Forgot to mention but I‚Äôm using Turbo and not GPT4 from Azure OpenAI. Been on waitlist for 5+ weeks and they are saying GPT4 access is very difficult right now due to GPU shortage.

Message : GPU shortage I have also heard from AWS side
Quoted Message : Forgot to mention but I‚Äôm using Turbo and not GPT4 from Azure OpenAI. Been on waitlist for 5+ weeks and they are saying GPT4 access is very difficult right now due to GPU shortage.

Message : The requests / minute for GPT4 is 18 on Azure OpenAI service right now. That's a fairly small number of requests
Quoted Message : Forgot to mention but I‚Äôm using Turbo and not GPT4 from Azure OpenAI. Been on waitlist for 5+ weeks and they are saying GPT4 access is very difficult right now due to GPU shortage.

Message : I think that's why from an inference side, I believe we will have much smaller models which can potentially be hosted locally on the user's device and the ecosystem is available as API interfaces and how a user wants to be connected to internet or access govt. services is something that they get done via these LLM assistants.

Message : Gorilla kind of thing

Message : ‚Äé<attached: 00006832-PHOTO-2023-06-03-11-28-15.jpg>

Message : The power of Gorilla is that it's trained to do better tool selection

Message : in legal and rights and entitlement space as well, these tools e.g. all the acts in India or a particular judgement may become available to these LLM legal assistants

Message : So you can have two deployments in each of the 4 data centers that have OpenAI services. 144 requests per second are still decent. Of course, you need the access first.
Quoted Message : The requests / minute for GPT4 is 18 on Azure OpenAI service right now. That's a fairly small number of requests

Message : Agreed, that's not bad
Quoted Message : So you can have two deployments in each of the 4 data centers that have OpenAI services. 144 requests per second are still decent. Of course, you need the access first.

Message : Anyone deploying models like Falcon on their (business) applications? What is the performance like?

Message : I just got it running in Colab on A100: https://colab.research.google.com/drive/1Fjwq3GPCqNTlWJG2T07vIRJw4L9_nkfj?usp=sharing
Quoted Message : Anyone deploying models like Falcon on their (business) applications? What is the performance like?

Message : (Official HF Instructions are broken)

Message : Yes needed to install more dependency than what HF mentioned

Message : And `pipeline` is also broken if you don't load the model separately
Quoted Message : Yes needed to install more dependency than what HF mentioned

Message : What's the context token limit on falcon?

Message : Pretty cool Nirant! These are premium Colab instances? What are the charges like?

Message : ‚Äé<attached: 00006844-PHOTO-2023-06-03-12-05-39.jpg>
Quoted Message : Pretty cool Nirant! These are premium Colab instances? What are the charges like?

Message : https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=2011456595

Gold -  Logic tests on various open LLMs

Message : And a nice comparison

Message : More context - https://www.reddit.com/r/LocalLLaMA/comments/13yfask/manticore13bchatpygguanacoggmlq4_0_americas_next/

Message : Yeah, Redis does get expensive - more than anything hidden costs of PaaS in the cloud get me.
Quoted Message :  2023_06_03_3EB0FD5995AA1A387CA5C1.jpeg

Message : Fantastic
Quoted Message : https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=2011456595\n\nGold -  Logic tests on various open LLMs

Message : To be fair, this is a High Availability setup in redis cloud.

Message : ‚Äé~‚ÄØKaushik Bokka added ~‚ÄØMadhav Singhal

Message : Interesting open source tool - Ul visual tool for LangChain

https://twitter.com/FlowiseAI/status/1646176565691023360?t=rBUfyGkbP3_o9IjDc4YRkw&s=19

Message : Any best resources for creating charts/graphs from data, open-source "Chart-GPT" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : D3.js. They have Python bindings as well
Quoted Message : Any best resources for creating charts/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : Chart.js is also a good option for basic garphs. We implemented something where ChatGPT generates python code that can take query object as input and output chart.js params which can be directly passed onto Frontend.
Quoted Message : Any best resources for creating charts/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : Consistent Policy around Events: 

All events in India to be published here:
https://docs.google.com/spreadsheets/d/e/2PACX-1vTftcrqLyUN8N81ekOBsQgWUWqg_t0QKk0Xil49OZKNhSrhHHN3DZRucTo4RJnYGQBYzes0NFxJKAL_/pubhtml

The only event announced is a Mixer from Wyse

You can submit the event here:
https://docs.google.com/forms/d/e/1FAIpQLSdWA6lJaw28VFDRUX_q6kj9xZXECkvrE2DgWnLaJDRy1ifjkw/viewform

Both are updated at https://nirantk.com/community as well.

Message : ‚Äé~‚ÄØNirant changed the group description

Message : I think if you have the code interpreter plug-in enabled that‚Äôs the best way to go?
Quoted Message : Any best resources for creating charts/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : ‚Äé<attached: 00006861-PHOTO-2023-06-03-15-24-47.jpg>

Message : ‚Äé<attached: 00006862-PHOTO-2023-06-03-15-24-48.jpg>

Message : ‚Äé<attached: 00006863-PHOTO-2023-06-03-15-24-49.jpg>

Message : ‚Äé<attached: 00006864-PHOTO-2023-06-03-15-24-50.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Any best resources for creating charts/graphs from data, open-source "Chart-GPT" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : D3.js. They have Python bindings as well
Quoted Message : Any best resources for creating charts/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : Chart.js is also a good option for basic garphs. We implemented something where ChatGPT generates python code that can take query object as input and output chart.js params which can be directly passed onto Frontend.
Quoted Message : Any best resources for creating charts/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : Consistent Policy around Events: 

All events in India to be published here:
https://docs.google.com/spreadsheets/d/e/2PACX-1vTftcrqLyUN8N81ekOBsQgWUWqg_t0QKk0Xil49OZKNhSrhHHN3DZRucTo4RJnYGQBYzes0NFxJKAL_/pubhtml

The only event announced is a Mixer from Wyse

You can submit the event here:
https://docs.google.com/forms/d/e/1FAIpQLSdWA6lJaw28VFDRUX_q6kj9xZXECkvrE2DgWnLaJDRy1ifjkw/viewform

Both are updated at https://nirantk.com/community as well.

Message : ‚Äé~‚ÄØNirant changed the group description

Message : I think if you have the code interpreter plug-in enabled that‚Äôs the best way to go?
Quoted Message : Any best resources for creating charts/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : ‚Äé<attached: 00006861-PHOTO-2023-06-03-15-24-47.jpg>

Message : ‚Äé<attached: 00006862-PHOTO-2023-06-03-15-24-48.jpg>

Message : ‚Äé<attached: 00006863-PHOTO-2023-06-03-15-24-49.jpg>

Message : ‚Äé<attached: 00006864-PHOTO-2023-06-03-15-24-50.jpg>

Message : ‚Äé<attached: 00006865-PHOTO-2023-06-03-15-24-52.jpg>

Message : ‚Äé<attached: 00006866-PHOTO-2023-06-03-15-24-52.jpg>

Message : https://youtu.be/slEMhl1U1_s

Message : https://youtu.be/BwNdj4zNEuk

Message : Tbis stuff is wild üòÅ

Message : https://youtu.be/DP9EY4xMlTE

Message : This is one way to convert me into a copyright activist. That song got butchered so bad.
Quoted Message : https://youtu.be/BwNdj4zNEuk

Message : I really like this one
Quoted Message : https://youtu.be/DP9EY4xMlTE

Message : 3:35 to 4:05 is ü§ê
Quoted Message : https://youtu.be/slEMhl1U1_s

Message : There‚Äôs a trump Coldplay cover

Message : https://youtu.be/omRTS-XsEGU

Message : Listen from 3:00 üòÅ

Message : i found this very good!
Quoted Message : https://youtu.be/omRTS-XsEGU

Message : Brilliant. The Frank Sinatra cover of Bon Jovi is even better. How did they build this?
Quoted Message : https://youtu.be/omRTS-XsEGU

Message : Damn!
Quoted Message : https://youtu.be/omRTS-XsEGU

Message : https://www.youtube.com/watch?v=rNKJcoSB8YU

i found this also very good

Message : Is it possible to use a different tokeniser while training a LLM model cia LoRA/QLoRA ? I am assuming I will have to make changes to the model as well. If anyone has any resources on this that would be great.

Message : I don‚Äôt know üòÅ
Quoted Message : Brilliant. The Frank Sinatra cover of Bon Jovi is even better. How did they build this?

Message : by doing that you might be effectively throwing away all the learning in the embeddings layer

adding tokens during finetuning process is still okay
Quoted Message : Is it possible to use a different tokeniser while training a LLM model cia LoRA/QLoRA ? I am assuming I will have to make changes to the model as well. If anyone has any resources on this that would be great.

Message : Best diagram based implementations exist via mermaid js code generation. There's a plugin for that as well in chatGPT plus.
Quoted Message : Any best resources for creating charts/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives.

Message : Yeah,  wanted to understand if there is a way to mitigate that. Thanks.
Quoted Message : by doing that you might be effectively throwing away all the learning in the embeddings layer\n\nadding tokens during finetuning process is still okay

Message : Hey folks! Welcome @1519702xxxx üëãüèº
He‚Äôs part of the ML team at Replit!

Message : Is there a better resource to prompt engineering than https://github.com/dair-ai/Prompt-Engineering-Guide that I may be missing? I find it pretty good along with a list of papers and seems to be kept fairly up to date. But who knows what else I might be missing? Any further pointers appreciated

Message : nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Quoted Message : Is there a better resource to prompt engineering than https://github.com/dair-ai/Prompt-Engineering-Guide that I may be missing? I find it pretty good along with a list of papers and seems to be kept fairly up to date. But who knows what else I might be missing? Any further pointers appreciated

Message : https://github.com/brexhq/prompt-engineering
Quoted Message : Is there a better resource to prompt engineering than https://github.com/dair-ai/Prompt-Engineering-Guide that I may be missing? I find it pretty good along with a list of papers and seems to be kept fairly up to date. But who knows what else I might be missing? Any further pointers appreciated

Message : One idea Id like your inputs on is the following;
Context;
Clipdrop has these style presets it applies to a prompt for SD.

If one used LoRA (eg https://replicate.com/blog/lora-faster-fine-tuning-of-stable-diffusion) to fine-tune on styles say;
- Ravi Verma art
- Mughal miniatures
- Bandhni/Bandhej
- Sanjay Leela movie sets

The above styles could be used as uniquely Indian presets in a Clipdrop like setting?

Is this directionally a feasible idea?

Message : Is there a reliable way to inject knowledge into a RLHF trained model?

Message : For text generation

Message : What does 'inject' mean? What use cases do you've which an in-context, dynamic prompt does not cover?
Quoted Message : Is there a reliable way to inject knowledge into a RLHF trained model?

Message : 2048, with a 65K vocab

From: https://huggingface.co/tiiuae/falcon-7b/blob/main/tokenizer_config.json

TIL Huggingface encourages this tokenizer config, so we can just look this up for most FOSS models.
Quoted Message : What's the context token limit on falcon?

Message : Falcon is also trained with Alibi Position Encoder/Linear Attention (https://arxiv.org/abs/2108.12409v2) ‚Äî so you can finetune and increase context window as well. 

Source: Chetanya, Alexa Prize Winner and Stanford Lecturer, https://twitter.com/ChetanyaRastogi/status/1665118748095725571

Message : Qdrant not writing to storage , therefore works fine it is running , but data cannot be retrieved once stopped and restarted

Message : Did anybody face this problem

Message : In 1 machine, I am having this problem while in the other follows the expected behaviour

Message : Since this is device, config specific ‚Äî do you want to ask this on the Qdrant Discord instead? https://discord.gg/qma5DQkH
Quoted Message : In 1 machine, I am having this problem while in the other follows the expected behaviour

Message : Sure
Quoted Message : Since this is device, config specific ‚Äî do you want to ask this on the Qdrant Discord instead? https://discord.gg/qma5DQkH

Message : Imagine making QnA engine on the No moat article. You have chunk & indexed the article. 
User asks why does google have no moat.. retrieval might match some or no chunks because not all chunks mention word google and moat, leading to inferior result. The ideal answer has to be based on full context of the article. If we could add knowledge to the model, we can skip retrieval component and generate answers from longer context across articles. Apart from this OpenAI would like to update the existing GPT with data post 2021 rather than again train with full data. Technical term for this problem is continual learning. I am not sure if there is a solution to this
Quoted Message : What does 'inject' mean? What use cases do you've which an in-context, dynamic prompt does not cover?

Message : Fine tuning on enough instances of such information is  what‚Äôs ideally needed. But it doesn‚Äôt work always from what I‚Äôve read

Message : Current techniques need a lot of data to imbibe something

Message : Embedding etc is just a faster hack


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Falcon is also trained with Alibi Position Encoder/Linear Attention (https://arxiv.org/abs/2108.12409v2) ‚Äî so you can finetune and increase context window as well. 

Source: Chetanya, Alexa Prize Winner and Stanford Lecturer, https://twitter.com/ChetanyaRastogi/status/1665118748095725571

Message : Qdrant not writing to storage , therefore works fine it is running , but data cannot be retrieved once stopped and restarted

Message : Did anybody face this problem

Message : In 1 machine, I am having this problem while in the other follows the expected behaviour

Message : Since this is device, config specific ‚Äî do you want to ask this on the Qdrant Discord instead? https://discord.gg/qma5DQkH
Quoted Message : In 1 machine, I am having this problem while in the other follows the expected behaviour

Message : Sure
Quoted Message : Since this is device, config specific ‚Äî do you want to ask this on the Qdrant Discord instead? https://discord.gg/qma5DQkH

Message : Imagine making QnA engine on the No moat article. You have chunk & indexed the article. 
User asks why does google have no moat.. retrieval might match some or no chunks because not all chunks mention word google and moat, leading to inferior result. The ideal answer has to be based on full context of the article. If we could add knowledge to the model, we can skip retrieval component and generate answers from longer context across articles. Apart from this OpenAI would like to update the existing GPT with data post 2021 rather than again train with full data. Technical term for this problem is continual learning. I am not sure if there is a solution to this
Quoted Message : What does 'inject' mean? What use cases do you've which an in-context, dynamic prompt does not cover?

Message : Fine tuning on enough instances of such information is  what‚Äôs ideally needed. But it doesn‚Äôt work always from what I‚Äôve read

Message : Current techniques need a lot of data to imbibe something

Message : Embedding etc is just a faster hack

Message : Hierarchical chunks - title , article summary , then children - paragraphs and so on. This is essentially a search engine type problem.
Quoted Message : Imagine making QnA engine on the No moat article. You have chunk & indexed the article. \nUser asks why does google have no moat.. retrieval might match some or no chunks because not all chunks mention word google and moat, leading to inferior result. The ideal answer has to be based on full context of the article. If we could add knowledge to the model, we can skip retrieval component and generate answers from longer context across articles. Apart from this OpenAI would like to update the existing GPT with data post 2021 rather than again train with full data. Technical term for this problem is continual learning. I am not sure if there is a solution to this

Message : If I ask ‚Äúwho wrote the google no moat article‚Äù it won‚Äôt match any chunk per se

Message : Model Editing methods use logits and alter or update meaning of tokens. 


This paper talks about limitations of those methods, so check it's citation graph for what they can do:
https://arxiv.org/abs/2305.17553

Message : The interesting thing is the models do learn inside the context. But then it can‚Äôt be stored in the model.

Message : Increasing context window is a good hack too

Message : ‚Äé<attached: 00006911-PHOTO-2023-06-04-19-29-51.jpg>

Message : Fine-tuning here is not a new model, just fine tuning on top of GPT3.5/4.

Message : what would this fine tuning involve?
Quoted Message : Fine-tuning here is not a new model, just fine tuning on top of GPT3.5/4.

Message : Following the guide here :
https://platform.openai.com/docs/guides/fine-tuning

{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
...
Quoted Message : what would this fine tuning involve?

Message : it's for gpt-3. Not available for 3.5/4
Quoted Message : Following the guide here :\nhttps://platform.openai.com/docs/guides/fine-tuning\n\n{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n...

Message : I'm not the expert here, hence the request for help

Message : You can't finetune GPT3.5/4

text-davinci-003 can be finetuned, but terribly expensive and not worth the money

You don't really hit RateLimitErrors if you do Retrieval well and don't stuff the context too much
Quoted Message :  2023_06_04_3EB048A2B3758DAE0CC56F.jpeg

Message : Thanks. Looking for guidance from anyone who has made customer support both or Q&A bot in production
Quoted Message :  2023_06_04_3EB048A2B3758DAE0CC56F.jpeg

Message : I‚Äôm working on this for work. This is not as easy as it looks. Like the steps aren‚Äôt wrong or anything but it needs a lot of work to make it work properly.
Quoted Message :  2023_06_04_3EB048A2B3758DAE0CC56F.jpeg

Message : I'm new to this but wouldn't semantic search be better than finetuning?

Message : No not really. Fine tuning can make deeper connections inside what the model knows. Vanilla embeddings are very fuzzy
Quoted Message : I'm new to this but wouldn't semantic search be better than finetuning?

Message : For this case?

Message : No semantic search is good once you have the answers in the DB .. but customer support can be fluid ..

Message : It depends on complexity of the task as well. For eg coding

Message : If we are just retrieving snippets and showing that‚Äôs a search engine.

Message : If a customer is valuable enough spending a few dollars on them for a case is worth it

Message : is bard doing a version of this (embedding lookup) or are they doing frequent retraining and/or fine-tuning?

Message : None of these. It's just a more recent freeze of the weights and data. And combined with Internet search, looks like it's recent
Quoted Message : is bard doing a version of this (embedding lookup) or are they doing frequent retraining and/or fine-tuning?

Message : Yup same thoughts!
Quoted Message : Hierarchical chunks - title , article summary , then children - paragraphs and so on. This is essentially a search engine type problem.

Message : Thats the costly slow backup option for sure. Like in the problem statement I gave we can just match article titles and then add the whole article in the context for answering.
Quoted Message : Increasing context window is a good hack too

Message : A related question to this

How does Microsoft copilot update their chat models for different product? (what they showed in demo 2 months back)
- fix bad generations
- new type of queries
- Microsoft x(powerpoint, word) feature updates
- the func to be executed changes(name, params etc)

Do they just do retrieval over very well-defined docs OR fine tune? If they get failure cases every day and want to fix asap, making sure retrieval works seems like the only way to me. Thoughts?
Quoted Message : Imagine making QnA engine on the No moat article. You have chunk & indexed the article. \nUser asks why does google have no moat.. retrieval might match some or no chunks because not all chunks mention word google and moat, leading to inferior result. The ideal answer has to be based on full context of the article. If we could add knowledge to the model, we can skip retrieval component and generate answers from longer context across articles. Apart from this OpenAI would like to update the existing GPT with data post 2021 rather than again train with full data. Technical term for this problem is continual learning. I am not sure if there is a solution to this

Message : Changing sampling alone goes a long way for code updates :)
Quoted Message : A related question to this\n\nHow does Microsoft copilot update their chat models for different product? (what they showed in demo 2 months back)\n- fix bad generations\n- new type of queries\n- Microsoft x(powerpoint, word) feature updates\n- the func to be executed changes(name, params etc) \n\nDo they just do retrieval over very well-defined docs OR fine tune? If they get failure cases every day and want to fix asap, making sure retrieval works seems like the only way to me. Thoughts?

Message : That‚Äôs not how NLP models work. You cannot dynamically add new training data to transformers. You may be able to hack some params using some ‚Äúhelper‚Äù models but updating the original model is not possible.
Quoted Message : Is there a reliable way to inject knowledge into a RLHF trained model?

Message : Did not get you!?
Quoted Message : Changing sampling alone goes a long way for code updates :)

Message : Hoping for some breakthrough!
Quoted Message : That‚Äôs not how NLP models work. You cannot dynamically add new training data to transformers. You may be able to hack some params using some ‚Äúhelper‚Äù models but updating the original model is not possible.

Message : The only paper I found is https://openreview.net/pdf?id=yd7uyR9_0iU so the hope is alive!
Quoted Message : Hoping for some breakthrough!

Message : https://aclanthology.org/2022.conll-1.4.pdf the non-anonymous one.
Quoted Message : The only paper I found is https://openreview.net/pdf?id=yd7uyR9_0iU so the hope is alive!

Message : https://arxiv.org/abs/2104.08164
Related
Quoted Message : Is there a reliable way to inject knowledge into a RLHF trained model?

Message : So there‚Äôs is a paper from deep mind called RETRO that shows a way to do it. If someone can figure out a way to hack this into present models . But it‚Äôs basically a serious research question

Message : I think RETRO , Toolformer , WebGPT , LoRA these papers have some solid ideas. If combined well can solve a lot of present day issues

Message : Webgpt is what chatgpt with browsing is
Quoted Message : I think RETRO , Toolformer , WebGPT , LoRA these papers have some solid ideas. If combined well can solve a lot of present day issues

Message : Yeah but ppl have said it doesn‚Äôt work well

Message : They've made some improvements
Quoted Message : Yeah but ppl have said it doesn‚Äôt work well

Message : Just read through your article, looks great!
Quoted Message : Changing sampling alone goes a long way for code updates :)

Message : Azure is 3x faster than OpenAI for Gpt3.5 

Source: https://twitter.com/dzhng/status/1665250854922747907?s=48


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : The only paper I found is https://openreview.net/pdf?id=yd7uyR9_0iU so the hope is alive!
Quoted Message : Hoping for some breakthrough!

Message : https://aclanthology.org/2022.conll-1.4.pdf the non-anonymous one.
Quoted Message : The only paper I found is https://openreview.net/pdf?id=yd7uyR9_0iU so the hope is alive!

Message : https://arxiv.org/abs/2104.08164
Related
Quoted Message : Is there a reliable way to inject knowledge into a RLHF trained model?

Message : So there‚Äôs is a paper from deep mind called RETRO that shows a way to do it. If someone can figure out a way to hack this into present models . But it‚Äôs basically a serious research question

Message : I think RETRO , Toolformer , WebGPT , LoRA these papers have some solid ideas. If combined well can solve a lot of present day issues

Message : Webgpt is what chatgpt with browsing is
Quoted Message : I think RETRO , Toolformer , WebGPT , LoRA these papers have some solid ideas. If combined well can solve a lot of present day issues

Message : Yeah but ppl have said it doesn‚Äôt work well

Message : They've made some improvements
Quoted Message : Yeah but ppl have said it doesn‚Äôt work well

Message : Just read through your article, looks great!
Quoted Message : Changing sampling alone goes a long way for code updates :)

Message : Azure is 3x faster than OpenAI for Gpt3.5 

Source: https://twitter.com/dzhng/status/1665250854922747907?s=48

Message : Do they mean turbo? That is anyways really fast.
Any faster they might as well  read my thoughts
Quoted Message : Azure is 3x faster than OpenAI for Gpt3.5 \n\nSource: https://twitter.com/dzhng/status/1665250854922747907?s=48

Message : I've heard azure gives better uptime as well
Quoted Message : Azure is 3x faster than OpenAI for Gpt3.5 \n\nSource: https://twitter.com/dzhng/status/1665250854922747907?s=48

Message : Can confirm this by using it in prod. But the default rate limits for some are low. Like chatGPT is 300 / min as opposed to 3500/min with OpenAI. But with azure I thinkyou get 99.99% uptime which is a big plus
Quoted Message : Azure is 3x faster than OpenAI for Gpt3.5 \n\nSource: https://twitter.com/dzhng/status/1665250854922747907?s=48

Message : Q. for Nirant , others : are you aware of papers/efforts on continuously "online" learning LLMs ?

Wikipedia, pubmed, arxiv : everyday new data is being added

Have there been efforts to crawl these pre- training dataset updates at some frequency (15 days e.g.) and add this delta (relative to the last model update) to the pretraining, and revise model weights to be used for inference based on that ?
Quoted Message : That‚Äôs not how NLP models work. You cannot dynamically add new training data to transformers. You may be able to hack some params using some ‚Äúhelper‚Äù models but updating the original model is not possible.

Message : Look at Never Ending Language Learning, Never Ending Image Learning projects. They've been running for couple of years.
Quoted Message : Q. for Nirant , others : are you aware of papers/efforts on continuously \"online\" learning LLMs ?\n\nWikipedia, pubmed, arxiv : everyday new data is being added \n\nHave there been efforts to crawl these pre- training dataset updates at some frequency (15 days e.g.) and add this delta (relative to the last model update) to the pretraining, and revise model weights to be used for inference based on that ?

Message : https://www.cloudskillsboost.google/paths/118

Google just dropped a learning path for Generative AI on their training site.

Message : ‚Äé<attached: 00006952-PHOTO-2023-06-05-08-25-00.jpg>

Message : That was so quick.

Message : Llama cpp is doing 40tok/s inference for 7B model on a Macbook M2 Max. 24tok/s with 13B and 5tok/s with 65B models. 

https://twitter.com/natfriedman/status/1665402680376987648?s=46&t=WT1iAtjftW-5_e62F8FZTg

Message : Noob question: does finetuning affect inference speeds?

Message : What tokenization method works best for Indic languages as the character level tokinization has higher token count for a Hindi sentence?

Message : Sentencepiece
Quoted Message : What tokenization method works best for Indic languages as the character level tokinization has higher token count for a Hindi sentence?

Message : That's a good starting point

Message : What about spacy? How do the two compare
Quoted Message : Sentencepiece

Message : SpacCy*

Message : Nope
Quoted Message : Noob question: does finetuning affect inference speeds?

Message : Spacy I'm not sure.
Quoted Message : What about spacy? How do the two compare

Message : For tokenization its better to be subword level than word level

Message : Spacy would do word level.

Message : *spaCy is word level tokenisation, so if you're doing it for humans ‚Äî perhaps among the best. Right there with Stanza (Stanford). 

For anything like training models, sentencepiece mentioned by Abhinav @91982023xxxx is a great first candidate. I'd also look at other subword tokenizers
Quoted Message : What about spacy? How do the two compare

Message : What‚Äôs your goal?
Quoted Message : What tokenization method works best for Indic languages as the character level tokinization has higher token count for a Hindi sentence?

Message : GM fam, Anyone has the link to the doc shared in this group which had the summary of all recent discussions ?

Message : Did you mean this? 

https://docs.google.com/document/d/1Wnw-vS9lATKTRAdEPxRm2uKgZlk4BKEmi7b8DL83NPs/edit#
Quoted Message : GM fam, Anyone has the link to the doc shared in this group which had the summary of all recent discussions ?

Message : Yes, thanks.

Message : Is there any Event link from where I can register for this event ??
Quoted Message : Consistent Policy around Events: \n\nAll events in India to be published here: \nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vTftcrqLyUN8N81ekOBsQgWUWqg_t0QKk0Xil49OZKNhSrhHHN3DZRucTo4RJnYGQBYzes0NFxJKAL_/pubhtml\n\nThe only event announced is a Mixer from Wyse\n\nYou can submit the event here: \nhttps://docs.google.com/forms/d/e/1FAIpQLSdWA6lJaw28VFDRUX_q6kj9xZXECkvrE2DgWnLaJDRy1ifjkw/viewform\n\nBoth are updated at https://nirantk.com/community as well.

Message : https://lu.ma/fvm2odkj
Yes here it is
Quoted Message : Is there any Event link from where I can register for this event ??

Message : GPT-3.5 in ChatGPT now points to ```‚Ä¶/?model=text-davinci-002-render-sha```  
They are prioritising security over normal ```text-davinci-003``` or am I missing something here?

Message : ‚Äé<attached: 00006973-PHOTO-2023-06-05-11-56-43.jpg>

Message : its been like that since April as far as i can remember
Quoted Message : GPT-3.5 in ChatGPT now points to ```‚Ä¶/?model=text-davinci-002-render-sha```  \nThey are prioritising security over normal ```text-davinci-003``` or am I missing something here?

Message : Is there a good source of use cases of GenAI and users from India? As in what companies are building? what traction?

Message : Was it not ```text-davinci-003``` or ```gpt-3.5-turbo``` ?
Quoted Message : its been like that since April as far as i can remember

Message : yeah it was using turbo but they changed to 002 after GPT4 rollout i think
Quoted Message : Was it not ```text-davinci-003``` or ```gpt-3.5-turbo``` ?

Message : https://aviary.anyscale.com/

Prolly the best app to test LLMs. From Goku Mohandas and team

Message : https://github.com/ray-project/aviary/

Message : No sir, it‚Äôs by Anyscale
Quoted Message : https://aviary.anyscale.com/\n\nProlly the best app to test LLMs. From Goku Mohandas and team

Message : Ah my bad, but still a good resource

Message : haha definitely

Message : @91824021xxxx I happened to notice this as well. Check this, might help
Quoted Message : https://github.com/saschaschramm/chatgpt#gpt-35

Message : Not a different model I believe if we go by the analysis
Quoted Message : @9182xxxxxxxx I happened to notice this as well. Check this, might help

Message : https://twitter.com/bigansh/status/1665643668605378560


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Was it not ```text-davinci-003``` or ```gpt-3.5-turbo``` ?
Quoted Message : its been like that since April as far as i can remember

Message : yeah it was using turbo but they changed to 002 after GPT4 rollout i think
Quoted Message : Was it not ```text-davinci-003``` or ```gpt-3.5-turbo``` ?

Message : https://aviary.anyscale.com/

Prolly the best app to test LLMs. From Goku Mohandas and team

Message : https://github.com/ray-project/aviary/

Message : No sir, it‚Äôs by Anyscale
Quoted Message : https://aviary.anyscale.com/\n\nProlly the best app to test LLMs. From Goku Mohandas and team

Message : Ah my bad, but still a good resource

Message : haha definitely

Message : @91824021xxxx I happened to notice this as well. Check this, might help
Quoted Message : https://github.com/saschaschramm/chatgpt#gpt-35

Message : Not a different model I believe if we go by the analysis
Quoted Message : @9182xxxxxxxx I happened to notice this as well. Check this, might help

Message : https://twitter.com/bigansh/status/1665643668605378560

Message : Anyone here who has run one of these open source LLMs in cloud with a webserver attached to it?
context : I'm trying to run an open source LLM, (preferring falcon 40B) in aws using sagemaker and HF inference container (https://huggingface.co/blog/sagemaker-huggingface-llm) falcon 7B is giving me an error cause of a bug in the container init, so would love to discuss with people who have already done it.

Message : @91981126xxxx has built something similar for his company
Quoted Message : Anyone here who has run one of these open source LLMs in cloud with a webserver attached to it?\ncontext : I'm trying to run an open source LLM, (preferring falcon 40B) in aws using sagemaker and HF inference container (https://huggingface.co/blog/sagemaker-huggingface-llm) falcon 7B is giving me an error cause of a bug in the container init, so would love to discuss with people who have already done it.

Message : Are you having an issue loading the model?
Quoted Message : Anyone here who has run one of these open source LLMs in cloud with a webserver attached to it?\ncontext : I'm trying to run an open source LLM, (preferring falcon 40B) in aws using sagemaker and HF inference container (https://huggingface.co/blog/sagemaker-huggingface-llm) falcon 7B is giving me an error cause of a bug in the container init, so would love to discuss with people who have already done it.

Message : Nope. I was successfully able to do this in my local, I can replicate that on ec2, but I wanted to do it via sagemaker cause of better infra support. 
The issue is when I‚Äôm running the inference container, for falcon, it‚Äôs giving me an error because it can‚Äôt run some configuration code inside the container without a flag. And in case of llama, it seems to be a tokenizer issue. Still debugging.
Quoted Message : Are you having an issue loading the model?

Message : Sam Altman, IIIT-D, Delhi, Thursday. 

https://twitter.com/IIITDelhi/status/1665634578453897216

Message : Tickets unavailable it says ü´°
Quoted Message : Sam Altman, IIIT-D, Delhi, Thursday. \n\nhttps://twitter.com/IIITDelhi/status/1665634578453897216

Message : yeah, i got some waitlist. 

it's less than 20 min from my home üòÖ

Message : I have a ticket for this but I'm in Chennai and won't be able to make it. Happy to give it away to anyone from Delhi ‚Äì can change the name & details on Eventbrite.
Quoted Message : Sam Altman, IIIT-D, Delhi, Thursday. \n\nhttps://twitter.com/IIITDelhi/status/1665634578453897216

Message : Dibs
Quoted Message : I have a ticket for this but I'm in Chennai and won't be able to make it. Happy to give it away to anyone from Delhi ‚Äì can change the name & details on Eventbrite.

Message : Apologies for posting job here. I wasn't aware it's against the protocol

Message : Guys one question to people using cohere models in production. Specifically the embedding and rerank models.

When did the new pricing come into effect? And last month were you charged according to new pricing?

Message : Wonder why they chose IIIT. Hope it wasn't a typo from the media team :P
Quoted Message : Sam Altman, IIIT-D, Delhi, Thursday. \n\nhttps://twitter.com/IIITDelhi/status/1665634578453897216

Message : Iiit d has done some work in nlp as well. Remember this in 2019 when was working in unfound news and fact check stuff was high priority they had released a paper with an approach. Don't remember it now, it was also not feasible to implement in prod at the time

Message : Here is a hint: https://cai.iiitd.ac.in/index.php/faculties
Quoted Message : Wonder why they chose IIIT. Hope it wasn't a typo from the media team :P

Message : Lol - so you're saying the profs they have are deeper in the space. Interesting

Message : I know this guy, Raghava Mutharaju, he was in my research lab but joined PhD program when I finished.
Quoted Message : Here is a hint: https://cai.iiitd.ac.in/index.php/faculties

Message : Anyone with experience handling production grade facial recognition applications? Looking for some suggestions/ recos on tech stack for various stages of the pipeline.

Message : Also it is called Infosys center, Infosys was one of the first investor in OpenAI

Message : *Donner*

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : I would suggest search previous chat or your site first. Many repeat questions.
Quoted Message : PSA: \n\nGeneral good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking \"Can I ask questions about X?\"

Message : Also, I feel iffy about giving space to discussions which have done more harm than good e.g. face apps, deep fakes already. It's no longer a hypothetical

Message : Didn't know this. Thanks!

https://infotechlead.com/bpo/infosys-invested-artificial-intelligence-research-company-openai-37207
Quoted Message : Also it is called Infosys center, Infosys was one of the first investor in OpenAI

Message : Hello! 

As I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.

If you see your name or phone number in this "removal" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing

That'd indicate to me that you're at least reading some messages :)

Message : PS: Staying on brand, the entire list is generated by ChatGPT

Message : Anyone attending the Sam Altman delhi meetup on 8th June ?

Message : the tickets got sold out so quickly
Quoted Message : Anyone attending the Sam Altman delhi meetup on 8th June ?

Message : Low key happy that Sam Altman sold out faster than many bad concerts!
Quoted Message : the tickets got sold out so quickly

Message : Imagine touts selling tickets for this in black
Quoted Message : Low key happy that Sam Altman sold out faster than many bad concerts!

Message : Hope they have someone asking smart questions

Message : If you were given the opportunity what would you ask?
Quoted Message : Hope they have someone asking smart questions

Message : Do the questions need to be before September 2021?
Quoted Message : Hope they have someone asking smart questions

Message : How about hosting OpenAI models in Indian data centers, so in case of AI embargo India can still access the models.
Quoted Message : If you were given the opportunity what would you ask?

Message : I would ask for better guidelines for finetuning. 
The documentation here can be improved even with the base models. And of course if we can finetune the newer models

Main questions regarding
Is there a base token recommendation for finetuning.
Quoted Message : If you were given the opportunity what would you ask?

Message : Why would you ask tech question to sama?
Quoted Message : I would ask for better guidelines for finetuning. \nThe documentation here can be improved even with the base models. And of course if we can finetune the newer models \n\nMain questions regarding \nIs there a base token recommendation for finetuning.

Message : How technical can you ask questions here

Message : Fair point. But I also think he has a close eye on the technical side as well
Quoted Message : Why would you ask tech question to sama?

Message : I don't want to ask questions on agi because I don't trust him to give the right answers

Message : Not how, why? Find OpenAI folks on twitter for tech questions.

Message : May be ask why he changed his stance in last two-three months


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : If you were given the opportunity what would you ask?
Quoted Message : Hope they have someone asking smart questions

Message : Do the questions need to be before September 2021?
Quoted Message : Hope they have someone asking smart questions

Message : How about hosting OpenAI models in Indian data centers, so in case of AI embargo India can still access the models.
Quoted Message : If you were given the opportunity what would you ask?

Message : I would ask for better guidelines for finetuning. 
The documentation here can be improved even with the base models. And of course if we can finetune the newer models

Main questions regarding
Is there a base token recommendation for finetuning.
Quoted Message : If you were given the opportunity what would you ask?

Message : Why would you ask tech question to sama?
Quoted Message : I would ask for better guidelines for finetuning. \nThe documentation here can be improved even with the base models. And of course if we can finetune the newer models \n\nMain questions regarding \nIs there a base token recommendation for finetuning.

Message : How technical can you ask questions here

Message : Fair point. But I also think he has a close eye on the technical side as well
Quoted Message : Why would you ask tech question to sama?

Message : I don't want to ask questions on agi because I don't trust him to give the right answers

Message : Not how, why? Find OpenAI folks on twitter for tech questions.

Message : May be ask why he changed his stance in last two-three months

Message : Official OpenAI Guide on Prompting: https://platform.openai.com/docs/guides/gpt-best-practices/strategy-test-changes-systematically

Message : What did they find in training that suddenly they are all into regulations?

Message : I can't believe bulk of their entire advice boils down to "use regression tests" ü´¢ü§Ø

Message : This I don't trust him to give the right answer because of conflict of interest
Quoted Message : What did they find in training that suddenly they are all into regulations?

Message : If that has to happen azure will have to upgrade their could centers in india significantly ryt
Quoted Message : How about hosting OpenAI models in Indian data centers, so in case of AI embargo India can still access the models.

Message : Cloud*

Message : Fair point. But changed to what. Is it that article which was deleted recently or the one that he gave at the US congress
Quoted Message : May be ask why he changed his stance in last two-three months

Message : Yeah, that's why it is a good question. That means more GPUs in India.
Quoted Message : If that has to happen azure will have to upgrade their could centers in india significantly ryt

Message : I suspect recent "soft" export bans from US will block something like this even if Tata says I'll pay you for the entire inference compute
Quoted Message : How about hosting OpenAI models in Indian data centers, so in case of AI embargo India can still access the models.

Message : I guess GPT4 will be beaten by OSS soon anyway, but US is not going to stop training GPT5, 6 and these senate committees will start placing an embargo on the export of next

Message : Will openai look to reduce the prices of the older models as it gives preference to chat models

Message : On fun side, asking him about Atman <> Brahman philosophy, he is deep into that philosophy

Message : Has Sama tried Sama juice üòÇ
Quoted Message : On fun side, asking him about Atman <> Brahman philosophy, he is deep into that philosophy

Message : What has your experience been with OSS. I've found for my use cases there is a significant difference still. Although there are a couple that have given surprisingly good results
Quoted Message : I guess GPT4 will be beaten by OSS soon anyway, but US is not going to stop training GPT5, 6 and these senate committees will start placing an embargo on the export of next

Message : I have been fine tuning open-source models and testing them out.
But it always fail in comparison to closed source apis like gpt or claude

What would be an insentive for companies to fine tune their own models as they are more expensive to host as well

Message : I'll wager that nothing comes close to GPT4 in task planning, multi step reasoning beyond 3 before 2024 Q1
Quoted Message : I guess GPT4 will be beaten by OSS soon anyway, but US is not going to stop training GPT5, 6 and these senate committees will start placing an embargo on the export of next

Message : I'm thinking a good solution might be OSS for small use cases.

Like api selection using gorilla model etc.
Quoted Message : I'll wager that nothing comes close to GPT4 in task planning, multi step reasoning beyond 3 before 2024 Q1

Message : You can add even coding to that list too. 
Many uses cases that people are building products for, I.e. summarization, etc, fine tuned oss may work out.
Quoted Message : I'll wager that nothing comes close to GPT4 in task planning, multi step reasoning beyond 3 before 2024 Q1

Message : Yeah, this can get competitive, but this is narrow AI again ‚Äî just a different kind of narrow than 2019
Quoted Message : I'm thinking a good solution might be OSS for small use cases.\n\nLike api selection using gorilla model etc.

Message : Ohh yeah, QA, Summarisation ‚Äî most things are competitive
Quoted Message : You can add even coding to that list too. \nMany uses cases that people are building products for, I.e. summarization, etc, fine tuned oss may work out.

Message : The replit model, have you tried it? They say it's pretty good
Quoted Message : You can add even coding to that list too. \nMany uses cases that people are building products for, I.e. summarization, etc, fine tuned oss may work out.

Message : If wwdc goes well today, all everyone is going to be talking about is VR for the next few weeks.

His take on that would be quite nice

Message : StarCoder and the Teknium Finetune are both better
Quoted Message : The replit model, have you tried it? They say it's pretty good

Message : No. I have stopped trying new models now. I just follow some smart folks on Twitter and check their benchmarks. If you keep tinkering, you can never focus on building one thing.
Quoted Message : The replit model, have you tried it? They say it's pretty good

Message : Agree
Quoted Message : No. I have stopped trying new models now. I just follow some smart folks on Twitter and check their benchmarks. If you keep tinkering, you can never focus on building one thing.

Message : Did you stop tinkering after trying n/e models? ü§£

For those who don't get the joke: https://www.wikiwand.com/en/Secretary_problem
Quoted Message : No. I have stopped trying new models now. I just follow some smart folks on Twitter and check their benchmarks. If you keep tinkering, you can never focus on building one thing.

Message : I also ran out of my 8TB storage, no time to upgrade üòÇ
Quoted Message : No. I have stopped trying new models now. I just follow some smart folks on Twitter and check their benchmarks. If you keep tinkering, you can never focus on building one thing.

Message : https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=4d2224d775c5

Message : Seems like quite the smear campaign

Message : One motto we have at our company for ML folks is to ‚Äúbe a generalist when it comes to inputs and a specialist when it comes to outputs. That‚Äôs because only a generalist knows what tradeoffs are possible and worthwhile‚Äù
Quoted Message : No. I have stopped trying new models now. I just follow some smart folks on Twitter and check their benchmarks. If you keep tinkering, you can never focus on building one thing.

Message : I see two sides. This looks like a hit piece for sure but Emad also made so many crazy claims while the models coming out of Stability AI were subpar.
Quoted Message : Seems like quite the smear campaign

Message : Jokes on anyone who takes their technology news from Forbes
Quoted Message : https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=4d2224d775c5

Message : I agree

But is there anything on his record that's actually wrong
Quoted Message : I see two sides. This looks like a hit piece for sure but Emad also made so many crazy claims while the models coming out of Stability AI were subpar.

Message : The whole article is just a series of claims that can be called "problematic" at best

Message : He is also SV outsider, and was going heads on to YC mafias. üòÇ
Quoted Message : I agree\n\nBut is there anything on his record that's actually wrong

Message : On this note: Any recommendations for good quality sources for tech / AI news? Beyond this group of course. Thanks in advance.
Quoted Message : Jokes on anyone who takes their technology news from Forbes

Message : I will also add nyt and vice to this list
Quoted Message : Jokes on anyone who takes their technology news from Forbes

Message : Isn't vice bankrupt?
Quoted Message : I will also add nyt and vice to this list

Message : Github Feed is severely underrated e.g. one could tell GPT4 was coming out when they pushed the changes to Python lib xD
Quoted Message : On this note: Any recommendations for good quality sources for tech / AI news? Beyond this group of course. Thanks in advance.

Message : Even the Emad piece mentions this: https://github.com/CompVis/stable-diffusion

And you can see when Stability and Runway decided to call a truce from the commit history: https://github.com/CompVis/stable-diffusion/commits/main/README.md


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I see two sides. This looks like a hit piece for sure but Emad also made so many crazy claims while the models coming out of Stability AI were subpar.
Quoted Message : Seems like quite the smear campaign

Message : Jokes on anyone who takes their technology news from Forbes
Quoted Message : https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=4d2224d775c5

Message : I agree

But is there anything on his record that's actually wrong
Quoted Message : I see two sides. This looks like a hit piece for sure but Emad also made so many crazy claims while the models coming out of Stability AI were subpar.

Message : The whole article is just a series of claims that can be called "problematic" at best

Message : He is also SV outsider, and was going heads on to YC mafias. üòÇ
Quoted Message : I agree\n\nBut is there anything on his record that's actually wrong

Message : On this note: Any recommendations for good quality sources for tech / AI news? Beyond this group of course. Thanks in advance.
Quoted Message : Jokes on anyone who takes their technology news from Forbes

Message : I will also add nyt and vice to this list
Quoted Message : Jokes on anyone who takes their technology news from Forbes

Message : Isn't vice bankrupt?
Quoted Message : I will also add nyt and vice to this list

Message : Github Feed is severely underrated e.g. one could tell GPT4 was coming out when they pushed the changes to Python lib xD
Quoted Message : On this note: Any recommendations for good quality sources for tech / AI news? Beyond this group of course. Thanks in advance.

Message : Even the Emad piece mentions this: https://github.com/CompVis/stable-diffusion

And you can see when Stability and Runway decided to call a truce from the commit history: https://github.com/CompVis/stable-diffusion/commits/main/README.md

Message : Yes
Quoted Message : Isn't vice bankrupt?

Message : https://www.linkedin.com/company/generative-ai-media-marketing-creative-conference/
Quoted Message : On this note: Any recommendations for good quality sources for tech / AI news? Beyond this group of course. Thanks in advance.

Message : They have a newsletter, it's more focused on new domains (mostly related to media) where genAi is applied

Message : I was sad to see my name in the list of inactive users, and then I realized it was because I hadn't posted any updates from my previous prompt injection updates for a while. So, to avoid being classified by chat GPT as inactive again, here is my latest prompt injection (complete prompt posted in an earlier message).

Message : ‚Äé<attached: 00007079-PHOTO-2023-06-05-21-47-58.jpg>

Message : Shashank(me) was mentioned in the sheet, there are 3 Shashanks here üòÇ. 

i hope i don't get removed by mistake.
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)

Message : This is fantastic stuff.

Message : Is there a good guide anyone knows to prompt injection techniques, and more generally, LLM based chat bot testing

Message : Was drooling all over his 20vc podcast untill I read this. Tall claims in the podcast but most of them sounded reasonable with hard work. Did not know the past then, in the back of my head the proof was mid-journey. Not sure what to make of any of this, inclined to believe the article now with Rahul Yadav recency bias ‚òπÔ∏è
Quoted Message : https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=4d2224d775c5

Message : From now on we'll probably just remove the least active N users ourselves. If they want back in they can text us.
Running an opt-out Google sheet hijacks the usual conversations here

Message : Good one
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)

Message : Wow, that was a crazy article. Glad these are getting written
Quoted Message : https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=4d2224d775c5

Message : It is tough to separate signal from noise with many of these articles. We‚Äôve seen smear pieces and hit pieces in the past and we also know the value of not turning a blind ear to things like this lest we get another Theranos or another FTX but most of us consuming this news from thousands of miles away have so little context

Message : emad wrote a counter. frankly, that Forbes piece exaggerated a lot of growing pains associated with running a startup, figuring stuff out.
https://twitter.com/EMostaque/status/1665459321180680192
Quoted Message : Was drooling all over his 20vc podcast untill I read this. Tall claims in the podcast but most of them sounded reasonable with hard work. Did not know the past then, in the back of my head the proof was mid-journey. Not sure what to make of any of this, inclined to believe the article now with Rahul Yadav recency bias ‚òπÔ∏è

Message : Hard to separate growing pains from mismanagement. So much of this is subjective.
Quoted Message : emad wrote a counter. frankly, that Forbes piece exaggerated a lot of growing pains associated with running a startup, figuring stuff out.\n https://twitter.com/EMostaque/status/1665459321180680192

Message : ‚Äé~‚ÄØNirant changed the group description

Message : Are you guys following this?

Message : It's absolutely breathtaking

Message : And finally Apple does AR
Quoted Message : If wwdc goes well today, all everyone is going to be talking about is VR for the next few weeks.\n\nHis take on that would be quite nice

Message : AR has always been the real goldmine

Message : This is surely a revolution in AR

Message : And with no controllers

Message : I was having a conversation with @91955016xxxx today about monitors. 

He was trying to find a good work monitor. We're still discussing the right size.

Message : Yes it is. A giant leap.
Quoted Message : It's absolutely breathtaking

Message : Now I think he should get this

Message : Eyes are the monitors now
Quoted Message : Now I think he should get this

Message : I originally wanted buy a 49incher like @91989227xxxx but I'm strongly reconsidering.

Message : Imagine Gen AI for this?

Message : So far quantisation has mainly been for NLPs

Message : I foresee the same for vision models now

Message : This is absolutely magical

Message : GenAI + AR

Message : ‚Äé<attached: 00007107-PHOTO-2023-06-06-00-00-37.jpg>
Quoted Message : Imagine Gen AI for this?

Message : In a few months I would love to see models that can generate multiple SD2.1 grade images in seconds

Message : Was just telling one of my friends that Apple just saved them (MagicLeap) or Apple is screwed. AR is until now is like Afganistan, the place superpowers go to get beat. Let's hope Apple has figured out ü§û

Message : This can then be mixed with AR in very creative ways
Quoted Message : In a few months I would love to see models that can generate multiple SD2.1 grade images in seconds

Message : that eye reveal thing. tuning immersion using crown. üëåüëå

Message : Shopify is doing some great work here
Quoted Message : This can then be mixed with AR in very creative ways

Message : Taking deep work to next level
Quoted Message : that eye reveal thing. tuning immersion using crown. üëåüëå

Message : What exactly? I'm very intrigued
Quoted Message : Shopify is doing some great work here


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This is absolutely magical

Message : GenAI + AR

Message : ‚Äé<attached: 00007107-PHOTO-2023-06-06-00-00-37.jpg>
Quoted Message : Imagine Gen AI for this?

Message : In a few months I would love to see models that can generate multiple SD2.1 grade images in seconds

Message : Was just telling one of my friends that Apple just saved them (MagicLeap) or Apple is screwed. AR is until now is like Afganistan, the place superpowers go to get beat. Let's hope Apple has figured out ü§û

Message : This can then be mixed with AR in very creative ways
Quoted Message : In a few months I would love to see models that can generate multiple SD2.1 grade images in seconds

Message : that eye reveal thing. tuning immersion using crown. üëåüëå

Message : Shopify is doing some great work here
Quoted Message : This can then be mixed with AR in very creative ways

Message : Taking deep work to next level
Quoted Message : that eye reveal thing. tuning immersion using crown. üëåüëå

Message : What exactly? I'm very intrigued
Quoted Message : Shopify is doing some great work here

Message : They really nail the UX
Quoted Message : that eye reveal thing. tuning immersion using crown. üëåüëå

Message : yup. rest of the safari etc demos aren't that exciting. 

but the interface, transition bw real and virtual worldüí∞üëå
Quoted Message : They really nail the UX

Message : This is something they did sometime back: https://twitter.com/strangenative/status/1640741787105984512?s=46&t=WT1iAtjftW-5_e62F8FZTg
Quoted Message : What exactly? I'm very intrigued

Message : and the interface with Mac was just shown, this is exciting. Imagining not using a physical extended monitor for work!

Message : Some players tried this earlier, like Nimo Planet. But this seems miles ahead
Quoted Message : and the interface with Mac was just shown, this is exciting. Imagining not using a physical extended monitor for work!

Message : The only concern I‚Äôm seeing is where‚Äôs the dangling cable connecting to üòÖ

Message : The new Quest 3 looks really good. Meta has done really well with their oculus devices
Quoted Message : Was just telling one of my friends that Apple just saved them (MagicLeap) or Apple is screwed. AR is until now is like Afganistan, the place superpowers go to get beat. Let's hope Apple has figured out ü§û

Message : Spatial Video !

Message : Yes. This seems way ahead. A part of it is because of the ecosystem effect. The userbase is, in a way, trained to imagine at a scale of the bandwidth they want them to access (their diverse products).
Quoted Message : Some players tried this earlier, like Nimo Planet. But this seems miles ahead

Message : Looks like going for a kill on the profit pools of TV screens for sure

Message : This is crazy stuff. The impact on entertainment is massive.

Message : Though it will boil down to how long can you have a thing right infront of your eyes wrapped around. If this is the future, the user will adapt I suppose.

Message : Eye strain and headache from weight imbalance are common with headsets.

Message : The stuff on EyeSight and the responsiveness to gaze for icons and buttons are the kinds of UX Apple has nailed

Message : For those who want a textual summary

https://9to5mac.com/2023/06/05/apple-vision-pro/

Message : Yeah that and they really think hard how to make it work. Like recording in 3D (am assuming) for capturing life moments, this is a use case that MagicLeap or even Daqri could have done. None did it.
Quoted Message : Yes. This seems way ahead. A part of it is because of the ecosystem effect. The userbase is, in a way, trained to imagine at a scale of the bandwidth they want them to access (their diverse products).

Message : So it‚Äôs an external battery
Quoted Message : The only concern I‚Äôm seeing is where‚Äôs the dangling cable connecting to üòÖ

Message : Yes. Its Crazy!!!
Quoted Message : Are you guys following this?

Message : Interesting choice. They put processors in the device and battery outside. Seems like pretty high res.

Message : Power of prop silicon ! üôá‚Äç‚ôÇÔ∏è

Message : Exactly. This allowed to get the form factor a lot better
Quoted Message : Interesting choice. They put processors in the device and battery outside. Seems like pretty high res.

Message : No most of them moved the processors outside due to heat issues. Our faces are particularly very sensitive. So seems like they have solved heating really well or they actually have more than battery in puck or whatever they call it.
Quoted Message : Exactly. This allowed to get the form factor a lot better

Message : *them = others

Message : Though I am completely mesmerised by visionpro, still looking for tickets for Sam Atlan's delhi visit - do share if someone wants to sell/can help with tickets üôèüèº

Message : The only thing this is changing is your bank balance.

Message : $3499

Message : The price is way too much though- even the meta quest pro is available for $1000 ü•≤

Message : Same here - ready to fly down to Delhi in a days notice. Couldn‚Äôt get my hands on the tickets üò≠
Quoted Message : Though I am completely mesmerised by visionpro, still looking for tickets for Sam Atlan's delhi visit - do share if someone wants to sell/can help with tickets üôèüèº

Message : Im saving up ü´†

Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.
Quoted Message : The price is way too much though- even the meta quest pro is available for $1000 ü•≤

Message : But the power is ability for all apps to be integrated.
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : Vision Pro might not be directed to the masses yet. We didn‚Äôt really think they‚Äôd price it for less than an Iphone 14 pro did we üòÇ
I haven‚Äôt tried the Quest 3, but the displays in Quest 2 were mid. There is full color pass through in the Quest 3, but they wouldn‚Äôt be anywhere near the vision pro with the sensor array it has.
As soon as I saw the sensors on the bottom, I knew: No controllers
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : Right, Meta Quests are more mixed reality. This is full AR
Quoted Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those

Message : I have the quest 2 and it's priced just right. The quest pro was considered expensive- and now apple knocks the pricing out of the park üòÇ
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : How nicely they normalize walking around the house wearing a head gear

Message : Oppo right around the corner now to release their copy ü§ô

Message : Quest pro is pretty similar with its see through capabilities 

https://youtu.be/jUIE2l_9ig8
Quoted Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those

Message : I think they still haven't solved object recognition accurately enough thus no interactive augmented / mixed reality stuff. Also they might not have solved the colocalization either, thus not talking about shared experiences. Probably all for later releases.
Quoted Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those

Message : What's colocalization?
Quoted Message : I think they still haven't solved object recognition accurately enough thus no interactive augmented / mixed reality stuff. Also they might not have solved the colocalization either, thus not talking about shared experiences. Probably all for later releases.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : But the power is ability for all apps to be integrated.
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : Vision Pro might not be directed to the masses yet. We didn‚Äôt really think they‚Äôd price it for less than an Iphone 14 pro did we üòÇ
I haven‚Äôt tried the Quest 3, but the displays in Quest 2 were mid. There is full color pass through in the Quest 3, but they wouldn‚Äôt be anywhere near the vision pro with the sensor array it has.
As soon as I saw the sensors on the bottom, I knew: No controllers
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : Right, Meta Quests are more mixed reality. This is full AR
Quoted Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those

Message : I have the quest 2 and it's priced just right. The quest pro was considered expensive- and now apple knocks the pricing out of the park üòÇ
Quoted Message : quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.

Message : How nicely they normalize walking around the house wearing a head gear

Message : Oppo right around the corner now to release their copy ü§ô

Message : Quest pro is pretty similar with its see through capabilities 

https://youtu.be/jUIE2l_9ig8
Quoted Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those

Message : I think they still haven't solved object recognition accurately enough thus no interactive augmented / mixed reality stuff. Also they might not have solved the colocalization either, thus not talking about shared experiences. Probably all for later releases.
Quoted Message : I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those

Message : What's colocalization?
Quoted Message : I think they still haven't solved object recognition accurately enough thus no interactive augmented / mixed reality stuff. Also they might not have solved the colocalization either, thus not talking about shared experiences. Probably all for later releases.

Message : Can‚Äôt wait to see how well they‚Äôre doing the face reconstruction

Message : That would be super compelling for doing remote experiences together with people

Message : Localise multiple people wearing with each other and thus shared sort of experience. So magic leap etc can detect a table that both people of you see, then understand 3D structure of the table. You show same animations (think characters jumping out of top of your table) for both users from different POV on top of this surface.
Quoted Message : What's colocalization?

Message : They've gotten themselves in a great position. It's truly something to marvel at.

For years they've been cursed about the big notch, and they've stuck to face ID despite competitors going far ahead with their camera based authentication.

But now Apple probably has enough data to master a ridiculously accurate facial reconstruction.

Then they just need to encode the movement of certain common trackpoints like corner of the eyes and width of the nose into positional vectors.

They will just transmit the positional vectors of the facial movement and reconstruct a hyperrealistic face on the receiver device

Message : Imagine characterAI

Message : With this

Message : I'd love to talk to a few people in history face-to-face

Message : Instead of a chat interface

Message : Possibilities are endless. And they‚Äôre not releasing it now. So by then who knows we might have this and much more üòÑ
Quoted Message : I'd love to talk to a few people in history face-to-face

Message : I have high hopes for wearing comfort factor and face reconstruction - these were my #1 sore points with the quest

Message : Agents just got a bit too real üòÅ
Quoted Message : I'd love to talk to a few people in history face-to-face

Message : Is this a consumer device though?

Message : Will be really nice to see healthy competition here
Quoted Message : Oppo right around the corner now to release their copy ü§ô

Message : Apple does so much of ML that‚Äôs neatly tucked into functional use cases - even stuff like moving wallpapers

CoreML seems to be getting quite powerful

https://github.com/apple/coremltools

Message : Will be interesting to see what you can train and fine tune on the new Mac Pro - it‚Äôs only slightly more expensive than a fully tricked out RTX 4090 gaming PC, did I get that right ?
Quoted Message : Apple does so much of ML that‚Äôs neatly tucked into functional use cases - even stuff like moving wallpapers\n\nCoreML seems to be getting quite powerful \n\nhttps://github.com/apple/coremltools

Message : India store price doesn‚Äôt look great üòÑ
Quoted Message : Will be interesting to see what you can train and fine tune on the new Mac Pro - it‚Äôs only slightly more expensive than a fully tricked out RTX 4090 gaming PC, did I get that right ?

Message : Mac Pro with M2 Ultra has 192 gigs ram üòÇ

I think they mentioned ‚Äútraining transformers models‚Äù as one of the use cases
Quoted Message : Will be interesting to see what you can train and fine tune on the new Mac Pro - it‚Äôs only slightly more expensive than a fully tricked out RTX 4090 gaming PC, did I get that right ?

Message : Not sure if this has been shared earlier but i found this website to be amazing for use case based prompting

https://learnprompting.org/docs/basics/prompting

Message : They already have ridiculously accurate model in true depth, I think they probably didn't want to wash you face with LiDAR for long periods of time. So they probably used LiDAR based keypoints + facial fiduciaries to do things like low fidelity cartoon character animation one could do now. This solution is because they can't capture your face because it is blocked by the device. So they are forced to provide minimal deformation sort of model.
Quoted Message : They've gotten themselves in a great position. It's truly something to marvel at.\n\nFor years they've been cursed about the big notch, and they've stuck to face ID despite competitors going far ahead with their camera based authentication.\n\nBut now Apple probably has enough data to master a ridiculously accurate facial reconstruction. \n\nThen they just need to encode the movement of certain common trackpoints like corner of the eyes and width of the nose into positional vectors.\n\nThey will just transmit the positional vectors of the facial movement and reconstruct a hyperrealistic face on the receiver device

Message : LiDAR to provide base structure.

Message : Above is guess, they might as well just be using just facial key points.

Message : M2 is known to be power efficient. So it probably doesn't generate significant heat to begin with
Quoted Message : No most of them moved the processors outside due to heat issues. Our faces are particularly very sensitive. So seems like they have solved heating really well or they actually have more than battery in puck or whatever they call it.

Message : The battery pack can easily be offset to the back strap as well, making it kind of offset the main device.
Quoted Message : No most of them moved the processors outside due to heat issues. Our faces are particularly very sensitive. So seems like they have solved heating really well or they actually have more than battery in puck or whatever they call it.

Message : There‚Äôs a paper around here that did face reconstruction using only top view camera feeds
Quoted Message : Above is guess, they might as well just be using just facial key points.

Message : it might be the case that the device can handle a few minutes on its own while the user switches the battery when one runs out. Paired with prop silicon this would mean many hours of use

Message : https://youtu.be/hkSfHCtpnHU
Quoted Message : There‚Äôs a paper around here that did face reconstruction using only top view camera feeds

Message : What you‚Äôre talking about here btw is also old tech - https://youtu.be/dVa1xRaHTA0 - and I really doubt they are using face id data for training a face reconstruction model. Face ID never leaves the device afaik
Quoted Message : They've gotten themselves in a great position. It's truly something to marvel at.\n\nFor years they've been cursed about the big notch, and they've stuck to face ID despite competitors going far ahead with their camera based authentication.\n\nBut now Apple probably has enough data to master a ridiculously accurate facial reconstruction. \n\nThen they just need to encode the movement of certain common trackpoints like corner of the eyes and width of the nose into positional vectors.\n\nThey will just transmit the positional vectors of the facial movement and reconstruct a hyperrealistic face on the receiver device

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAnsh Agarwal üë©üèΩ‚ÄçüöÄ

Message : Removed for self promotion more than once

Message : Unity popped 17pc last night on the partnership announcement

Message : Overall I don‚Äôt see anyone really buying these Apple VR headsets apart from the same crowd that buys Mac pros. And that excludes most of us

Message : All said, incredible looking product

Message : I have a contrarian view.

How comfortable are AR/VR headsets ?
How long can you wear them before your brain & eyes want a break ?
There is no sticky usage
Quoted Message : AR has always been the real goldmine

Message : Try the skybox blockadelabs 360 image generation in your VR browser. Works great on my pico and oculus.
Quoted Message : Imagine Gen AI for this?

Message : I use them for 3.5 hrs without any issues. Have been using headsets for 5 years now
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : A couple of hours max. Because you tend to blink less often, makes my eyes dry. The other factor is weight imbalance. Improperly fit headsets can cause headaches and neck strain, but there are lots of ways to fix that.
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : I have two VR and an FPV drone VR, all of them collecting dust.

Message : I have the Occulus 2, and I can‚Äôt use it for too long, max an hour. Also there is the https://en.m.wikipedia.org/wiki/Vergence-accommodation_conflict. Since the focal point of the lens of the eyes and the stereo conflict, it may cause issues for some people.
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : Often its the battery life that is the constraint for me, not comfort (I use a quest 2)

Message : Magic leap was trying to fix it with their light field display, but they didn‚Äôt come too far yet.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Overall I don‚Äôt see anyone really buying these Apple VR headsets apart from the same crowd that buys Mac pros. And that excludes most of us

Message : All said, incredible looking product

Message : I have a contrarian view.

How comfortable are AR/VR headsets ?
How long can you wear them before your brain & eyes want a break ?
There is no sticky usage
Quoted Message : AR has always been the real goldmine

Message : Try the skybox blockadelabs 360 image generation in your VR browser. Works great on my pico and oculus.
Quoted Message : Imagine Gen AI for this?

Message : I use them for 3.5 hrs without any issues. Have been using headsets for 5 years now
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : A couple of hours max. Because you tend to blink less often, makes my eyes dry. The other factor is weight imbalance. Improperly fit headsets can cause headaches and neck strain, but there are lots of ways to fix that.
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : I have two VR and an FPV drone VR, all of them collecting dust.

Message : I have the Occulus 2, and I can‚Äôt use it for too long, max an hour. Also there is the https://en.m.wikipedia.org/wiki/Vergence-accommodation_conflict. Since the focal point of the lens of the eyes and the stereo conflict, it may cause issues for some people.
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : Often its the battery life that is the constraint for me, not comfort (I use a quest 2)

Message : Magic leap was trying to fix it with their light field display, but they didn‚Äôt come too far yet.

Message : It's fun for couple of hours, days then the novelty wears down quickly.
Quoted Message : I have two VR and an FPV drone VR, all of them collecting dust.

Message : Yeah, Very curious to know how they have managed VAC. Atleast for 2-3hr periods of usage. If they can do that, it will enable a whole bunch of  application. But Apple being Apple, I am guessing they have a solution.
Quoted Message : I have the Occulus 2, and I can‚Äôt use it for too long, max an hour. Also there is the https://en.m.wikipedia.org/wiki/Vergence-accommodation_conflict. Since the focal point of the lens of the eyes and the stereo conflict, it may cause issues for some people.

Message : Battery: I think you can do both 2hr and plugged in it seems. Their res is very high, guessing early 4k x 2.5k or so, almost thrice of Quest 3. Weight imbalance: I am guessing they have solved it. Else they are screwed. Yeah, I think the real thing is do they have apps with sticky workflow.

Message : DAQRI, MagicLeap, Holo lens all had nice 3D rendered promo videos which were very far from real product and they couldn't close the gap soon enough. Disclaimer: Did some work for DAQRI in 2014-2016 period.

Message : Absolutely banger paper from Microsoft Research, illustrates how you can distill a larger model's reasoning capabilities into a smaller model (think of all your agent behaviour) https://arxiv.org/abs/2306.02707

Openly contradicting/side stepping  the previous research which argued that small models don't have the world knowledge which large models do.

Surpasses Vicuna-13B by *100%*

No code, no data ‚Äî but planning to release model weights under a research license similar to Llama

Message : https://twitter.com/sterlingcrispin/status/1665792422914453506?s=46&t=v5MAnKU6XwMWCzMNzmBUuA

Message : One of the coolest results involved predicting a user was going to click on something before they actually did. That was a ton of work and something I‚Äôm proud of. Your pupil reacts before you click in part because you expect something will happen after you click. So you can create biofeedback with a user's brain by monitoring their eye behavior, and redesigning the UI in real time to create more of this anticipatory pupil response. It‚Äôs a crude brain computer interface via the eyes, but very cool
Quoted Message : https://twitter.com/sterlingcrispin/status/1665792422914453506?s=46&t=v5MAnKU6XwMWCzMNzmBUuA

Message : Nice feature, but I foresee the same kind of research used for UX dark patterns in VR headsets in the future - we already see how effective these can be at guiding/interrupting user behaviour on regular websites
Quoted Message : One of the coolest results involved predicting a user was going to click on something before they actually did. That was a ton of work and something I‚Äôm proud of. Your pupil reacts before you click in part because you expect something will happen after you click. So you can create biofeedback with a user's brain by monitoring their eye behavior, and redesigning the UI in real time to create more of this anticipatory pupil response. It‚Äôs a crude brain computer interface via the eyes, but very cool

Message : Makes a lot of sense to pursue this line of research because outside of the big research labs, most companies won't build completely new LLMs, but will build on top of the big LLMs and their capabilities in a specific area, sub-problem, domain.
Quoted Message : Absolutely banger paper from Microsoft Research, illustrates how you can distill a larger model's reasoning capabilities into a smaller model (think of all your agent behaviour) https://arxiv.org/abs/2306.02707\n\nOpenly contradicting/side stepping  the previous research which argued that small models don't have the world knowledge which large models do.\n\nSurpasses Vicuna-13B by *100%*\n\nNo code, no data ‚Äî but planning to release model weights under a research license similar to Llama

Message : Really interesting paper, thanks for sharing

Message : Can a RLHF tuned model be considered a foundation model?

Message : You can do whatever, say whatever as long as you can popularise your terms like RLHF or Foundation Model üòâ
Quoted Message : Can a RLHF tuned model be considered a foundation model?

Message : fair enough.
Quoted Message : You can do whatever, say whatever as long as you can popularise your terms like RLHF or Foundation Model üòâ

Message : andrew ng changed the game when he marketed the term deep learning. Or maybe  it was someone else.

Message : We were just yesterday talking about step by step thought process capability of GPT4.
Quoted Message : Absolutely banger paper from Microsoft Research, illustrates how you can distill a larger model's reasoning capabilities into a smaller model (think of all your agent behaviour) https://arxiv.org/abs/2306.02707\n\nOpenly contradicting/side stepping  the previous research which argued that small models don't have the world knowledge which large models do.\n\nSurpasses Vicuna-13B by *100%*\n\nNo code, no data ‚Äî but planning to release model weights under a research license similar to Llama

Message : OpenAI updated their developer docs last night . Pretty neat https://platform.openai.com/docs/guides/gpt-best-practices

Message : OpenAI should do this as a successor to fine-tuning.
Quoted Message : Absolutely banger paper from Microsoft Research, illustrates how you can distill a larger model's reasoning capabilities into a smaller model (think of all your agent behaviour) https://arxiv.org/abs/2306.02707\n\nOpenly contradicting/side stepping  the previous research which argued that small models don't have the world knowledge which large models do.\n\nSurpasses Vicuna-13B by *100%*\n\nNo code, no data ‚Äî but planning to release model weights under a research license similar to Llama

Message : also by Subhabhrata (though not the first author) is the ReWOO paper addressing reasoning - https://arxiv.org/abs/2305.18323 I think this can be a potential game changer too.
Quoted Message : Absolutely banger paper from Microsoft Research, illustrates how you can distill a larger model's reasoning capabilities into a smaller model (think of all your agent behaviour) https://arxiv.org/abs/2306.02707\n\nOpenly contradicting/side stepping  the previous research which argued that small models don't have the world knowledge which large models do.\n\nSurpasses Vicuna-13B by *100%*\n\nNo code, no data ‚Äî but planning to release model weights under a research license similar to Llama

Message : I have been looking to buy Oculus for a while but could not find anywhere to test it in India. 
I also was thinking the same if it would be comfortable if worn for long. Anyone who owns a Oculus can maybe answer
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : My company had bought one from the US. After around 30-40 minutes of usage with specs, you do feel dizzy (sample size was small though)
Quoted Message : I have been looking to buy Oculus for a while but could not find anywhere to test it in India. \nI also was thinking the same if it would be comfortable if worn for long. Anyone who owns a Oculus can maybe answer

Message : This guy spends 40-50 hours per week working in VR and finds good productivity gain: https://medium.com/immersedteam/working-from-orbit-39bf95a6d385 In my experience the number of pixels in quest 2 is not enough for me to replace monitors with it, but I don't find it tiring if used for few hours. I do experience heavy motion sickness if the scene is moving and I can't use it for more than half an hour
Quoted Message : I have a contrarian view.\n\nHow comfortable are AR/VR headsets ?\nHow long can you wear them before your brain & eyes want a break ?\nThere is no sticky usage

Message : My initial experience with oculus was mind blown, it was the first genuinely new user interface I experienced since keyboard screen and mouse. 

Creator tools were the most interesting apps.

Comfort on the other hand was downright abysmal. 20 minutes leaves me uncomfortable. 30 really annoyed. Almost never make it beyond 45.

Message : Anyway, from a Gen AI perspective, I think a spatial and gestural interface is particularly disruptive

Message : My Oculus has been gathering dust

Message : Because it offers an alternative to text as generative input

Message : Please feel free to gift me. I accept donations.
Quoted Message : My Oculus has been gathering dust

Message : Lol, but it‚Äôs fun for flaunting when wiser friends are around
Quoted Message : Please feel free to gift me. I accept donations.

Message : Organise a oculus testing activity for the group
Quoted Message : My Oculus has been gathering dust

Message : I‚Äôll get one in the next meet-up
Quoted Message : Organise a oculus testing activity for the group

Message : has anyone here experimented with Neurosity Crown? and the membership?

Message : Which version do you have.  I have quest and I can easily spend hour...

I have watched full blown movies on this app called big screen.. Played tt for an hour
Quoted Message : My initial experience with oculus was mind blown, it was the first genuinely new user interface I experienced since keyboard screen and mouse. \n\nCreator tools were the most interesting apps.\n\nComfort on the other hand was downright abysmal. 20 minutes leaves me uncomfortable. 30 really annoyed. Almost never make it beyond 45.

Message : Same here. Has been sitting in the shelf after a month of getting it.

The eyes burn is quite enough already with the excessive computer and phone time. This takes it to a whole new level with those LEDs right in front of the eyes.
Quoted Message : My Oculus has been gathering dust

Message : A couple of my colleagues have dry eye issues - due to excess device use. We need more AR tech that doesn't put a big screen in front of your eyes, closer to it, but uses other senses to inform us about the environment. I'll buy some of that kind of tech if it is interesting
Quoted Message : Same here. Has been sitting in the shelf after a month of getting it.\n\nThe eyes burn is quite enough already with the excessive computer and phone time. This takes it to a whole new level with those LEDs right in front of the eyes.

Message : I went from Oculus Go in 2018 to HTC Vive. Bought and returned Quest 2. Got Pico4 which is good for giant screen content and watching F1. Works well with both spectacles and contact lenses.

Message : Immersive travel using 360 images generated by stable diffusion seems to work quite well. 
https://skybox.blockadelabs.com/

Message : Thinking more critically about the Apple VR headset release it doesn't do anything fundamentally different compared to the likes of Oculus VR, it is an upgrade for those really into the space. Sensing this trend lately at Apple in building mass market stuff like M1/M2 Macs and then also having Studio/Earpods Max/Mac Pro/iPad Pro M1-M2 and now their VR headset - all of these are for a small sliver of users.

Message : Not to mention Apple Watch Ultra

Message : Have a question regarding instruction tuning. I have come across two methods of fine-tuning:
1. The loss is only calculated on the output(answer to the input instruction)
2. The loss is calculated on the entire example including the instruction.

Any thoughts on which one does better?

Message : If I was an Apple investor I'd love these new demos but I'd be wondering where the cheddar is going to come from. Maybe gaming? One possibility since Nvidia despite its trillion dollars market cap isn't able to attract mass market GPU buyers. PC gamers seem more and more black pilled about the GPU scene from what I can tell. Generative AI won't necessarily change that market since mass market GPUs like the (underwhelming) 4000 series are not targeted at AI dev teams

Message : The quest 2 I think ?? I got early last year. Not sure exactly.

To be honest I did push myself and used it beyond 45 minutes, but it was painful.

It could be because I also wear prescription glasses, and that I have particularly dry eyes.
Quoted Message : Which version do you have.  I have quest and I can easily spend hour...\n\nI have watched full blown movies on this app called big screen.. Played tt for an hour


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Which version do you have.  I have quest and I can easily spend hour...

I have watched full blown movies on this app called big screen.. Played tt for an hour
Quoted Message : My initial experience with oculus was mind blown, it was the first genuinely new user interface I experienced since keyboard screen and mouse. \n\nCreator tools were the most interesting apps.\n\nComfort on the other hand was downright abysmal. 20 minutes leaves me uncomfortable. 30 really annoyed. Almost never make it beyond 45.

Message : Same here. Has been sitting in the shelf after a month of getting it.

The eyes burn is quite enough already with the excessive computer and phone time. This takes it to a whole new level with those LEDs right in front of the eyes.
Quoted Message : My Oculus has been gathering dust

Message : A couple of my colleagues have dry eye issues - due to excess device use. We need more AR tech that doesn't put a big screen in front of your eyes, closer to it, but uses other senses to inform us about the environment. I'll buy some of that kind of tech if it is interesting
Quoted Message : Same here. Has been sitting in the shelf after a month of getting it.\n\nThe eyes burn is quite enough already with the excessive computer and phone time. This takes it to a whole new level with those LEDs right in front of the eyes.

Message : I went from Oculus Go in 2018 to HTC Vive. Bought and returned Quest 2. Got Pico4 which is good for giant screen content and watching F1. Works well with both spectacles and contact lenses.

Message : Immersive travel using 360 images generated by stable diffusion seems to work quite well. 
https://skybox.blockadelabs.com/

Message : Thinking more critically about the Apple VR headset release it doesn't do anything fundamentally different compared to the likes of Oculus VR, it is an upgrade for those really into the space. Sensing this trend lately at Apple in building mass market stuff like M1/M2 Macs and then also having Studio/Earpods Max/Mac Pro/iPad Pro M1-M2 and now their VR headset - all of these are for a small sliver of users.

Message : Not to mention Apple Watch Ultra

Message : Have a question regarding instruction tuning. I have come across two methods of fine-tuning:
1. The loss is only calculated on the output(answer to the input instruction)
2. The loss is calculated on the entire example including the instruction.

Any thoughts on which one does better?

Message : If I was an Apple investor I'd love these new demos but I'd be wondering where the cheddar is going to come from. Maybe gaming? One possibility since Nvidia despite its trillion dollars market cap isn't able to attract mass market GPU buyers. PC gamers seem more and more black pilled about the GPU scene from what I can tell. Generative AI won't necessarily change that market since mass market GPUs like the (underwhelming) 4000 series are not targeted at AI dev teams

Message : The quest 2 I think ?? I got early last year. Not sure exactly.

To be honest I did push myself and used it beyond 45 minutes, but it was painful.

It could be because I also wear prescription glasses, and that I have particularly dry eyes.
Quoted Message : Which version do you have.  I have quest and I can easily spend hour...\n\nI have watched full blown movies on this app called big screen.. Played tt for an hour

Message : Yep, not a good experience with glasses.
Quoted Message : The quest 2 I think ?? I got early last year. Not sure exactly.\n\nTo be honest I did push myself and used it beyond 45 minutes, but it was painful.\n\nIt could be because I also wear prescription glasses, and that I have particularly dry eyes.

Message : Depends a bit on your masking e.g. one trick to mask some part of instructions too and that seems to improve generalisation in small models. But to the best of my knowledge, in most cases -- we do calculate loss on the entire prompt/context, right?
Quoted Message : Have a question regarding instruction tuning. I have come across two methods of fine-tuning:\n 1. The loss is only calculated on the output(answer to the input instruction)\n2. The loss is calculated on the entire example including the instruction. \n\nAny thoughts on which one does better?

Message : Thinking of getting a VR headset myself. Which one of pico4 vs quest2 do you prefer?
Quoted Message : I went from Oculus Go in 2018 to HTC Vive. Bought and returned Quest 2. Got Pico4 which is good for giant screen content and watching F1. Works well with both spectacles and contact lenses.

Message : ‚Äé<attached: 00007242-PHOTO-2023-06-06-12-02-06.jpg>
Quoted Message : Depends a bit on your masking e.g. one trick to mask some part of instructions too and that seems to improve generalisation in small models. But to the best of my knowledge, in most cases -- we do calculate loss on the entire prompt/context, right?

Message : yes
-100 is ignored in CrossEntropyLoss
Quoted Message :  2023_06_06_52B8B2C435D6A39B91A74EAD04AD30DD.jpeg

Message : Calculating loss on the entire context does work reasonably well in my experience but a lot of the repositories that I have come across recently mask the input completely. So I was wondering which is the better way to go.

Message : https://developer.apple.com/wwdc23/topics/ml-vision/  They are releasing access to segmentation (human/animals) and pose (both again) for Devs. Their own embedding for 27 languages as well. Quite a few interesting things.

Message : ‚Äé<attached: 00007246-PHOTO-2023-06-06-12-43-24.jpg>

Message : Does it find otp from messages? Or anything else as well
Quoted Message :  2023_06_06_3A0A56F39D34F375AFD9.jpeg

Message : This is a joke. But yeah I think if it can connect to your phone messages
Quoted Message : Does it find otp from messages? Or anything else as well

Message : This is a long standing apple meme joke

Message : OhhüòÖ
Quoted Message : This is a long standing apple meme joke

Message : https://aistartupstrategy.com/home

Message : what do y'all think of this?

https://www.linkedin.com/posts/ritendradatta_amidst-the-craze-for-generative-ai-products-activity-7070889891676520448-rKTP?utm_source=share&utm_medium=member_android

Message : Excellent thread... Which begs the Q: are there good thread summarisers? Maybe a browser extension?
Quoted Message : what do y'all think of this?\n\nhttps://www.linkedin.com/posts/ritendradatta_amidst-the-craze-for-generative-ai-products-activity-7070889891676520448-rKTP?utm_source=share&utm_medium=member_android

Message : I am not sure I understand a 100%. 

Is he saying ki more then generating content, AI will help in consuming content?
Quoted Message : Excellent thread... Which begs the Q: are there good thread summarisers? Maybe a browser extension?

Message : A16z also has the same kind POV for B2B https://a16z.com/2023/03/30/b2b-generative-ai-synthai/
Quoted Message : what do y'all think of this?\n\nhttps://www.linkedin.com/posts/ritendradatta_amidst-the-craze-for-generative-ai-products-activity-7070889891676520448-rKTP?utm_source=share&utm_medium=member_android

Message : Hello, has anyone tried TheBloke/falcon-7b-instruct-GPTQ? If yes, any reference notebook having the implementation?

context -: falcon-7b-instruct-GPTQ is an implementation for 4bit model for Falcon-7B-Instruct. It is the result of quantizing to 4 bits using AutoGPTQ.

Message : I agree with this 100%

Especially in businesses, the problem is not generating content (read noise); challenge is making sense of what‚Äôs happening around you.

I personally use GPT-4 at least 30-40% of time to understand content rather than generating; and I have no organization to deal with.
Quoted Message : what do y'all think of this?\n\nhttps://www.linkedin.com/posts/ritendradatta_amidst-the-craze-for-generative-ai-products-activity-7070889891676520448-rKTP?utm_source=share&utm_medium=member_android

Message : My 2c: The OP is less gung ho about the long term business use case of creative AI, it seems. He says consumption ML (recommendation algorithms?) makes more business sense. Kind of when Andrew Ng said most ML was supervised, though unsupervised is more cool.  The thread has others interesting replies though
Quoted Message : I am not sure I understand a 100%. \n\nIs he saying ki more then generating content, AI will help in consuming content?

Message : This is great, thanks for sharing.
Quoted Message : A16z also has the same kind POV for B2B https://a16z.com/2023/03/30/b2b-generative-ai-synthai/

Message : I am still wondering what it implies for marketers. How do we stay ahead of the curve. 

So far, the only piece of advice I've received is to be hands on with the genAI tools.
Quoted Message : I agree with this 100%\n\nEspecially in businesses, the problem is not generating content (read noise); challenge is making sense of what‚Äôs happening around you.\n\nI personally use GPT-4 at least 30-40% of time to understand content rather than generating; and I have no organization to deal with.

Message : I do agree with him - the novelty of using the new platforms will wear off.
Quoted Message : My 2c: The OP is less gung ho about the long term business use case of creative AI, it seems. He says consumption ML (recommendation algorithms?) makes more business sense. Kind of when Andrew Ng said most ML was supervised, though unsupervised is more cool.  The thread has others interesting replies though

Message : There's an initial shock and awe when new tech is introduced to us but we get used to it pretty quickly also

Message : I think that‚Äôs the only meaningful advice right now. Nobody in the world knows how all the pieces will interact with each other and the end effects on individual industries and roles.
Quoted Message : I am still wondering what it implies for marketers. How do we stay ahead of the curve. \n\nSo far, the only piece of advice I've received is to be hands on with the genAI tools.

Message : Novelty will wear off, but we are also truly limited by our imagination today. So new use-cases will keep coming even if we choose to ignore the seismic shifts of more capable models or larger context windows or faster latencies.
Quoted Message : I do agree with him - the novelty of using the new platforms will wear off.

Message : Hmmm. One of my theories is that the noise will increase manifold, so the ability of a marketer to differentiate their brand will become even more significant.
Quoted Message : Novelty will wear off, but we are also truly limited by our imagination today. So new use-cases will keep coming even if we choose to ignore the seismic shifts of more capable models or larger context windows or faster latencies.

Message : For eg, it used to take 2 hours and someone really skilled to do the equivalent of Photoshop background filler. 

Now that everyone can do it, WHAT you do with it becomes the point of differentiation

Message : is the question from the perspective of the photoshop expert or the person who commissioned that assignment?
Quoted Message : For eg, it used to take 2 hours and someone really skilled to do the equivalent of Photoshop background filler. \n\nNow that everyone can do it, WHAT you do with it becomes the point of differentiation

Message : From the pov of market demand. Differentiating yourself (a photoshop expert) in a market where ai wrappers can do in minutes what took you hours.

Message : So strategy will become more imp

Message : Yes, your ability to decide the plan/instructions/imagination becomes the differentiator

Message : Also, when turn around time reduces beyond a certain threshold because of tool improvement, people with overlapping skill sets become dramatically more leveraged

Message : Say the marketer who now knows how to use Photoshop will have way higher productivity than someone who needs one more person to be productive 

Silly example; but I stand by the intent

Message : Makes sense.

Message : I was speaking to a senior data scientist at swiggy last weekend and she suggested to look at all ai tools and this entire wave as a new computer that's way more powerful than what we have on hand.

Message : At the end of the day, marketers need not try to understand how these tools work.

Message : Just need to be able to use them

Message : https://www.youtube.com/watch?v=sKFwS0TEHHM

New pycon videos are out, and there are sooo many! üòç so glad we have recovered from covid

Message : does the feel like a similar angle that mojo is taking
Quoted Message : https://www.youtube.com/watch?v=sKFwS0TEHHM\n\nNew pycon videos are out, and there are sooo many! üòç so glad we have recovered from covid


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : So strategy will become more imp

Message : Yes, your ability to decide the plan/instructions/imagination becomes the differentiator

Message : Also, when turn around time reduces beyond a certain threshold because of tool improvement, people with overlapping skill sets become dramatically more leveraged

Message : Say the marketer who now knows how to use Photoshop will have way higher productivity than someone who needs one more person to be productive 

Silly example; but I stand by the intent

Message : Makes sense.

Message : I was speaking to a senior data scientist at swiggy last weekend and she suggested to look at all ai tools and this entire wave as a new computer that's way more powerful than what we have on hand.

Message : At the end of the day, marketers need not try to understand how these tools work.

Message : Just need to be able to use them

Message : https://www.youtube.com/watch?v=sKFwS0TEHHM

New pycon videos are out, and there are sooo many! üòç so glad we have recovered from covid

Message : does the feel like a similar angle that mojo is taking
Quoted Message : https://www.youtube.com/watch?v=sKFwS0TEHHM\n\nNew pycon videos are out, and there are sooo many! üòç so glad we have recovered from covid

Message : ‚Äé<attached: 00007281-PHOTO-2023-06-06-17-05-31.jpg>

Message : *who all are attending

Message : Folks, quick question. How are you all doing iterative prompt engineering? Seeing that even moving one prompt up and down makes a difference for several LLMs. How do you track sensitivity to added or deleted prompts?

Message : I guess i'm not cool enough to get an afterparty invite üòÄ
Quoted Message :  2023_06_06_B7736D7B842549E97E2EFE133CA07503.jpeg

Message : this is different right. I just signed up and saw that there r about 100 tickets left
Quoted Message : I guess i'm not cool enough to get an afterparty invite üòÄ

Message : https://bit.ly/43qE9GD this is link btw
Quoted Message : I guess i'm not cool enough to get an afterparty invite üòÄ

Message : thanks, I RSVP'd.

Message : Have a test battery of some sort to, commit frequently and log both the prompt and output
Quoted Message : Folks, quick question. How are you all doing iterative prompt engineering? Seeing that even moving one prompt up and down makes a difference for several LLMs. How do you track sensitivity to added or deleted prompts?

Message : True but no way to measure sensitivity or accuracy iteratively against a gold standard answer yet right?

Message : is this truly generative (e.g writing something). Then it's tough. But if it's more objective, then why can't you measure? See this sheet for example for logic tests https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=2011456595 What this guy has done for m questions across n LLMs you can do for p prompts for the same LLM and check the output (I hope I'm understanding your question correctly).

Message : Not sure what you mean by sensitivity or accuracy in the context of generated text, but you can use task-specific scores e.g. ROUGE/BLEU for summaries and so on
Quoted Message : True but no way to measure sensitivity or accuracy iteratively against a gold standard answer yet right?

Message : This is interesting. Unfortunately I‚Äôm looking at written support responses to user queries and need to test this on a number of inputs links/queries + different prompts to find the ideal output.

Message : https://vickiboykis.com/what_are_embeddings/

Message : We do use embeddings, but it‚Äôs still a veery iterative process :)

Message : Hey Folks,

I work for Hasura. We are focused on improving developer experience. Hasura has simplified the data access story for application developers. We are looking to do the same for VectorDB users.

I am doing research to understand real (not my assumptions) pain points in working with vectorDBs.

If you are interested in contributing to user study, please ping me. I will have a quick call/chat with you to understand the gaps and brainstorm what kind of solution can help you.

Message : Would love to chat with anyone who does prompt engineering on a regular basis to understand best practises. Do lmk :)

Message : You can check this too: http://nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Quoted Message : Would love to chat with anyone who does prompt engineering on a regular basis to understand best practises. Do lmk :)

Message : NICE, looking like few seats are left now
Quoted Message : this is different right. I just signed up and saw that there r about 100 tickets left

Message : -> Since we could not accommodate everyone at the afternoon meetup & we got an overwhelming response, hence opened up an after-event party, just after the meetup so that more folks can meet, learn and showcase their products.  

Just clarifying this, not promoting it. :)
Quoted Message :  2023_06_06_B7736D7B842549E97E2EFE133CA07503.jpeg

Message : Does anyone know of startups working on AI in the legal domain .. i need some help/advice. It would be great if anyone could DM me.

Message : @91942037xxxx
Quoted Message : Does anyone know of startups working on AI in the legal domain .. i need some help/advice. It would be great if anyone could DM me.

Message : and so as Nirant suggested, you should be able to use ROUGE/BLEU scores and rank your prompts then?
Quoted Message : This is interesting. Unfortunately I‚Äôm looking at written support responses to user queries and need to test this on a number of inputs links/queries + different prompts to find the ideal output.

Message : DMing you ..@91819726xxxx and few others are building in this space as well.
Quoted Message : Does anyone know of startups working on AI in the legal domain .. i need some help/advice. It would be great if anyone could DM me.

Message : Does anyone know of a media production house using Gen AI in their workflows?

Message : cc @91874202xxxx thought this might be interesting to you
Quoted Message : Does anyone know of a media production house using Gen AI in their workflows?

Message : Hi, I know a few, who are doing this.
Quoted Message : Does anyone know of a media production house using Gen AI in their workflows?

Message : We‚Äôre trying a few things at The Viral Fever. Please DM
Quoted Message : Does anyone know of a media production house using Gen AI in their workflows?

Message : Would love to know more
Quoted Message : Hi, I know a few, who are doing this.

Message : Sure, lets talk on DM?
Quoted Message : Would love to know more

Message : Has anyone here tried to fine-tune Falcon-40B or 7B?

Context: trying to understand how to fine-tune OSS models. If there's any resources apart from the Replit blog which provides more in-depth explanation to fine-tuning LLMs, would be super helpful!

Message : yep I have tried it 
but you will have to follow a video
https://youtu.be/DcBC4yGHV4Q
he hasnt linked the notebook tho
Quoted Message : Has anyone here tried to fine-tune Falcon-40B or 7B?\n\nContext: trying to understand how to fine-tune OSS models. If there's any resources apart from the Replit blog which provides more in-depth explanation to fine-tuning LLMs, would be super helpful!

Message : Yes I wear glasses too. It's a bit tricky to setup. Initially

I eventually ended up buying 3p  headbands... There stock ones are crap
Quoted Message : The quest 2 I think ?? I got early last year. Not sure exactly.\n\nTo be honest I did push myself and used it beyond 45 minutes, but it was painful.\n\nIt could be because I also wear prescription glasses, and that I have particularly dry eyes.

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØAbhishek Sagar

Message : Added Abhishek Sagar @91961917xxxx. Currently VP Engineering at Zomato

Message : Official Hugginface instructions on training Falcon7B with their PEFT lib huggingface.co/blog/falcon#fine-tuning-with-peft
Quoted Message : Has anyone here tried to fine-tune Falcon-40B or 7B?\n\nContext: trying to understand how to fine-tune OSS models. If there's any resources apart from the Replit blog which provides more in-depth explanation to fine-tuning LLMs, would be super helpful!

Message : Thanks Pranjal. Looking forward to learn and collaborate here
Quoted Message : Added Abhishek Sagar @9196xxxxxxxx. Currently VP Engineering at Zomato

Message : We have invested heavily in building a benchmark. Run it on every commit. Tag ground truth queries with tags so that you can get quick feedback Om which kind of queries fail
Quoted Message : Folks, quick question. How are you all doing iterative prompt engineering? Seeing that even moving one prompt up and down makes a difference for several LLMs. How do you track sensitivity to added or deleted prompts?

Message : https://huyenchip.com/2023/04/11/llm-engineering.html

Message : After LangchainAI's $10M seed round, Llama Index has raised $8.5M seed (Greylock) 
https://twitter.com/jerryjliu0/status/1666095220252106752

Message : Langchain's investment seems to be making a difference - at least in code that has changed. Some API changes clearly visible in versions weeks apart
Quoted Message : After LangchainAI's $10M seed round, Llama Index has raised $8.5M seed (Greylock) \nhttps://twitter.com/jerryjliu0/status/1666095220252106752


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : yep I have tried it 
but you will have to follow a video
https://youtu.be/DcBC4yGHV4Q
he hasnt linked the notebook tho
Quoted Message : Has anyone here tried to fine-tune Falcon-40B or 7B?\n\nContext: trying to understand how to fine-tune OSS models. If there's any resources apart from the Replit blog which provides more in-depth explanation to fine-tuning LLMs, would be super helpful!

Message : Yes I wear glasses too. It's a bit tricky to setup. Initially

I eventually ended up buying 3p  headbands... There stock ones are crap
Quoted Message : The quest 2 I think ?? I got early last year. Not sure exactly.\n\nTo be honest I did push myself and used it beyond 45 minutes, but it was painful.\n\nIt could be because I also wear prescription glasses, and that I have particularly dry eyes.

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØAbhishek Sagar

Message : Added Abhishek Sagar @91961917xxxx. Currently VP Engineering at Zomato

Message : Official Hugginface instructions on training Falcon7B with their PEFT lib huggingface.co/blog/falcon#fine-tuning-with-peft
Quoted Message : Has anyone here tried to fine-tune Falcon-40B or 7B?\n\nContext: trying to understand how to fine-tune OSS models. If there's any resources apart from the Replit blog which provides more in-depth explanation to fine-tuning LLMs, would be super helpful!

Message : Thanks Pranjal. Looking forward to learn and collaborate here
Quoted Message : Added Abhishek Sagar @9196xxxxxxxx. Currently VP Engineering at Zomato

Message : We have invested heavily in building a benchmark. Run it on every commit. Tag ground truth queries with tags so that you can get quick feedback Om which kind of queries fail
Quoted Message : Folks, quick question. How are you all doing iterative prompt engineering? Seeing that even moving one prompt up and down makes a difference for several LLMs. How do you track sensitivity to added or deleted prompts?

Message : https://huyenchip.com/2023/04/11/llm-engineering.html

Message : After LangchainAI's $10M seed round, Llama Index has raised $8.5M seed (Greylock) 
https://twitter.com/jerryjliu0/status/1666095220252106752

Message : Langchain's investment seems to be making a difference - at least in code that has changed. Some API changes clearly visible in versions weeks apart
Quoted Message : After LangchainAI's $10M seed round, Llama Index has raised $8.5M seed (Greylock) \nhttps://twitter.com/jerryjliu0/status/1666095220252106752

Message : Do you like those changes? Want to elaborate which ones caught your eye?
Quoted Message : Langchain's investment seems to be making a difference - at least in code that has changed. Some API changes clearly visible in versions weeks apart

Message : Actually something that used to work earlier doesn't work. With the Langchain SQL agent. :D

Message : That said it is probably just us trying to get up to speed. We'll get there

Message : The list of demos, APIs which are core and now broken/no longer maintained is very long
Quoted Message : Actually something that used to work earlier doesn't work. With the Langchain SQL agent. :D

Message : Indeed!

Message : seems like they are going to build another Jina
Quoted Message : After LangchainAI's $10M seed round, Llama Index has raised $8.5M seed (Greylock) \nhttps://twitter.com/jerryjliu0/status/1666095220252106752

Message : All ML tools converge to Jina and Haystack ü§£

Message : Haystack seemed very promising, I haven't tried it yet, but was seeing the docs

Message : Anyone know a good guide to testing chat bots? Really interested in that right now

Message : Full end-to-end testing, with automation.

Message : I say this with some degree of exposure e.g. I used to head ML for Verloop.io ‚Äî Nykaa's chat support bot maker: 

Open domain chatbots cannot be tested without running a Turing test
Quoted Message : Anyone know a good guide to testing chat bots? Really interested in that right now

Message : Happy to chat. Do we want to do a group call this week? On legal side?
Quoted Message : DMing you ..@9181xxxxxxxx and few others are building in this space as well.

Message : For conceptual design of *testing* chat bots, Rasa continues to be the highest return on your reading effort: https://rasa.com/docs/rasa/testing-your-assistant/#how-to-write-test-cases

Utterance, Slots ‚Äî quite powerful constructs even today

Message : We built some chat bots on Rasa to act as fasting coach (at Nintee)

The edge cases start piling up pretty soon.

It‚Äôs very hard to test chat bots systematically

Message : Thanks, Nirant. I am familiar with Rasa for NLU, perhaps time to revisit in this context
Quoted Message : For conceptual design of *testing* chat bots, Rasa continues to be the highest return on your reading effort: https://rasa.com/docs/rasa/testing-your-assistant/#how-to-write-test-cases\n\nUtterance, Slots ‚Äî quite powerful constructs even today

Message : Nat Friedman and Daniel Gross have invested in Llama.cpp ‚Äî the company is called ggml.ai 

https://twitter.com/ggerganov/status/1666120568993730561

Message : While I don‚Äôt know much in NLU for chatbots ,I‚Äôve evaluated and piloted quite a fair bit of 3rd party SaaS integrations including Verloop,Yellow and Haptik for customer care and support queries.

Suffice to say that beyond narrow range of queries chatbots built pre-LLM era were not delivering on the promise of query automation.

I‚Äôm more bullish on LLM based chatbots iff prompt injection attacks can be solved for.
Quoted Message : I say this with some degree of exposure e.g. I used to head ML for Verloop.io ‚Äî Nykaa's chat support bot maker: \n\nOpen domain chatbots cannot be tested without running a Turing test

Message : Would love to hear thought if someone has compared Google's STT vs Whisper or any other model. Any pros/cons for both to decide which one to use if performance is a big weighting factor?

Message : Prompt injection is top of mind for me right now. Anyone looked at automated prompt engineering ? There‚Äôs work done on this and published as a paper (with code)
Quoted Message : While I don‚Äôt know much in NLU for chatbots ,I‚Äôve evaluated and piloted quite a fair bit of 3rd party SaaS integrations including Verloop,Yellow and Haptik for customer care and support queries.\n\nSuffice to say that beyond narrow range of queries chatbots built pre-LLM era were not delivering on the promise of query automation.\n\nI‚Äôm more bullish on LLM based chatbots iff prompt injection attacks can be solved for.

Message : This would have been shared earlier in the group 
So far it‚Äôs the closest to prompt engineering resource I‚Äôve seen

https://github.com/microsoft/guidance
Quoted Message : Prompt injection is top of mind for me right now. Anyone looked at automated prompt engineering ? There‚Äôs work done on this and published as a paper (with code)

Message : I‚Äôve come across guidance but we‚Äôre figuring out how langchain and this fit in together. Have you built with this framework and do you have suggestions?
Quoted Message : This would have been shared earlier in the group \nSo far it‚Äôs the closest to prompt engineering resource I‚Äôve seen \n\nhttps://github.com/microsoft/guidance

Message : Kor is interesting for some use cases. Specifically structured data extraction

Message : No I haven‚Äôt used it.I‚Äôm still figuring it out too,feel that it‚Äôs slightly complicated üòÖ
Quoted Message : I‚Äôve come across guidance but we‚Äôre figuring out how langchain and this fit in together. Have you built with this framework and do you have suggestions?

Message : I hear you. Lots of frameworks at this stage. Just the state of the tech right now
Quoted Message : No I haven‚Äôt used it.I‚Äôm still figuring it out too,feel that it‚Äôs slightly complicated üòÖ

Message : i am  using langchain for the agents part of it
and guidance for places where structured out put is required
Quoted Message : I‚Äôve come across guidance but we‚Äôre figuring out how langchain and this fit in together. Have you built with this framework and do you have suggestions?

Message : people who are using langchain here, just curious - which agents are u folks using ? 
i have generally seen RetrievalQA and VectorDBQA being the most popular. just trying to get an idea which ones have u seen being useful in production.

Message : Has anybody setup privategpt? I am thinking of using it for a project in my org. I wanted to see if there are any caveats / pitfalls before hand

Message : Is this similar to guardrails.ai?
Quoted Message : This would have been shared earlier in the group \nSo far it‚Äôs the closest to prompt engineering resource I‚Äôve seen \n\nhttps://github.com/microsoft/guidance

Message : Yeah, you can't use it your org. Research license only for Llama
Quoted Message : Has anybody setup privategpt? I am thinking of using it for a project in my org. I wanted to see if there are any caveats / pitfalls before hand

Message : Using SQL and the ones you mentioned
Quoted Message : people who are using langchain here, just curious - which agents are u folks using ? \ni have generally seen RetrievalQA and VectorDBQA being the most popular. just trying to get an idea which ones have u seen being useful in production.

Message : Thanks Nirant.

What are some options that we have considering we are in a heavily regulated industry?

Any form of data sharing (even temp storage) on 3rd party services is a challenge today.
Quoted Message : Yeah, you can't use it your org. Research license only for Llama

Message : If you're on Azure VPC, this should not be that hard tbh. But that said, you can make one using Falcon-7B/40B Instruct
Quoted Message : Thanks Nirant.\n\nWhat are some options that we have considering we are in a heavily regulated industry?\n\nAny form of data sharing (even temp storage) on 3rd party services is a challenge today.

Message : That is permissively licensed

Message : If we use Azure OpenAI and we don‚Äôt choose the option to share data with openAi, am I right in my understanding that this data will be local to your model deployment?
Quoted Message : If you're on Azure VPC, this should not be that hard tbh. But that said, you can make one using Falcon-7B/40B Instruct

Message : Guardrails is for making sure LLM output is in desired schema, they're talking about prompts in the other message
Quoted Message : Is this similar to guardrails.ai?

Message : data will be local to model yes. but you will still violate india data residency regulations (if they apply to you) since data will cross India borders
Quoted Message : If we use Azure OpenAI and we don‚Äôt choose the option to share data with openAi, am I right in my understanding that this data will be local to your model deployment?

Message : Those regulations do apply to us. Thanks Sandeep for your input.
Quoted Message : data will be local to model yes. but you will still violate india data residency regulations (if they apply to you) since data will cross India borders

Message : Azure should make these models available in the India region. Any idea if that is in the works?
Quoted Message : Those regulations do apply to us. Thanks Sandeep for your input.

Message : This was a question someone wanted to ask Sam Altman
Quoted Message : Azure should make these models available in the India region. Any idea if that is in the works?

Message : my bet is not possible - unless US regulations on export of LLM gets clarified. will take some time, but eventually will happen.
Quoted Message : This was a question someone wanted to ask Sam Altman


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Thanks Nirant.

What are some options that we have considering we are in a heavily regulated industry?

Any form of data sharing (even temp storage) on 3rd party services is a challenge today.
Quoted Message : Yeah, you can't use it your org. Research license only for Llama

Message : If you're on Azure VPC, this should not be that hard tbh. But that said, you can make one using Falcon-7B/40B Instruct
Quoted Message : Thanks Nirant.\n\nWhat are some options that we have considering we are in a heavily regulated industry?\n\nAny form of data sharing (even temp storage) on 3rd party services is a challenge today.

Message : That is permissively licensed

Message : If we use Azure OpenAI and we don‚Äôt choose the option to share data with openAi, am I right in my understanding that this data will be local to your model deployment?
Quoted Message : If you're on Azure VPC, this should not be that hard tbh. But that said, you can make one using Falcon-7B/40B Instruct

Message : Guardrails is for making sure LLM output is in desired schema, they're talking about prompts in the other message
Quoted Message : Is this similar to guardrails.ai?

Message : data will be local to model yes. but you will still violate india data residency regulations (if they apply to you) since data will cross India borders
Quoted Message : If we use Azure OpenAI and we don‚Äôt choose the option to share data with openAi, am I right in my understanding that this data will be local to your model deployment?

Message : Those regulations do apply to us. Thanks Sandeep for your input.
Quoted Message : data will be local to model yes. but you will still violate india data residency regulations (if they apply to you) since data will cross India borders

Message : Azure should make these models available in the India region. Any idea if that is in the works?
Quoted Message : Those regulations do apply to us. Thanks Sandeep for your input.

Message : This was a question someone wanted to ask Sam Altman
Quoted Message : Azure should make these models available in the India region. Any idea if that is in the works?

Message : my bet is not possible - unless US regulations on export of LLM gets clarified. will take some time, but eventually will happen.
Quoted Message : This was a question someone wanted to ask Sam Altman

Message : until then - it is Falcon 40B

Message : Sandeep - are you fine-tuning falcon-7/40b for custom use?
Quoted Message : until then - it is Falcon 40B

Message : ‚Äé<attached: 00007366-PHOTO-2023-06-06-23-22-17.jpg>

Message : Even I interpreted the meaning of the excerpt the way ChatGPT thought of it.

> here, the first "I don't think" is redundant
Why/how do you say so?
Quoted Message :  2023_06_06_3EB0F4B4C8B1D058783B8D.jpeg

Message : @91773788xxxx what is your take on Tree of thought?

Message : based on the video.

these are cues which text doesn't pick up. basically he started a sentence "i don't think..." then interrupted it with "it's smart" and continued "but i don't think..."
Quoted Message : Even I interpreted the meaning of the excerpt the way ChatGPT thought of it.\n\n> here, the first \"I don't think\" is redundant\nWhy/how do you say so?

Message : ‚Äé<attached: 00007370-PHOTO-2023-06-06-23-38-46.jpg>

Message : I mean, does it make sense to say ‚Äúthere is an embeddings model for gpt-4‚Äù or are they unrelated/independent?

Message : Completions model accept plaintext toh, so whether you embed or not pre-completion is independent/use-case wise.
And for embeddings, you may choose OSS (say sentence-transformers) as well, OpenAI's embedding service is just another option.
Quoted Message :  2023_06_06_3AE0759D3D43489AA93E.jpeg

Message : not really - im on the side of working with prompts and vector db to do the same stuff that a finetuning would.

but i admit there might be certain usecases which would work well with finetuning. genuinely curious - what kind of usecases (not data) are u looking to enable ?
Quoted Message : Sandeep - are you fine-tuning falcon-7/40b for custom use?

Message : They are independent. I choose HF's instruct over ada-002 usually.
Quoted Message :  2023_06_06_3AE0759D3D43489AA93E.jpeg

Message : 7b fine-tuning to get a reasonable QnA performance with all prompt engg possible.

Both one-shot and few-shot haven't worked well for 7b or less size models. Plus figuring out internal hosting optimizations, it's a requirement due to data related constraints.

After QnA, there are a few more use cases.
Quoted Message : not really - im on the side of working with prompts and vector db to do the same stuff that a finetuning would.\n\nbut i admit there might be certain usecases which would work well with finetuning. genuinely curious - what kind of usecases (not data) are u looking to enable ?

Message : super interesting. ur saying the prompts havent worked ? are u using the standard langchain chains/prompts ? 

typically i have seen this is a quirk of how their chain of thought functions. did u try your prompts with GPT (even if u dont plan to use them long term)
Quoted Message : 7b fine-tuning to get a reasonable QnA performance with all prompt engg possible.\n\nBoth one-shot and few-shot haven't worked well for 7b or less size models. Plus figuring out internal hosting optimizations, it's a requirement due to data related constraints.\n\nAfter QnA, there are a few more use cases.

Message : Can you share model card for this?
Quoted Message : They are independent. I choose HF's instruct over ada-002 usually.

Message : Folks basic question - when does one use LlamaIndex vs Langchain ?

Message : Yes, it worked reasonably well with gpt-3.5, even zero-shot was okay in some cases.

I tested standard chains and then some custom templates for priming and instruction tuning wherever possible.
Quoted Message : super interesting. ur saying the prompts havent worked ? are u using the standard langchain chains/prompts ? \n\ntypically i have seen this is a quirk of how their chain of thought functions. did u try your prompts with GPT (even if u dont plan to use them long term)

Message : this is very interesting. i am pretty sure u will get bang for buck by writing custom chains for falcon. unfortunately i havent done so, or i would have pointed out.
Quoted Message : Yes, it worked reasonably well with gpt-3.5, even zero-shot was okay in some cases.\n\nI tested standard chains and then some custom templates for priming and instruction tuning wherever possible.

Message : This thread from @91773788xxxx answers it well

https://twitter.com/NirantK/status/1656803881308024832?t=a4rhYFXV9dOm5UMzDFbPvg&s=19
Quoted Message : Folks basic question - when does one use LlamaIndex vs Langchain ?

Message : No clue how to approach it but worth a shot. Are you hosting privately as well? I want to understand cost and scaling dynamics.

Not considering AWS/databricks/HF inference solutions for now.
Quoted Message : this is very interesting. i am pretty sure u will get bang for buck by writing custom chains for falcon. unfortunately i havent done so, or i would have pointed out.

Message : not yet. but there seems to be a whole bunch of startups who are providing inference hosting. its generally commodity, but the key is going to be GPU rates/availability which seems to be the blocker these days.
Quoted Message : No clue how to approach it but worth a shot. Are you hosting privately as well? I want to understand cost and scaling dynamics.\n\nNot considering AWS/databricks/HF inference solutions for now.

Message : that said AWS Sagemaker might end up being the cheapest.

Message : P.S. Falcon was trained on sagemaker

Message : Well deserved. ggerganov single handedly making Bulgaria an AI power house. Meanwhile, Nat and David Gross have been supporting many Indie hackers, challenges and sponsoring similar events here in Bay, too. We don't have any significant project like this coming out of India. Not even fine tuned models like what Teknium is doing.
Quoted Message : Nat Friedman and Daniel Gross have invested in Llama.cpp ‚Äî the company is called ggml.ai \n\nhttps://twitter.com/ggerganov/status/1666120568993730561

Message : Has anyone built their own GPU rig or knows someone who has?

Message : @91913108xxxx  have you guys done anything like this?
Quoted Message : Has anyone built their own GPU rig or knows someone who has?

Message : ‚Äé<attached: 00007389-PHOTO-2023-06-07-08-47-54.jpg>

Message : ‚Äé<attached: 00007390-PHOTO-2023-06-07-09-08-28.jpg>
Quoted Message : Imagine characterAI

Message : Woah!!!
Quoted Message :  2023_06_07_3A1B6B756B519AAA01A1.jpeg

Message : cc @91875456xxxx @91740765xxxx
Quoted Message : Has anyone built their own GPU rig or knows someone who has?

Message : Ty! 
Happy to answer any Qs ü´°

Message : I need help with board specs to build 7 3090 GPU rig and dealing with multi PSU pwm sync. Any suggestion?
Quoted Message : Ty! \nHappy to answer any Qs ü´°

Message : whoa that is cool!
would love to hear ur experience after the event üôå
Quoted Message :  2023_06_07_3A1B6B756B519AAA01A1.jpeg

Message : I am building a document similarity project. I created text embeddings using USE. But is there a way to use BERT tuned on my corpus so it learns domain specific elements and gives better text encodings ? The methods I have seen are supervised - create pairs of sentences and provide a similarity score for training data. 
Is there an alternate unsupervised way ?

Message : On text gen evaluation, I found this prompt in the new Andrew NG course on LLM

Message : ‚Äé<attached: 00007398-PHOTO-2023-06-07-09-34-27.jpg>

Message : Does anyone here use Jina?

Message : in general, bert encodings don't work so well for similarity (our experience, I'll see if I can try to find references). FAISS might be better than USE (again, our experience), you might want to try that.
Quoted Message : I am building a document similarity project. I created text embeddings using USE. But is there a way to use BERT tuned on my corpus so it learns domain specific elements and gives better text encodings ? The methods I have seen are supervised - create pairs of sentences and provide a similarity score for training data. \nIs there an alternate unsupervised way ?

Message : also see https://www.sbert.net/docs/usage/semantic_textual_similarity.html for BERT embeddings for similarity

Message : it also has domain adaptation, etc. But honestly, the BERT vocab isn't so big (intentionally) so there might be trade offs depending on the data you have.

Message : Yes I explored this one. But this requires you to have a pair of sentences with similarity score for training.
Quoted Message : also see https://www.sbert.net/docs/usage/semantic_textual_similarity.html for BERT embeddings for similarity


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I need help with board specs to build 7 3090 GPU rig and dealing with multi PSU pwm sync. Any suggestion?
Quoted Message : Ty! \nHappy to answer any Qs ü´°

Message : whoa that is cool!
would love to hear ur experience after the event üôå
Quoted Message :  2023_06_07_3A1B6B756B519AAA01A1.jpeg

Message : I am building a document similarity project. I created text embeddings using USE. But is there a way to use BERT tuned on my corpus so it learns domain specific elements and gives better text encodings ? The methods I have seen are supervised - create pairs of sentences and provide a similarity score for training data. 
Is there an alternate unsupervised way ?

Message : On text gen evaluation, I found this prompt in the new Andrew NG course on LLM

Message : ‚Äé<attached: 00007398-PHOTO-2023-06-07-09-34-27.jpg>

Message : Does anyone here use Jina?

Message : in general, bert encodings don't work so well for similarity (our experience, I'll see if I can try to find references). FAISS might be better than USE (again, our experience), you might want to try that.
Quoted Message : I am building a document similarity project. I created text embeddings using USE. But is there a way to use BERT tuned on my corpus so it learns domain specific elements and gives better text encodings ? The methods I have seen are supervised - create pairs of sentences and provide a similarity score for training data. \nIs there an alternate unsupervised way ?

Message : also see https://www.sbert.net/docs/usage/semantic_textual_similarity.html for BERT embeddings for similarity

Message : it also has domain adaptation, etc. But honestly, the BERT vocab isn't so big (intentionally) so there might be trade offs depending on the data you have.

Message : Yes I explored this one. But this requires you to have a pair of sentences with similarity score for training.
Quoted Message : also see https://www.sbert.net/docs/usage/semantic_textual_similarity.html for BERT embeddings for similarity

Message : Does FAISS have domain specific adaptations ? Will definitely explore this one.
Quoted Message : in general, bert encodings don't work so well for similarity (our experience, I'll see if I can try to find references). FAISS might be better than USE (again, our experience), you might want to try that.

Message : FAISS is a similarity library, and does not support finetuning or training vectors. Did you mean to say that direct vector similarity works?
Quoted Message : in general, bert encodings don't work so well for similarity (our experience, I'll see if I can try to find references). FAISS might be better than USE (again, our experience), you might want to try that.

Message : yes, in our final implementation we trained vectors using fasttext on our own corpus and then the similarity is using faiss.

Message : Just saw this: LLM with 5 million token window (can engulf a company's whole codebase)

OpenAI is also working to drastically increase context length. Many AI apps may have to go back to the drawing board when that happens

https://twitter.com/magicailabs/status/1666116935904292869

Message : What‚Äôs a gpu rig? Do you mean a computer or like those crypto garages
Quoted Message : Has anyone built their own GPU rig or knows someone who has?

Message : Actually this is the question I'll try to ask Sam Altman tomorrow, if I get a chance to.
With large token window sizes, it is impractical to send the context each time with the query

So will OpenAI provide a hosted "context storage". Or in other words, a vector DB?
Quoted Message : Just saw this: LLM with 5 million token window (can engulf a company's whole codebase)\n\nOpenAI is also working to drastically increase context length. Many AI apps may have to go back to the drawing board when that happens\n\nhttps://twitter.com/magicailabs/status/1666116935904292869

Message : We have a 3070 rig for gaming. Looking to build a larger for ML.

But also if support for apple M-series GPUs gets better is it really worth making one or just getting like a Mac Studio?
Quoted Message : Has anyone built their own GPU rig or knows someone who has?

Message : OpenAI is maai baap ü•≤

Ideally, all app interactions, how we do prompting would also change
Quoted Message : Actually this is the question I'll try to ask Sam Altman tomorrow, if I get a chance to.\nWith large token window sizes, it is impractical to send the context each time with the query \n\nSo will OpenAI provide a hosted \"context storage\". Or in other words, a vector DB?

Message : When's the next Gen AI meetup?

Message : 24th June tentatively, hasn't been announced anywhere yet ‚Äî experimenting with a format change, might not do talks this time
Quoted Message : When's the next Gen AI meetup?

Message : Sure

Message : Does fasttext provide non supervised training on corpus ?
Quoted Message : yes, in our final implementation we trained vectors using fasttext on our own corpus and then the similarity is using faiss.

Message : Yes. fasttext is popularly used for embedding, you do not need labels.
Quoted Message : Does fasttext provide non supervised training on corpus ?

Message : I thought so too. Evaluated it for similarity but end up using nmslib.
Quoted Message : FAISS is a similarity library, and does not support finetuning or training vectors. Did you mean to say that direct vector similarity works?

Message : Does anyone know of any api/tools that implement something like this? 
https://arxiv.org/pdf/1904.05440.pdf

Message : aieeeeee I wrote FAISS when I meant fasttext. Sorry for the confusion, my bad ... ü§¶‚Äç‚ôÄÔ∏è
Quoted Message : in general, bert encodings don't work so well for similarity (our experience, I'll see if I can try to find references). FAISS might be better than USE (again, our experience), you might want to try that.

Message : ```fasttext``` is a text classifier right?
What exactly do you classify your texts into before doing a similarly search? Can you give an example?
Quoted Message : aieeeeee I wrote FAISS when I meant fasttext. Sorry for the confusion, my bad ... ü§¶‚Äç‚ôÄÔ∏è

Message : Fasttext is embeddings.
Quoted Message : ```fasttext``` is a text classifier right?\nWhat exactly do you classify your texts into before doing a similarly search? Can you give an example?

Message : word vectors specifically.

Message : See https://fasttext.cc/docs/en/unsupervised-tutorial.html

Message : *subword vectors, and for the longest time ‚Äî the best subword vectors
Quoted Message : word vectors specifically.

Message : And even today, if you're doing something like really fast, think Cloudflare Edge workers or Raspberry Pi ‚Äî the best quality vectors you can train there in theory

Message : might be a noob question sorry as I‚Äôm learning on the go, but how is it different from an embedding model like openai‚Äôs or HF‚Äôs?
Quoted Message : *subword vectors, and for the longest time ‚Äî the best subword vectors

Message : And thanks to this approach, it's quite tolerant of spelling mistakes!
Quoted Message : *subword vectors, and for the longest time ‚Äî the best subword vectors

Message : 1. It works‚Ñ¢Ô∏è
2. It's fast on CPU, both train and inference
3. Doesn't need you to send data or GPU
Quoted Message : might be a noob question sorry as I‚Äôm learning on the go, but how is it different from an embedding model like openai‚Äôs or HF‚Äôs?

Message : okay so you don‚Äôt have to call the API everytime
Quoted Message : 1. It works‚Ñ¢Ô∏è\n2. It's fast on CPU, both train and inference\n3. Doesn't need you to send data or GPU

Message : you can run it locally. very lightweight.
Quoted Message : okay so you don‚Äôt have to call the API everytime

Message : Has anyone deployed Qdrant in production cloud ? Would be interested to hear

Message : Locally is best I think
Quoted Message : And even today, if you're doing something like really fast, think Cloudflare Edge workers or Raspberry Pi ‚Äî the best quality vectors you can train there in theory

Message : Cloud as in Azure AWS Gcp own subscription

Message : i ran a similar search api for a papers startup for years with an allen ai model from hf for embeddings and aws open search with a knn index
Quoted Message : might be a noob question sorry as I‚Äôm learning on the go, but how is it different from an embedding model like openai‚Äôs or HF‚Äôs?

Message : Quite a few folks run their own Qdrant over Docker, their Discord has some folks working on optim for this too.
Quoted Message : Has anyone deployed Qdrant in production cloud ? Would be interested to hear

Message : Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence.
Quoted Message : 1. It works‚Ñ¢Ô∏è\n2. It's fast on CPU, both train and inference\n3. Doesn't need you to send data or GPU

Message : worked great and was zero cost since we computed the embeddings on our laptop and updated production open source a couple times a day however today i would go with open I embeddings endpoint
Quoted Message : i ran a similar search api for a papers startup for years with an allen ai model from hf for embeddings and aws open search with a knn index

Message : Yes Docker Qdrant on cloud Azure AWS that's what I am after
Quoted Message : Quite a few folks run their own Qdrant over Docker, their Discord has some folks working on optim for this too.

Message : i used hf sentence transformer for creating embeddings before worked great
Quoted Message : Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence.

Message : this is the case with most embeddings i would compute embeddings per short paragraphs over pearce blocks of text
Quoted Message : Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence.

Message : you mean chunking the documents right?
Quoted Message : this is the case with most embeddings i would compute embeddings per short paragraphs over pearce blocks of text

Message : Need some suggestions,
My use-case -: I have some documents that I have converted into embeddings and stored in a VectorDB. Now I need to kind of chat which the document or perform some query on top of the document.

What I am doing -: Using MiniLM for embedding and Falcon-7b-Instruct for query purposes.
Question -: Which model should be the right one for this use case, an "instruct" or "chat model".

Message : You want to use one that is better for search.
You can start with minlm and even try coheres embedding and go from there.
Quoted Message : Need some suggestions,\nMy use-case -: I have some documents that I have converted into embeddings and stored in a VectorDB. Now I need to kind of chat which the document or perform some query on top of the document.\n\nWhat I am doing -: Using MiniLM for embedding and Falcon-7b-Instruct for query purposes. \nQuestion -: Which model should be the right one for this use case, an \"instruct\" or \"chat model\".


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : i ran a similar search api for a papers startup for years with an allen ai model from hf for embeddings and aws open search with a knn index
Quoted Message : might be a noob question sorry as I‚Äôm learning on the go, but how is it different from an embedding model like openai‚Äôs or HF‚Äôs?

Message : Quite a few folks run their own Qdrant over Docker, their Discord has some folks working on optim for this too.
Quoted Message : Has anyone deployed Qdrant in production cloud ? Would be interested to hear

Message : Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence.
Quoted Message : 1. It works‚Ñ¢Ô∏è\n2. It's fast on CPU, both train and inference\n3. Doesn't need you to send data or GPU

Message : worked great and was zero cost since we computed the embeddings on our laptop and updated production open source a couple times a day however today i would go with open I embeddings endpoint
Quoted Message : i ran a similar search api for a papers startup for years with an allen ai model from hf for embeddings and aws open search with a knn index

Message : Yes Docker Qdrant on cloud Azure AWS that's what I am after
Quoted Message : Quite a few folks run their own Qdrant over Docker, their Discord has some folks working on optim for this too.

Message : i used hf sentence transformer for creating embeddings before worked great
Quoted Message : Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence.

Message : this is the case with most embeddings i would compute embeddings per short paragraphs over pearce blocks of text
Quoted Message : Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence.

Message : you mean chunking the documents right?
Quoted Message : this is the case with most embeddings i would compute embeddings per short paragraphs over pearce blocks of text

Message : Need some suggestions,
My use-case -: I have some documents that I have converted into embeddings and stored in a VectorDB. Now I need to kind of chat which the document or perform some query on top of the document.

What I am doing -: Using MiniLM for embedding and Falcon-7b-Instruct for query purposes.
Question -: Which model should be the right one for this use case, an "instruct" or "chat model".

Message : You want to use one that is better for search.
You can start with minlm and even try coheres embedding and go from there.
Quoted Message : Need some suggestions,\nMy use-case -: I have some documents that I have converted into embeddings and stored in a VectorDB. Now I need to kind of chat which the document or perform some query on top of the document.\n\nWhat I am doing -: Using MiniLM for embedding and Falcon-7b-Instruct for query purposes. \nQuestion -: Which model should be the right one for this use case, an \"instruct\" or \"chat model\".

Message : So search part I can experiment with different models like MiniLM or instructor-xl. But should I go for an "instruct" model or a "chat" model, will that matter much in the performance?
Quoted Message : You want to use one that is better for search.\nYou can start with minlm and even try coheres embedding and go from there.

Message : That won't matter. Quality of the model will matter.
Try with the 7b instruct and go from there
Quoted Message : So search part I can experiment with different models like MiniLM or instructor-xl. But should I go for an \"instruct\" model or a \"chat\" model, will that matter much in the performance?

Message : Also for POC purposes, I am using ChromaDB. Do you suggest trying Weaviate etc? I think the search will differ.
Quoted Message : That won't matter. Quality of the model will matter.\nTry with the 7b instruct and go from there

Message : Weaviate supports hybrid search, which we know from MIRACL and BIER both is better than doing just Vector Similarity
Quoted Message : Also for POC purposes, I am using ChromaDB. Do you suggest trying Weaviate etc? I think the search will differ.

Message : It's also wayyy more performant than Chroma e.g. in RAM usage, QPS etc

Message : üòÇüòÇ

Message : This is for the people have created custom Langchain agents- Can you suggest how to create a Langchain agent for a python library?

I'm trying to understand how pandas langchain agent was created and if this can be replicated for other libraries as well.

Message : Look up Yolo pandas source code
Quoted Message : This is for the people have created custom Langchain agents- Can you suggest how to create a Langchain agent for a python library?\n\nI'm trying to understand how pandas langchain agent was created and if this can be replicated for other libraries as well.

Message : I didn't do it for any lib, but I wrote a custom agent which basically let's llm decide what method or function needs to be called and then hooked a function execution hook.

This custom agent I developed to add Metadata which I didn't want llm to handle.

Also, I learnt this by direct llm communication, then read the agent code which enabled me. And of course promp template and output parsers are also important.

If your usecase is simple agent with tools having input and output strings then you can leverage their decorator. Then focusing on prompt template and output parser is the important part.
Quoted Message : This is for the people have created custom Langchain agents- Can you suggest how to create a Langchain agent for a python library?\n\nI'm trying to understand how pandas langchain agent was created and if this can be replicated for other libraries as well.

Message : >*I wrote a custom agent which basically let's llm decide what method or function needs to be called and then hooked a function execution hook*.

>*This custom agent I developed to add Metadata which I didn't want llm to handle*

hi - could you explain these two points ? these sound interesting, but im not sure how they are intended to work. would love to learn
Quoted Message : I didn't do it for any lib, but I wrote a custom agent which basically let's llm decide what method or function needs to be called and then hooked a function execution hook.\n\nThis custom agent I developed to add Metadata which I didn't want llm to handle. \n\nAlso, I learnt this by direct llm communication, then read the agent code which enabled me. And of course promp template and output parsers are also important.\n\nIf your usecase is simple agent with tools having input and output strings then you can leverage their decorator. Then focusing on prompt template and output parser is the important part.

Message : Loud and clear ü§™
Quoted Message :  2023_06_07_CFD8D57ADA5D0D8B7E6D26EC17C77227.jpeg

Message : is it just me or is the openai completion api throwing more errors than usual today?

Message : yes, for me as well. Had to restructure the entire prompt pipeline to accomodate for the subtle change.

Message : Nirant,
What is miracl and bier
What is their use case
Quoted Message : Weaviate supports hybrid search, which we know from MIRACL and BIER both is better than doing just Vector Similarity

Message : https://github.com/beir-cellar/beir
Quoted Message : Nirant,\nWhat is miracl and bier \nWhat is their use case

Message : https://project-miracl.github.io/

Message : Curious about this - what kind of errors led you to change prompt pipeline?

This isn‚Äôt API outage but something else?
Quoted Message : yes, for me as well. Had to restructure the entire prompt pipeline to accomodate for the subtle change.

Message : I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?

Message : ‚ÄéPOLL:
Do you think LLM apps have no inherent moat?
‚ÄéOPTION: Yes, anyone can build wrapper apps (15 votes)
‚ÄéOPTION: No, there are enough nuances (23 votes)

Message : Ofc i don't agree that llm apps have no inherent (tech) moat.
Quoted Message : I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?

Message : The question isn't about moats around LLMs, it is about building viable businesses using it. I think VCs should probably look at the fundamentals of the business more than just the fact that the team happens to be using LLMs.
Quoted Message : I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?

Message : Yes. But argument is if business fundamentals are built on top of LLMs which have no moat. Anyone can build the business on top of the shiny llm tech

Message : I think at need to define what really a moat is here.

Any tech moat in the world is not really a moat given resources.
Quoted Message : I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?

Message : Does it mean no moat?

Message : Yes. We are talking about inherent product moat i.e. technology moat.
Quoted Message : I think at need to define what really a moat is here.\n\nAny tech moat in the world is not really a moat given resources.

Message : Do you call Google a tech moat or distribution moat?

Message : Defensibility will depend on the nuances of the problem they are solving. In business context. In stickiness with users. In operating model etc.
Quoted Message : Yes. But argument is if business fundamentals are built on top of LLMs which have no moat. Anyone can build the business on top of the shiny llm tech

Message : Also a lot of tech moat is a function of distribution and a lot of distribution moat is a function of tech. ü§∑‚Äç‚ôÇÔ∏è
Quoted Message : Do you call Google a tech moat or distribution moat?

Message : Google had a huge tech moat when they started. It was founders research thesis put to commercial use.
Quoted Message : Do you call Google a tech moat or distribution moat?

Message : I would argue that the presence of a moat is owed to production traction in the market. Does Pytorch have a moat? i'd argue yes. Does Azure or big cloud have a moat? I'd again say yes.
Quoted Message : Also a lot of tech moat is a function of distribution and a lot of distribution moat is a function of tech. ü§∑‚Äç‚ôÇÔ∏è

Message : *product traction in the market (not production traction)

Message : Then you‚Äôre saying moat is temporal too. Fair. 
Then when someone says moat, we have to ask, moat for how long? 1y? 6 months or 5y?
Quoted Message : Google had a huge tech moat when they started. It was founders research thesis put to commercial use.

Message : I don‚Äôt know how PyTorch needs to be evaluated here since it‚Äôs not a for profit business.
Quoted Message : I would argue that the presence of a moat is owed to production traction in the market. Does Pytorch have a moat? i'd argue yes. Does Azure or big cloud have a moat? I'd again say yes.

Message : Agree. It isn't for-profit, not a great example. Perhaps Azure / AWS are better examples
Quoted Message : I don‚Äôt know how PyTorch needs to be evaluated here since it‚Äôs not a for profit business.

Message : Do you think they have a tech moat? Id like to argue they have a distribution or capital moat.
Quoted Message : Agree. It isn't for-profit, not a great example. Perhaps Azure / AWS are better examples

Message : Yep. Absolutely. Now the question becomes if everyone is positioning to increase productivity (more specifically business productivity) what happens to product lifecycle and moat lifecycle. 

It's like when everyone started producing quality content, overall attention span dropped.
Quoted Message : Then you‚Äôre saying moat is temporal too. Fair. \nThen when someone says moat, we have to ask, moat for how long? 1y? 6 months or 5y?

Message : A temporary moat is just a head start. A moat is a long term deterrent to new entrants.
Quoted Message : Then you‚Äôre saying moat is temporal too. Fair. \nThen when someone says moat, we have to ask, moat for how long? 1y? 6 months or 5y?

Message : as a VC actively investing in GenAI I wanted to provide some nuance from the "other side". The idea of moat is critical in building anything because lack thereof over-crowds the market too soon and without perfect knowledge, the capital needed to build a lasting company gets spread out too thin across a large # of "attempts". That said, if your only moat is "building on LLMs" then it's equivalent to when you were in the late 90s and were saying your only moat is "building on the internet". Was it useful -- absolutely; if you were early enough, there were not that many folks building into that ecosystem so you had less competition so "being early was the moat" to capture the users. Did it last, not much. Same happened with mobile or cloud ecosystems -- I remember in 2012 in the valley just how many startups started to put .io in their names to ride the cloud wave. It was def a moat for the early movers but soon everyone caught on. Only those that built lasting values survived and often they weren't the early ones. So if your only moat is being early to LLM waves and the layers above that are too thin / easy to build by others, then I'd say your moat is there but not going to last.
Quoted Message : I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?

Message : Most complete opinion I've read in this chat
Quoted Message : as a VC actively investing in GenAI I wanted to provide some nuance from the \"other side\". The idea of moat is critical in building anything because lack thereof over-crowds the market too soon and without perfect knowledge, the capital needed to build a lasting company gets spread out too thin across a large # of \"attempts\". That said, if your only moat is \"building on LLMs\" then it's equivalent to when you were in the late 90s and were saying your only moat is \"building on the internet\". Was it useful -- absolutely; if you were early enough, there were not that many folks building into that ecosystem so you had less competition so \"being early was the moat\" to capture the users. Did it last, not much. Same happened with mobile or cloud ecosystems -- I remember in 2012 in the valley just how many startups started to put .io in their names to ride the cloud wave. It was def a moat for the early movers but soon everyone caught on. Only those that built lasting values survived and often they weren't the early ones. So if your only moat is being early to LLM waves and the layers above that are too thin / easy to build by others, then I'd say your moat is there but not going to last.

Message : Moats of most large businesses have been on sourcing / distribution in the longer term. Most early technologies will be very easy to replicate (unless proprietary). VCs should be betting on good founders with a long term vision building in a growing market. Just being on an early tech edge is foolish imo.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : *product traction in the market (not production traction)

Message : Then you‚Äôre saying moat is temporal too. Fair. 
Then when someone says moat, we have to ask, moat for how long? 1y? 6 months or 5y?
Quoted Message : Google had a huge tech moat when they started. It was founders research thesis put to commercial use.

Message : I don‚Äôt know how PyTorch needs to be evaluated here since it‚Äôs not a for profit business.
Quoted Message : I would argue that the presence of a moat is owed to production traction in the market. Does Pytorch have a moat? i'd argue yes. Does Azure or big cloud have a moat? I'd again say yes.

Message : Agree. It isn't for-profit, not a great example. Perhaps Azure / AWS are better examples
Quoted Message : I don‚Äôt know how PyTorch needs to be evaluated here since it‚Äôs not a for profit business.

Message : Do you think they have a tech moat? Id like to argue they have a distribution or capital moat.
Quoted Message : Agree. It isn't for-profit, not a great example. Perhaps Azure / AWS are better examples

Message : Yep. Absolutely. Now the question becomes if everyone is positioning to increase productivity (more specifically business productivity) what happens to product lifecycle and moat lifecycle. 

It's like when everyone started producing quality content, overall attention span dropped.
Quoted Message : Then you‚Äôre saying moat is temporal too. Fair. \nThen when someone says moat, we have to ask, moat for how long? 1y? 6 months or 5y?

Message : A temporary moat is just a head start. A moat is a long term deterrent to new entrants.
Quoted Message : Then you‚Äôre saying moat is temporal too. Fair. \nThen when someone says moat, we have to ask, moat for how long? 1y? 6 months or 5y?

Message : as a VC actively investing in GenAI I wanted to provide some nuance from the "other side". The idea of moat is critical in building anything because lack thereof over-crowds the market too soon and without perfect knowledge, the capital needed to build a lasting company gets spread out too thin across a large # of "attempts". That said, if your only moat is "building on LLMs" then it's equivalent to when you were in the late 90s and were saying your only moat is "building on the internet". Was it useful -- absolutely; if you were early enough, there were not that many folks building into that ecosystem so you had less competition so "being early was the moat" to capture the users. Did it last, not much. Same happened with mobile or cloud ecosystems -- I remember in 2012 in the valley just how many startups started to put .io in their names to ride the cloud wave. It was def a moat for the early movers but soon everyone caught on. Only those that built lasting values survived and often they weren't the early ones. So if your only moat is being early to LLM waves and the layers above that are too thin / easy to build by others, then I'd say your moat is there but not going to last.
Quoted Message : I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?

Message : Most complete opinion I've read in this chat
Quoted Message : as a VC actively investing in GenAI I wanted to provide some nuance from the \"other side\". The idea of moat is critical in building anything because lack thereof over-crowds the market too soon and without perfect knowledge, the capital needed to build a lasting company gets spread out too thin across a large # of \"attempts\". That said, if your only moat is \"building on LLMs\" then it's equivalent to when you were in the late 90s and were saying your only moat is \"building on the internet\". Was it useful -- absolutely; if you were early enough, there were not that many folks building into that ecosystem so you had less competition so \"being early was the moat\" to capture the users. Did it last, not much. Same happened with mobile or cloud ecosystems -- I remember in 2012 in the valley just how many startups started to put .io in their names to ride the cloud wave. It was def a moat for the early movers but soon everyone caught on. Only those that built lasting values survived and often they weren't the early ones. So if your only moat is being early to LLM waves and the layers above that are too thin / easy to build by others, then I'd say your moat is there but not going to last.

Message : Moats of most large businesses have been on sourcing / distribution in the longer term. Most early technologies will be very easy to replicate (unless proprietary). VCs should be betting on good founders with a long term vision building in a growing market. Just being on an early tech edge is foolish imo.

Message : I think if you learn how to talk to LLM which is not very steep learning curve then "Anyone can build a wrapper". 

But the question that needs to be considered is what does the app solve? short term - to long term?

Most of the early adopters like you mentioned in the vote might seem like a wrapper app. But in long run if they have a roadmap and vision to leverage to solve a real world problem using llm which scales and usable by anybody seamlessly not knowing what llms are then developers will need to have more than wrapper tech, they will have to build pipeline, hooks and many other tech incorporated.

Message : ‚Äé<attached: 00007489-PHOTO-2023-06-07-17-31-55.jpg>
Quoted Message : as a VC actively investing in GenAI I wanted to provide some nuance from the \"other side\". The idea of moat is critical in building anything because lack thereof over-crowds the market too soon and without perfect knowledge, the capital needed to build a lasting company gets spread out too thin across a large # of \"attempts\". That said, if your only moat is \"building on LLMs\" then it's equivalent to when you were in the late 90s and were saying your only moat is \"building on the internet\". Was it useful -- absolutely; if you were early enough, there were not that many folks building into that ecosystem so you had less competition so \"being early was the moat\" to capture the users. Did it last, not much. Same happened with mobile or cloud ecosystems -- I remember in 2012 in the valley just how many startups started to put .io in their names to ride the cloud wave. It was def a moat for the early movers but soon everyone caught on. Only those that built lasting values survived and often they weren't the early ones. So if your only moat is being early to LLM waves and the layers above that are too thin / easy to build by others, then I'd say your moat is there but not going to last.

Message : As a compute user, I'm also bullish that more large enterprises will see their costs go down by adding self-owned compute to their cloud usage ‚Äî DC design will have to evolve to adapt for this

Message : Intel Bangalore works on Intel Habana Accelerator. We could get someone to talk at one of the events
Quoted Message :  2023_06_07_3EB02EC5948ED187F9197F.jpeg

Message : As someone who has actively worked with global Telcos and around network and data centers.. was in awe of this DC thread from @91931565xxxx earlier today
Quoted Message :  2023_06_07_3EB02EC5948ED187F9197F.jpeg

Message : IMO here are the ways to look for moats in the LLM land (from the tech perspective) as it stands today. 
1. Input Data
a. Proprietary data which no one has
b. Cleanups / dedup / selection etc which no one else knows how to do
c. Tagged data or such which is very valuable
2. Building and operating LLMs
a. Smaller, faster, cheaper
b. Techniques which no one else knows of
c. Custom LLMs which no one else is building
d. Side LLMs (proprietary) which help in better prompting, etc.
3. Integrations
a. More integrations with LLMs than others
b. Smarter integrations which leverage LLMs + some outside tool(s)
4. QA
a. Better QA than anyone else so that you can give more confidence than others about LLM outputs regarding discrimination, jailbreaking/safety, hallucinations, factual responses etc

Happy to hear others' thoughts and add to my list

Message : Amazing. This kind of defines the nuances in a structured way. I can probably add 5th point after QA is - memory management. 

Akin to human intelligence, how well you are able to retrieve old QAs will also define the success.
Quoted Message : IMO here are the ways to look for moats in the LLM land (from the tech perspective) as it stands today. \n1. Input Data\na. Proprietary data which no one has\nb. Cleanups / dedup / selection etc which no one else knows how to do\nc. Tagged data or such which is very valuable\n2. Building and operating LLMs\na. Smaller, faster, cheaper\nb. Techniques which no one else knows of\nc. Custom LLMs which no one else is building\nd. Side LLMs (proprietary) which help in better prompting, etc.\n3. Integrations\na. More integrations with LLMs than others\nb. Smarter integrations which leverage LLMs + some outside tool(s)\n4. QA\na. Better QA than anyone else so that you can give more confidence than others about LLM outputs regarding discrimination, jailbreaking/safety, hallucinations, factual responses etc \n\nHappy to hear others' thoughts and add to my list

Message : My intuition is that LLM API apps have a very limited moat, but apps built atop open-source LLMs with the right amount of messing around will have solid moats.

Message : And some new features/frontiers

Multimodality (Aural and Visual) (Something even OpenAI finds difficult to release enmasse)
Higher context windows (In the scope of 100s of thousands to millions)
(Very useful for better intellisense/code completion)
Pocket LLMs which can run on regular devices like smartphones in an offline/online capacity (Currently being worked on, but very weak)
Multilingual llms
And of course, we have definitely not extinguished prompt engineering techniques which is a main factor in what pushed GPT and LLMs into the front base
Quoted Message : IMO here are the ways to look for moats in the LLM land (from the tech perspective) as it stands today. \n1. Input Data\na. Proprietary data which no one has\nb. Cleanups / dedup / selection etc which no one else knows how to do\nc. Tagged data or such which is very valuable\n2. Building and operating LLMs\na. Smaller, faster, cheaper\nb. Techniques which no one else knows of\nc. Custom LLMs which no one else is building\nd. Side LLMs (proprietary) which help in better prompting, etc.\n3. Integrations\na. More integrations with LLMs than others\nb. Smarter integrations which leverage LLMs + some outside tool(s)\n4. QA\na. Better QA than anyone else so that you can give more confidence than others about LLM outputs regarding discrimination, jailbreaking/safety, hallucinations, factual responses etc \n\nHappy to hear others' thoughts and add to my list

Message : ‚Äé<attached: 00007499-PHOTO-2023-06-07-18-16-42.jpg>

Message : You can watch it live here: https://www.youtube.com/watch?v=AiE7FsdRzz8

Message : personally I'm not convinced that vanilla prompt engineering is a moat. In my mind, prompt engineering is to llm what SEO is to search. You are trying to outsmart others but it's all kinda hacky. Pretty soon, everyone else is also doing it, so you are back to square one. Or (worse) the underlying algorithm changes and all your efforts are gone. There is something to be said about generating prompts intelligently using some proprietary data, feedback or using some other LLMs that can be a lasting moat which I look to capture in (2) (d) in my list. Happy to hear from others
Quoted Message : And some new features/frontiers\n\nMultimodality (Aural and Visual) (Something even OpenAI finds difficult to release enmasse)\nHigher context windows (In the scope of 100s of thousands to millions)\n(Very useful for better intellisense/code completion)\nPocket LLMs which can run on regular devices like smartphones in an offline/online capacity (Currently being worked on, but very weak)\nMultilingual llms\nAnd of course, we have definitely not extinguished prompt engineering techniques which is a main factor in what pushed GPT and LLMs into the front base

Message : What about an autogpt style prompt engineering?

Message : LLMs are like databases.

Databases aren‚Äôt moats. What you do with is a moat.

Message : My long thesis - infrastructure is the model. The pipeline is - including the prompt selection, inference, prompt caching, jsonforming, private data filtering, etc etc.

Message : This would depend heavily on the underlying model itself. If everyone is using the same model, everyone is also going to use same best practices to get functional autoGPT behaviour.
Quoted Message : What about an autogpt style prompt engineering?

Message : It was funny to listen to the questions asked by learned men/founders/VCs to Sam Altman. I mean - Are these the same people giving full time gyaan on all platforms asking some questions to just get noticed or for the sake of asking questions. :/

Message : I think the moat is you throw many things at the wall and see what sticks.
Quoted Message : This would depend heavily on the underlying model itself. If everyone is using the same model, everyone is also going to use same best practices to get functional autoGPT behaviour.

Message : Don't call LLMs databases. I know it might have good recall but this just gives more ammo to people who think all LLMs do is memorize and plagiarize work
Quoted Message : LLMs are like databases.\n\nDatabases aren‚Äôt moats. What you do with is a moat.

Message : Care to share a few examples ?
I know there was an ET TCS event in Delhi today but haven't seen what questions were asked.

But tbh not surprised, amplified version of tech company structures where CEO s(non hands on people), make critical decisions about company strategy and investments without deeply understanding the tech in depth
Quoted Message : It was funny to listen to the questions asked by learned men/founders/VCs to Sam Altman. I mean - Are these the same people giving full time gyaan on all platforms asking some questions to just get noticed or for the sake of asking questions. :/

Message : ‚Äé<attached: 00007513-PHOTO-2023-06-07-19-58-03.jpg>

Message : Disagree. There‚Äôs at least some amount of logic/reasoning which is a game changer. See the Sparks of AGI talk (or paper) https://youtu.be/qbIk7-JPB2c I think most of the wow going ahead is going to be in the reasoning/planning/logic side of things. I don‚Äôt see LLMs replacing databases as such. Again, happy to hear thoughts otherwise
Quoted Message : LLMs are like databases.\n\nDatabases aren‚Äôt moats. What you do with is a moat.

Message : I don‚Äôt mean it in the sense of what databases do, but in the sense of they being infra components
Quoted Message : Disagree. There‚Äôs at least some amount of logic/reasoning which is a game changer. See the Sparks of AGI talk (or paper) https://youtu.be/qbIk7-JPB2c I think most of the wow going ahead is going to be in the reasoning/planning/logic side of things. I don‚Äôt see LLMs replacing databases as such. Again, happy to hear thoughts otherwise

Message : Kunal Shah asked sama a very interesting qn at the ET TCS event today.

‚ÄúWhat has AI taught you about humans?‚Äù

The response was equally interesting. (Paraphrasing, don‚Äôt remember the exact - it‚Äôs an interpretation).

‚ÄúHumans have always imagined themselves to be the center of the universe, and that‚Äôs been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.‚Äù

The last sentence really struck a chord I hadn‚Äôt thought of, ever. Still don‚Äôt know what that means.

Message : The other thing which was cool, and he‚Äôs of course said this many times but it‚Äôs always interesting to hear it again, is that energy and intelligence are two core units of our world, the decreasing costs of which have traditionally driven technology and society forward.

Naturally a reference to helion and his fundamental belief that fusion could create energy sources that are an order of magnitude (or a few) cheaper than energy today.

Message : Btw I hope this is interesting, just thought I‚Äôd share what stood out for the group‚Äôs benefit.

The question that was most well received by Sama (amongst a barrage of other not-the-smartest/kindest questions) was the Fractal founder‚Äôs question.

‚ÄúWhat are the evals you would use to measure AGI, as and when you get there?‚Äù

He didn‚Äôt have a deep answer to it, but was very clear in the belief that the sparks of AGI hypothesis in the MSFT research work is mistaken. GPT4 is nowhere close to AGI, but the question of how to evaluate AGI is the one they are spending the most time thinking about.

Message : That‚Äôs interesting insight
Quoted Message : The other thing which was cool, and he‚Äôs of course said this many times but it‚Äôs always interesting to hear it again, is that energy and intelligence are two core units of our world, the decreasing costs of which have traditionally driven technology and society forward.\n\nNaturally a reference to helion and his fundamental belief that fusion could create energy sources that are an order of magnitude (or a few) cheaper than energy today.

Message : This will make a killing in the Philosophy group!
Quoted Message : Kunal Shah asked sama a very interesting qn at the ET TCS event today.\n\n‚ÄúWhat has AI taught you about humans?‚Äù\n\nThe response was equally interesting. (Paraphrasing, don‚Äôt remember the exact - it‚Äôs an interpretation).\n\n‚ÄúHumans have always imagined themselves to be the center of the universe, and that‚Äôs been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.‚Äù\n\nThe last sentence really struck a chord I hadn‚Äôt thought of, ever. Still don‚Äôt know what that means.

Message : I‚Äôve wondered about the hypothesis of whether empowerment really brings betterment. Lest I get called out that is something to think about. When we build new differentiated capabilities and tech and put it in the hands of people, are we doing the fundamentally right thing? What is the right thing and how would it be decided? These are questions of technology and ethics. One of the old sci-fi shows I liked often saw this kind of theme and it makes you think about whether capitalism combined with a scientific / technological industrial complex produces more inequality and overall more downsides than upsides.

Message : This is probably a post for the philosophy group though. Sorry to have posted here
Quoted Message : I‚Äôve wondered about the hypothesis of whether empowerment really brings betterment. Lest I get called out that is something to think about. When we build new differentiated capabilities and tech and put it in the hands of people, are we doing the fundamentally right thing? What is the right thing and how would it be decided? These are questions of technology and ethics. One of the old sci-fi shows I liked often saw this kind of theme and it makes you think about whether capitalism combined with a scientific / technological industrial complex produces more inequality and overall more downsides than upsides.

Message : AI, Policy and Philosophy group link for reference: 
https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Quoted Message : This is probably a post for the philosophy group though. Sorry to have posted here

Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.

Airbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.
Quoted Message : LLMs are like databases.\n\nDatabases aren‚Äôt moats. What you do with is a moat.

Message : Pratik worries so much about ads, it adds up to ads
Quoted Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.\n\nAirbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.

Message : Marketing matters. Atleast in gen AI space. The amount of people who said retrieval qa is training on your data to sell

Message : Today Sam compared GPT4 to the old Nokia brick phones and said GPT15 will be very different and we won't remember GPT4. Just FYI. 

I wanted to say this here since we all need to think about how all this will change in one two three years. Though the tools we use are today's.

Message : Strange. Is he making a case that intelligence can't be substrate independent?
Quoted Message : Kunal Shah asked sama a very interesting qn at the ET TCS event today.\n\n‚ÄúWhat has AI taught you about humans?‚Äù\n\nThe response was equally interesting. (Paraphrasing, don‚Äôt remember the exact - it‚Äôs an interpretation).\n\n‚ÄúHumans have always imagined themselves to be the center of the universe, and that‚Äôs been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.‚Äù\n\nThe last sentence really struck a chord I hadn‚Äôt thought of, ever. Still don‚Äôt know what that means.

Message : I tbh found that question bit rhetorical. Like kunal already has an answer in his mind and he wants to validate his point of view. Also, what sama answered was equally interesting. üò¨
Quoted Message : Kunal Shah asked sama a very interesting qn at the ET TCS event today.\n\n‚ÄúWhat has AI taught you about humans?‚Äù\n\nThe response was equally interesting. (Paraphrasing, don‚Äôt remember the exact - it‚Äôs an interpretation).\n\n‚ÄúHumans have always imagined themselves to be the center of the universe, and that‚Äôs been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.‚Äù\n\nThe last sentence really struck a chord I hadn‚Äôt thought of, ever. Still don‚Äôt know what that means.

Message : ‚Äé<attached: 00007530-PHOTO-2023-06-07-20-57-05.jpg>
Quoted Message : Marketing matters. Atleast in gen AI space. The amount of people who said retrieval qa is training on your data to sell

Message : The Gujarati in me thinks this is fair game, the engineer in me thinks this is blasphemy. The net result is I've not made anywhere close to the money this person has made from git cloning langchain docs
Quoted Message :  2023_06_07_3A7D571B750F2A1DD9EB.jpeg

Message : Something I know by talking with one of the founder is many of them actually tried training davinci on docs and failed and then they came to know RAG works better
Quoted Message :  2023_06_07_3A7D571B750F2A1DD9EB.jpeg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : AI, Policy and Philosophy group link for reference: 
https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Quoted Message : This is probably a post for the philosophy group though. Sorry to have posted here

Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.

Airbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.
Quoted Message : LLMs are like databases.\n\nDatabases aren‚Äôt moats. What you do with is a moat.

Message : Pratik worries so much about ads, it adds up to ads
Quoted Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.\n\nAirbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.

Message : Marketing matters. Atleast in gen AI space. The amount of people who said retrieval qa is training on your data to sell

Message : Today Sam compared GPT4 to the old Nokia brick phones and said GPT15 will be very different and we won't remember GPT4. Just FYI. 

I wanted to say this here since we all need to think about how all this will change in one two three years. Though the tools we use are today's.

Message : Strange. Is he making a case that intelligence can't be substrate independent?
Quoted Message : Kunal Shah asked sama a very interesting qn at the ET TCS event today.\n\n‚ÄúWhat has AI taught you about humans?‚Äù\n\nThe response was equally interesting. (Paraphrasing, don‚Äôt remember the exact - it‚Äôs an interpretation).\n\n‚ÄúHumans have always imagined themselves to be the center of the universe, and that‚Äôs been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.‚Äù\n\nThe last sentence really struck a chord I hadn‚Äôt thought of, ever. Still don‚Äôt know what that means.

Message : I tbh found that question bit rhetorical. Like kunal already has an answer in his mind and he wants to validate his point of view. Also, what sama answered was equally interesting. üò¨
Quoted Message : Kunal Shah asked sama a very interesting qn at the ET TCS event today.\n\n‚ÄúWhat has AI taught you about humans?‚Äù\n\nThe response was equally interesting. (Paraphrasing, don‚Äôt remember the exact - it‚Äôs an interpretation).\n\n‚ÄúHumans have always imagined themselves to be the center of the universe, and that‚Äôs been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.‚Äù\n\nThe last sentence really struck a chord I hadn‚Äôt thought of, ever. Still don‚Äôt know what that means.

Message : ‚Äé<attached: 00007530-PHOTO-2023-06-07-20-57-05.jpg>
Quoted Message : Marketing matters. Atleast in gen AI space. The amount of people who said retrieval qa is training on your data to sell

Message : The Gujarati in me thinks this is fair game, the engineer in me thinks this is blasphemy. The net result is I've not made anywhere close to the money this person has made from git cloning langchain docs
Quoted Message :  2023_06_07_3A7D571B750F2A1DD9EB.jpeg

Message : Something I know by talking with one of the founder is many of them actually tried training davinci on docs and failed and then they came to know RAG works better
Quoted Message :  2023_06_07_3A7D571B750F2A1DD9EB.jpeg

Message : What‚Äôs his MRR?
Quoted Message : The Gujarati in me thinks this is fair game, the engineer in me thinks this is blasphemy. The net result is I've not made anywhere close to the money this person has made from git cloning langchain docs

Message : And more people ask Tanmay Bhatt and Varun Mayya questions about AI than you or me @91989227xxxx bhai ‚Äî so clearly, distribution wins over knowledge. Everywhere.

Message : It was 60k last month.
Quoted Message : What‚Äôs his MRR?

Message : Yes, who asks Wes Mckinney about Pandas for example - poor guy probably is busy building away and being ignored. And this is also the reason why Bernard Marr's articles on AI are everywhere üòÖ
Quoted Message : And more people ask Tanmay Bhatt and Varun Mayya questions about AI than you or me @9198xxxxxxxx bhai ‚Äî so clearly, distribution wins over knowledge. Everywhere.

Message : Good for them!
Quoted Message : And more people ask Tanmay Bhatt and Varun Mayya questions about AI than you or me @9198xxxxxxxx bhai ‚Äî so clearly, distribution wins over knowledge. Everywhere.

Message : That‚Äôs why I want to learn frontend. AI is looking a weak part of my own moat now
Quoted Message : And more people ask Tanmay Bhatt and Varun Mayya questions about AI than you or me @9198xxxxxxxx bhai ‚Äî so clearly, distribution wins over knowledge. Everywhere.

Message : @91630952xxxx se seekho
Quoted Message : That‚Äôs why I want to learn frontend. AI is looking a weak part of my own moat now

Message : We've had this convo. And we've digressed quite a bit from the topic :)
Quoted Message : @9163xxxxxxxx se seekho

Message : Context window se baahar ho gaya

Message : Need a vector db for my brain

Message : My motivation is that if my AI SaaS apps fail or I get bored in a few years, I wanna be atleast the most eligible CTO in the market üòÖ
Quoted Message : @9163xxxxxxxx se seekho

Message : I think this becomes more important now that our jobs are starting to come in the line
Quoted Message : My motivation is that if my AI SaaS apps fail or I get bored in a few years, I wanna be atleast the most eligible CTO in the market üòÖ

Message : Deepmind trained alphazero style (SoTA models on Go, Chess and Shogi) Reinforcement Learning agents to find faster algorithms for sorting and hashing. In this algorithm finding game, their state was assembly instructions selected till now and information in registers and action was the next instruction to add to the algorithm. This problem will be as complex as playing chess or Go and the algorithm for sorting discovered by AlphaDev is 70% faster for shorter sequences and 1.7% faster for long (>250,000) sequences. https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms

Message : https://www.youtube.com/live/AiE7FsdRzz8?feature=share

55:00 onwards
Quoted Message : Kunal Shah asked sama a very interesting qn at the ET TCS event today.\n\n‚ÄúWhat has AI taught you about humans?‚Äù\n\nThe response was equally interesting. (Paraphrasing, don‚Äôt remember the exact - it‚Äôs an interpretation).\n\n‚ÄúHumans have always imagined themselves to be the center of the universe, and that‚Äôs been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.‚Äù\n\nThe last sentence really struck a chord I hadn‚Äôt thought of, ever. Still don‚Äôt know what that means.

Message : Also feel there's a bit of an over indexation on moats. It makes perfect sense for VCs - their business model is to search for an outlier co, a 100xer that has strong defensibility

That being said, we also saw extraordinarily successful and profitable ludo and crossword apps that came early on, and ones afterwards that overtook them

Basically, tons of tiny opportunities to make hay while the sun is evaporating your moat
Quoted Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.\n\nAirbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.

Message : Fair plan
Quoted Message : My motivation is that if my AI SaaS apps fail or I get bored in a few years, I wanna be atleast the most eligible CTO in the market üòÖ

Message : What happens when we deliver the same experience on a platform which provides many more opportunities to deliver value, is that new experiences overtake the ones we initially port to it. We see this pattern with other games too - we ported pong to a digital medium, but soon discovered asteroids can be a more fun game, and we could never have devised an asteroids game or a bricks game and its mechanisms in real life
Quoted Message : Also feel there's a bit of an over indexation on moats. It makes perfect sense for VCs - their business model is to search for an outlier co, a 100xer that has strong defensibility\n\nThat being said, we also saw extraordinarily successful and profitable ludo and crossword apps that came early on, and ones afterwards that overtook them\n\nBasically, tons of tiny opportunities to make hay while the sun is evaporating your moat

Message : The same thing will happen with AI - we build solutions to real world problems with AI techniques, only to discover that there is a set of impactful AI specific capabilities that can drive even more value from AI than the ones we set out to solve. And these couldn't have been solved without the AI

Message : Just a take from side for the sake of an argument: Distribution and knowledge both are leverage of their own kind. They both also lose their value when your competitors have access to the same level of distribution or same level of Knowledge. 

However, I'm well aware that the level of knowledge to distinguish oneself on the same level is going to be very high, distribution might be more accessible via marketing/networking.
Quoted Message : And more people ask Tanmay Bhatt and Varun Mayya questions about AI than you or me @9198xxxxxxxx bhai ‚Äî so clearly, distribution wins over knowledge. Everywhere.

Message : This is true. There has to be a term to describe the asymmetrical success of bullshitting.
Quoted Message : Just a take from side for the sake of an argument: Distribution and knowledge both are leverage of their own kind. They both also lose their value when your competitors have access to the same level of distribution or same level of Knowledge. \n\nHowever, I'm well aware that the level of knowledge to distinguish oneself on the same level is going to be very high, distribution might be more accessible via marketing/networking.

Message : Brandolini's law ü§£
Quoted Message : This is true. There has to be a term to describe the asymmetrical success of bullshitting.

Message : TIL https://en.wikipedia.org/wiki/Brandolini%27s_law
Quoted Message : Brandolini's law ü§£

Message : Idea for metaverse room - where Brandolini's law and Hanlon's razor meet

Message : Indeed. That's a great example. Using the same analogy, it's probably a good idea to start making pong, even if others are as well. You'll probably discover the idea of asteroids along the way

At which point, you'll have the knowledge of how to make a paddle, and how to model the physics of a ball bouncing off it
Quoted Message : The same thing will happen with AI - we build solutions to real world problems with AI techniques, only to discover that there is a set of impactful AI specific capabilities that can drive even more value from AI than the ones we set out to solve. And these couldn't have been solved without the AI

Message : This is why AI-native startups (starting now) have a different kind of advantage over existing incumbents (who have distribution advantage)
Quoted Message : What happens when we deliver the same experience on a platform which provides many more opportunities to deliver value, is that new experiences overtake the ones we initially port to it. We see this pattern with other games too - we ported pong to a digital medium, but soon discovered asteroids can be a more fun game, and we could never have devised an asteroids game or a bricks game and its mechanisms in real life

Message : How to change pose of a person keeping identity constant, like i wanna take a source image, just change the direction in which a person is looking and regenerate the image

Message : Can anyone give a tl;dr of Sam Altman's Econ Times talk? Or the most interesting bits?

Message : Or is it worth watching in full? (had planned to watch but randomly saw Prasoon Joshi in the audience so kinda depriortized it abhi)
Quoted Message : Can anyone give a tl;dr of Sam Altman's Econ Times talk? Or the most interesting bits?

Message : Lol
Quoted Message : Or is it worth watching in full? (had planned to watch but randomly saw Prasoon Joshi in the audience so kinda depriortized it abhi)

Message : LLMs outperform RL at game play by studying papers and reasoning through chain-of-thought. 

https://arxiv.org/pdf/2305.15486.pdf

Message : New open source text to video model: potat 1 by camenduru


https://twitter.com/camenduru/status/1665635019790876673?t=Z9JEG19jpvf-5s8d3kvBbw&s=19

Message : came across this via LiverDoc's thread?
Quoted Message : Brandolini's law ü§£

Message : Ya he's been on a crusade against fitness influencers recently
Quoted Message : came across this via LiverDoc's thread?

Message : ‚Äé<attached: 00007566-PHOTO-2023-06-07-22-21-49.jpg>
Quoted Message : This is true. There has to be a term to describe the asymmetrical success of bullshitting.

Message : @91914857xxxx - two questions from this, when I load the dataset via HF, the feature order is reversed (answer, question), was it same with you?

When I generate text post fine-tuning, it produces the answer and then the assistant starts another round of QnA by itself until the max tokens are reached. How does it know when to stop without reaching max limit?
Quoted Message : yep I have tried it \nbut you will have to follow a video\nhttps://youtu.be/DcBC4yGHV4Q\nhe hasnt linked the notebook tho

Message : Complex Product processes can be moats as well.
Quoted Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.\n\nAirbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.

Message : Doing complex and boring things are great moats!
Quoted Message : Complex Product processes can be moats as well.

Message : Using RL to improve sorting algorithms

https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms

Also what do folks think of this :
Nature has a policy that all code must be released from papers - but apparently Deep Mind has released the "pseudocode" for the algorithm instead of reproducible code. Interesting how AI companies are can balance competitive advantage while still getting high impact pubs
(https://twitter.com/andrewwhite01/status/1666494856212930561?s=46&t=pt9BgXoRTmqx5FEPyAl9bg)

Message : This is scary and exciting at the same time. Alphadev could next discover the best possible compression algorithm, graph traversal algorithms and humans would start completing relying on alphadev like AIs.
Quoted Message : Deepmind trained alphazero style (SoTA models on Go, Chess and Shogi) Reinforcement Learning agents to find faster algorithms for sorting and hashing. In this algorithm finding game, their state was assembly instructions selected till now and information in registers and action was the next instruction to add to the algorithm. This problem will be as complex as playing chess or Go and the algorithm for sorting discovered by AlphaDev is 70% faster for shorter sequences and 1.7% faster for long (>250,000) sequences. https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms

Message : These algorithms have been integrated in llvm c++ sort library replacing previous known human benchmarks.
Quoted Message : Using RL to improve sorting algorithms\n\nhttps://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms\n\nAlso what do folks think of this :\nNature has a policy that all code must be released from papers - but apparently Deep Mind has released the \"pseudocode\" for the algorithm instead of reproducible code. Interesting how AI companies are can balance competitive advantage while still getting high impact pubs \n(https://twitter.com/andrewwhite01/status/1666494856212930561?s=46&t=pt9BgXoRTmqx5FEPyAl9bg)


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : New open source text to video model: potat 1 by camenduru


https://twitter.com/camenduru/status/1665635019790876673?t=Z9JEG19jpvf-5s8d3kvBbw&s=19

Message : came across this via LiverDoc's thread?
Quoted Message : Brandolini's law ü§£

Message : Ya he's been on a crusade against fitness influencers recently
Quoted Message : came across this via LiverDoc's thread?

Message : ‚Äé<attached: 00007566-PHOTO-2023-06-07-22-21-49.jpg>
Quoted Message : This is true. There has to be a term to describe the asymmetrical success of bullshitting.

Message : @91914857xxxx - two questions from this, when I load the dataset via HF, the feature order is reversed (answer, question), was it same with you?

When I generate text post fine-tuning, it produces the answer and then the assistant starts another round of QnA by itself until the max tokens are reached. How does it know when to stop without reaching max limit?
Quoted Message : yep I have tried it \nbut you will have to follow a video\nhttps://youtu.be/DcBC4yGHV4Q\nhe hasnt linked the notebook tho

Message : Complex Product processes can be moats as well.
Quoted Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.\n\nAirbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.

Message : Doing complex and boring things are great moats!
Quoted Message : Complex Product processes can be moats as well.

Message : Using RL to improve sorting algorithms

https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms

Also what do folks think of this :
Nature has a policy that all code must be released from papers - but apparently Deep Mind has released the "pseudocode" for the algorithm instead of reproducible code. Interesting how AI companies are can balance competitive advantage while still getting high impact pubs
(https://twitter.com/andrewwhite01/status/1666494856212930561?s=46&t=pt9BgXoRTmqx5FEPyAl9bg)

Message : This is scary and exciting at the same time. Alphadev could next discover the best possible compression algorithm, graph traversal algorithms and humans would start completing relying on alphadev like AIs.
Quoted Message : Deepmind trained alphazero style (SoTA models on Go, Chess and Shogi) Reinforcement Learning agents to find faster algorithms for sorting and hashing. In this algorithm finding game, their state was assembly instructions selected till now and information in registers and action was the next instruction to add to the algorithm. This problem will be as complex as playing chess or Go and the algorithm for sorting discovered by AlphaDev is 70% faster for shorter sequences and 1.7% faster for long (>250,000) sequences. https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms

Message : These algorithms have been integrated in llvm c++ sort library replacing previous known human benchmarks.
Quoted Message : Using RL to improve sorting algorithms\n\nhttps://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms\n\nAlso what do folks think of this :\nNature has a policy that all code must be released from papers - but apparently Deep Mind has released the \"pseudocode\" for the algorithm instead of reproducible code. Interesting how AI companies are can balance competitive advantage while still getting high impact pubs \n(https://twitter.com/andrewwhite01/status/1666494856212930561?s=46&t=pt9BgXoRTmqx5FEPyAl9bg)

Message : The policy is ‚ÄúAuthors must make available upon request, to editors and reviewers, any previously unreported custom computer code or algorithm used to generate results that are reported in the paper and central to its main claims.‚Äù Deepmind has a history of publishing in nature (since DQN paper in 2015) and they have never shared source code .
Quoted Message : Using RL to improve sorting algorithms\n\nhttps://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms\n\nAlso what do folks think of this :\nNature has a policy that all code must be released from papers - but apparently Deep Mind has released the \"pseudocode\" for the algorithm instead of reproducible code. Interesting how AI companies are can balance competitive advantage while still getting high impact pubs \n(https://twitter.com/andrewwhite01/status/1666494856212930561?s=46&t=pt9BgXoRTmqx5FEPyAl9bg)

Message : Checkpoints for Openllama - anyone tried it yet?
https://huggingface.co/openlm-research/open_llama_7b?text=My+name+is+Merve+and+my+favorite

Message : Got an extra ticket for a friend for tomorrow‚Äôs sam altman chat happening in iiit delhi. DM if anyone‚Äôs interested in getting one.

Message : Reminds me of Saurabh Mukherjea‚Äôs article on forming moats (@91773788xxxx don‚Äôt hate me for mentioning him)

https://marcellus.in/blogs/the-antifragility-test-applied-to-consistent-compounders/
Quoted Message : I have another opinion. Moat is the sum of all advantages. So model also ads to moat.\n\nAirbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.

Message : Hi all

We got this from Anthropic:

"Unfortunately, based on the information you've provided we cannot approve your current use of Claude for commercial purposes at this time due to risk of exploitability. We are continuously working on improving our model's safety and capabilities, and hope that we will have a more robust system for responsibly managing the risk of uses like these in the near future. Best, Landon Trust and Safety Team Anthropic"

Do people have access to Claude API for commercial use? Or someone else who has been denied on similar grounds?

Message : They've shared implementation as llvm already integrated this in STD c++ sort library.

Here's the code review link of the same in llvm source - https://reviews.llvm.org/D118029
Quoted Message : The policy is ‚ÄúAuthors must make available upon request, to editors and reviewers, any previously unreported custom computer code or algorithm used to generate results that are reported in the paper and central to its main claims.‚Äù Deepmind has a history of publishing in nature (since DQN paper in 2015) and they have never shared source code .

Message : They shared C++ implementation of the sorting algorithm discovered by AlphaDev. But they haven‚Äôt shared code of training AlphaDev.
Quoted Message : They've shared implementation as llvm already integrated this in STD c++ sort library.\n\nHere's the code review link of the same in llvm source - https://reviews.llvm.org/D118029

Message : But deepmind usually doesn‚Äôt open source their code at all..Meta comes in and builds an open source version of deepmind papers.

Message : Ohh ok. Misunderstood the reference.
Quoted Message : They shared C++ implementation of the sorting algorithm discovered by AlphaDev. But they haven‚Äôt shared code of training AlphaDev.

Message : Yes true.
Quoted Message : But deepmind usually doesn‚Äôt open source their code at all..Meta comes in and builds an open source version of deepmind papers.

Message : We have. They actually asked lots of detailed questions multiple times and it seemed like the quality of the response matters to them.

So maybe reapply with detailed, through answers.
Quoted Message : Hi all\n\nWe got this from Anthropic:\n\n\"Unfortunately, based on the information you've provided we cannot approve your current use of Claude for commercial purposes at this time due to risk of exploitability. We are continuously working on improving our model's safety and capabilities, and hope that we will have a more robust system for responsibly managing the risk of uses like these in the near future. Best, Landon Trust and Safety Team Anthropic\"\n\nDo people have access to Claude API for commercial use? Or someone else who has been denied on similar grounds?

Message : Thank you - might DM you for more information but will reapply for now.
Quoted Message : We have. They actually asked lots of detailed questions multiple times and it seemed like the quality of the response matters to them.\n\nSo maybe reapply with detailed, through answers.

Message : I've been trying to get access to Claude 100k for hobbyist experiments and couldn't get it even after trying twice. 

Don't know what's the secret sauce they need in the answers. Probably need to write that I'll be solving world hunger or something via their api.
Quoted Message : We have. They actually asked lots of detailed questions multiple times and it seemed like the quality of the response matters to them.\n\nSo maybe reapply with detailed, through answers.

Message : We just gave them our use case and how we plan to use it. It was a technical answer
Quoted Message : I've been trying to get access to Claude 100k for hobbyist experiments and couldn't get it even after trying twice. \n\nDon't know what's the secret sauce they need in the answers. Probably need to write that I'll be solving world hunger or something via their api.

Message : What's the usual time they take to assess your application? Might need to brute force this one with multiple answers. Knowing how long should I wait before trying again would help.

Message : Can someone tell me how ```FAISS``` is better than a custom nearest neighbor classifier that one can build in Python, i.e., say using scikitlearn‚Äôs ```KNNClassifier```?

Message : I'm obscuring a few details for shorter answer - FAISS is awesome. They employ a bunch of techniques.

Basically optimal data structures, indexing, parallelism via CPU, GPU, optimal low level code implementations and leveraging efficient Lin algebra lib like BLAS
Quoted Message : Can someone tell me how ```FAISS``` is better than a custom nearest neighbor classifier that one can build in Python, i.e., say using scikitlearn‚Äôs ```KNNClassifier```?

Message : Kind of like they went ahead and decided to improve SOTA block for each and everything in the pipeline for nearest neighbour similarity search and clustering.

Message : So does it only improve scalability, or are there minute advancements in the underlying algorithm as well, i.e., in terms of complexity?

Message : 1. It's not better in algo. It's better in performance. FAISS is fairly hand tuned.

2. FAISS comes with many algorithms that are battle tested like HNSW. U can choose between them to do an algorithm comparison.
Quoted Message : Can someone tell me how ```FAISS``` is better than a custom nearest neighbor classifier that one can build in Python, i.e., say using scikitlearn‚Äôs ```KNNClassifier```?

Message : Mostly under the hood optimisations in the pipeline. 

If you're interested in thorough benchmarks here is a good benchmarking for recall per query per second.


Reference - https://ann-benchmarks.com/
Quoted Message : So does it only improve scalability, or are there minute advancements in the underlying algorithm as well, i.e., in terms of complexity?

Message : And their really meticulously maintained GitHub repo with test suite for ann benchmarking you can try yourself - https://github.com/erikbern/ann-benchmarks/

Message : What is the definition of ```recall``` ?
Quoted Message : Mostly under the hood optimisations in the pipeline. \n\nIf you're interested in thorough benchmarks here is a good benchmarking for recall per query per second.\n\n\nReference - https://ann-benchmarks.com/

Message : in this context
#relevant/#everything that was fetched
Quoted Message : What is the definition of ```recall``` ?

Message : thank you very much

Message : https://twitter.com/albtaiuti/status/1666464784995459074?s=48&t=dSB_vXgXsC6qhF1TYEKlZw

Message : GM fam, does anyone know of any test to determine consciousness of a system ? OpenAI claims that chatgpt4 isnt conscious, but how can they be certain if a future version of chatGPT is or isn't conscious .

Message : This is perhaps best answered and discussed in the philosophy group of the community.
Quoted Message : GM fam, does anyone know of any test to determine consciousness of a system ? OpenAI claims that chatgpt4 isnt conscious, but how can they be certain if a future version of chatGPT is or isn't conscious .

Message : Good morning folks. Any laptop recommendations for text based LMs/NLP work? Cheaper the better, other functionalities irrelevant.

Message : Do you want to train ML on laptop or just do basic work on it and use VM for training?
Quoted Message : Good morning folks. Any laptop recommendations for text based LMs/NLP work? Cheaper the better, other functionalities irrelevant.

Message : What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?

Message : https://twitter.com/RajanAnandan/status/1666641010284449792?s=20

Message : #truth 

Just gotta keep trying.

But one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models.

We don't lack talent or money. But coordinated efforts over long periods without any in-between "payouts" still seems a luxury for us.

And it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.
Quoted Message : https://twitter.com/RajanAnandan/status/1666641010284449792?s=20

Message : same question 
any tutorial for deployment?
Quoted Message : What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?

Message : Train on laptop, yes.
Quoted Message : Do you want to train ML on laptop or just do basic work on it and use VM for training?

Message : Sam had his Tony stark moment. ü§∑üèª‚Äç‚ôÇÔ∏è
Quoted Message : https://twitter.com/RajanAnandan/status/1666641010284449792?s=20

Message : But didn't like his shrewdness.

Message : Good that Rajan sir took it sportingly. We shouldn't stop trying.

Message : I'd say invest then
Quoted Message : Train on laptop, yes.

Message : Razer blade is really sleek


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?

Message : https://twitter.com/RajanAnandan/status/1666641010284449792?s=20

Message : #truth 

Just gotta keep trying.

But one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models.

We don't lack talent or money. But coordinated efforts over long periods without any in-between "payouts" still seems a luxury for us.

And it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.
Quoted Message : https://twitter.com/RajanAnandan/status/1666641010284449792?s=20

Message : same question 
any tutorial for deployment?
Quoted Message : What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?

Message : Train on laptop, yes.
Quoted Message : Do you want to train ML on laptop or just do basic work on it and use VM for training?

Message : Sam had his Tony stark moment. ü§∑üèª‚Äç‚ôÇÔ∏è
Quoted Message : https://twitter.com/RajanAnandan/status/1666641010284449792?s=20

Message : But didn't like his shrewdness.

Message : Good that Rajan sir took it sportingly. We shouldn't stop trying.

Message : I'd say invest then
Quoted Message : Train on laptop, yes.

Message : Razer blade is really sleek

Message : Top class build quality. Latest model is ryzen 6900 with Nvidia 3080 gpu

Message : What‚Äôs wrong with what he says?

Companies end up specialising ultimately
Quoted Message : https://twitter.com/RajanAnandan/status/1666641010284449792?s=20

Message : If you don't want to get into Macs, it's the best

Message : I also would recommend the Asus rog x13 or z13

Message : Or even the G series

Message : But these are very sleek, very portable and powerful
Quoted Message : I also would recommend the Asus rog x13 or z13

Message : Most of my college folks use alienware gaming laptops for ML training because of high configuration.  
I would recommend desktop over gaming laptops for these reasons
a. Most ML folks are concerned about RAM and GPU size (GBs) not too much on speed like MHz, FLOPS (tradeoff can save a lot of money).
b. Its easy to upgrade a hardware in desktop, laptops are not that friendly.
c. Cooling systems are effective in desktop, Laptops heat up a lot after 8-10 hours of training.
d. Need not spend much on faster display, better keyword etc.
Quoted Message : Train on laptop, yes.

Message : Will check it out üëçüèΩüëçüèΩ
Quoted Message : Top class build quality. Latest model is ryzen 6900 with Nvidia 3080 gpu

Message : Friends, I think we've discussed laptops/personal compute quite often here -- and this forum isn't uniquely the best places for that. The wider web has more than enough answers which address ML specific needs. 

Please respond to the asker directly :)

Message : Thanks, this is super useful üòä
Quoted Message : Most of my college folks use alienware gaming laptops for ML training because of high configuration.  \nI would recommend desktop over gaming laptops for these reasons\na. Most ML folks are concerned about RAM and GPU size (GBs) not too much on speed like MHz, FLOPS (tradeoff can save a lot of money).\nb. Its easy to upgrade a hardware in desktop, laptops are not that friendly.\nc. Cooling systems are effective in desktop, Laptops heat up a lot after 8-10 hours of training.\nd. Need not spend much on faster display, better keyword etc.

Message : https://twitter.com/goodside/status/1666598580319035392?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Trust Riley goodside to come up with hacks on gpt

Message : These are called "Glitch Tokens" and a well known artefact of all token-based LLMs, dating back to embeddings themselves: https://www.youtube.com/watch?v=WO2X3oZEJOA&t=224s

Message : https://twitter.com/TheEthanDing/status/1666109071278104578

what do u folks think ? especially people who have worked with langchain, etc.

Message : I just read Llama index raised 8.5m
Quoted Message : https://twitter.com/TheEthanDing/status/1666109071278104578\n\nwhat do u folks think ? especially people who have worked with langchain, etc.

Message : In all my discussions with Google and Microsoft, they have been saying they are using langchain for their work

Message : I am terribly sad that Langchain and Pinecone are not listed companies, I'd have made a killing shorting them
Quoted Message : https://twitter.com/TheEthanDing/status/1666109071278104578\n\nwhat do u folks think ? especially people who have worked with langchain, etc.

Message : Microsoft has something of their own as well, semantic kernel  IIRC

Message : So in the long term definitely we will have better platforms built. But as of today this we what most folks use

Message : https://github.com/microsoft/semantic-kernel
Quoted Message : Microsoft has something of their own as well, semantic kernel  IIRC

Message : But that's part of any new tech evolution, right?

Message : If you notice the folks Llama has been hiring, they're not a thin client which most folks are thinking about them. They're definitely looking to integrate backwards in the _same spirit_ as Ethan bhaiya said
Quoted Message : I just read Llama index raised 8.5m

Message : Looking at their work, they seem to be building towards having all types of data sources integrated with LLMs. It's a smart move as that is cumbersome. Moat like
Quoted Message : If you notice the folks Llama has been hiring, they're not a thin client which most folks are thinking about them. They're definitely looking to integrate backwards in the _same spirit_ as Ethan bhaiya said

Message : Llama index has more potential than Langchain as a company

Message : Man, you realize the impact of open source contributions when you see the growth of such products

Message : This is the very question I asked Jerry, how are you coming up with few strategies and features atm? He was like it‚Äôs all open source man

Message : The community is driving it

Message : new strategies*

Message : Where is the +1000 emoji when I need it
Quoted Message : This is the very question I asked Jerry, how are you coming up with few strategies and features atm? He was like it‚Äôs all open source man

Message : I know someone at the HF0 Residency is building a framework for creating Agents. He has a lot of credibility

Message : Langchain, llamaindex have positioning as hubs of all activity around LLMs, all new stuff like babyAGI, autoGPT, privategpt got sucked really fast into the langchain ecosystem.

Message : As a point of comparison: You can also see Langchain team actively just ignoring issues and PRs both.
Quoted Message : This is the very question I asked Jerry, how are you coming up with few strategies and features atm? He was like it‚Äôs all open source man

Message : Our boy is maybe too busy with developer advocacy haha
Quoted Message : As a point of comparison: You can also see Langchain team actively just ignoring issues and PRs both.

Message : To this point, since I just moved from a ML/ Data Scientist role to a VC role, one of the things I wanted to do is contribute back to the community. (I literally owe my career to them). 
We are trying to fund a small number of open source projects. You can refer to this tweet. Ofcourse it will be nowhere near to what you would need to create a top library/model, but I hope it helps projects get off the ground -

https://twitter.com/brijbhasin/status/1666663734385979392?s=20
Quoted Message : #truth \n\nJust gotta keep trying. \n\nBut one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models. \n\nWe don't lack talent or money. But coordinated efforts over long periods without any in-between \"payouts\" still seems a luxury for us. \n\nAnd it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.

Message : How exactly?
Quoted Message : Llama index has more potential than Langchain as a company

Message : I think VCs should try and support research based firms. I can understand their desire for investing in money making engines. But in order to have an Indian deepmind or an Indian openAI investors should soften themselves up towards startups that are in search for new models, that are in search for new training methods.

OpenAI and deepmind didn't start out as "businesses", they started out as research factories. But now they're in a position to monetize their research, which is their moat.

Maybe my view is biased because of only coming across funding rounds for fancy wrapper firms, and not for the boring research firms. But this has been my observation so far.
Quoted Message : #truth \n\nJust gotta keep trying. \n\nBut one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models. \n\nWe don't lack talent or money. But coordinated efforts over long periods without any in-between \"payouts\" still seems a luxury for us. \n\nAnd it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.

Message : Curious - how much do these cost? And what kind of investment in terms of time, money, and human resource we're looking at here?
Quoted Message : #truth \n\nJust gotta keep trying. \n\nBut one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models. \n\nWe don't lack talent or money. But coordinated efforts over long periods without any in-between \"payouts\" still seems a luxury for us. \n\nAnd it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.

Message : Amjad Massad of replit is always on point with his wit !
https://twitter.com/amasad/status/1666690663587680257

Message : True. Throwing 10M is not to going to create another OpenAI. Also, I talked about this thing two days back that we haven‚Äôt even seen fine tuned Llama, like Teknium is training, from India, which will cost 2-3k. Because India is not focused on indie hacking, taking a deep problem heads on, but everyone wants to build quick tool to raise money.
Quoted Message : I think VCs should try and support research based firms. I can understand their desire for investing in money making engines. But in order to have an Indian deepmind or an Indian openAI investors should soften themselves up towards startups that are in search for new models, that are in search for new training methods.\n\nOpenAI and deepmind didn't start out as \"businesses\", they started out as research factories. But now they're in a position to monetize their research, which is their moat.\n\nMaybe my view is biased because of only coming across funding rounds for fancy wrapper firms, and not for the boring research firms. But this has been my observation so far.

Message : And May be investor mindset also set the the tone for entrepreneurs.

Message : Just saw this - https://twitter.com/etnowlive/status/1666460799093620738?s=46

Why compete on foundation models when there is a cemetery of failed or outdated models?

From the models coming out it seems releasing usable instruction tuned model is not dependent on funding in millions or proprietary skill set.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : As a point of comparison: You can also see Langchain team actively just ignoring issues and PRs both.
Quoted Message : This is the very question I asked Jerry, how are you coming up with few strategies and features atm? He was like it‚Äôs all open source man

Message : Our boy is maybe too busy with developer advocacy haha
Quoted Message : As a point of comparison: You can also see Langchain team actively just ignoring issues and PRs both.

Message : To this point, since I just moved from a ML/ Data Scientist role to a VC role, one of the things I wanted to do is contribute back to the community. (I literally owe my career to them). 
We are trying to fund a small number of open source projects. You can refer to this tweet. Ofcourse it will be nowhere near to what you would need to create a top library/model, but I hope it helps projects get off the ground -

https://twitter.com/brijbhasin/status/1666663734385979392?s=20
Quoted Message : #truth \n\nJust gotta keep trying. \n\nBut one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models. \n\nWe don't lack talent or money. But coordinated efforts over long periods without any in-between \"payouts\" still seems a luxury for us. \n\nAnd it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.

Message : How exactly?
Quoted Message : Llama index has more potential than Langchain as a company

Message : I think VCs should try and support research based firms. I can understand their desire for investing in money making engines. But in order to have an Indian deepmind or an Indian openAI investors should soften themselves up towards startups that are in search for new models, that are in search for new training methods.

OpenAI and deepmind didn't start out as "businesses", they started out as research factories. But now they're in a position to monetize their research, which is their moat.

Maybe my view is biased because of only coming across funding rounds for fancy wrapper firms, and not for the boring research firms. But this has been my observation so far.
Quoted Message : #truth \n\nJust gotta keep trying. \n\nBut one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models. \n\nWe don't lack talent or money. But coordinated efforts over long periods without any in-between \"payouts\" still seems a luxury for us. \n\nAnd it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.

Message : Curious - how much do these cost? And what kind of investment in terms of time, money, and human resource we're looking at here?
Quoted Message : #truth \n\nJust gotta keep trying. \n\nBut one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models. \n\nWe don't lack talent or money. But coordinated efforts over long periods without any in-between \"payouts\" still seems a luxury for us. \n\nAnd it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.

Message : Amjad Massad of replit is always on point with his wit !
https://twitter.com/amasad/status/1666690663587680257

Message : True. Throwing 10M is not to going to create another OpenAI. Also, I talked about this thing two days back that we haven‚Äôt even seen fine tuned Llama, like Teknium is training, from India, which will cost 2-3k. Because India is not focused on indie hacking, taking a deep problem heads on, but everyone wants to build quick tool to raise money.
Quoted Message : I think VCs should try and support research based firms. I can understand their desire for investing in money making engines. But in order to have an Indian deepmind or an Indian openAI investors should soften themselves up towards startups that are in search for new models, that are in search for new training methods.\n\nOpenAI and deepmind didn't start out as \"businesses\", they started out as research factories. But now they're in a position to monetize their research, which is their moat.\n\nMaybe my view is biased because of only coming across funding rounds for fancy wrapper firms, and not for the boring research firms. But this has been my observation so far.

Message : And May be investor mindset also set the the tone for entrepreneurs.

Message : Just saw this - https://twitter.com/etnowlive/status/1666460799093620738?s=46

Why compete on foundation models when there is a cemetery of failed or outdated models?

From the models coming out it seems releasing usable instruction tuned model is not dependent on funding in millions or proprietary skill set.

Message : i think it boils down to research mindset, barring a few universities in india, we don't have a research culture
Quoted Message : True. Throwing 10M is not to going to create another OpenAI. Also, I talked about this thing two days back that we haven‚Äôt even seen fine tuned Llama, like Teknium is training, from India, which will cost 2-3k. Because India is not focused on indie hacking, taking a deep problem heads on, but everyone wants to build quick tool to raise money.

Message : VCs are not interested in making bets anymore. They're only interested in ensuring returns. Risk averse VCs are best paired with fixed deposits, not investing in high risk ventures like tech startups
Quoted Message : I think VCs should try and support research based firms. I can understand their desire for investing in money making engines. But in order to have an Indian deepmind or an Indian openAI investors should soften themselves up towards startups that are in search for new models, that are in search for new training methods.\n\nOpenAI and deepmind didn't start out as \"businesses\", they started out as research factories. But now they're in a position to monetize their research, which is their moat.\n\nMaybe my view is biased because of only coming across funding rounds for fancy wrapper firms, and not for the boring research firms. But this has been my observation so far.

Message : Ilya used to charge $1M/year in 2017. That's one senior exec at OpenAI.
Quoted Message : Curious - how much do these cost? And what kind of investment in terms of time, money, and human resource we're looking at here?

Message : Midjourney is an example of a small bootstrapped team taking on OpenAI and building a better foundational model

Message : Safe to say we don't have affordable talent to make a super computer either, which Azure built specifically for LLM training and inference workloads for OpenAI. 

As bad as you might feel, Sam Altman is completely right: Indians making Foundational Models is "hopeless"

Message : 1 million per year as a salary in SF is more common than we might think. Only normal that well funded startup talent receives such money
Quoted Message : Ilya used to charge $1M/year in 2017. That's one senior exec at OpenAI.

Message : ‚Ä¶

I think we should complaint about lack of investor trust after we put an instruction tuned Falcon at top of Open LLM and Helm by fine tuning with less than <$1000 budget
Quoted Message : Just saw this - https://twitter.com/etnowlive/status/1666460799093620738?s=46\n\nWhy compete on foundation models when there is a cemetery of failed or outdated models?\n\nFrom the models coming out it seems releasing usable instruction tuned model is not dependent on funding in millions or proprietary skill set.

Message : I mean, look at the number of Asians (Chinese, Japanese, Koreans) building LoRA on Civitai, and look what we've for desi celebs/art forms. If we don't even have 10K LoRAs, where the talent, compute, cost ‚Äî  is basically hobby tier: $100 or less ‚Äî  I don't think we've a fair shot at even training GPT4.

Message : I think you should talk to a vc before being this strongly opinionated.
Quoted Message : VCs are not interested in making bets anymore. They're only interested in ensuring returns. Risk averse VCs are best paired with fixed deposits, not investing in high risk ventures like tech startups

Message : We can realistically can do Falcon, but is there a single private investor/funder willing to risk even $150-$200K for that? (not counting IITs, GoI) 

I do think companies directly impacted by LLMs e.g. IT Services giants like Infosys, TCS have an incentive to do this. But I've no information if they are doing so.

Message : what is the benefit for commercial entities doing academic research?
Quoted Message : We can realistically can do Falcon, but is there a single private investor/funder willing to risk even $150-$200K for that? (not counting IITs, GoI) \n\nI do think companies directly impacted by LLMs e.g. IT Services giants like Infosys, TCS have an incentive to do this. But I've no information if they are doing so.

Message : I suspect that is part of the issue ‚Äî this is NOT research
Quoted Message : what is the benefit for commercial entities doing academic research?

Message : TCS sponsored ET for hosting Sam üòÖ
Quoted Message : We can realistically can do Falcon, but is there a single private investor/funder willing to risk even $150-$200K for that? (not counting IITs, GoI) \n\nI do think companies directly impacted by LLMs e.g. IT Services giants like Infosys, TCS have an incentive to do this. But I've no information if they are doing so.

Message : foundational models are not research? do you mean taking existing architecture and replicating runs?
Quoted Message : I suspect that is part of the issue ‚Äî this is NOT research

Message : Why do you need $200k?
Quoted Message : We can realistically can do Falcon, but is there a single private investor/funder willing to risk even $150-$200K for that? (not counting IITs, GoI) \n\nI do think companies directly impacted by LLMs e.g. IT Services giants like Infosys, TCS have an incentive to do this. But I've no information if they are doing so.

Message : Falcon-sized Foundations Models are not research
Quoted Message : foundational models are not research? do you mean taking existing architecture and replicating runs?

Message : So that I can afford engineers like you in addition to the compute and data. I don't think it's fair to ask you to volunteer your time.
Quoted Message : Why do you need $200k?

Message : Or pay you below market rates either

Message : I kind of agree. We started with llama index and are now building outside of it - we're obviously very small and exactly fit their usecase but it just does not work for prod (scale etc)
Quoted Message : https://twitter.com/TheEthanDing/status/1666109071278104578\n\nwhat do u folks think ? especially people who have worked with langchain, etc.

Message : Did you've to step out become of complexity or scaling challenge
Quoted Message : I kind of agree. We started with llama index and are now building outside of it - we're obviously very small and exactly fit their usecase but it just does not work for prod (scale etc)

Message : @91773788xxxx I think 200k isn‚Äôt enough btw

Message : But you can do it yourself with your 10k budget and keep all the equity. My point is it does not require many engineers
Quoted Message : So that I can afford engineers like you in addition to the compute and data. I don't think it's fair to ask you to volunteer your time.

Message : Fair, I'll ask @91740765xxxx for the rest
Quoted Message : @9177xxxxxxxx I think 200k isn‚Äôt enough btw

Message : Pay entry level salaries of 3.2 lakhs in 2023, and sponsor million dollar conferences. Priorities are right.
Quoted Message : TCS sponsored ET for hosting Sam üòÖ

Message : Equity (startup)
Quoted Message : But you can do it yourself with your 10k budget and keep all the equity. My point is it does not require many engineers

Message : It either requires money or time no?
Quoted Message : Equity (startup)

Message : One person will take a lot of time.

Message : As bad as you might feel, Sam Altman is completely right: Indians making Foundational Models is "hopeless"

Message : The thing is Ilya, Karpathy, Alex are probably one in generation scientists, they are 10x valuable than Sama. But Sam decided to use his life savings and place a bet on them as an investor first and then operator. Where are those investors in India who will seek talent and then enable them like that, instead of building cheaper Indian copies of established US business models.
Quoted Message : Ilya used to charge $1M/year in 2017. That's one senior exec at OpenAI.

Message : People should not join if they don‚Äôt like the salary. Employee can always decide to fix their pay
Quoted Message : Pay entry level salaries of 3.2 lakhs in 2023, and sponsor million dollar conferences. Priorities are right.

Message : bit of both
Quoted Message : Did you've to step out become of complexity or scaling challenge

Message : Aah. I've a lot of questions around this. DMing.
Quoted Message : bit of both

Message : Alpaca, koala were made in days by a small team right?
Quoted Message : One person will take a lot of time.

Message : Things are changing, but salaries in ITES are still low - and each of those companies wants to build next gen tech but pay peanuts to young talent
Quoted Message : People should not join if they don‚Äôt like the salary. Employee can always decide to fix their pay

Message : Why?  Curious to hear your thoughts on this...
Quoted Message : As bad as you might feel, Sam Altman is completely right: Indians making Foundational Models is \"hopeless\"

Message : ‚Äé<attached: 00007690-PHOTO-2023-06-08-12-36-06.jpg>
Quoted Message : Alpaca, koala were made in days by a small team right?

Message : Perhaps a lesson in this is that organization scale itself doesn't lend scale capability to execute

Message : Want to know more
Quoted Message : bit of both

Message : they're answerable to their LPs and usually, they compete with PE firms for better returns. there needs to be commercial incentive. And even before that - I second what paras said. there should be government/research incentive before commercial and India isn't just there yet.
Quoted Message : VCs are not interested in making bets anymore. They're only interested in ensuring returns. Risk averse VCs are best paired with fixed deposits, not investing in high risk ventures like tech startups

Message : curious - is it possible to build for India from outside by convincing outside talent?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : bit of both
Quoted Message : Did you've to step out become of complexity or scaling challenge

Message : Aah. I've a lot of questions around this. DMing.
Quoted Message : bit of both

Message : Alpaca, koala were made in days by a small team right?
Quoted Message : One person will take a lot of time.

Message : Things are changing, but salaries in ITES are still low - and each of those companies wants to build next gen tech but pay peanuts to young talent
Quoted Message : People should not join if they don‚Äôt like the salary. Employee can always decide to fix their pay

Message : Why?  Curious to hear your thoughts on this...
Quoted Message : As bad as you might feel, Sam Altman is completely right: Indians making Foundational Models is \"hopeless\"

Message : ‚Äé<attached: 00007690-PHOTO-2023-06-08-12-36-06.jpg>
Quoted Message : Alpaca, koala were made in days by a small team right?

Message : Perhaps a lesson in this is that organization scale itself doesn't lend scale capability to execute

Message : Want to know more
Quoted Message : bit of both

Message : they're answerable to their LPs and usually, they compete with PE firms for better returns. there needs to be commercial incentive. And even before that - I second what paras said. there should be government/research incentive before commercial and India isn't just there yet.
Quoted Message : VCs are not interested in making bets anymore. They're only interested in ensuring returns. Risk averse VCs are best paired with fixed deposits, not investing in high risk ventures like tech startups

Message : curious - is it possible to build for India from outside by convincing outside talent?

Message : I'm happy to work with anyone interested in India style LoRAs. 

We can build a civit for Indiam
Quoted Message : I mean, look at the number of Asians (Chinese, Japanese, Koreans) building LoRA on Civitai, and look what we've for desi celebs/art forms. If we don't even have 10K LoRAs, where the talent, compute, cost ‚Äî  is basically hobby tier: $100 or less ‚Äî  I don't think we've a fair shot at even training GPT4.

Message : Sorry but a lot of people they hire are not ‚Äòtalent‚Äô. They are a product of a terrible education system. Many of these companies become the place where they actually gain education
Quoted Message : Things are changing, but salaries in ITES are still low - and each of those companies wants to build next gen tech but pay peanuts to young talent

Message : Don‚Äôt you have like 5 friends to do this now? And anyways you don‚Äôt need a lot of people to do it now that you know the recipe. Training 7b model is not an infra problem when you know it costs only <1k
Quoted Message :  2023_06_08_3EB0E31504478BDA3E4199.jpeg

Message : Desi founders can't pay Bengaluru salaries which match Tower Capital. I doubt we can hire anyone at SF salaries
Quoted Message : curious - is it possible to build for India from outside by convincing outside talent?

Message : there's a lot of indian diaspora sitting around doing basic programming.
Quoted Message : Desi founders can't pay Bengaluru salaries which match Tower Capital. I doubt we can hire anyone at SF salaries

Message : Who has that kind of money in India? 
Or even ability to find such talent who stays in India?
Quoted Message : The thing is Ilya, Karpathy, Alex are probably one in generation scientists, they are 10x valuable than Sama. But Sam decided to use his life savings and place a bet on them as an investor first and then operator. Where are those investors in India who will seek talent and then enable them like that, instead of building cheaper Indian copies of established US business models.

Message : Aeee. You and I are not doing this peanut 7B models for pure marketing
Quoted Message : Don‚Äôt you have like 5 friends to do this now? And anyways you don‚Äôt need a lot of people to do it now that you know the recipe. Training 7b model is not an infra problem when you know it costs only <1k

Message : outside india. I have friends who are applied scientists at Microsoft and OpenAI with big fat salaries looking to do something for India but they just don't have the right channels.
Quoted Message : there's a lot of indian diaspora sitting around doing basic programming.

Message : We not doing it is not a proof that it cannot be done. Just misplaced priorities
Quoted Message : Aeee. You and I are not doing this peanut 7B models for pure marketing

Message : Ask any of them to take a "3 month sabbatical" and do this for us ‚Äî and you'll see how many of them respond :)
Quoted Message : outside india. I have friends who are applied scientists at Microsoft and OpenAI with big fat salaries looking to do something for India but they just don't have the right channels.

Message : *with us

Message : Been there done that. No one does.
Quoted Message : Ask any of them to take a \"3 month sabbatical\" and do this for us ‚Äî and you'll see how many of them respond :)

Message : @1408306xxxx
Quoted Message : Ask any of them to take a \"3 month sabbatical\" and do this for us ‚Äî and you'll see how many of them respond :)

Message : Don‚Äôt they have a non-compete?
Quoted Message : Ask any of them to take a \"3 month sabbatical\" and do this for us ‚Äî and you'll see how many of them respond :)

Message : lmk if they are looking for opportunities haha
Quoted Message : what is the benefit for commercial entities doing academic research?

Message : have anything to contribute?
Quoted Message : @140xxxxxxxx

Message : .
Quoted Message : outside india. I have friends who are applied scientists at Microsoft and OpenAI with big fat salaries looking to do something for India but they just don't have the right channels.

Message : I think @1937708xxxx  mentioned how it is important to get to the deep roots of problems and solve them. That *generates* value, and investors will come looking for such talent. That's what we need, perhaps, not a new initiative to have the best come and build for India in India (at exorbitant cost to our investors/companies)

Message : My experience in this department is summarised best by: Talk, even before LLMs was cheap
Quoted Message : Ask any of them to take a \"3 month sabbatical\" and do this for us ‚Äî and you'll see how many of them respond :)

Message : well, a lot of them have left their full-time jobs to come to build for India.
Quoted Message : Ask any of them to take a \"3 month sabbatical\" and do this for us ‚Äî and you'll see how many of them respond :)

Message : at least in my network.

Message : Sama found Ilya before DL phenomenon started. Waymo, Tesla picked up whole CMU and stand firm team. May be someone had picked up Bhasini team before they moved out of India to work for Azure.
Quoted Message : Who has that kind of money in India? \nOr even ability to find such talent who stays in India?

Message : "lot"? Less than 0.1%.
Quoted Message : well, a lot of them have left their full-time jobs to come to build for India.

Message : Will touch base.
Quoted Message : .

Message : No, they've come to build a business with 100% equity and realised that cost of living and talent is cheaper in India. Don't confuse the two.
Quoted Message : well, a lot of them have left their full-time jobs to come to build for India.

Message : yes, was just about to mention that. not sure if their interest lies in research.
Quoted Message : No, they've come to build a business with 100% equity and realised that cost of living and talent is cheaper in India. Don't confuse the two.

Message : Waymo, Sama and Tesla have very big pockets before they did so.
Quoted Message : Sama found Ilya before DL phenomenon started. Waymo, Tesla picked up whole CMU and stand firm team. May be someone had picked up Bhasini team before they moved out of India to work for Azure.

Message : To reiterate, 13B, 40B models are not research. They're engineering problems today.
Quoted Message : yes, was just about to mention that. not sure if their interest lies in research.

Message : A thing where India shines is frugal & cost-effective engineering - all of our success stories have been that

ISRO is a classic example and to have also come out of Bangalore as well. Not very familiar w/ the HAL story but have heard similar things about it (happy to be corrected)
Quoted Message : #truth \n\nJust gotta keep trying. \n\nBut one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models. \n\nWe don't lack talent or money. But coordinated efforts over long periods without any in-between \"payouts\" still seems a luxury for us. \n\nAnd it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it.

Message : Just one thought. I read the orca paper. Pretty interesting. But my main takeaway was that the models don't have great training data. I think we can work to that.  There's a few ways

Message : No one does. 

Moving back to India is hard. I've done it twice. Reasons were not as ideal as we are discussing here. But now that many of us have this desire, we have to start.

Need to take a moonshot and just keep plugging away at. At some point, something will happen.

This is much better than ensuring nothing happens.
Quoted Message : Been there done that. No one does.

Message : Do you mean it has data quality issues ?
Quoted Message : Just one thought. I read the orca paper. Pretty interesting. But my main takeaway was that the models don't have great training data. I think we can work to that.  There's a few ways

Message : agree, and your point is that India needs them for indic languages because tokens are costlier in english first models?
Quoted Message : To reiterate, 13B, 40B models are not research. They're engineering problems today.

Message : +1. Not twice but once in my case. But similar thoughts
Quoted Message : No one does. \n\nMoving back to India is hard. I've done it twice. Reasons were not as ideal as we are discussing here. But now that many of us have this desire, we have to start. \n\nNeed to take a moonshot and just keep plugging away at. At some point, something will happen. \n\nThis is much better than ensuring nothing happens.

Message : No, we need to do English because we need to have the talent and skill to do this.
Quoted Message : agree, and your point is that India needs them for indic languages because tokens are costlier in english first models?

Message : I also don't think we've a talent shortage ‚Äî we can pull if there are investors.

Message : Profit/Non-Profit

Message : May be then we will never have anything big because our Unicorns‚Äô account sheets are not healthy to invest in future, old elephants are full of bureaucrats, and investors are not big enough to take bets on big ideas.
Quoted Message : Waymo, Sama and Tesla have very big pockets before they did so.

Message : Yes. Big time
Quoted Message : Do you mean it has data quality issues ?

Message : but why re-create a me-too model? if high quality, english open source models exist, why spend energy there?
Quoted Message : No, we need to do English because we need to have the talent and skill to do this.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : No one does. 

Moving back to India is hard. I've done it twice. Reasons were not as ideal as we are discussing here. But now that many of us have this desire, we have to start.

Need to take a moonshot and just keep plugging away at. At some point, something will happen.

This is much better than ensuring nothing happens.
Quoted Message : Been there done that. No one does.

Message : Do you mean it has data quality issues ?
Quoted Message : Just one thought. I read the orca paper. Pretty interesting. But my main takeaway was that the models don't have great training data. I think we can work to that.  There's a few ways

Message : agree, and your point is that India needs them for indic languages because tokens are costlier in english first models?
Quoted Message : To reiterate, 13B, 40B models are not research. They're engineering problems today.

Message : +1. Not twice but once in my case. But similar thoughts
Quoted Message : No one does. \n\nMoving back to India is hard. I've done it twice. Reasons were not as ideal as we are discussing here. But now that many of us have this desire, we have to start. \n\nNeed to take a moonshot and just keep plugging away at. At some point, something will happen. \n\nThis is much better than ensuring nothing happens.

Message : No, we need to do English because we need to have the talent and skill to do this.
Quoted Message : agree, and your point is that India needs them for indic languages because tokens are costlier in english first models?

Message : I also don't think we've a talent shortage ‚Äî we can pull if there are investors.

Message : Profit/Non-Profit

Message : May be then we will never have anything big because our Unicorns‚Äô account sheets are not healthy to invest in future, old elephants are full of bureaucrats, and investors are not big enough to take bets on big ideas.
Quoted Message : Waymo, Sama and Tesla have very big pockets before they did so.

Message : Yes. Big time
Quoted Message : Do you mean it has data quality issues ?

Message : but why re-create a me-too model? if high quality, english open source models exist, why spend energy there?
Quoted Message : No, we need to do English because we need to have the talent and skill to do this.

Message : i'd be interested if we garner enough VC interest.
Quoted Message : No one does. \n\nMoving back to India is hard. I've done it twice. Reasons were not as ideal as we are discussing here. But now that many of us have this desire, we have to start. \n\nNeed to take a moonshot and just keep plugging away at. At some point, something will happen. \n\nThis is much better than ensuring nothing happens.

Message : Why does it have to me-too? 

We can do codegen, SQL, code-refactor for enterprise, webdev, action models like Adept.ai
Quoted Message : but why re-create a me-too model? if high quality, english open source models exist, why spend energy there?

Message : The plain vanilla LLM is the basic skillset you need to even think about doing these

Message : or if any VC would be willing to take the bet.
Quoted Message : i'd be interested if we garner enough VC interest.

Message : See waiting for any validation sets up unnecessary hurdles. As it is we haven't started. 

VCs have different incentives.

We are doing this so India has a say in AI at the foundation model levels.

That some day a Samay Or a Samiksh laughs at a question when they are invited in USA or China.
Quoted Message : i'd be interested if we garner enough VC interest.

Message : *Samiksha

Message : I think that's why Rajan sir laughed when he mentioned the 10mil bit.
Quoted Message : or if any VC would be willing to take the bet.

Message : Why do you need VC interest to be able to build a product? 
VC will automatically be interested if the product has business value.

Products dont get build because VC is interested but because founders find a business and product and convince VCs. We have to flip this.
Quoted Message : or if any VC would be willing to take the bet.

Message : hmm.
Quoted Message : See waiting for any validation sets up unnecessary hurdles. As it is we haven't started. \n\nVCs have different incentives. \n\nWe are doing this so India has a say in AI at the foundation model levels. \n\nThat some day a Samay Or a Samiksh laughs at a question when they are invited in USA or China.

Message : well, good foundational models are good at these skills.

the real question is if there's an edge for specialized models, and if they're specialized are they really foundational?

i guess we're talking about two slightly different things
Quoted Message : Why does it have to me-too? \n\nWe can do codegen, SQL, code-refactor for enterprise, webdev, action models like Adept.ai

Message : This group is enough. We don't need more. Folks here can come up with hundred different ideas. Just few of us need to start.

Message : You're right. They're adjacent, slightly different. To be clear, StarCoder is better at Codegen than GPT4. 

That is why Code Interpreter had to be RLHF'd.
Quoted Message : well, good foundational models are good at these skills.\n\nthe real question is if there's an edge for specialized models, and if they're specialized are they really foundational?\n\ni guess we're talking about two slightly different things

Message : And Replit sized 1.3B models are still quite valuable because of how powerful and cheap they're

Message : Yeah so training a 1.3B model won‚Äôt be costly.
Quoted Message : And Replit sized 1.3B models are still quite valuable because of how powerful and cheap they're

Message : its a personal reservation - that I wouldn't want to waste my life in building something that someone might not fund, eventually. And I think I am not alone in this. its very difficult to gauge VC/or lets just say risk capital interest.
Quoted Message : Why do you need VC interest to be able to build a product? \nVC will automatically be interested if the product has business value.\n\nProducts dont get build because VC is interested but because founders find a business and product and convince VCs. We have to flip this.

Message : Is there any benchmark supporting this?
Quoted Message : You're right. They're adjacent, slightly different. To be clear, StarCoder is better at Codegen than GPT4. \n\nThat is why Code Interpreter had to be RLHF'd.

Message : Inside track: Teknium is working on one.
Quoted Message : Is there any benchmark supporting this?

Message : things are different in west. You get money for trying. I think someone mentioned earlier that we don't have experiment capital in India/or appetite. So I'd understand a founder's dilemma to raise money for money.
Quoted Message : its a personal reservation - that I wouldn't want to waste my life in building something that someone might not fund, eventually. And I think I am not alone in this. its very difficult to gauge VC/or lets just say risk capital interest.

Message : pl correct me if am wrong.

Message : Dont you think that someone funding or not shouldnt be the decision maker but rather your depth of the problem the decision maker on whether the idea can make money.
If you arent able to convince yourself on a product, how do you expect to convince others? Entire job of a founder is selling their idea everyday of their life - VC, employees, users etc.

VCs are only to speed up things or put upfront capital. But we should know what it is for and what are the returns no?
Quoted Message : its a personal reservation - that I wouldn't want to waste my life in building something that someone might not fund, eventually. And I think I am not alone in this. its very difficult to gauge VC/or lets just say risk capital interest.

Message : I work with MSRIT Bangalore students. 

Want to expose them to codegen tools. Just so they know what's out there.

GPT-4 is awesome but they may not pay 20$/monthly.

Anyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?
Quoted Message : You're right. They're adjacent, slightly different. To be clear, StarCoder is better at Codegen than GPT4. \n\nThat is why Code Interpreter had to be RLHF'd.

Message : we're talking deep-tech only here.
Quoted Message : Dont you think that someone funding or not shouldnt be the decision maker but rather your depth of the problem the decision maker on whether the idea can make money.\nIf you arent able to convince yourself on a product, how do you expect to convince others? Entire job of a founder is selling their idea everyday of their life - VC, employees, users etc.\n\nVCs are only to speed up things or put upfront capital. But we should know what it is for and what are the returns no?

Message : StarCoder doesn't have a VS Code extension which is any code. But happy to do a walkthrough of both instruct and auto-complete finetuned models from Replit.
Quoted Message : I work with MSRIT Bangalore students. \n\nWant to expose them to codegen tools. Just so they know what's out there. \n\nGPT-4 is awesome but they may not pay 20$/monthly.\n\nAnyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?

Message : ISRO doesn't have to worry about a competitor paying them a higher salary. so easier to be cost effective there.
Quoted Message : A thing where India shines is frugal & cost-effective engineering - all of our success stories have been that\n\nISRO is a classic example and to have also come out of Bangalore as well. Not very familiar w/ the HAL story but have heard similar things about it (happy to be corrected)

Message : This domain also presents a unique challenge of having money not necessarily leading to progress.  Getting GPUs and assembling clusters have long waiting times now.

Message : You think deep-tech doesnt need to have a business value?
Quoted Message : we're talking deep-tech only here.

Message : deep-tech only changes return timeline for capital.

Message : okay, are they willing to wait that long?
Quoted Message : You think deep-tech doesnt need to have a business value?

Message : Indian VCs dont have that deep pockets from my prelim research. There has to be some decent sized wins to be able to do that. There arent many unfortunately.
Quoted Message : okay, are they willing to wait that long?

Message : exactly.
Quoted Message : Indian VCs dont have that deep pockets from my prelim research. There has to be some decent sized wins to be able to do that. There arent many unfortunately.

Message : plus not to forget outside competition.

Message : tech is and will always be global.

Message : Yes. So, raise from a non Indian VC if the product is great?

Message : we can do 1 to n tech here but 0 to 1 in any field hands-down balls-deep is extremely difficult.

Message : Many investors in India need to embrace risk - not enough of them do, so the likes of Antler, Sequoia and others swoop in to make dividends on our builders and talent.
Quoted Message : things are different in west. You get money for trying. I think someone mentioned earlier that we don't have experiment capital in India/or appetite. So I'd understand a founder's dilemma to raise money for money.

Message : Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model‚Äôs geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan

Message : Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model‚Äôs geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan

Message : We need Patrons, pre independence or near independence India. Likes of Tatas and Birlas, to invest in long horizon projects. Right now only institute that is can do invest in deep tech is probably the GOI.
Quoted Message : exactly.

Message : Why blame VCs for this?

These are systemic issues.

Message : We've discussed this in plenty of detail. Just last week. Please scroll up.
Quoted Message : Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model‚Äôs geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : plus not to forget outside competition.

Message : tech is and will always be global.

Message : Yes. So, raise from a non Indian VC if the product is great?

Message : we can do 1 to n tech here but 0 to 1 in any field hands-down balls-deep is extremely difficult.

Message : Many investors in India need to embrace risk - not enough of them do, so the likes of Antler, Sequoia and others swoop in to make dividends on our builders and talent.
Quoted Message : things are different in west. You get money for trying. I think someone mentioned earlier that we don't have experiment capital in India/or appetite. So I'd understand a founder's dilemma to raise money for money.

Message : Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model‚Äôs geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan

Message : Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model‚Äôs geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan

Message : We need Patrons, pre independence or near independence India. Likes of Tatas and Birlas, to invest in long horizon projects. Right now only institute that is can do invest in deep tech is probably the GOI.
Quoted Message : exactly.

Message : Why blame VCs for this?

These are systemic issues.

Message : We've discussed this in plenty of detail. Just last week. Please scroll up.
Quoted Message : Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model‚Äôs geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan

Message : How man?
Check out their fund sizes and returns they have got in past 5y. Where will the money come from?
Quoted Message : Many investors in India need to embrace risk - not enough of them do, so the likes of Antler, Sequoia and others swoop in to make dividends on our builders and talent.

Message : From what I have seen - cheap hard-tech MVP that can be scaled from a manufacturing pov can guarantee great returns as government and policy support is well-defined.
Quoted Message : Yes. So, raise from a non Indian VC if the product is great?

Message : Look at funds like GVFL

Message : Not true na, how?
Quoted Message : ISRO doesn't have to worry about a competitor paying them a higher salary. so easier to be cost effective there.

Message : https://zerocowfactory.com/ <--- something like this.

Message : talent can go overseas, correct?
Quoted Message : Not true na, how?

Message : He's right. NASA has to compete with the likes of Lockheed and SpaceX for talent - not the case with ISRO. Plus aerospace engg or education talent in India hasn't distinguished itself as tech talent perhaps has
Quoted Message : Not true na, how?

Message : Why not ISRO? Do they have a laxman rekha on their engineers lol?
Quoted Message : He's right. NASA has to compete with the likes of Lockheed and SpaceX for talent - not the case with ISRO. Plus aerospace engg or education talent in India hasn't distinguished itself as tech talent perhaps has

Message : True. They are missing home runs to grow pockets first,  then invest some in long horizon projects.
Quoted Message : Why blame VCs for this?\n\nThese are systemic issues.

Message : In fact the Laxman Rekha is around ISRO. Private defence/space tech companies in India have tall regulatory walls to scale before they can be productive
Quoted Message : Why not ISRO? Do they have a laxman rekha on their engineers lol?

Message : *productive and profitable

Message : No but what can bear them working for the likes of SpaceX/NASA? Had a friend in college, shifted to US, joined MIT's space eng program and now she's aiming to be an astronaut.
Quoted Message : In fact the Laxman Rekha is around ISRO. Private defence/space tech companies in India have tall regulatory walls to scale before they can be productive

Message : from working*

Message : Decidedly off topic for this forum. Maybe move this convo-fork to DM?
Quoted Message : No but what can bear them working for the likes of SpaceX/NASA? Had a friend in college, shifted to US, joined MIT's space eng program and now she's aiming to be an astronaut.

Message : With all factors equal, it's obvious that a region with more funding is likely to prosper than other regions.

So if our consensus belief is that we have no lack of talent as compared to other nations, then factors like funding have to play a significant role

Completely aligned on "if you're good enough you'll make it" school of thought, bulk onus of responsibility should indeed be on the founders. But they can only go so far with a skeptical funding sources.
Quoted Message : Dont you think that someone funding or not shouldnt be the decision maker but rather your depth of the problem the decision maker on whether the idea can make money.\nIf you arent able to convince yourself on a product, how do you expect to convince others? Entire job of a founder is selling their idea everyday of their life - VC, employees, users etc.\n\nVCs are only to speed up things or put upfront capital. But we should know what it is for and what are the returns no?

Message : Sure.
Quoted Message : Decidedly off topic for this forum. Maybe move this convo-fork to DM?

Message : Frugal innovation is hard to do when the price and targets are set by an increasingly global market and talent pool. If cloud costs the same everywhere, talent costs the same everywhere, but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base), investors should want to invest here because they get dividends

Message : "but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base)" - Not enough proof yet on if they can make money.

Message : ‚Äé<attached: 00007795-PHOTO-2023-06-08-13-16-22.jpg>
Quoted Message : StarCoder doesn't have a VS Code extension which is any code. But happy to do a walkthrough of both instruct and auto-complete finetuned models from Replit.

Message : I've tried it, it's terribly slow üòÖ
Quoted Message :  2023_06_08_3EB04BF6571F3743B23CF6.jpeg

Message : This question is going to define India at 2045. If we believe in this or not.
Quoted Message : \"but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base)\" - Not enough proof yet on if they can make money.

Message : More proof (depending on use case of course) perhaps than the guys who funded the "Yo" app or Juicero had. Idiotic products get funded in Si Valley sometimes because it is possible to throw money around there. Discerning investors won't do that in India even for legit use cases at the same level
Quoted Message : \"but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base)\" - Not enough proof yet on if they can make money.

Message : Heck, they even funded Nikola millions of dollars without a single truck produced and that turned out to be a scam

Message : The details to setup the extension and using it via shortcuts is all there on the installation page on the vs code extension itself.
I didn't like starcoder or starchat as much but it is good for some basic stuff.
Quoted Message : I work with MSRIT Bangalore students. \n\nWant to expose them to codegen tools. Just so they know what's out there. \n\nGPT-4 is awesome but they may not pay 20$/monthly.\n\nAnyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?

Message : Are you saying India doesnt have enough weird ideas being funded? :P
Quoted Message : More proof (depending on use case of course) perhaps than the guys who funded the \"Yo\" app or Juicero had. Idiotic products get funded in Si Valley sometimes because it is possible to throw money around there. Discerning investors won't do that in India even for legit use cases at the same level

Message : Hehe. I think it is a signal of risk. Shitty businesses will fail in a downturn but good ideas will make hay during an upswing.
Quoted Message : Are you saying India doesnt have enough weird ideas being funded? :P

Message : Half-good ideas even if they're sometimes boring can also do well if given a chance. I think that kind of thing doesn't happen often enough here.

Message : Also, if your req. is just to get a free decent code autocomplete - please check codeium/AWS Toolkit Codewhisperer.
Though nothing comes even close to GPT4.
Quoted Message : I work with MSRIT Bangalore students. \n\nWant to expose them to codegen tools. Just so they know what's out there. \n\nGPT-4 is awesome but they may not pay 20$/monthly.\n\nAnyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?

Message : Yes. Codeium is also quite decent
Quoted Message : Also, if your req. is just to get a free decent code autocomplete - please check codeium/AWS Toolkit Codewhisperer.\nThough nothing comes even close to GPT4.

Message : GitHub copilot is free for students (they need to provide supporting documents). There are some pretty amazing tools in their pipeline. I've tried their copilot chat, copilot labs tools (explain, translate, brushes etc.), Copilot for command line. All are really good
Quoted Message : I work with MSRIT Bangalore students. \n\nWant to expose them to codegen tools. Just so they know what's out there. \n\nGPT-4 is awesome but they may not pay 20$/monthly.\n\nAnyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?

Message : cc @91866009xxxx if students are familiar with Git and Github, Github Copilot is easiest to use.
Quoted Message : GitHub copilot is free for students (they need to provide supporting documents). There are some pretty amazing tools in their pipeline. I've tried their copilot chat, copilot labs tools (explain, translate, brushes etc.), Copilot for command line. All are really good

Message : https://education.github.com/pack/join

free for students
Quoted Message : I work with MSRIT Bangalore students. \n\nWant to expose them to codegen tools. Just so they know what's out there. \n\nGPT-4 is awesome but they may not pay 20$/monthly.\n\nAnyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?

Message : Point taken but an ecosystem like berkeley/bair takes decades to build !
I am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.

I recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .
https://arxiv.org/abs/2005.08209
Quoted Message : Alpaca, koala were made in days by a small team right?

Message : If only I had 4-5 AI researchers on my payroll......
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : Is this wav2lip team? This is base for SadTalker and other oss models that can easily and cheaply replace D-ID.
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : There are world class researchers building high impact projects in India, especially in academia & industrial research labs(MSR work on native languages).
we need govt backing them much more with grants & funds.

And also the insane startup energy at places like Stanford & berkeley - the same intensity is not there in india yet, but we are catching up quickly.

My dream is that somebody in the govt has the foresight to dedicate a large chunk of money & institutional effort to make India, an attractive hub of ai research - including sops & incentives to motivate researchers of indian origin outside india, to come back & start labs & companies in india.

Its a 5-10 year timeline mission, wont happen in a year or so but you need an industry, govt partnership to articulate a grand, moonshot vision & then relentlessly execute on that.

</rant> :D
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : Nirant, how does copilot compare vs replit ghostwriter ?
Quoted Message : cc @9186xxxxxxxx if students are familiar with Git and Github, Github Copilot is easiest to use.

Message : Is anyone here at the Sam Altman meet at IIIT DELHI today?

Message : This is the David Vs Goliath thing. If it was impossible, OpenAI would not have been able to stress out Google. And many other startups would not have disrupted the leaders. It happens all the time as per the history.
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : https://twitter.com/huggingface/status/1666737999990730752?t=mM6813k-AXjJXMoQxLResw&s=08


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : cc @91866009xxxx if students are familiar with Git and Github, Github Copilot is easiest to use.
Quoted Message : GitHub copilot is free for students (they need to provide supporting documents). There are some pretty amazing tools in their pipeline. I've tried their copilot chat, copilot labs tools (explain, translate, brushes etc.), Copilot for command line. All are really good

Message : https://education.github.com/pack/join

free for students
Quoted Message : I work with MSRIT Bangalore students. \n\nWant to expose them to codegen tools. Just so they know what's out there. \n\nGPT-4 is awesome but they may not pay 20$/monthly.\n\nAnyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?

Message : Point taken but an ecosystem like berkeley/bair takes decades to build !
I am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.

I recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .
https://arxiv.org/abs/2005.08209
Quoted Message : Alpaca, koala were made in days by a small team right?

Message : If only I had 4-5 AI researchers on my payroll......
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : Is this wav2lip team? This is base for SadTalker and other oss models that can easily and cheaply replace D-ID.
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : There are world class researchers building high impact projects in India, especially in academia & industrial research labs(MSR work on native languages).
we need govt backing them much more with grants & funds.

And also the insane startup energy at places like Stanford & berkeley - the same intensity is not there in india yet, but we are catching up quickly.

My dream is that somebody in the govt has the foresight to dedicate a large chunk of money & institutional effort to make India, an attractive hub of ai research - including sops & incentives to motivate researchers of indian origin outside india, to come back & start labs & companies in india.

Its a 5-10 year timeline mission, wont happen in a year or so but you need an industry, govt partnership to articulate a grand, moonshot vision & then relentlessly execute on that.

</rant> :D
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : Nirant, how does copilot compare vs replit ghostwriter ?
Quoted Message : cc @9186xxxxxxxx if students are familiar with Git and Github, Github Copilot is easiest to use.

Message : Is anyone here at the Sam Altman meet at IIIT DELHI today?

Message : This is the David Vs Goliath thing. If it was impossible, OpenAI would not have been able to stress out Google. And many other startups would not have disrupted the leaders. It happens all the time as per the history.
Quoted Message : Point taken but an ecosystem like berkeley/bair takes decades to build !\nI am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.\n\nI recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work .\nhttps://arxiv.org/abs/2005.08209

Message : https://twitter.com/huggingface/status/1666737999990730752?t=mM6813k-AXjJXMoQxLResw&s=08

Message : https://twitter.com/brijbhasin/status/1666663734385979392?s=46

Message : We've discussed this aplenty. As earlier, will ask the the next contributor to chip in with code, data or money.
Quoted Message : https://twitter.com/brijbhasin/status/1666663734385979392?s=46

Message : Hey guys, how bad were the questions that were asked to Sam Altman yesterday? Lot of people dissing on Twitter

Message : When is the iiitd chat?

Message : It‚Äôs happened. https://www.youtube.com/live/Pig9WbMN1lQ?feature=share
Quoted Message : When is the iiitd chat?

Message : not bad at all. not even a week of memes.
Quoted Message : Hey guys, how bad were the questions that were asked to Sam Altman yesterday? Lot of people dissing on Twitter

Message : Lol they're blowing out of proportion.
Quoted Message : Hey guys, how bad were the questions that were asked to Sam Altman yesterday? Lot of people dissing on Twitter

Message : Let's just put it this way - an AMA on r/India would've given us 100x interesting discussions at 99x lesser logistical costs

Message : Here comes the maestro! üòÇ
Quoted Message : not bad at all. not even a week of memes.

Message : Were the people there any AI people ki nahi?
Quoted Message : Let's just put it this way - an AMA on r/India would've given us 100x interesting discussions at 99x lesser logistical costs

Message : All I need with evening coffee is second hand embarrassment from watching this.
Quoted Message : It‚Äôs happened. https://www.youtube.com/live/Pig9WbMN1lQ?feature=share

Message : Roast of AI when?
Quoted Message : not bad at all. not even a week of memes.

Message : @91991113xxxx +1
You should do an ai themed set !

Unsolicited joke idea : humour has been hard for LLMs so far , so your job is safe, *so far* :)
Quoted Message : Roast of AI when?

Message : The IIITD session today was not bad. The moderators were pretty brutal on media and VC.

Message : The anchor was unbearable tbh. The other prof was up to the chop
Quoted Message : The IIITD session today was not bad. The moderators were pretty brutal on media and VC.

Message : The anchor was unbearable tbh. The other prof was up to the chop

Message : Knew it long back, hence in the profession. Can‚Äôt imagine a code for sarcasm
Quoted Message : @9199xxxxxxxx +1\nYou should do an ai themed set !\n\nUnsolicited joke idea : humour has been hard for LLMs so far , so your job is safe, *so far* :)

Message : Algo for badshah songs is still possible

Message : Is anyone working on converting complex-to-use software(most enterprise saas software) to chat-based interface software?
Something like what hubspot did: https://chatspot.ai/

Any resources or ideas on how to approach this?

Message : Don't worry, can't take your job since you don't get paid anyway Garv.

(This is what we call, a roast)
Quoted Message : Knew it long back, hence in the profession. Can‚Äôt imagine a code for sarcasm

Message : What makes you say so?
Quoted Message : The IIITD session today was not bad. The moderators were pretty brutal on media and VC.

Message : Ha anyone tried to solve for a contract analysis use case using AI?

Message : I randomly picked 36:00 in and was promptly amused
Quoted Message : Don't worry, can't take your job since you don't get paid anyway Garv.\n\n(This is what we call, a roast)

Message : Accidentally pre-empted

Message : Did anyone ask him what his background in AI is ?

Message : I still clearly recall the days when everyone was building a location based mobile app and Loopt was one of the also rans

Message : Yes dm-ing.
Quoted Message : Ha anyone tried to solve for a contract analysis use case using AI?

Message : It‚Äôs amazing the trajectories that are available to an take on a playground of fertile innovation

Message : you mean like adept.ai? (some demos https://twitter.com/AdeptAILabs/status/1570144499187453952 )
Quoted Message : Is anyone working on converting complex-to-use software(most enterprise saas software) to chat-based interface software?\nSomething like what hubspot did: https://chatspot.ai/\n\nAny resources or ideas on how to approach this?

Message : @91773788xxxx Do you know on what Ashish Vaswani and Niki Parmar working on after leaving adept?
Quoted Message : you mean like adept.ai? (some demos https://twitter.com/AdeptAILabs/status/1570144499187453952 )

Message : I was looking for more like ChatGPT. Everything is just chat. More or less it also solves the problem. How they are doing it?
Quoted Message : you mean like adept.ai? (some demos https://twitter.com/AdeptAILabs/status/1570144499187453952 )

Message : Nahi
Quoted Message : @9177xxxxxxxx Do you know on what Ashish Vaswani and Niki Parmar working on after leaving adept?

Message : It will interesting to see what they come up with.
Quoted Message : Nahi

Message : Would you like to more precise?
Quoted Message : Ha anyone tried to solve for a contract analysis use case using AI?

Message : If you want to highlight particular clauses in a long contract, try using squad dataset

Message : There is a paper on it, they have also trained a roberta based model for the same

Message : https://arxiv.org/abs/1606.05250

Message : Half serious, half joking q :

What if we trained a GarvGPT on all your existing videos , Insta and twitter posts, and made it "learn" Garv's "signature style " ?

Not easy, but given the pace of progress, I would say you have a  year before being GPT-ed away üòÇüòÇüòÇ
Quoted Message : Knew it long back, hence in the profession. Can‚Äôt imagine a code for sarcasm

Message : ‚Äé<attached: 00007859-PHOTO-2023-06-08-19-37-27.jpg>

Message : ‚Äé<attached: 00007860-GIF-2023-06-08-19-39-36.mp4>
Quoted Message :  2023_06_08_3EB077B519EB0590E91B96.jpeg


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I was looking for more like ChatGPT. Everything is just chat. More or less it also solves the problem. How they are doing it?
Quoted Message : you mean like adept.ai? (some demos https://twitter.com/AdeptAILabs/status/1570144499187453952 )

Message : Nahi
Quoted Message : @9177xxxxxxxx Do you know on what Ashish Vaswani and Niki Parmar working on after leaving adept?

Message : It will interesting to see what they come up with.
Quoted Message : Nahi

Message : Would you like to more precise?
Quoted Message : Ha anyone tried to solve for a contract analysis use case using AI?

Message : If you want to highlight particular clauses in a long contract, try using squad dataset

Message : There is a paper on it, they have also trained a roberta based model for the same

Message : https://arxiv.org/abs/1606.05250

Message : Half serious, half joking q :

What if we trained a GarvGPT on all your existing videos , Insta and twitter posts, and made it "learn" Garv's "signature style " ?

Not easy, but given the pace of progress, I would say you have a  year before being GPT-ed away üòÇüòÇüòÇ
Quoted Message : Knew it long back, hence in the profession. Can‚Äôt imagine a code for sarcasm

Message : ‚Äé<attached: 00007859-PHOTO-2023-06-08-19-37-27.jpg>

Message : ‚Äé<attached: 00007860-GIF-2023-06-08-19-39-36.mp4>
Quoted Message :  2023_06_08_3EB077B519EB0590E91B96.jpeg

Message : We are building a gpt bot that can have multi-turn conversation with the user based on a given text document. 

What are some ways for the bot to ask cross questions from the user after the initial query from the user so that the bot can get more context about the query and answer better.
For example, the doc is about vpn issues but has some points different for mac vs windows. The user in its first instance doesnt specify the OS. But the bot asks a cross question asking for the OS before giving the solution to user's query.
The actual bot is more advanced but I have simplified the description to focus on the problem at hand.

Message : Dropped in to joke on the same but beaten by your meme.
Quoted Message :  2023_06_08_7D733A8227D138A84332F31F25138B12.mp4

Message : If I am unfunny, model trained on me will be unfunny too

You could generate content that sounds like me, but for it to be funny, it depends on other people also. Like even I can only say with 50% accuracy that it will be funny.

To make it easier, videos are less, i can give a few hundred pages of what I have written in last 8 years and see if we can do text funny
Quoted Message : Half serious, half joking q :\n\nWhat if we trained a GarvGPT on all your existing videos , Insta and twitter posts, and made it \"learn\" Garv's \"signature style \" ?\n\nNot easy, but given the pace of progress, I would say you have a  year before being GPT-ed away üòÇüòÇüòÇ

Message : here's my 2s prompt...
Quoted Message : We are building a gpt bot that can have multi-turn conversation with the user based on a given text document. \n\nWhat are some ways for the bot to ask cross questions from the user after the initial query from the user so that the bot can get more context about the query and answer better. \nFor example, the doc is about vpn issues but has some points different for mac vs windows. The user in its first instance doesnt specify the OS. But the bot asks a cross question asking for the OS before giving the solution to user's query. \nThe actual bot is more advanced but I have simplified the description to focus on the problem at hand.

Message : You are a support bot answering technical support questions about networking.

A user has raised an issue about her VPN not working. In order to resolve this issue, what other information would be needed by you?

Message : and here's the response

Message : To effectively troubleshoot your VPN issue, I would need the following information:

1. **VPN Service Provider**: The name of the company or organization that provides your VPN service.

2. **Error Message or Description of the Issue**: If there are any error messages appearing when you try to connect to your VPN, please provide them. If there are no specific error messages, a detailed description of what happens when you try to connect would be helpful.

3. **Device and Operating System**: Information about the device and the operating system you are using. For instance, are you using Windows, macOS, Linux, iOS, Android, etc.? What is the version of the operating system?

4. **Network Information**: Are you using a home network, public Wi-Fi, or mobile data? Some networks may have restrictions that affect VPN usage.

5. **Location**: The country or region you are in may have specific laws or restrictions that affect VPN usage.

6. **VPN Software Version**: The version of the VPN software you are using.

7. **When the issue started**: Did the issue start recently? Or has the VPN never worked on your device? Did any specific event coincide with the start of the issue, such as a software update or change in network settings?

8. **Troubleshooting Steps Already Tried**: Have you tried any solutions already? What were the results? This can help avoid suggesting steps you've already taken.

Remember to never share sensitive information like passwords or specific IP addresses when seeking support.

Message : there you have it ... üôÇ

Message : Here's how I would design something for the challenge, just for the kick:

* I would take your data and instruction-tune alpaca based on your jokes.
* Let the AI produce 50-60 segments of jokes. Then take feedback on these jokes by RLHFF (Reinforcement laughter where Human finds Funny)

Then based on the funniest segments, we'll present a short set.
Quoted Message : If I am unfunny, model trained on me will be unfunny too\n\nYou could generate content that sounds like me, but for it to be funny, it depends on other people also. Like even I can only say with 50% accuracy that it will be funny. \n\nTo make it easier, videos are less, i can give a few hundred pages of what I have written in last 8 years and see if we can do text funny

Message : Would loove to see results. Can i DM you

Message : Yes. What sort of analysis
Quoted Message : Ha anyone tried to solve for a contract analysis use case using AI?

Message : üòÇ sure.
Quoted Message : Would loove to see results. Can i DM you

Message : https://www.linkedin.com/posts/rishi-sunak_as-the-world-grapples-with-the-challenges-activity-7072467476185243648-ttl8?utm_source=share&utm_medium=member_desktop

Message : Seems Rishi Sunak is directly Taking some AI lessons from Sir Narayan Murthy, father-in-law to rishi sunak

Message : I would love to join in on the effort Abhishek ! 
Sounds like a fun project to work on !
Quoted Message : Here's how I would design something for the challenge, just for the kick:\n\n* I would take your data and instruction-tune alpaca based on your jokes. \n* Let the AI produce 50-60 segments of jokes. Then take feedback on these jokes by RLHFF (Reinforcement laughter where Human finds Funny)\n\nThen based on the funniest segments, we'll present a short set.

Message : I also want to know what these folks are doing: https://samaya.ai/

Maithra is from the same bunch of researchers who left Brain
Quoted Message : It will interesting to see what they come up with.

Message : @91833389xxxx
Quoted Message : Ha anyone tried to solve for a contract analysis use case using AI?

Message : i would like to see a benchmark of this finetuned model..versus a non-finetuned model with jokes in a vector db/embeddings. and just using retrieval q&a
Quoted Message : Here's how I would design something for the challenge, just for the kick:\n\n* I would take your data and instruction-tune alpaca based on your jokes. \n* Let the AI produce 50-60 segments of jokes. Then take feedback on these jokes by RLHFF (Reinforcement laughter where Human finds Funny)\n\nThen based on the funniest segments, we'll present a short set.

Message : Who wants to volunteer to do the RLHF ? :)
Quoted Message : i would like to see a benchmark of this finetuned model..versus a non-finetuned model with jokes in a vector db/embeddings. and just using retrieval q&a

Message : If there are people willing to do the comparisons, I can help out with RLHF training part. We will need large amount of comparisons.
Quoted Message : Who wants to volunteer to do the RLHF ? :)

Message : I am familiar with solutions using symbolic representation and DSLs to some extent. With gen AI, i have seen people make plugins that use openai APIs to simplify clauses.

As a patent freelancer who has done some work with contracts, I feel there are several problems that would require different approaches. Which specific problem are you working on?

Feel free to DM me for a longer discussion
Quoted Message : Ha anyone tried to solve for a contract analysis use case using AI?

Message : I was thinking of using Deepspeed chat for this. But haven't put it into use yet. Do you have other methods in mind?
Quoted Message : If there are people willing to do the comparisons, I can help out with RLHF training part. We will need large amount of comparisons.

Message : I had written scripts to train with RLHF. Writing these scripts directly or using deepspeed chat or TRLX is comparatively easy task. To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring. Also quality of SFT model determines how many comparisons we need. Sometimes both comparisons are bad and have to throw them away after evaluating.

Message : Yeah we won't have that many sets of instruction response pairs for this task in the first place. I don't think we'll get even 1000 instruction-joke pairs on this. Most of the content would also be in Hinglish and some work would need to be done to make it fit for the instruction tuning.

I'll probably DM you around the time I'm done with the initial part.
Quoted Message : I had written scripts to train with RLHF. Writing these scripts directly or using deepspeed chat or TRLX is comparatively easy task. To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring. Also quality of SFT model determines how many comparisons we need. Sometimes both comparisons are bad and have to throw them away after evaluating.

Message : > To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring

DPO/Pairwise Ranking losses help?

> SFT model determines how many comparisons we need
> Have a heuristic e.g. this good vs this many comparisons?

Want to explain SFT for wider readers?

Message : This ui should have a positive affirmation message after every few annotations to keep the motivating
Quoted Message : > To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring\n\nDPO/Pairwise Ranking losses help?\n\n> SFT model determines how many comparisons we need\n> Have a heuristic e.g. this good vs this many comparisons?\n\nWant to explain SFT for wider readers?

Message : Motivation *

Message : https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence

Message : I haven't read the SLiC-HF paper yet. So can't comment on Pairwise Ranking. With DPO, they don't mention if DPO - Direct Preference Optimisation reduces sample complexity(number of comparisons needed to train equivalent of RLHF model.) But they do claim training with DPO is stable. So am guessing we might be able to do with 10 - 25% less samples. (Pure speculation from my side).
Quoted Message : > To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring\n\nDPO/Pairwise Ranking losses help?\n\n> SFT model determines how many comparisons we need\n> Have a heuristic e.g. this good vs this many comparisons?\n\nWant to explain SFT for wider readers?

Message : SFT is supervised finetuning. Alpaca model is an SFT model built on top of Llama model. With SFT, we take the base language model (like Llama) and then finetune it on few thousands of prompt- response pairs. If we want our SFT model to follow instructions, we would curate few thousand examples like this - "Prompt": "Explain the moon landing to a 6 year old"; "Response": "People went to the moon, took photos and sent them back to the earth.". If we want SFT models to be chat models, we will keep the previous chat history in prompt and in response, we will add  whatever reply would be given to the last message in chat. SFT is effective when we have > 1000 examples; but can be useful with >100 examples too. If we have a good enough SFT model(Most outputs are at least somewhat funny), around 1000 - 2000 comparisons should be enough to see the magic of RLHF. (But here we will be operating with Jokes; so hard to predict.)
Quoted Message : > To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring\n\nDPO/Pairwise Ranking losses help?\n\n> SFT model determines how many comparisons we need\n> Have a heuristic e.g. this good vs this many comparisons?\n\nWant to explain SFT for wider readers?

Message : Btw for those interested in papers about Reasoning ‚Ä¶ this is Disneyland üòÄ https://github.com/atfortes/LLM-Reasoning-Papers

Message : Just a suggestion: you can maybe instruction tune falcon (as it's license is permissible)  and use self instruct like alpaca to  generate a dataset. This may save you a lot of time.
Quoted Message : Yeah we won't have that many sets of instruction response pairs for this task in the first place. I don't think we'll get even 1000 instruction-joke pairs on this. Most of the content would also be in Hinglish and some work would need to be done to make it fit for the instruction tuning.\n\nI'll probably DM you around the time I'm done with the initial part.

Message : For this specific task, we actually need Garv's stand up or other similar comic sets as content. Generating content via api distillation won't help here as we need exactly one specific users style to be copied.

Otherwise it's straightforward to use alpaca style fine tuning using GPT3/4 generated content.

For Falcon, I've not yet explored it for fine tuning. I'll do it soon as now even the 7B version is out.
Quoted Message : Just a suggestion: you can maybe instruction tune falcon (as it's license is permissible)  and use self instruct like alpaca to  generate a dataset. This may save you a lot of time.

Message : new wrapper: simpleaichat

"I built simpleaichat out of sheer frustration with LangChain and aim to make it the easiest way to make AI apps."

https://twitter.com/minimaxir/status/1666828520981692416

https://github.com/minimaxir/simpleaichat

Message : https://twitter.com/francis_yao_/status/1666833311279517696?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Yao Fu et. a. found out prompts which gave accuracy of around 61 % on MMLU. Llama paper claims 63 % accuracy; but the best accuracy reported with open source prompts using Llama on MMLU was 48% till now. So Llama models are mostly as good as claimed by authors.

Message : Occam's razor!

https://twitter.com/dimitrispapail/status/1666843952824168465?s=48&t=FvScmWlwJalkIndmUHhjjQ

Message : ‚Äé<attached: 00007899-PHOTO-2023-06-09-01-03-39.jpg>

Message : Not sure of Jason's intent though but ‚ù§Ô∏èüî•

Message : It should be called Everest Project instead of Manhattan.

Message : dozen manhattan projects is a wild claim. doubt if he's being sarcastic.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Btw for those interested in papers about Reasoning ‚Ä¶ this is Disneyland üòÄ https://github.com/atfortes/LLM-Reasoning-Papers

Message : Just a suggestion: you can maybe instruction tune falcon (as it's license is permissible)  and use self instruct like alpaca to  generate a dataset. This may save you a lot of time.
Quoted Message : Yeah we won't have that many sets of instruction response pairs for this task in the first place. I don't think we'll get even 1000 instruction-joke pairs on this. Most of the content would also be in Hinglish and some work would need to be done to make it fit for the instruction tuning.\n\nI'll probably DM you around the time I'm done with the initial part.

Message : For this specific task, we actually need Garv's stand up or other similar comic sets as content. Generating content via api distillation won't help here as we need exactly one specific users style to be copied.

Otherwise it's straightforward to use alpaca style fine tuning using GPT3/4 generated content.

For Falcon, I've not yet explored it for fine tuning. I'll do it soon as now even the 7B version is out.
Quoted Message : Just a suggestion: you can maybe instruction tune falcon (as it's license is permissible)  and use self instruct like alpaca to  generate a dataset. This may save you a lot of time.

Message : new wrapper: simpleaichat

"I built simpleaichat out of sheer frustration with LangChain and aim to make it the easiest way to make AI apps."

https://twitter.com/minimaxir/status/1666828520981692416

https://github.com/minimaxir/simpleaichat

Message : https://twitter.com/francis_yao_/status/1666833311279517696?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Yao Fu et. a. found out prompts which gave accuracy of around 61 % on MMLU. Llama paper claims 63 % accuracy; but the best accuracy reported with open source prompts using Llama on MMLU was 48% till now. So Llama models are mostly as good as claimed by authors.

Message : Occam's razor!

https://twitter.com/dimitrispapail/status/1666843952824168465?s=48&t=FvScmWlwJalkIndmUHhjjQ

Message : ‚Äé<attached: 00007899-PHOTO-2023-06-09-01-03-39.jpg>

Message : Not sure of Jason's intent though but ‚ù§Ô∏èüî•

Message : It should be called Everest Project instead of Manhattan.

Message : dozen manhattan projects is a wild claim. doubt if he's being sarcastic.

Message : The Manhattan project was 0.9% of US GDP. Rounding to 1% that's a hilarious amount to spend to spite a bay area visitor
Quoted Message : dozen manhattan projects is a wild claim. doubt if he's being sarcastic.

Message : Our USP has always been great quality at low price (ex. Mangalyaan), it makes more sense in the Indian context to work on efficient training and inference.

Imagine you get GPT-4 level quality at a fraction of the price

Message : Not sarcasm. I think he doesn‚Äôt like OpenAI and Sama, since he was banned from YC demo days.
Quoted Message : dozen manhattan projects is a wild claim. doubt if he's being sarcastic.

Message : these guys and their vendettas lol.

Message : This is my review of the orca paper. Currently upto the result section
https://shadowed-season-d38.notion.site/Orca-paper-Explained-136fbed4b1cc40e28f56fdab2755b6fd?pvs=4

The link to original paper
https://arxiv.org/pdf/2306.02707.pdf

If anyone has read the paper, feel free to suggest feedbacks on this. This was partially written with the help of GPT-4

Message : unfortunately, he's elon musk's echo chamber
Quoted Message : these guys and their vendettas lol.

Message : also - chamath is a part of the all in podcast so who knows rofl.

Message : I hope some outsourcing sweatshop doesn‚Äôt convince government to spend a lot on some illusive AI Manhattan project that may become out dated in 3-4 weeks.

Message : Don‚Äôt give ideas
Quoted Message : I hope some outsourcing sweatshop doesn‚Äôt convince government to spend a lot on some illusive AI Manhattan project that may become out dated in 3-4 weeks.

Message : Hello Everyone, my name is Brij Singh and I'm a General Partner at Rebright Partners an India-Japan Cross Border VC Fund. We have invested in startups like Inshorts, Medibuddy, Jiffy.ai etc. I'm the one that made the Twitter post yesterday on Emerging OSS Fellowship Program / Fund, which was posted on this group by my colleague @91995246xxxx who is a Sr. Data Science Associate at our Fund. I was not part of this WA Group at that time and couldn't participate in the discussion, but happy to answer any questions here now. Since yesterday, we have had about 20 folks reach out from the community and will be meeting them over the coming weeks to see how we can support some of them.

Message : Also, I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and the lack of FM's in India of equivalent capability. 

Perhaps a few valiant efforts using OSS alternatives as a base will be able to match it in the next 6-12 months. However, SamaA has repeated time and again that his and OpenAI's sole mission is to invent Artificial General Intelligence (AGI), and all their activities GPT4, ChatGPT, Tools, monetization, and Microsoft Partnerships are just meant to that end.

Hence, if we truly wish to compete, we must go where the puck will be down the line, and not where it is today. The 3 most important ingredients for that goal are People, Data, and Compute, which is why OpenAI had to sell out its original vision of being truly "Open" and raise from Microsoft. But given the pace of innovation over the last few months, there might be some alternative paths for a country like ours, assuming there will be no large pools of capital available from VCs, Ultra HNI's, or the Govt.

50 years ago, we achieved a major feat in the Nuclear race, Project Smiling Buddha. A scrappy team of Indian Scientists conducted our very first test of an Atomic Bomb, under utmost secrecy and against immense pressure from the Americans. Perhaps, what is needed today is a similar effort, but we need not be defensive about it, or do it under secret. But a response must be made, especially to something that could be an existential threat. Coming back to the 3 most important ingredients - People, Data and Compute. Perhaps this could be a way ‚Äì

** Project Laughing Buddha **

A nationwide effort to create India's version of truly Open Protocols based Foundational Models with an explicitly stated goal towards Artificial General Intelligence, which could perhaps be through a combination of hundreds of Foundational Models, instead of one large one.
- The project code, weights & temperatures of FMs are in the public domain, and ownership

- Team of 1000 of India's top AI Researchers, Data Scientists, ML Engineers, and RLHF Engineers organized through best Open Source practices - Decentralised GPU compute donated through millions of idle devices by Indian citizens aggregated through nodes akin to the SETI Project

- Datasets for training that are donated by leading Startups, Citizen Groups, Open Govt Data, and Citizens

If it is successful, we could perhaps protect our Data and AI Sovereignty and provide the foundations necessary for 100K Startups to build and scale on top, without being subservient to other organizations or countries.

Message : Success of such a plan hinges on someone in the government convinced of the stratwgic need to do the *right* things now , so India is well placed in the global ai economy in the next 5-10 years.

As happens often in India, teh govery will be a bit of a laggard. But efforts like Bhashini( ai4 Bharat, Nilekani centre at IIT Madras), give me a little bit of hope.

My prediction is that industry and academia in India will take the lead in open source ml research & innovation, despite a lack of concerted efforts from the government.

Finally on the hardware and compute needs of the future, I hope the Indiqn government can strike strategic partnerships with TSMC and Nvidia, among others to eataish facilities in India.
My final prediction is Nvidia will rule the roost but a new wave of fabless GPU designers and cloud providers will emerge all.over the world. We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !
Quoted Message : Also, I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and the lack of FM's in India of equivalent capability. \n\nPerhaps a few valiant efforts using OSS alternatives as a base will be able to match it in the next 6-12 months. However, SamaA has repeated time and again that his and OpenAI's sole mission is to invent Artificial General Intelligence (AGI), and all their activities GPT4, ChatGPT, Tools, monetization, and Microsoft Partnerships are just meant to that end. \n\nHence, if we truly wish to compete, we must go where the puck will be down the line, and not where it is today. The 3 most important ingredients for that goal are People, Data, and Compute, which is why OpenAI had to sell out its original vision of being truly \"Open\" and raise from Microsoft. But given the pace of innovation over the last few months, there might be some alternative paths for a country like ours, assuming there will be no large pools of capital available from VCs, Ultra HNI's, or the Govt. \n\n50 years ago, we achieved a major feat in the Nuclear race, Project Smiling Buddha. A scrappy team of Indian Scientists conducted our very first test of an Atomic Bomb, under utmost secrecy and against immense pressure from the Americans. Perhaps, what is needed today is a similar effort, but we need not be defensive about it, or do it under secret. But a response must be made, especially to something that could be an existential threat. Coming back to the 3 most important ingredients - People, Data and Compute. Perhaps this could be a way ‚Äì \n\n** Project Laughing Buddha ** \n\nA nationwide effort to create India's version of truly Open Protocols based Foundational Models with an explicitly stated goal towards Artificial General Intelligence, which could perhaps be through a combination of hundreds of Foundational Models, instead of one large one. \n- The project code, weights & temperatures of FMs are in the public domain, and ownership \n\n- Team of 1000 of India's top AI Researchers, Data Scientists, ML Engineers, and RLHF Engineers organized through best Open Source practices - Decentralised GPU compute donated through millions of idle devices by Indian citizens aggregated through nodes akin to the SETI Project \n\n- Datasets for training that are donated by leading Startups, Citizen Groups, Open Govt Data, and Citizens \n\nIf it is successful, we could perhaps protect our Data and AI Sovereignty and provide the foundations necessary for 100K Startups to build and scale on top, without being subservient to other organizations or countries.

Message : On this point, how are we doing building Hindi or Kannada Language Models, is important.
Quoted Message : Success of such a plan hinges on someone in the government convinced of the stratwgic need to do the *right* things now , so India is well placed in the global ai economy in the next 5-10 years.\n\nAs happens often in India, teh govery will be a bit of a laggard. But efforts like Bhashini( ai4 Bharat, Nilekani centre at IIT Madras), give me a little bit of hope.\n\nMy prediction is that industry and academia in India will take the lead in open source ml research & innovation, despite a lack of concerted efforts from the government.\n\nFinally on the hardware and compute needs of the future, I hope the Indiqn government can strike strategic partnerships with TSMC and Nvidia, among others to eataish facilities in India.\nMy final prediction is Nvidia will rule the roost but a new wave of fabless GPU designers and cloud providers will emerge all.over the world. We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !

Message : IndicLM is Least important thing in the stack rank of hard and valuable things: 

Limited academic value and no commercial utility.

It's a false flag and we should not be sidetracked in such misguided pursuits
Quoted Message : On this point, how are we doing building Hindi or Kannada Language Models, is important.

Message : https://ai4bharat.org/
Quoted Message : On this point, how are we doing building Hindi or Kannada Language Models, is important.

Message : Doesn‚Äôt token cost matter for the complexity of applications to be built given fixed context windows?
Quoted Message : IndicLM is Least important thing in the stack rank of hard and valuable things: \n\nLimited academic value and no commercial utility. \n\nIt's a false flag and we should not be sidetracked in such misguided pursuits

Message : Although, as the context windows increase to 30k+, for a general purpose use-cases it shouldn‚Äôt matter I guess.

Message : I would partially disagree. 
To build end user ai digital public goods, this is important.

e.g. Conaider a healthcare usecase : a DoctorGPT Chatbot , available as a WhatsApp or even SMS not( to run on cheap feature phones) which does high level traige of medical symptoms for under served populations ideally should have a native language voice input.

Quality of native language speech to text and translation to English are important problems for applications like this, no ?
Quoted Message : IndicLM is Least important thing in the stack rank of hard and valuable things: \n\nLimited academic value and no commercial utility. \n\nIt's a false flag and we should not be sidetracked in such misguided pursuits

Message : Which Hindi application do you've on your phone which you:

1) use for more than 10 minutes a day
2) pay more than $10/mo?
Quoted Message : Doesn‚Äôt token cost matter for the complexity of applications to be built given fixed context windows?

Message : Also, this entire chat is English

Message : Isn't that purely a translation problem? Why does the base model need to be trained in different languages?
Quoted Message : I would partially disagree. \nTo build end user ai digital public goods, this is important.\n\ne.g. Conaider a healthcare usecase : a DoctorGPT Chatbot , available as a WhatsApp or even SMS not( to run on cheap feature phones) which does high level traige of medical symptoms for under served populations ideally should have a native language voice input.\n\nQuality of native language speech to text and translation to English are important problems for applications like this, no ?

Message : I don‚Äôt but the number of regional content apps are exploding in India.
Quoted Message : Which Hindi application do you've on your phone which you:\n\n1) use for more than 10 minutes a day\n2) pay more than $10/mo?

Message : I would strongly disagree that there are no use-cases for local languages. I assumed what‚Äôs being argued is the ROI for improving efficiency.

Message : I'll pause now, I just woke up on the wrong side of bed. I've spent some fraction of my youth on this and realised there is no money, respect, at best there is some social currency in doing so. Perhaps, I'm just a bit sour.

Message : Language is accessibility

Message : I don‚Äôt disagree on that at all. People who will pay for digital goods and can‚Äôt use English is a very small market.
Quoted Message : I'll pause now, I just woke up on the wrong side of bed. I've spent some fraction of my youth on this and realised there is no money, respect, at best there is some social currency in doing so. Perhaps, I'm just a bit sour.

Message : People can derive value of these, if there will be paid use-cases are not is for entrepreneurs and VCs to take a bet on.

Message : Let me be clear, I am certainly not one of them.

Message : Throw bricks on me but IMO it‚Äôs also a misguided thought process and effort. Build another windows also, another google also, another AWS also ‚Ä¶ keep playing catch up? What‚Äôs the point? Far better to innovate than to copy. Then these people go out and call themselves Thought Leaders. Sick.
Quoted Message :  2023_06_09_C1EF3E398FACAB69EFCE8E7E16610BE7.jpeg

Message : Amazing podcast translation to Hindi ‚Äî maybe if you feel so much about it, invite him here and upvote on PH. He's an indiehacker, I don't know him and no affiliation whatsoever

https://www.producthunt.com/posts/translateaudio

Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : Yes. Seen this first hand.
Quoted Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : What would a 1/3/5 year execution path look for this - 

We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !
Quoted Message : Success of such a plan hinges on someone in the government convinced of the stratwgic need to do the *right* things now , so India is well placed in the global ai economy in the next 5-10 years.\n\nAs happens often in India, teh govery will be a bit of a laggard. But efforts like Bhashini( ai4 Bharat, Nilekani centre at IIT Madras), give me a little bit of hope.\n\nMy prediction is that industry and academia in India will take the lead in open source ml research & innovation, despite a lack of concerted efforts from the government.\n\nFinally on the hardware and compute needs of the future, I hope the Indiqn government can strike strategic partnerships with TSMC and Nvidia, among others to eataish facilities in India.\nMy final prediction is Nvidia will rule the roost but a new wave of fabless GPU designers and cloud providers will emerge all.over the world. We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !

Message : Education - that's the most important I think
Quoted Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : and banking, ads, entertainment
Quoted Message : Education - that's the most important I think

Message : I am personally working on Software Development using AI; but if I have to choose one field where I truly believe AI should and can create the largest impact, it has to be Education

Message : We can now create personalized education for every kid

Message : In the future, I hope AI takes care of teaching and teachers take care of the personal & emotional wellbeing of kids

Message : Education is part knowledge transfer, part motivation, and part well being. Our teachers today, especially in rural areas barely have bandwidth for knowledge transfer.... let alone motivation or wellbeing.

Message : If putting $1B per state is going to create a model that is "effective" in that language, it would totally worth government spend.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : Yes. Seen this first hand.
Quoted Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : What would a 1/3/5 year execution path look for this - 

We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !
Quoted Message : Success of such a plan hinges on someone in the government convinced of the stratwgic need to do the *right* things now , so India is well placed in the global ai economy in the next 5-10 years.\n\nAs happens often in India, teh govery will be a bit of a laggard. But efforts like Bhashini( ai4 Bharat, Nilekani centre at IIT Madras), give me a little bit of hope.\n\nMy prediction is that industry and academia in India will take the lead in open source ml research & innovation, despite a lack of concerted efforts from the government.\n\nFinally on the hardware and compute needs of the future, I hope the Indiqn government can strike strategic partnerships with TSMC and Nvidia, among others to eataish facilities in India.\nMy final prediction is Nvidia will rule the roost but a new wave of fabless GPU designers and cloud providers will emerge all.over the world. We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !

Message : Education - that's the most important I think
Quoted Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : and banking, ads, entertainment
Quoted Message : Education - that's the most important I think

Message : I am personally working on Software Development using AI; but if I have to choose one field where I truly believe AI should and can create the largest impact, it has to be Education

Message : We can now create personalized education for every kid

Message : In the future, I hope AI takes care of teaching and teachers take care of the personal & emotional wellbeing of kids

Message : Education is part knowledge transfer, part motivation, and part well being. Our teachers today, especially in rural areas barely have bandwidth for knowledge transfer.... let alone motivation or wellbeing.

Message : If putting $1B per state is going to create a model that is "effective" in that language, it would totally worth government spend.

Message : Knowledge gap assessment and Interactive textbooks are perhaps the early applications in this area.
Quoted Message : We can now create personalized education for every kid

Message : Something like khanmigo from Khan academy

Message : BTW Microsoft is selling this hard to all Education Ministries across the world. I do see this coming in soon.

Message : @658752xxxx there has been a growing consensus among all today at the lack of innovation in Education. AI and special a combination of Generative and Reinforcement AI strategies could bring that and truly d√©mocratise Education. The internet and mobile have brought a giant leap in this case but education from a personal touch point is truly something that would change this sector
Quoted Message : Education is part knowledge transfer, part motivation, and part well being. Our teachers today, especially in rural areas barely have bandwidth for knowledge transfer.... let alone motivation or wellbeing.

Message : We have been working on student assessment and evaluation. Deepsy.in.
Quoted Message : Knowledge gap assessment and Interactive textbooks are perhaps the early applications in this area.

Message : Just a hello. I am heading the AI division at IHX a startup in the healthcare domain https://www.ihx.in/ Ine of our major products is Claims Management and processing. We have just started looking into LLMs as a tool for information extraction especially from discharge summaries. Will keep you all posted ‚Ä¶

Message : Is this a B2B or B2C approach?
Quoted Message : We have been working on student assessment and evaluation. Deepsy.in.

Message : Also, usefulness of language modelsl also follow the data and as our data becomes more valuable or useful, models will have to perform with those languages? Not sure where this will end up at.
Quoted Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : I did something adjacent for an East Coast dentist chain. Info extraction with LLMs is quite robust and powerful
Quoted Message : Just a hello. I am heading the AI division at IHX a startup in the healthcare domain https://www.ihx.in/ Ine of our major products is Claims Management and processing. We have just started looking into LLMs as a tool for information extraction especially from discharge summaries. Will keep you all posted ‚Ä¶

Message : B2B. We are working with our first customers - univs and ed-tech.
Quoted Message : Is this a B2B or B2C approach?

Message : This is very interesting a combination of this with a recommendation engine for course plans would be very interesting for any parent. B2C .  Especially in core subjects
Quoted Message : We have been working on student assessment and evaluation. Deepsy.in.

Message : How good are your qualitative scores? Is there a demo I can see?
Quoted Message : We have been working on student assessment and evaluation. Deepsy.in.

Message : Dm-ing to set up.
Quoted Message : How good are your qualitative scores? Is there a demo I can see?

Message : Yes. :) Now it's been one day at a time.
Quoted Message : This is very interesting a combination of this with a recommendation engine for course plans would be very interesting for any parent. B2C .  Especially in core subjects

Message : Everything Rural has demand for language, not just India, as we getting calls from many countries to build similar platform for their languages and knowledge base. I personally see good translator models to be better solution around Indic language  problem while keep English to train LLM to achieve SOTA perf. Any subpar model will never be used in Production.
Quoted Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : One question is, is their unique training material in Indic languages that would make the training worthwhile 

Different grammar structures, knowledge patterns, and it changes the behaviour of LLMs?
Quoted Message : Everything Rural has demand for language, not just India, as we getting calls from many countries to build similar platform for their languages and knowledge base. I personally see good translator models to be better solution around Indic language  problem while keep English to train LLM to achieve SOTA perf. Any subpar model will never be used in Production.

Message : Of course it‚Äôs a different thing if training data at that level exists/is accessible easily
Quoted Message : One question is, is their unique training material in Indic languages that would make the training worthwhile \n\nDifferent grammar structures, knowledge patterns, and it changes the behaviour of LLMs?

Message : Money maybe no.
Respect and greater social impact of ai digital public goods - yes !

The  utopian optimist in me sees a future where high quality indic models enable a lot of non-profit /govt run public goods ( ala Aadhaar, abdm )

But I defer to your actual experience in this field compared to my armchair imagining :D
p.s. we should talk sometime about your experience building these in your youth
Quoted Message : I'll pause now, I just woke up on the wrong side of bed. I've spent some fraction of my youth on this and realised there is no money, respect, at best there is some social currency in doing so. Perhaps, I'm just a bit sour.

Message : I think someone mentioned it in passing. If we think of this as a machine translation problem then the source could always be English but you could rather work on an interface around an LLM based solution.

Message : Localisation happens at the interface level

Message : How many people have tried Bhasini models and here and how many use in production. Even we can start with ggerganov like efforts and improve performance of those models. Optimized Bhasini have many out of box production use case than LLaMa, IMO.

Message : Just stumbled onto this demo on twitter.

Imagine this demo happening in an Indian kid‚Äòs native language !

https://twitter.com/amasad/status/1666889016527163392?s=46&t=pt9BgXoRTmqx5FEPyAl9bg
Quoted Message : We can now create personalized education for every kid

Message : ‚Äé<attached: 00007966-PHOTO-2023-06-09-09-25-02.jpg>
Quoted Message : Just stumbled onto this demo on twitter.\n\nImagine this demo happening in an Indian kid‚Äòs native language !\n\nhttps://twitter.com/amasad/status/1666889016527163392?s=46&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Demand is huge in rural areas for Indic languages but building B2C revenue generation channels might be hard. 

For what it's worth, current SoTA performance lies here only - GPT3/4 + whisper GGML or elevenlabs.io. Primarily because we don't have a decent substitute yet that can have GPT3 level performance to interact with a human.

Once that happens, a lot of value is going to come out of just SoTA translate + SoTA STT + English OSS LLM.
Quoted Message : Everything Rural has demand for language, not just India, as we getting calls from many countries to build similar platform for their languages and knowledge base. I personally see good translator models to be better solution around Indic language  problem while keep English to train LLM to achieve SOTA perf. Any subpar model will never be used in Production.

Message : This is game changing. I personally never liked our sheep (coaching) farms, and this will focus on individuals and their strength.
Quoted Message : Just stumbled onto this demo on twitter.\n\nImagine this demo happening in an Indian kid‚Äòs native language !\n\nhttps://twitter.com/amasad/status/1666889016527163392?s=46&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Let me check what's the underlying architecture for Bhashini, if it's anything ggml already supports like GPT J or GPT Neo, something can be done right away.
Quoted Message : How many people have tried Bhasini models and here and how many use in production. Even we can start with ggerganov like efforts and improve performance of those models. Optimized Bhasini have many out of box production use case than LLaMa, IMO.

Message : I‚Äôm not going to go against Nirant‚Äôs policy to self promote, but it is happening and I‚Äôm overwhelmed with customers interest. If we stop focusing on building cheap copies and get head out of Tier1 cities, we have so many things to do. Of course, one shouldn‚Äôt expect to be a unicorn in few years, but when ‚ÄòBharat‚Äô picks up China like income growth, these fields will explode.
Quoted Message : Demand is huge in rural areas for Indic languages but building B2C revenue generation channels might be hard. \n\nFor what it's worth, current SoTA performance lies here only - GPT3/4 + whisper GGML or elevenlabs.io. Primarily because we don't have a decent substitute yet that can have GPT3 level performance to interact with a human.\n\nOnce that happens, a lot of value is going to come out of just SoTA translate + SoTA STT + English OSS LLM.

Message : Is it weird if my brain is imagining children jailbreaking this tutor to get it to say censored stuff and posting it on insta üòÖ?
Quoted Message : Just stumbled onto this demo on twitter.\n\nImagine this demo happening in an Indian kid‚Äòs native language !\n\nhttps://twitter.com/amasad/status/1666889016527163392?s=46&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Do it. An optimized Bhasini can open up so many flood gates, even independent startup for API based STT, TTS and Translator. Cloud translators APIs are expensive.
Quoted Message : Let me check what's the underlying architecture for Bhashini, if it's anything ggml already supports like GPT J or GPT Neo, something can be done right away.

Message : Good one. With elections coming maybe it can be a digital infra. Last elections WhatsApp volumes were huge. Maybe this time all voters will get personalised videos ü§´‚Ä¶..
Quoted Message : Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.

Message : There's no getting around alternative uses and abuses of new technology of any kind.
Quoted Message : Good one. With elections coming maybe it can be a digital infra. Last elections WhatsApp volumes were huge. Maybe this time all voters will get personalised videos ü§´‚Ä¶..

Message : Yup. How you use a knife is totally fair.

Wasn‚Äôt even saying in a negative tone. Just in fact that it‚Äôs a fair and valid marketing use case. If anyone wants to seriously build it, call me up. Let‚Äôs do something hacky
Quoted Message : There's no getting around alternative uses and abuses of new technology of any kind.

Message : IndicLLM even if not the most powerful is important for equitable outcomes for everyone. Back when I was at make a difference, one of the biggest problem we faced while teaching shelter home kids who aren‚Äôt from background like ours was their inability to interpret in english as well as they could do in their native language. Ofcourse there is no money - but it is of national importance.

Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.

Probably more value will be there in
1. Falcon/llama + fine-tuning chat datasets for at least one Indian language
2. Waiting for something that's trained on Indic stuff in the first place and is open.

First one has good demo level perf. but it's limited in many ways. Second is not there yet.

I can see probably why we haven't made much progress on individual level in this area.

Message : Got a link/source for the technical architecture/stack of Bhashini ?
Their website didn't have much info
Quoted Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.\n\nProbably more value will be there in \n1. Falcon/llama + fine-tuning chat datasets for at least one Indian language\n2. Waiting for something that's trained on Indic stuff in the first place and is open.\n\nFirst one has good demo level perf. but it's limited in many ways. Second is not there yet. \n\nI can see probably why we haven't made much progress on individual level in this area.

Message : https://huggingface.co/aashay96/indic-BloomLM

Training script and an initial Lora model + datasets are all there. Feel free to train it further
Quoted Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.\n\nProbably more value will be there in \n1. Falcon/llama + fine-tuning chat datasets for at least one Indian language\n2. Waiting for something that's trained on Indic stuff in the first place and is open.\n\nFirst one has good demo level perf. but it's limited in many ways. Second is not there yet. \n\nI can see probably why we haven't made much progress on individual level in this area.

Message : I have few suggestions as you and @91990057xxxx are genuinely trying something good
(1) Let‚Äôs create a real open source org/repo/structure, outside of bureaucratic interference like ai4bharat
(2) Start with collecting all Indic resources and datasets under one umbrella, pre training data is most important to move forwad with foundation and even fine tuned model
(3) crowdsource problems from oss community, need to be solved, and are not part of a blind race to prove someone wrong
Quoted Message : IndicLLM even if not the most powerful is important for equitable outcomes for everyone. Back when I was at make a difference, one of the biggest problem we faced while teaching shelter home kids who aren‚Äôt from background like ours was their inability to interpret in english as well as they could do in their native language. Ofcourse there is no money - but it is of national importance.

Message : ‚Äé<attached: 00007981-PHOTO-2023-06-09-09-51-40.jpg>
Quoted Message : Got a link/source for the technical architecture/stack of Bhashini ?\nTheir website didn't have much info

Message : I that‚Äôs not true. Check Ai4Bharat website and repo for models
Quoted Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.\n\nProbably more value will be there in \n1. Falcon/llama + fine-tuning chat datasets for at least one Indian language\n2. Waiting for something that's trained on Indic stuff in the first place and is open.\n\nFirst one has good demo level perf. but it's limited in many ways. Second is not there yet. \n\nI can see probably why we haven't made much progress on individual level in this area.

Message : We should get Dr.Pratyush from ai4bharat here üòÜ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : There's no getting around alternative uses and abuses of new technology of any kind.
Quoted Message : Good one. With elections coming maybe it can be a digital infra. Last elections WhatsApp volumes were huge. Maybe this time all voters will get personalised videos ü§´‚Ä¶..

Message : Yup. How you use a knife is totally fair.

Wasn‚Äôt even saying in a negative tone. Just in fact that it‚Äôs a fair and valid marketing use case. If anyone wants to seriously build it, call me up. Let‚Äôs do something hacky
Quoted Message : There's no getting around alternative uses and abuses of new technology of any kind.

Message : IndicLLM even if not the most powerful is important for equitable outcomes for everyone. Back when I was at make a difference, one of the biggest problem we faced while teaching shelter home kids who aren‚Äôt from background like ours was their inability to interpret in english as well as they could do in their native language. Ofcourse there is no money - but it is of national importance.

Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.

Probably more value will be there in
1. Falcon/llama + fine-tuning chat datasets for at least one Indian language
2. Waiting for something that's trained on Indic stuff in the first place and is open.

First one has good demo level perf. but it's limited in many ways. Second is not there yet.

I can see probably why we haven't made much progress on individual level in this area.

Message : Got a link/source for the technical architecture/stack of Bhashini ?
Their website didn't have much info
Quoted Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.\n\nProbably more value will be there in \n1. Falcon/llama + fine-tuning chat datasets for at least one Indian language\n2. Waiting for something that's trained on Indic stuff in the first place and is open.\n\nFirst one has good demo level perf. but it's limited in many ways. Second is not there yet. \n\nI can see probably why we haven't made much progress on individual level in this area.

Message : https://huggingface.co/aashay96/indic-BloomLM

Training script and an initial Lora model + datasets are all there. Feel free to train it further
Quoted Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.\n\nProbably more value will be there in \n1. Falcon/llama + fine-tuning chat datasets for at least one Indian language\n2. Waiting for something that's trained on Indic stuff in the first place and is open.\n\nFirst one has good demo level perf. but it's limited in many ways. Second is not there yet. \n\nI can see probably why we haven't made much progress on individual level in this area.

Message : I have few suggestions as you and @91990057xxxx are genuinely trying something good
(1) Let‚Äôs create a real open source org/repo/structure, outside of bureaucratic interference like ai4bharat
(2) Start with collecting all Indic resources and datasets under one umbrella, pre training data is most important to move forwad with foundation and even fine tuned model
(3) crowdsource problems from oss community, need to be solved, and are not part of a blind race to prove someone wrong
Quoted Message : IndicLLM even if not the most powerful is important for equitable outcomes for everyone. Back when I was at make a difference, one of the biggest problem we faced while teaching shelter home kids who aren‚Äôt from background like ours was their inability to interpret in english as well as they could do in their native language. Ofcourse there is no money - but it is of national importance.

Message : ‚Äé<attached: 00007981-PHOTO-2023-06-09-09-51-40.jpg>
Quoted Message : Got a link/source for the technical architecture/stack of Bhashini ?\nTheir website didn't have much info

Message : I that‚Äôs not true. Check Ai4Bharat website and repo for models
Quoted Message : Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.\n\nProbably more value will be there in \n1. Falcon/llama + fine-tuning chat datasets for at least one Indian language\n2. Waiting for something that's trained on Indic stuff in the first place and is open.\n\nFirst one has good demo level perf. but it's limited in many ways. Second is not there yet. \n\nI can see probably why we haven't made much progress on individual level in this area.

Message : We should get Dr.Pratyush from ai4bharat here üòÜ

Message : üòù my point is towards how goals get diverted and delayed where Government is a major contributor in funds
Quoted Message : We should get Dr.Pratyush from ai4bharat here üòÜ

Message : Yeah they have multiple NER, transliteration, translate modelsb in HF/github but in the articles for Bhashini I didn't find a connection to those models. Probably because I referred to wrong article, I got in a different direction - https://indianexpress.com/article/explained/explained-sci-tech/chatgpt-on-whatsapp-bhashini-welfare-schemes-8442622/
Quoted Message : I that‚Äôs not true. Check Ai4Bharat website and repo for models

Message : Some details here :

https://github.com/AI4Bharat/IndicTrans2

https://ai4bharat.iitm.ac.in/indic-trans2
Quoted Message : I that‚Äôs not true. Check Ai4Bharat website and repo for models

Message : Bloom family of models has ggml support, so I guess something can be tried here. But they perform poorly on most tasks, don't know much about this one. I'll try it out.
Quoted Message : https://huggingface.co/aashay96/indic-BloomLM\n\nTraining script and an initial Lora model + datasets are all there. Feel free to train it further

Message : Thanks, I haven‚Äôt tested IndicTrans2 yet, this only two weeks old. I tried original IndicTrans in production but was disappointed for inference speed.
Quoted Message : Some details here :\n\nhttps://github.com/AI4Bharat/IndicTrans2\n\nhttps://ai4bharat.iitm.ac.in/indic-trans2

Message : this is overly optimistic Aakash ji. I am a fan of Ethan Mollick's 'education explorations with ChatGPT' - but, *there's a crucial 'developing' process* missing that the student can't access and the 'educator' isn't able to deliver. It's in technology's blindspot, for now - resourcing contextual opportunities for learning. Most gedanken experiments devoid of local environment, not blaming the metaverse, aren't powerful enough levers.

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØTanishk Sharma

Message : What's the best way to compress models or generate lighter models? I have come across quantization and conversion to ONNX and other formats. I've used ONNX but in some cases it does increase inference time. Is there a way to ensure the inference time is low as well? Any good guides to this?

Message : On python based inference onnx performs really well, if you go to C++ then ncnn is the best. Have tried ncnn for both CPU and GPU(using Vulkan) it outperforms torch lib and tensorflow c++
Quoted Message : What's the best way to compress models or generate lighter models? I have come across quantization and conversion to ONNX and other formats. I've used ONNX but in some cases it does increase inference time. Is there a way to ensure the inference time is low as well? Any good guides to this?

Message : I've found that for (simpler, non-DL) models, ONNX is slower than pickle binaries. Could I be doing something wrong?
Quoted Message : On python based inference onnx performs really well, if you go to C++ then ncnn is the best. Have tried ncnn for both CPU and GPU(using Vulkan) it outperforms torch lib and tensorflow c++

Message : Keywords you are looking for: Quantization, Pruning, Sparsification, Distillation. You shouldn't see speed increase. Will DM you details later.
Quoted Message : What's the best way to compress models or generate lighter models? I have come across quantization and conversion to ONNX and other formats. I've used ONNX but in some cases it does increase inference time. Is there a way to ensure the inference time is low as well? Any good guides to this?

Message : Just change the model to falcon or whichever you want for training
Quoted Message : Bloom family of models has ggml support, so I guess something can be tried here. But they perform poorly on most tasks, don't know much about this one. I'll try it out.

Message : As per the original context, looking for models that have a GGML supported architecture so that something can be done for them right away. Falcon isn't supported with GGML quantization properly yet.
Quoted Message : Just change the model to falcon or whichever you want for training

Message : ‚Äé<attached: 00007997-PHOTO-2023-06-09-11-11-10.jpg>

Message : I can totally get behind Applied Statistics

Message : Well that's not fun and  dull. I am all for AI. It has a sense of mystery in it
Quoted Message : I can totally get behind Applied Statistics

Message : AI on the streets, AS in the sheets

Message : Thank you, Sumod
Quoted Message : Keywords you are looking for: Quantization, Pruning, Sparsification, Distillation. You shouldn't see speed increase. Will DM you details later.

Message : Haha, can always bank on him to bring a new perspective
Quoted Message :  2023_06_09_4EDE9AD3CD5204439F5E4545771CD5E0.jpeg

Message : +1 any good guide/ref pages for implementing/deploying hybrid search?
Quoted Message : What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?

Message : It's funny how sci-fi writers like Ted Chiang, Eliezer Yudkowsky have become quotable experts of AI. One look at their statements and it immediately makes you want to stop reading the article.

On one hand, we have people looking out for sudden loss drops and on the other hand, we are calling it Applied Stats.
Quoted Message :  2023_06_09_4EDE9AD3CD5204439F5E4545771CD5E0.jpeg

Message : We're doing this at Dukaan. Happy to discuss further with you.
Quoted Message : +1 any good guide/ref pages for implementing/deploying hybrid search?

Message : Link please?
Quoted Message :  2023_06_09_4EDE9AD3CD5204439F5E4545771CD5E0.jpeg

Message : https://twitter.com/emostaque/status/1666817719554174977?s=46

Emad is bullish on India

Message : The original authors of Retrieval Augmented Generation, InferSent, SentEval and many others have teamed up to start a RAG company. They've raised a $20M Seed Round.  

https://contextual.ai/announcing-next-generation-language-models/

Message : Same crew did GLUE/SuperGLUE too

Message : Isn‚Äôt the original paper 3 year old?
Quoted Message : The original authors of Retrieval Augmented Generation, InferSent, SentEval and many others have teamed up to start a RAG company. They've raised a $20M Seed Round.  \n\nhttps://contextual.ai/announcing-next-generation-language-models/

Message : https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84
Quoted Message : Link please?

Message : Yes, https://arxiv.org/abs/2005.11401
Quoted Message : Isn‚Äôt the original paper 3 year old?

Message : ya RAG has been in place since 2020 when facebook launched their dpr models
Quoted Message : Isn‚Äôt the original paper 3 year old?

Message : paywall sigh
Quoted Message : https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84

Message : The PIO Amanpreet Singh is a 2013 IIT R grad from the very famous SDS Lab. Has interned with Wingify in India

cc @91986822xxxx

Message : https://archive.is/xCmxi
Quoted Message : paywall sigh

Message : *A friend asked this, can someone please advise?*
I am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : DMing you
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : Similar request from my end as well, if anyone can help.
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : ‚Äé<attached: 00008022-PHOTO-2023-06-09-12-50-57.jpg>
Quoted Message : The original authors of Retrieval Augmented Generation, InferSent, SentEval and many others have teamed up to start a RAG company. They've raised a $20M Seed Round.  \n\nhttps://contextual.ai/announcing-next-generation-language-models/

Message : Great to see you here @91998080xxxx - forwarded your query already üëÜüèº
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : What nobody has managed to answer for me is the question of whether humans are doing anything more sophisticated than this in their own heads. There are probably many intelligence mechanisms that are decidedly simple - and there is a tendency on the part of commentators to just group everything together
Quoted Message :  2023_06_09_4EDE9AD3CD5204439F5E4545771CD5E0.jpeg

Message : @91981126xxxx can help
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : paywall sigh
Quoted Message : https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84

Message : The PIO Amanpreet Singh is a 2013 IIT R grad from the very famous SDS Lab. Has interned with Wingify in India

cc @91986822xxxx

Message : https://archive.is/xCmxi
Quoted Message : paywall sigh

Message : *A friend asked this, can someone please advise?*
I am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : DMing you
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : Similar request from my end as well, if anyone can help.
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : ‚Äé<attached: 00008022-PHOTO-2023-06-09-12-50-57.jpg>
Quoted Message : The original authors of Retrieval Augmented Generation, InferSent, SentEval and many others have teamed up to start a RAG company. They've raised a $20M Seed Round.  \n\nhttps://contextual.ai/announcing-next-generation-language-models/

Message : Great to see you here @91998080xxxx - forwarded your query already üëÜüèº
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : What nobody has managed to answer for me is the question of whether humans are doing anything more sophisticated than this in their own heads. There are probably many intelligence mechanisms that are decidedly simple - and there is a tendency on the part of commentators to just group everything together
Quoted Message :  2023_06_09_4EDE9AD3CD5204439F5E4545771CD5E0.jpeg

Message : @91981126xxxx can help
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : Same from my side as well...


Also for b2b business
What's best practices for the model inference in a multi tenant environment as context would be different for all
Quoted Message : Similar request from my end as well, if anyone can help.

Message : Awesome, thanks. I will reach out to him.
Quoted Message : @9198xxxxxxxx can help

Message : Every generation of scientific advancement tries to define human capacity in terms of current understanding. This is how we got the racial theories that defended slavery, and the eugenics movement that went on to cause much grief.

It is dangerous to assume we know how the human mind works.
Quoted Message : What nobody has managed to answer for me is the question of whether humans are doing anything more sophisticated than this in their own heads. There are probably many intelligence mechanisms that are decidedly simple - and there is a tendency on the part of commentators to just group everything together

Message : Distillation https://neptune.ai/blog/knowledge-distillation
Quoted Message : What's the best way to compress models or generate lighter models? I have come across quantization and conversion to ONNX and other formats. I've used ONNX but in some cases it does increase inference time. Is there a way to ensure the inference time is low as well? Any good guides to this?

Message : When you mention GPU based models do you mean they require a GPU at inference time? For standard cpu inference we are using AWS Fargate with auto scaling. Behind an Nguni load balancer
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : In google we used GoLang GRPC services on k8
Quoted Message : *A friend asked this, can someone please advise?*\nI am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.

Message : Yes, need GPU at inference
Quoted Message : When you mention GPU based models do you mean they require a GPU at inference time? For standard cpu inference we are using AWS Fargate with auto scaling. Behind an Nguni load balancer

Message : Very insightful piece, thanks Michael
Quoted Message : Distillation https://neptune.ai/blog/knowledge-distillation

Message : PIO?
Quoted Message : The PIO Amanpreet Singh is a 2013 IIT R grad from the very famous SDS Lab. Has interned with Wingify in India\n\ncc @9198xxxxxxxx

Message : Person of Indian Origin
Quoted Message : PIO?

Message : I use it the same way
Quoted Message : I agree with this 100%\n\nEspecially in businesses, the problem is not generating content (read noise); challenge is making sense of what‚Äôs happening around you.\n\nI personally use GPT-4 at least 30-40% of time to understand content rather than generating; and I have no organization to deal with.

Message : - Explain math , code , concepts 
- Explain what‚Äôs in papers
- Translate between languages both human and code
- Summarize
The biggest lever is in improving your own understanding.

Message : Your learning speed increases by 2x or more

Message : Also made hackerFM which was around the same idea - using AI to summarize the complex events in the tech industry

Message : We don‚Äôt release it anymore but a few users emailed asking for it back. So this use case has genuine traction based on my anecdotal experiences

Message : But it‚Äôs not obvious. You cannot demonstrate it immediately. It takes time to get used to this way of working

Message : My biggest use for gpt is to pass it an error stack, and it tells me how to fix it

Message : Debugging is understanding

Message : The complexity of a project a single developer can take on and ship quickly has already gone up.

Message : The consequences just aren‚Äôt evenly distributed yet

Message : A tool to simplify the world according to your own goals and values. Where the model is built up collaboratively over time. And is both visual and text. Blasting out endless streams of content is not where it‚Äôs at. Simple high signal actionable models / summaries of the world.

Message : I've been surprised at how poor other tools are at basic code tasks. Or maybe I'm not aware

But i repeatedly use gpt for a few things e.g.

1. Writing regex
2. Generating react components, animations, etc
3. Standalone functions like text manipulation

I've tried to get copilot a couple of times to do it

Message : But it's largely been poor at it

Message : Is hybrid search = cosine distance+ IDF 

Or is there an LLM involved ?
Quoted Message : What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?

Message : The first I‚Äôd assume
Quoted Message : Is hybrid search = cosine distance+ IDF \n\nOr is there an LLM involved ?

Message : How are you defining this additive property though?

Message : Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong
Quoted Message : I've been surprised at how poor other tools are at basic code tasks. Or maybe I'm not aware\n\nBut i repeatedly use gpt for a few things e.g.\n\n1. Writing regex\n2. Generating react components, animations, etc\n3. Standalone functions like text manipulation\n\nI've tried to get copilot a couple of times to do it

Message : Copilot would be built on top of Codex and InstructGPT (like ChatGPT). Not sure if those benefit from RLHF like ChatGPT has. Does anyone know?

Message : In Elasticsearch, this is composite, so it's not super tough.
Quoted Message : How are you defining this additive property though?

Message : I pay for it. But haven't been very impressed with copilot. For instance, it really annoys me when it gets closing brackets or double quotes wrong
Quoted Message : Copilot would be built on top of Codex and InstructGPT (like ChatGPT). Not sure if those benefit from RLHF like ChatGPT has. Does anyone know?

Message : You need to then go and figure what it added or missed that's causing everything to go an angry red ü•≤

Message : Depends on how one is using it. I deal with it how I'll deal with a completely fresh intern. Plan things on a high level and break down the tasks to create functions, scripts or classes. 

Then use these code modules by pasting them in newer context and assigning an enhancement, debug or application.
Quoted Message : Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong

Message : I‚Äôve had similar experience. Co pilot works better with existing code bases. 
Writing descriptive comments before each code block, including param structures, using apt variable names etc helps a lot.
Quoted Message : Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong

Message : But for writing from scratch, GPT4 is  amazing.

Message : This is a big issue with code gen tools - since we're not mentally involved in the code generation process it becomes complicated and annoying when a) we are skeptical about the output b) when there is clearly an error and we don't know where to start
Quoted Message : You need to then go and figure what it added or missed that's causing everything to go an angry red ü•≤

Message : https://youtu.be/Yf1o0TQzry8

Watch at 27:00 - the main activity is understanding

Message : Codex which powers copilot is a far smaller and simpler model
Quoted Message : Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong

Message : It trades off intelligence for latency

Message : Can you give a tldr like Nirant always pushes üòÖ
Quoted Message : https://youtu.be/Yf1o0TQzry8\n\nWatch at 27:00 - the main activity is understanding

Message : hopefully they'll replace it with a new gpt-4 based model soon.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You need to then go and figure what it added or missed that's causing everything to go an angry red ü•≤

Message : Depends on how one is using it. I deal with it how I'll deal with a completely fresh intern. Plan things on a high level and break down the tasks to create functions, scripts or classes. 

Then use these code modules by pasting them in newer context and assigning an enhancement, debug or application.
Quoted Message : Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong

Message : I‚Äôve had similar experience. Co pilot works better with existing code bases. 
Writing descriptive comments before each code block, including param structures, using apt variable names etc helps a lot.
Quoted Message : Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong

Message : But for writing from scratch, GPT4 is  amazing.

Message : This is a big issue with code gen tools - since we're not mentally involved in the code generation process it becomes complicated and annoying when a) we are skeptical about the output b) when there is clearly an error and we don't know where to start
Quoted Message : You need to then go and figure what it added or missed that's causing everything to go an angry red ü•≤

Message : https://youtu.be/Yf1o0TQzry8

Watch at 27:00 - the main activity is understanding

Message : Codex which powers copilot is a far smaller and simpler model
Quoted Message : Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong

Message : It trades off intelligence for latency

Message : Can you give a tldr like Nirant always pushes üòÖ
Quoted Message : https://youtu.be/Yf1o0TQzry8\n\nWatch at 27:00 - the main activity is understanding

Message : hopefully they'll replace it with a new gpt-4 based model soon.

Message : Understanding what is going on > trying to come up with new ideas before you have that

Message : Too expensive too slow
Quoted Message : hopefully they'll replace it with a new gpt-4 based model soon.

Message : I mean that is copilotX but it‚Äôs not in the direct coding flow

Message : 3.5 then. I'll take anything. Currently, I spend all day doing <tab>,<enter> repeat with copilot

Message : A typical hybrid search would be a combination of two or more of these methods:

* Semantic search to fetch top K
* Tf-idf or similar stuff like BM25
* Recency Bias - Newer information is weighted with more weighted more
* Associativity Bias - Information closely linked to predetermined important pieces is weighted more
* Repetition Bias - Information that is repeated more often in the document is deemed important

There's no fixed heuristic to implement a hybrid search but you would mostly find Semantic Search + TF-IDF/BM25 and some would go and add temporal or recency Bias
Quoted Message : Is hybrid search = cosine distance+ IDF \n\nOr is there an LLM involved ?

Message : Yes, I remember you mentioning the ```boost()``` method, but what if I‚Äôm not using ElasticSearch?
I guess I‚Äôm trying to understand more of what happens underneath üôÇ
Quoted Message : In Elasticsearch, this is composite, so it's not super tough.

Message : What do you mean by ‚Äú+‚Äù ?
Is there a way to possibly elaborate how the two are getting combined?
Quoted Message : A typical hybrid search would be a combination of two or more of these methods:\n\n* Semantic search to fetch top K\n* Tf-idf or similar stuff like BM25\n* Recency Bias - Newer information is weighted with more weighted more\n* Associativity Bias - Information closely linked to predetermined important pieces is weighted more\n* Repetition Bias - Information that is repeated more often in the document is deemed important\n\nThere's no fixed heuristic to implement a hybrid search but you would mostly find Semantic Search + TF-IDF/BM25 and some would go and add temporal or recency Bias

Message : It's a performance story. U can still do in memory, but ur performance will be hit
Quoted Message : Yes, I remember you mentioning the ```boost()``` method, but what if I‚Äôm not using ElasticSearch?\nI guess I‚Äôm trying to understand more of what happens underneath üôÇ

Message : Scaling up is a different story.
I‚Äôm first trying to understand how the two are getting combined üòÉ
Quoted Message : It's a performance story. U can still do in memory, but ur performance will be hit

Message : This makes a lot of sense, but still no LLM no ? I'm wondering how do u leverage LLM into the mix.

This stuff is still classical search for us Lucene folks (regardless of what the vector dbs say !)
Quoted Message : A typical hybrid search would be a combination of two or more of these methods:\n\n* Semantic search to fetch top K\n* Tf-idf or similar stuff like BM25\n* Recency Bias - Newer information is weighted with more weighted more\n* Associativity Bias - Information closely linked to predetermined important pieces is weighted more\n* Repetition Bias - Information that is repeated more often in the document is deemed important\n\nThere's no fixed heuristic to implement a hybrid search but you would mostly find Semantic Search + TF-IDF/BM25 and some would go and add temporal or recency Bias

Message : In memory. U get one array. U get another array and u then sort in memory. This is where llamaindex shines
Quoted Message : Scaling up is a different story.\nI‚Äôm first trying to understand how the two are getting combined üòÉ

Message : As far as involving an LLM layer goes, I‚Äôve seen some people talking about finetunig the ranking model with adversarial questions or doc2query.
It has proved to give better results than plain vector similarity
Quoted Message : This makes a lot of sense, but still no LLM no ? I'm wondering how do u leverage LLM into the mix.\n\nThis stuff is still classical search for us Lucene folks (regardless of what the vector dbs say !)

Message : LLM can be used as a final ranking / summarization pass.
can rephrase / translate queries
can suggest follow ups / related
Quoted Message : This makes a lot of sense, but still no LLM no ? I'm wondering how do u leverage LLM into the mix.\n\nThis stuff is still classical search for us Lucene folks (regardless of what the vector dbs say !)

Message : Can hallucinate answers that guide the rest of the system

Message : Can activate plugins

Message : LLMs come into play when you use the search for answer generation. Then there are a bunch of techniques where LLM has to play a part, 

Examples:

* HyDE - Let LLMs hallucinate answer first and then perform search which can then be used to arrive upon a complete and correct answer

* Breaking down search query - LLMs are instructed to break down search query based on their lack of knowledge on the topic, then come up with multiple search queries to get context on these terms first and then formulate final answer

* Autoprompt like methods - let LLM take your query and come up with a search prompt or question prompt by itself based on its understanding of previous question-answer pairs that were successful
Quoted Message : This makes a lot of sense, but still no LLM no ? I'm wondering how do u leverage LLM into the mix.\n\nThis stuff is still classical search for us Lucene folks (regardless of what the vector dbs say !)

Message : Hyde example is a great answer. Thanks üôè
Quoted Message : LLMs come into play when you use the search for answer generation. Then there are a bunch of techniques where LLM has to play a part, \n\nExamples:\n\n* HyDE - Let LLMs hallucinate answer first and then perform search which can then be used to arrive upon a complete and correct answer\n\n* Breaking down search query - LLMs are instructed to break down search query based on their lack of knowledge on the topic, then come up with multiple search queries to get context on these terms first and then formulate final answer\n\n* Autoprompt like methods - let LLM take your query and come up with a search prompt or question prompt by itself based on its understanding of previous question-answer pairs that were successful

Message : There's no fixed heuristic but good engineering practices to combine semantic search and keyword search techniques to optimise for cost, speed and performance

https://arxiv.org/abs/2210.11934
Quoted Message : What do you mean by ‚Äú+‚Äù ?\nIs there a way to possibly elaborate how the two are getting combined?

Message : So is that an intersection of the results of the search algorithm?
Quoted Message : A typical hybrid search would be a combination of two or more of these methods:\n\n* Semantic search to fetch top K\n* Tf-idf or similar stuff like BM25\n* Recency Bias - Newer information is weighted with more weighted more\n* Associativity Bias - Information closely linked to predetermined important pieces is weighted more\n* Repetition Bias - Information that is repeated more often in the document is deemed important\n\nThere's no fixed heuristic to implement a hybrid search but you would mostly find Semantic Search + TF-IDF/BM25 and some would go and add temporal or recency Bias

Message : https://twitter.com/hwchase17/status/1666829939918745600?t=nNVXyi6T4Ny7qvy1eXQldQ&s=19

Message : Are there any resources to go through to understand and implement HyDE?
Quoted Message : LLMs come into play when you use the search for answer generation. Then there are a bunch of techniques where LLM has to play a part, \n\nExamples:\n\n* HyDE - Let LLMs hallucinate answer first and then perform search which can then be used to arrive upon a complete and correct answer\n\n* Breaking down search query - LLMs are instructed to break down search query based on their lack of knowledge on the topic, then come up with multiple search queries to get context on these terms first and then formulate final answer\n\n* Autoprompt like methods - let LLM take your query and come up with a search prompt or question prompt by itself based on its understanding of previous question-answer pairs that were successful

Message : I‚Äôm not convinced this‚Äôll give very good results
Quoted Message : So is that an intersection of the results of the search algorithm?

Message : I think this repo uses contextual compression https://twitter.com/misbahsy/status/1656365370121285657?s=46&t=iGppsOleuAsMXDWuVmzUPQ
Quoted Message : https://twitter.com/hwchase17/status/1666829939918745600?t=nNVXyi6T4Ny7qvy1eXQldQ&s=19

Message : Not sure if this was shared earlier

Message : There's an implementation to HyDE paper from papers with code - https://github.com/texttron/hyde
Quoted Message : Are there any resources to go through to understand and implement HyDE?

Message : You can find two different fusion techniques mentioned here - Convex Combination (CC), and Retrieval Rank Fusion (RRF).

I've not really implemented these functions myself so any more details would be me just reading it off this paper - https://arxiv.org/abs/2210.11934
Quoted Message : So is that an intersection of the results of the search algorithm?

Message : Thanks üôè
Quoted Message : You can find two different fusion techniques mentioned here - Convex Combination (CC), and Retrieval Rank Fusion (RRF).\n\nI've not really implemented these functions myself so any more details would be me just reading it off this paper - https://arxiv.org/abs/2210.11934

Message : I've used RRF. It's beautiful how simple and fast it is.
Quoted Message : You can find two different fusion techniques mentioned here - Convex Combination (CC), and Retrieval Rank Fusion (RRF).\n\nI've not really implemented these functions myself so any more details would be me just reading it off this paper - https://arxiv.org/abs/2210.11934

Message : One heuristic to think about LLMs is how we tend to reflect on our answers.

First cut of our answer is always riddled with biases, but when we're asked to reflect on our own answer, we tend to improve it. Similarly, two people discussing a topic end up learning new (that's why student-teacher networks work out)

Anyone else finds this parallel fascinating?

Message : I rarely seen a GPU based live inference solution due to the cost but in general principle if you want scale then use some elastic infrastructure component but cost associated is very high and optimise as much as you can your model. 
We multiple models running 24/7 in our environment with a mixture of synchronous and asynchronous. We follow a strategy of micro service reducing the footprint of each model. Then wrap them in REST / gRPC API s , dickeriizing and running them on aws fargate . If we have asynchronous systems we use an SQS queue with Keda for scaling
Quoted Message : Yes, need GPU at inference

Message : ‚Äé<attached: 00008096-PHOTO-2023-06-09-16-21-53.jpg>

Message : Yeah...Indian academia is deeply cash-strapped. I knew some people at IIT-B that were doing some pretty killer NLP stuff (for 2018) but were limited by the very few number of GPUs available.
Quoted Message :  2023_06_09_3EB0D7B3E295B8AEBB23D1.jpeg

Message : Many basement in SV have more powerful ones
Quoted Message :  2023_06_09_3EB0D7B3E295B8AEBB23D1.jpeg

Message : Lots of people buy SLR cameras, if only we were inundated with great photos. A small fraction of the available compute is useful or well used compute.
Quoted Message : Many basement in SV have more powerful ones

Message : More cameras will increase the probability of more great pictures coming out

Message : Plus no camera when something epic is unfolding is most damaging

Message : Infrastructure is the model. That's why transformers works. It scales parallely - may not be the best algorithm.

Scale matters.

Message : Fascinating analogy Paras!

Who is the teacher in a ChatGPT - us conversation ?

ChatGPT knows all the facts, but we kind of instruct it to use a particular  "tone/style"( consider yourself to be a medical assistant, explain it to me like I am a 5 year old, write the poem in the style of Shakespeare, reason about it step by step, include references) for its generative abilities.
Quoted Message : One heuristic to think about LLMs is how we tend to reflect on our answers.\n\nFirst cut of our answer is always riddled with biases, but when we're asked to reflect on our own answer, we tend to improve it. Similarly, two people discussing a topic end up learning new (that's why student-teacher networks work out)\n\nAnyone else finds this parallel fascinating?

Message : Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the "decider"/"judged" LLM judging the output of the "student"/"workhorse" LLM

The context was to increase the quality of the generative outputs of the student LLM when it's outputs are "judged" by a "decider" LLM, for medical applications
Quoted Message : One heuristic to think about LLMs is how we tend to reflect on our answers.\n\nFirst cut of our answer is always riddled with biases, but when we're asked to reflect on our own answer, we tend to improve it. Similarly, two people discussing a topic end up learning new (that's why student-teacher networks work out)\n\nAnyone else finds this parallel fascinating?

Message : Isn't this a reworded "LLMs fine-tuned on GPT4 input/output pairs"
Quoted Message : Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the \"decider\"/\"judged\" LLM judging the output of the \"student\"/\"workhorse\" LLM\n\nThe context was to increase the quality of the generative outputs of the student LLM when it's outputs are \"judged\" by a \"decider\" LLM, for medical applications


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00008096-PHOTO-2023-06-09-16-21-53.jpg>

Message : Yeah...Indian academia is deeply cash-strapped. I knew some people at IIT-B that were doing some pretty killer NLP stuff (for 2018) but were limited by the very few number of GPUs available.
Quoted Message :  2023_06_09_3EB0D7B3E295B8AEBB23D1.jpeg

Message : Many basement in SV have more powerful ones
Quoted Message :  2023_06_09_3EB0D7B3E295B8AEBB23D1.jpeg

Message : Lots of people buy SLR cameras, if only we were inundated with great photos. A small fraction of the available compute is useful or well used compute.
Quoted Message : Many basement in SV have more powerful ones

Message : More cameras will increase the probability of more great pictures coming out

Message : Plus no camera when something epic is unfolding is most damaging

Message : Infrastructure is the model. That's why transformers works. It scales parallely - may not be the best algorithm.

Scale matters.

Message : Fascinating analogy Paras!

Who is the teacher in a ChatGPT - us conversation ?

ChatGPT knows all the facts, but we kind of instruct it to use a particular  "tone/style"( consider yourself to be a medical assistant, explain it to me like I am a 5 year old, write the poem in the style of Shakespeare, reason about it step by step, include references) for its generative abilities.
Quoted Message : One heuristic to think about LLMs is how we tend to reflect on our answers.\n\nFirst cut of our answer is always riddled with biases, but when we're asked to reflect on our own answer, we tend to improve it. Similarly, two people discussing a topic end up learning new (that's why student-teacher networks work out)\n\nAnyone else finds this parallel fascinating?

Message : Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the "decider"/"judged" LLM judging the output of the "student"/"workhorse" LLM

The context was to increase the quality of the generative outputs of the student LLM when it's outputs are "judged" by a "decider" LLM, for medical applications
Quoted Message : One heuristic to think about LLMs is how we tend to reflect on our answers.\n\nFirst cut of our answer is always riddled with biases, but when we're asked to reflect on our own answer, we tend to improve it. Similarly, two people discussing a topic end up learning new (that's why student-teacher networks work out)\n\nAnyone else finds this parallel fascinating?

Message : Isn't this a reworded "LLMs fine-tuned on GPT4 input/output pairs"
Quoted Message : Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the \"decider\"/\"judged\" LLM judging the output of the \"student\"/\"workhorse\" LLM\n\nThe context was to increase the quality of the generative outputs of the student LLM when it's outputs are \"judged\" by a \"decider\" LLM, for medical applications

Message : Replace gpt4 with any other smart LLM

Message : I know both the processes are different. But fundamentally this seems to be around aligning a smaller LLM to output like a bigger LLM (gpt4).
Quoted Message : Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the \"decider\"/\"judged\" LLM judging the output of the \"student\"/\"workhorse\" LLM\n\nThe context was to increase the quality of the generative outputs of the student LLM when it's outputs are \"judged\" by a \"decider\" LLM, for medical applications

Message : Which is the same idea adopted in projects like these
Quoted Message : Isn't this a reworded \"LLMs fine-tuned on GPT4 input/output pairs\"

Message : That seems closer to the orca paper by Microsoft research
Quoted Message : I know both the processes are different. But fundamentally this seems to be around aligning a smaller LLM to output like a bigger LLM (gpt4).

Message : Yes

Message : So I'm very curious to see the differences in benchmark across these two techniques that are trying to do the same thing but in a different way

Message : Reminds me of this one - Orca https://arxiv.org/abs/2306.02707
Quoted Message : Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the \"decider\"/\"judged\" LLM judging the output of the \"student\"/\"workhorse\" LLM\n\nThe context was to increase the quality of the generative outputs of the student LLM when it's outputs are \"judged\" by a \"decider\" LLM, for medical applications

Message : It would then become an interesting topic of research - what allows one approach to do better than the other one

Message : https://shadowed-season-d38.notion.site/Orca-paper-Explained-136fbed4b1cc40e28f56fdab2755b6fd?pvs=4
I'd written my explainer of the orca paper for someone who doesn't want to read all the pages

Message : https://youtu.be/Dt_UNg7Mchg

Message : Orca model seems promising based on results. It also puts emphasis on data curation and data diversity. I think this is something that can be achieved in India.

Message : I digged around and found the paper i was alluding to.
Context : i am interested in medical applications of LLMs


https://arxiv.org/abs/2303.17071

"Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks. In safety-critical applications such as healthcare, the utility of these models is governed by their ability to generate outputs that are factually accurate and complete. In this work, we present dialog-enabled resolving agents (DERA). DERA is a paradigm made possible by the increased conversational abilities of LLMs, namely GPT-4. It provides a simple, interpretable forum for models to communicate feedback and iteratively improve output. We frame our dialog as a discussion between two agent types - a Researcher, who processes information and identifies crucial problem components, and a Decider, who has the autonomy to integrate the Researcher's information and makes judgments on the final output.
We test DERA against three clinically-focused tasks. For medical conversation summarization and care plan generation, DERA shows significant improvement over the base GPT-4 performance in both human expert preference evaluations and quantitative metrics. In a new finding, we also show that GPT-4's performance (70%) on an open-ended version of the MedQA question-answering (QA) dataset (Jin et al. 2021, USMLE) is well above the passing level (60%), with DERA showing similar performance. We release the open-ended MEDQA dataset at this https URL"
Quoted Message : Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the \"decider\"/\"judged\" LLM judging the output of the \"student\"/\"workhorse\" LLM\n\nThe context was to increase the quality of the generative outputs of the student LLM when it's outputs are \"judged\" by a \"decider\" LLM, for medical applications

Message : ‚Äé<attached: 00008118-PHOTO-2023-06-09-18-24-06.jpg>

Message : Paper link - https://t.co/VYeo0ifuYF

Message : Exactly. It isn't only throwing compute at the model, but getting the data engineering right. Databricks demonstrated how they built Dolly with a smaller dataset
Quoted Message : Orca model seems promising based on results. It also puts emphasis on data curation and data diversity. I think this is something that can be achieved in India.

Message : i want to train any llm model and finetune or train on my domain related data which ecokmerce product related data , is there any good resource that u guys have found on this , which can help me start on this .

Message : This is a paper from my colleagues. Happy to discuss or answer any questions you may have
Quoted Message : I digged around and found the paper i was alluding to.\nContext : i am interested in medical applications of LLMs\n\n\nhttps://arxiv.org/abs/2303.17071\n\n\"Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks. In safety-critical applications such as healthcare, the utility of these models is governed by their ability to generate outputs that are factually accurate and complete. In this work, we present dialog-enabled resolving agents (DERA). DERA is a paradigm made possible by the increased conversational abilities of LLMs, namely GPT-4. It provides a simple, interpretable forum for models to communicate feedback and iteratively improve output. We frame our dialog as a discussion between two agent types - a Researcher, who processes information and identifies crucial problem components, and a Decider, who has the autonomy to integrate the Researcher's information and makes judgments on the final output.\nWe test DERA against three clinically-focused tasks. For medical conversation summarization and care plan generation, DERA shows significant improvement over the base GPT-4 performance in both human expert preference evaluations and quantitative metrics. In a new finding, we also show that GPT-4's performance (70%) on an open-ended version of the MedQA question-answering (QA) dataset (Jin et al. 2021, USMLE) is well above the passing level (60%), with DERA showing similar performance. We release the open-ended MEDQA dataset at this https URL\"

Message : Too broad a question perhaps, is there a specific problem you have in mind? E.g. product reviews fraud detection, ranking/search/recommendation system, parsing product reviews
Quoted Message : i want to train any llm model and finetune or train on my domain related data which ecokmerce product related data , is there any good resource that u guys have found on this , which can help me start on this .

Message : Small world indeed ! 
Dhruv, will DM you
Quoted Message : This is a paper from my colleagues. Happy to discuss or answer any questions you may have

Message : Mostly its question answers , and ranking i have data wrt product description title , etc

Message : Are you reporting to Anitha Kannan?
Quoted Message : This is a paper from my colleagues. Happy to discuss or answer any questions you may have

Message : Right now we are using the gpt model for doing this kind of product enquiry, but evaluating opensource model , and ways to train them . Just starting on this so have not much information except gpt . And on opensource model I am kind of not sure which one to start or look at .
Quoted Message : Mostly its question answers , and ranking i have data wrt product description title , etc

Message : For finetuning, this is a pretty good tutorial - https://huggingface.co/docs/transformers/training . To decide how to select different hyperparameters, this guide is nice ~ https://github.com/google-research/tuning_playbook

Message : Just skimmed the abstract.
LLMs playing "games" gives me RL vibes ! :)
Maybe there is an elegant way to combine LLMs and RL
Quoted Message : Paper link - https://t.co/VYeo0ifuYF

Message : Very thought provoking paper !

https://twitter.com/nouhadziri/status/1663936263324590083?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

"Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify Transformers, we investigate the limits of these models across three representative compositional tasks‚Äîmulti-digit multi- plication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that Transformers solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem- solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how Transformers‚Äô perfor- mance will rapidly decay with increased task complexity."


https://arxiv.org/abs/2305.18654

Message : Meta released another banger, MusicGen 
https://twitter.com/_akhaliq/status/1667175989862973453

Message : Yeah I loved it too. I had raised a pull request to add it to the reasoning paper list which just got merged. So it‚Äôs linked here too now. https://github.com/atfortes/LLM-Reasoning-Papers#analysis
Quoted Message : Very thought provoking paper !\n\nhttps://twitter.com/nouhadziri/status/1663936263324590083?s=48&t=pt9BgXoRTmqx5FEPyAl9bg\n\n\"Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify Transformers, we investigate the limits of these models across three representative compositional tasks‚Äîmulti-digit multi- plication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that Transformers solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem- solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how Transformers‚Äô perfor- mance will rapidly decay with increased task complexity.\"\n\n\nhttps://arxiv.org/abs/2305.18654

Message : Ooh lawsuits time üòõ
Quoted Message : Meta released another banger, MusicGen \nhttps://twitter.com/_akhaliq/status/1667175989862973453

Message : My (unsubstantiated) take on this- It‚Äôs a pretrained transformer. So pretraining it‚Äôs finding the patterns and then the generative part is filling in those blanks. A good paper overall. üëç
Quoted Message : Yeah I loved it too. I had raised a pull request to add it to the reasoning paper list which just got merged. So it‚Äôs linked here too now. https://github.com/atfortes/LLM-Reasoning-Papers#analysis

Message : I have a meta q to @91773788xxxx , @91986822xxxx , @91991692xxxx & others :

Do you have any practical advice(your own/ somebody else's) and suggestions on how to keep up with the deluge of new papers every freaking day ?

Somedays i feel i am able to keep up with my twitter feed(which is too many people, need to prune that a lot) , on other days i feel i am really "behind" and "missing out" and causes a lot of FOMO

Also, where do you find interesting papers to read besides this group ? Anyone want to share a twitter list of a few accounts who tweet majority of the interesting papers (akhaliq, Sebastian raschka , karpathy)

Any other must follow people and suggestions on this topic ?

Message : Well you did not ask me but I‚Äôll still go ahead and answer üòÄ

Message : https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-45d

Message : https://cameronrwolfe.me/blog

Message : I usually skim this group and stick to one personal and whatever professional projects I have around genAI.

Twitter, LinkedIn and YouTube is full of content that no one can absorb. My assumption is, all of it is not that important, if it is important with practical use case, some one will surface it in this group.
Quoted Message : I have a meta q to @9177xxxxxxxx , @9198xxxxxxxx , @9199xxxxxxxx & others :\n\nDo you have any practical advice(your own/ somebody else's) and suggestions on how to keep up with the deluge of new papers every freaking day ?\n\nSomedays i feel i am able to keep up with my twitter feed(which is too many people, need to prune that a lot) , on other days i feel i am really \"behind\" and \"missing out\" and causes a lot of FOMO\n\nAlso, where do you find interesting papers to read besides this group ? Anyone want to share a twitter list of a few accounts who tweet majority of the interesting papers (akhaliq, Sebastian raschka , karpathy) \n\nAny other must follow people and suggestions on this topic ?

Message : https://thegradient.pub/

Message : https://dblalock.substack.com/

Message : https://lastweekin.ai/

Message : https://twitter.com/omarsar0

Message : These are the resources I follow apart from this and a couple other groups I‚Äôm part of and the link to reasoning papers I posted above

Message : Adding to the above info problem. 

Many of the ML papers are highly technical for some of us with weaker core maths practice.

Is there is a chance, someone who understands them well, could organise weekly teach ins (book club styled?) for foundational ML papers?

Kind of dumb it down to a point where it‚Äôs comprehensible for a larger audience who still put in the effort?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Well you did not ask me but I‚Äôll still go ahead and answer üòÄ

Message : https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-45d

Message : https://cameronrwolfe.me/blog

Message : I usually skim this group and stick to one personal and whatever professional projects I have around genAI.

Twitter, LinkedIn and YouTube is full of content that no one can absorb. My assumption is, all of it is not that important, if it is important with practical use case, some one will surface it in this group.
Quoted Message : I have a meta q to @9177xxxxxxxx , @9198xxxxxxxx , @9199xxxxxxxx & others :\n\nDo you have any practical advice(your own/ somebody else's) and suggestions on how to keep up with the deluge of new papers every freaking day ?\n\nSomedays i feel i am able to keep up with my twitter feed(which is too many people, need to prune that a lot) , on other days i feel i am really \"behind\" and \"missing out\" and causes a lot of FOMO\n\nAlso, where do you find interesting papers to read besides this group ? Anyone want to share a twitter list of a few accounts who tweet majority of the interesting papers (akhaliq, Sebastian raschka , karpathy) \n\nAny other must follow people and suggestions on this topic ?

Message : https://thegradient.pub/

Message : https://dblalock.substack.com/

Message : https://lastweekin.ai/

Message : https://twitter.com/omarsar0

Message : These are the resources I follow apart from this and a couple other groups I‚Äôm part of and the link to reasoning papers I posted above

Message : Adding to the above info problem. 

Many of the ML papers are highly technical for some of us with weaker core maths practice.

Is there is a chance, someone who understands them well, could organise weekly teach ins (book club styled?) for foundational ML papers?

Kind of dumb it down to a point where it‚Äôs comprehensible for a larger audience who still put in the effort?

Message : Thanks Shan !

Do you have any suggestions on managing twitter overload ? :)
Quoted Message : These are the resources I follow apart from this and a couple other groups I‚Äôm part of and the link to reasoning papers I posted above

Message : Yeah. I don‚Äôt use twitter. üòÄ that Dair guys twitter is probably the only one. I directly go there every once in a while. (Also - ü§ó twitter account which I forgot to mention)

Message : https://twitter.com/huggingface specifically.

Message : I follow hacker news and a few subReddits 

Over weekends, end up reaching a few papers

There are very few novel ideas, most papers are incremental stuff
Quoted Message : I have a meta q to @9177xxxxxxxx , @9198xxxxxxxx , @9199xxxxxxxx & others :\n\nDo you have any practical advice(your own/ somebody else's) and suggestions on how to keep up with the deluge of new papers every freaking day ?\n\nSomedays i feel i am able to keep up with my twitter feed(which is too many people, need to prune that a lot) , on other days i feel i am really \"behind\" and \"missing out\" and causes a lot of FOMO\n\nAlso, where do you find interesting papers to read besides this group ? Anyone want to share a twitter list of a few accounts who tweet majority of the interesting papers (akhaliq, Sebastian raschka , karpathy) \n\nAny other must follow people and suggestions on this topic ?

Message : Skimming most papers is ok, I go into depth if an idea is truly novel
Quoted Message : I follow hacker news and a few subReddits \n\nOver weekends, end up reaching a few papers\n\nThere are very few novel ideas, most papers are incremental stuff

Message : Care to share the sub reddits Paras ?

Would love to see you do a tweet thread/post on how to read a research paper most efficiently
Quoted Message : I follow hacker news and a few subReddits \n\nOver weekends, end up reaching a few papers\n\nThere are very few novel ideas, most papers are incremental stuff

Message : this is an oversimplification:

just like them on twitter, tune the algo.

i do subscribe to a ton of the newsletters but I'm a sorta churned subscriber üòÇ.

most important papers will surface to the top anyways.

(insert Bell Curve meme here)

Message : ‚Äé<attached: 00008153-PHOTO-2023-06-09-20-44-46.jpg>
Quoted Message : Care to share the sub reddits Paras ?\n\nWould love to see you do a tweet thread/post on how to read a research paper most efficiently

Message : I think a Gpt style bot should be useful even for those used to the notation. Maybe there exists one already - wolfram + ELI5
Quoted Message : Adding to the above info problem. \n\nMany of the ML papers are highly technical for some of us with weaker core maths practice. \n\nIs there is a chance, someone who understands them well, could organise weekly teach ins (book club styled?) for foundational ML papers?\n\nKind of dumb it down to a point where it‚Äôs comprehensible for a larger audience who still put in the effort?

Message : I'm actually evaluating building a product that helps anyone be up to date with topics of their interest, served as a summary and adjusted to difficulty level.
Might just be useful for the kind of problems we're just discussing right?
Quoted Message : Adding to the above info problem. \n\nMany of the ML papers are highly technical for some of us with weaker core maths practice. \n\nIs there is a chance, someone who understands them well, could organise weekly teach ins (book club styled?) for foundational ML papers?\n\nKind of dumb it down to a point where it‚Äôs comprehensible for a larger audience who still put in the effort?

Message : Hey all, 
My name is Jeet. I work on CV in the Bay Area.

LinkedIn: https://www.linkedin.com/in/jeet-kanjani-a86062107

Twitter: https://twitter.com/kanjanijeet?s=11

Intrested in knowing more about the developments of genAI in India - Great to be added to this community!

Message : Anyone else who faces this problem (even if just for GenAI) or thinks it's worth solving, would love to connect and talk more!
Quoted Message : I'm actually evaluating building a product that helps anyone be up to date with topics of their interest, served as a summary and adjusted to difficulty level.\nMight just be useful for the kind of problems we're just discussing right?

Message : I was just about to automate my Twitter content actually. Currently I consume stuff through my own 2 NLP lists where I segregate top NLP signals by individuals and orgs separately. I'll DM you to know what's your approach towards this thing.
Quoted Message : Anyone else who faces this problem (even if just for GenAI) or thinks it's worth solving, would love to connect and talk more!

Message : I played this game for a long time and now don't find value in trying to keep up with every single piece of news.

You just need to start building stuff and keep abreast of SoTA in that area only.

I usually divide stuff like this to keep up and stick my nose in what is relevant to me -

* Build your own API
* Build your own dataset
* Build your own model - via training/fine tuning
* Build your own pipeline - for specific technologies

I'm interested in stuff where I build APIs and models only. Rest of the stuff I find when I need to look into it.

Other than this, it's easy to find places where you get "all" info - there are easily many such newsletters, weekly summary Twitter/LinkedIn accounts, subreddits, discords where you get to listen to the same stuff rinsed and repeated.

People quoting each other's posts as their own work and findings üòÇ and pushing out stuff everyday.

So best to just work on stuff and keep up with what's relevant to you
Quoted Message : I have a meta q to @9177xxxxxxxx , @9198xxxxxxxx , @9199xxxxxxxx & others :\n\nDo you have any practical advice(your own/ somebody else's) and suggestions on how to keep up with the deluge of new papers every freaking day ?\n\nSomedays i feel i am able to keep up with my twitter feed(which is too many people, need to prune that a lot) , on other days i feel i am really \"behind\" and \"missing out\" and causes a lot of FOMO\n\nAlso, where do you find interesting papers to read besides this group ? Anyone want to share a twitter list of a few accounts who tweet majority of the interesting papers (akhaliq, Sebastian raschka , karpathy) \n\nAny other must follow people and suggestions on this topic ?

Message : ‚Äé<attached: 00008160-PHOTO-2023-06-09-21-56-00.jpg>
Quoted Message : Care to share the sub reddits Paras ?\n\nWould love to see you do a tweet thread/post on how to read a research paper most efficiently

Message : Folks, is there any resource youve seen on how to translate natural language commands into actions?

Think of a command k bar that takes in natural language inputs, parses out relevant inputs, and executes if relevant or asks for more details if incomplete

Message : Teaching an LLM to use tools or plugins should not be any different than what you're asking for. We already have frameworks where the LLM looks for the best api, tool, plugin to complete the job. You probably want to look into those and replace names of APIs, tools with your own instructions. 

The input query from the user would need to be divided into *tool/api* to use, *instruction* to follow with the tool and *params* to pass to complete the job.


https://medium.com/@imicknl/how-do-chatgpt-plugins-and-similar-llm-concepts-work-2c83a4aeedd4

Message : This is very helpful. Thank you. The intent classifier seems to be key here. I'm trying to see how to make it have a conversation with the user in the event of incomplete inputs, or if it is unsure, to complete the  set of inputs it requires to execute the action

Message : This is a great starting point

Message : And gpt4 has been a very helpful as well

Message : It's great if you found it helpful.
Quoted Message : This is very helpful. Thank you. The intent classifier seems to be key here. I'm trying to see how to make it have a conversation with the user in the event of incomplete inputs, or if it is unsure, to complete the  set of inputs it requires to execute the action

Message : Closely following this conversation since I have trouble keeping up. Thanks for all the ideas
Quoted Message : I have a meta q to @9177xxxxxxxx , @9198xxxxxxxx , @9199xxxxxxxx & others :\n\nDo you have any practical advice(your own/ somebody else's) and suggestions on how to keep up with the deluge of new papers every freaking day ?\n\nSomedays i feel i am able to keep up with my twitter feed(which is too many people, need to prune that a lot) , on other days i feel i am really \"behind\" and \"missing out\" and causes a lot of FOMO\n\nAlso, where do you find interesting papers to read besides this group ? Anyone want to share a twitter list of a few accounts who tweet majority of the interesting papers (akhaliq, Sebastian raschka , karpathy) \n\nAny other must follow people and suggestions on this topic ?

Message : Again, adept.ai use case I presume?
Quoted Message : Folks, is there any resource youve seen on how to translate natural language commands into actions?\n\nThink of a command k bar that takes in natural language inputs, parses out relevant inputs, and executes if relevant or asks for more details if incomplete

Message : I'm not sure. Adept seems to have a very generic description on their website. But I think in the similar direction

Message : I'm surprised Google hasn't integrated something as simple as an instruction bar into their products

Like, I'd love to be able to setup a calendar invite by simply typing an instruction instead of clicking on the date, selecting the time, adding recipients, and a meeting subject

Message : I'd imagine a lot more tools can benefit from taking inputs as simple chat prompts instead of a sequence of button clicks

Message : The above could be a confirmatory step and for editing, instead of the full workflow

Message : Just for a dash of humour and wit on Friday night !

https://www.instagram.com/reel/Cqda2FuLqrI/?igshid=NjFhOGMzYTE3ZQ==

Message : genai.pdf ‚Ä¢ ‚Äé26 pages ‚Äé<attached: 00008174-genai.pdf>

Message : Is this from Chip ?
Quoted Message :  2023_06_09_E34D0BC9836C0A210637141424F02D50.pdf

Message : Yes
Quoted Message : Is this from Chip ?

Message : https://huggingface.co/spaces/facebook/MusicGen

Latest work by FB.

Message : Might be a stupid question but it says in the documentation that they cleaned out human vocals while providing training data to this: why? Are there any legal restrictions? Do we have large models like this that are trained on human vocals?
Quoted Message : https://huggingface.co/spaces/facebook/MusicGen\n\nLatest work by FB.

Message : Notebooks x LLMs
https://writings.stephenwolfram.com/2023/06/introducing-chat-notebooks-integrating-llms-into-the-notebook-paradigm/

Apparently there is jupyter-ai
https://github.com/jupyterlab/jupyter-ai
(via https://news.ycombinator.com/item?id=36265813 )

Message : I would imagine we are going to a see a lot of products that will attempt to do this in coming months. It‚Äôs a significant UI /UX innovation that reduces user friction to solve the same problems GUIs have been solving. Anyone know any early projects / demos that are in this direction? Apart from adept.
Quoted Message : I'd imagine a lot more tools can benefit from taking inputs as simple chat prompts instead of a sequence of button clicks

Message : Heck even a unix command line natural lang interface would be wonderful. ‚ÄúShow me 10 largest files that I have not accessed in the last month‚Äù would be soooo niiice üòÄ

Message : Yeah I think somebody already made this. Let me find and share it.
Quoted Message : Heck even a unix command line natural lang interface would be wonderful. ‚ÄúShow me 10 largest files that I have not accessed in the last month‚Äù would be soooo niiice üòÄ

Message : Here 
https://how2terminal.com/?ref=theresanaiforthat

Message : Good to know! I just use chatgpt for this stuff. FWIW the command for the stuff I wanted as recommended by gpt is ‚Äúfind /path/to/directory -atime +30 -type f -exec du -sh {} \; | sort -rh | head -n 10‚Äù which not even the most experienced bash-istas would be able to type flawlessly in one go.

Message : Haha, yeah. It has become an instinct now to rely on chatGPT for such stuff.
Quoted Message : Good to know! I just use chatgpt for this stuff. FWIW the command for the stuff I wanted as recommended by gpt is ‚Äúfind /path/to/directory -atime +30 -type f -exec du -sh {} \; | sort -rh | head -n 10‚Äù which not even the most experienced bash-istas would be able to type flawlessly in one go.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Yes
Quoted Message : Is this from Chip ?

Message : https://huggingface.co/spaces/facebook/MusicGen

Latest work by FB.

Message : Might be a stupid question but it says in the documentation that they cleaned out human vocals while providing training data to this: why? Are there any legal restrictions? Do we have large models like this that are trained on human vocals?
Quoted Message : https://huggingface.co/spaces/facebook/MusicGen\n\nLatest work by FB.

Message : Notebooks x LLMs
https://writings.stephenwolfram.com/2023/06/introducing-chat-notebooks-integrating-llms-into-the-notebook-paradigm/

Apparently there is jupyter-ai
https://github.com/jupyterlab/jupyter-ai
(via https://news.ycombinator.com/item?id=36265813 )

Message : I would imagine we are going to a see a lot of products that will attempt to do this in coming months. It‚Äôs a significant UI /UX innovation that reduces user friction to solve the same problems GUIs have been solving. Anyone know any early projects / demos that are in this direction? Apart from adept.
Quoted Message : I'd imagine a lot more tools can benefit from taking inputs as simple chat prompts instead of a sequence of button clicks

Message : Heck even a unix command line natural lang interface would be wonderful. ‚ÄúShow me 10 largest files that I have not accessed in the last month‚Äù would be soooo niiice üòÄ

Message : Yeah I think somebody already made this. Let me find and share it.
Quoted Message : Heck even a unix command line natural lang interface would be wonderful. ‚ÄúShow me 10 largest files that I have not accessed in the last month‚Äù would be soooo niiice üòÄ

Message : Here 
https://how2terminal.com/?ref=theresanaiforthat

Message : Good to know! I just use chatgpt for this stuff. FWIW the command for the stuff I wanted as recommended by gpt is ‚Äúfind /path/to/directory -atime +30 -type f -exec du -sh {} \; | sort -rh | head -n 10‚Äù which not even the most experienced bash-istas would be able to type flawlessly in one go.

Message : Haha, yeah. It has become an instinct now to rely on chatGPT for such stuff.
Quoted Message : Good to know! I just use chatgpt for this stuff. FWIW the command for the stuff I wanted as recommended by gpt is ‚Äúfind /path/to/directory -atime +30 -type f -exec du -sh {} \; | sort -rh | head -n 10‚Äù which not even the most experienced bash-istas would be able to type flawlessly in one go.

Message : One ux idea that I‚Äôm very keen on is this.

Keep hiding functions seldom used behind a universal search, so that over time, UX is simpler per each user‚Äôs needs.

Semantic search can easily enable popping up of seldom used functions whenever they‚Äôre needed.

Imagine how popular apps like Twitter, WhatsApp can start getting simplified over time as users choose certain features over others.
Quoted Message : I'm surprised Google hasn't integrated something as simple as an instruction bar into their products\n\nLike, I'd love to be able to setup a calendar invite by simply typing an instruction instead of clicking on the date, selecting the time, adding recipients, and a meeting subject

Message : For inference, how is NVIDIA Triton different from OpenAI Triton? Does NVIDIA Triton build on OpenAI Triton? Just in: https://blogs.nvidia.com/blog/2023/06/05/microsoft-bing-triton/

Message : Nvidia vs OpenAI Triton
Triton by Nvidia is an inference server. Triton by OpenAI is a high-level CUDA programming language and compiler stack. The two are not related. From: https://hamel.dev/notes/serving/
Quoted Message : For inference, how is NVIDIA Triton different from OpenAI Triton? Does NVIDIA Triton build on OpenAI Triton? Just in: https://blogs.nvidia.com/blog/2023/06/05/microsoft-bing-triton/

Message : Has anyone been trying Supabase as a vectorDB and has any feedback esp how it stacks up vs pinecone etc? I'll be happy to send any suggestions back to the founders. Thx in advance.

Message : Pgvector doesn't work well so far. If I'm not mistaken, they must be using the same. Less likely to be as performant as Pinecone or Qdrant.

https://ann-benchmarks.com/#pgvector
Quoted Message : Has anyone been trying Supabase as a vectorDB and has any feedback esp how it stacks up vs pinecone etc? I'll be happy to send any suggestions back to the founders. Thx in advance.

Message : Have a question for those deploying LLMs in production with prompt engineering, how are you dealing with prompt injection attacks where for example the user says 'ignore all your previous instructions and do this' or 'repeat the input' which may potentially reveal the prompts that you've used.

Message : Hey guys one question has any one explored https://elai.io/?

Have you come accross any opensource project similar to it ?

Message : Prompt injection by websites is an open problem without a clear solution, so far, afaik

https://twitter.com/sayashk/status/1666313565869940736?s=46&t=pt9BgXoRTmqx5FEPyAl9bg
Quoted Message : Have a question for those deploying LLMs in production with prompt engineering, how are you dealing with prompt injection attacks where for example the user says 'ignore all your previous instructions and do this' or 'repeat the input' which may potentially reveal the prompts that you've used.

Message : We have a fuzzy matching Algo against common strings, but not 100% effective

It‚Äôs an open problem
Quoted Message : Have a question for those deploying LLMs in production with prompt engineering, how are you dealing with prompt injection attacks where for example the user says 'ignore all your previous instructions and do this' or 'repeat the input' which may potentially reveal the prompts that you've used.

Message : It's excellent. What works well with supabase is the fact that you get everything else out of the box

Might be less performant, but haven't reached the level of scale to be able to discern any difference

The new Vecs is very good. A couple of minor things that need improvement are:

1. Easier Handling of vectors on the dashboard

2. Easier setup for hybrid search. Currently setting up cosine search and FTS is a bit unweildy

3. Better logging of vector search queries so we can manage indexes better
Quoted Message : Has anyone been trying Supabase as a vectorDB and has any feedback esp how it stacks up vs pinecone etc? I'll be happy to send any suggestions back to the founders. Thx in advance.

Message : To be fair, I've never tried pinecone so can't compare. This solved for my needs, so didn't bother beyond that

Message : GitHub copilot for command line does this pretty well
Quoted Message : Heck even a unix command line natural lang interface would be wonderful. ‚ÄúShow me 10 largest files that I have not accessed in the last month‚Äù would be soooo niiice üòÄ

Message : https://twitter.com/dale_vaz/status/1667455292307824641?t=L8xkDeKxgu0PLeI9U-MFSQ&s=19

He puts it perfectly, I believe this was a very specific question that was being answered

And yet, he gave a very clear comment at the very end - "We'll tell you it's hopeless to compete with us... But it's your job to try anyway... *And I believe both of those things*"

Message : Has anyone built a model router here to automatically route requests to different LLMs like OpenAI, Anthropic etc based on downtime, latency etc?

Message : let us stay offended and do something. Better for the timeline

Message : Checkout frugalgpt paper
Quoted Message : Has anyone built a model router here to automatically route requests to different LLMs like OpenAI, Anthropic etc based on downtime, latency etc?

Message : Is there an implementation of this available on Github or anyone using in production already?
Quoted Message : Checkout frugalgpt paper

Message : I would be more than happy if out of sheer arrogance someone tries to take on the challenge.

The efforts that would fail would still be paving the foundations for the future.
Quoted Message : https://twitter.com/dale_vaz/status/1667455292307824641?t=L8xkDeKxgu0PLeI9U-MFSQ&s=19\n\nHe puts it perfectly, I believe this was a very specific question that was being answered\n\nAnd yet, he gave a very clear comment at the very end - \"We'll tell you it's hopeless to compete with us... But it's your job to try anyway... *And I believe both of those things*\"

Message : Found a previous implementation: https://github.com/lchen001/FrugalML

Message : I stumbled onto ray a few days ago :

https://github.com/ray-project/aviary
Quoted Message : Has anyone built a model router here to automatically route requests to different LLMs like OpenAI, Anthropic etc based on downtime, latency etc?

Message : This is more for evaluation tho right?
Quoted Message : I stumbled onto ray a few days ago :\n\nhttps://github.com/ray-project/aviary

Message : This is evaluation, I think the question was to redirect request to a llm given a task if openai gpt3.5/4 isn‚Äôt responsive.

Basically an llm on top that decides which llm to call given the context and the task.
Quoted Message : I stumbled onto ray a few days ago :\n\nhttps://github.com/ray-project/aviary

Message : Still quite interesting, will try it out!

Message : Haven't tried it, just read the readme
Quoted Message : This is more for evaluation tho right?

Message : Right, we are paying like $100K to OpenAI and there's so much downtime going on.
Quoted Message : This is evaluation, I think the question was to redirect request to a llm given a task if openai gpt3.5/4 isn‚Äôt responsive.\n\nBasically an llm on top that decides which llm to call given the context and the task.

Message : Also, has anyone here got access to dedicated models on OpenAI or Azure already? If so, what's the experience been like?

Message : I like FrugalGPT's 3-step approach - 

1/ Prompt adaptation (Prompt selection + Query Concatenation)

2/ LLM approximation (Completion Cache & Model Fine tuning) &

3/ LLM cascade

A strikingly simple solution but one that is very effective

Message : For downtime handling won't try catch work

Message : Would need a timeout tho so responses would get delayed.
Quoted Message : For downtime handling won't try catch work

Message : Pass a timeout in the openai request
Quoted Message : Would need a timeout tho so responses would get delayed.

Message : Curious. Does it have to be a LLM monitoring other LLMs. Can we not use a service mesh and a controller approach to decide a optimal target? I could sound like a total idiot but still asking
Quoted Message : This is evaluation, I think the question was to redirect request to a llm given a task if openai gpt3.5/4 isn‚Äôt responsive.\n\nBasically an llm on top that decides which llm to call given the context and the task.

Message : I guess instead of doing that in every request tho, it would be good to have a separate layer that just checks the uptime/latency of multiple models.

Message : no, you are right, 
it doesn't have to be a llm,
it can also be a simple policy based model that overtime learns which model is better at what
Quoted Message : Curious. Does it have to be a LLM monitoring other LLMs. Can we not use a service mesh and a controller approach to decide a optimal target? I could sound like a total idiot but still asking

Message : Just curious , $100K/month ?
Which company is this , if you are comfortable sharing ?
Quoted Message : Right, we are paying like $100K to OpenAI and there's so much downtime going on.

Message : Writesonic

Message : Damn. Those are some incredibly good reviews. Nicely done
Quoted Message : Writesonic

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØNavita

Message : Good on him. Although I think this question was asked purely for optics I feel

Message : And the tweet to which Sam replied.
I mean come on, sounded as if gurnani  took offence on behalf of the whole Indian startup ecosystem.

India's fav past time : getting offended ü§¶ü§¶ü§¶

Message : Most of the questions in ET event were asked to either sound smart or funny.
Quoted Message : Good on him. Although I think this question was asked purely for optics I feel


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Curious. Does it have to be a LLM monitoring other LLMs. Can we not use a service mesh and a controller approach to decide a optimal target? I could sound like a total idiot but still asking
Quoted Message : This is evaluation, I think the question was to redirect request to a llm given a task if openai gpt3.5/4 isn‚Äôt responsive.\n\nBasically an llm on top that decides which llm to call given the context and the task.

Message : I guess instead of doing that in every request tho, it would be good to have a separate layer that just checks the uptime/latency of multiple models.

Message : no, you are right, 
it doesn't have to be a llm,
it can also be a simple policy based model that overtime learns which model is better at what
Quoted Message : Curious. Does it have to be a LLM monitoring other LLMs. Can we not use a service mesh and a controller approach to decide a optimal target? I could sound like a total idiot but still asking

Message : Just curious , $100K/month ?
Which company is this , if you are comfortable sharing ?
Quoted Message : Right, we are paying like $100K to OpenAI and there's so much downtime going on.

Message : Writesonic

Message : Damn. Those are some incredibly good reviews. Nicely done
Quoted Message : Writesonic

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØNavita

Message : Good on him. Although I think this question was asked purely for optics I feel

Message : And the tweet to which Sam replied.
I mean come on, sounded as if gurnani  took offence on behalf of the whole Indian startup ecosystem.

India's fav past time : getting offended ü§¶ü§¶ü§¶

Message : Most of the questions in ET event were asked to either sound smart or funny.
Quoted Message : Good on him. Although I think this question was asked purely for optics I feel

Message : Oh no. It was fun seeing a bunch of people boil over with rage in a patriotic fire

Message : Ya. Problem wahi hai
Quoted Message : Most of the questions in ET event were asked to either sound smart or funny.

Message : Was it though? Barring a couple of moments , I thought it was very good
Quoted Message : Most of the questions in ET event were asked to either sound smart or funny.

Message : Honestly, some of the comments seemed to be driven by a tinge of jealousy

Message : They outsource software, we outsource nationalism.
Quoted Message : Oh no. It was fun seeing a bunch of people boil over with rage in a patriotic fire

Message : Hahahhaha
Quoted Message : They outsource software, we outsource nationalism.

Message : Atleast, that's what I felt on Twitter. The negative reactions seemed way too overblown
Quoted Message : Honestly, some of the comments seemed to be driven by a tinge of jealousy

Message : hey bharat,
are you in any way associated with WHO academy ?
Quoted Message : Atleast, that's what I felt on Twitter. The negative reactions seemed way too overblown

Message : Let's have this forum for discussing ideas, not what others are talking about :) 

Thanks for sharing Sam's reply @1937708xxxx

Message : And maybe community driven commentary üòÖ
Quoted Message : And the tweet to which Sam replied.\nI mean come on, sounded as if gurnani  took offence on behalf of the whole Indian startup ecosystem.\n\nIndia's fav past time : getting offended ü§¶ü§¶ü§¶

Message : I'd be really curious to learn how many commentators were actually present in the event in person or have seen the full YouTube stream

Message : ü´° Yes, sir. I wanted to add to the previous discussion, but it makes sense. We will lose focus.
Quoted Message : Let's have this forum for discussing ideas, not what others are talking about :) \n\nThanks for sharing Sam's reply @193xxxxxxxx

Message : We are kind of using this - but in a very limited way and not really full fledged production. We have this deployed as a cache - which returns the LLM response (if cached) or frugalifies it (if no cache).
Quoted Message : Is there an implementation of this available on Github or anyone using in production already?

Message : Got it, thanks for sharing!
Quoted Message : We are kind of using this - but in a very limited way and not really full fledged production. We have this deployed as a cache - which returns the LLM response (if cached) or frugalifies it (if no cache).

Message : Hey Samanyou, we do this at Portkey and open sourcing parts of this soon. Also on to load balancing, fallbacks and more as part of this effort
Quoted Message : Has anyone built a model router here to automatically route requests to different LLMs like OpenAI, Anthropic etc based on downtime, latency etc?

Message : That sounds comforting. Will DM you, @91989995xxxx if that‚Äôs okay with you.

Been evaluating multiple platforms that cater to the whole nine yards of ops including production but yet to find something that‚Äôs prod grade.
Quoted Message : Hey Samanyou, we do this at Portkey and open sourcing parts of this soon. Also on to load balancing, fallbacks and more as part of this effort

Message : Absolutely! I‚Äôve strongly felt that deploying to LLMs and maintenance can be slightly iffy in production and we want to change that.
Quoted Message : That sounds comforting. Will DM you, @9198xxxxxxxx if that‚Äôs okay with you.\n\nBeen evaluating multiple platforms that cater to the whole nine yards of ops including production but yet to find something that‚Äôs prod grade.

Message : At the risk of sounding like a broken record - if anybody‚Äôs tried semantic caching, would love to connect. We‚Äôre starting to do backtesting on what we‚Äôve built and I want to learn more. Also if you‚Äôve seen any resources outside of GPTCache please send them. 

This is something that‚Äôs getting people excited but is a hard problem to get right

Message : We‚Äôre spending a lot of time thinking about this. Happy to connect and chat
Quoted Message : At the risk of sounding like a broken record - if anybody‚Äôs tried semantic caching, would love to connect. We‚Äôre starting to do backtesting on what we‚Äôve built and I want to learn more. Also if you‚Äôve seen any resources outside of GPTCache please send them. \n\nThis is something that‚Äôs getting people excited but is a hard problem to get right

Message : Even the operating system should follow the concept and keep only useful things on my desk top. It's a pain to clean up the desktop once every now and then.
Quoted Message : One ux idea that I‚Äôm very keen on is this.\n\nKeep hiding functions seldom used behind a universal search, so that over time, UX is simpler per each user‚Äôs needs.\n\nSemantic search can easily enable popping up of seldom used functions whenever they‚Äôre needed.\n\nImagine how popular apps like Twitter, WhatsApp can start getting simplified over time as users choose certain features over others.

Message : https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns/?utm_source=share&utm_medium=member_android

Message : Interesting to see so many companies in Health And drug discovery.

Message : There is already a bubble. We will see in 2024/5 whether there will be a good consolidation of some kind or a wipe out of the overvalued and over leveraged business
Quoted Message : https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns/?utm_source=share&utm_medium=member_android

Message : On this line, is there any basic course on drug discovery/biotech  + ML?
Quoted Message : https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns/?utm_source=share&utm_medium=member_android

Message : There is 0 in Ed

Message : I also have a doubt about so many companies raising in content gen ( audio, video, text) I highly doubt how will they keep up to that valuation after seeing what FAIR ( Facebook AI Research lab )  has been doing first with MusicGen and the kid of tools they will be rolling out on ads, agent chats, and photo editing.

Message : Something we follow here 

If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any admin for an invite link.

Message : Would love to test-drive the OS code when it's out üôå

Quick question - you mentioned fallbacks. How are you checking OpenAI heartbeat? Found only this API - https://status.openai.com/api/v2#status But it's not real-time.

Further, is there any way to get heartbeat at a model level?

Restriction - don't want to check status by generating response since it's wasteful
Quoted Message : Hey Samanyou, we do this at Portkey and open sourcing parts of this soon. Also on to load balancing, fallbacks and more as part of this effort

Message : https://ai.honu.io/papers/musicgen/

Message : Because we see requests across lots of users - we can sort of make a good judgement of API latencies and downtimes. 

Fallbacks are also more for rate-limits
Quoted Message : Would love to test-drive the OS code when it's out üôå\n\nQuick question - you mentioned fallbacks. How are you checking OpenAI heartbeat? Found only this API - https://status.openai.com/api/v2#status But it's not real-time. \n\nFurther, is there any way to get heartbeat at a model level?\n\nRestriction - don't want to check status by generating response since it's wasteful

Message : Does anyone know of good Text to presentation API?

Message : https://workspace.google.com/u/0/marketplace/app/plus_ai_for_google_slides/214277172452?ref=theresanaiforthat
Quoted Message : Does anyone know of good Text to presentation API?

Message : just added support for Palm models we now support openai, azure openai, google palm, alpha alpha do you guys know of any other hosted models that i should add support for. https://github.com/dosco/minds.

Message : Claude?

Message : how did i miss that one ü§¶‚Äç‚ôÇÔ∏èalso forgot to mention cohere
Quoted Message : Claude?

Message : Yeah, checked your readme before commenting. Saw cohere was already there so only mentioned Anthropic's Claude.

Message : thanks working on adding claude today. also the library got a mention on twitter from protosphinx https://twitter.com/protosphinx/status/1667557827211063299
Quoted Message : Yeah, checked your readme before commenting. Saw cohere was already there so only mentioned Anthropic's Claude.

Message : This is great, thanks for much for sharing. Just the Lib I needed today for our Sherpa Guide Agents.  Super helpful.  Does it also work with Active Pieces integrations?
Quoted Message : just added support for Palm models we now support openai, azure openai, google palm, alpha alpha do you guys know of any other hosted models that i should add support for. https://github.com/dosco/minds.

Message : could you explain that a bit more. it supports react prompting so yes you can include functions in your prompt that the ai will call as needed similar to chatgpt plugins
Quoted Message : This is great, thanks for much for sharing. Just the Lib I needed today for our Sherpa Guide Agents.  Super helpful.  Does it also work with Active Pieces integrations?

Message : Got it, our team is building flows https://cloud.activepieces.com/flows/ here and extending Agent frameworks further to handle enterprise class use case / error handling .. start, pause, rewind, end, BPM workflows, Decision trees etc


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Does anyone know of good Text to presentation API?

Message : https://workspace.google.com/u/0/marketplace/app/plus_ai_for_google_slides/214277172452?ref=theresanaiforthat
Quoted Message : Does anyone know of good Text to presentation API?

Message : just added support for Palm models we now support openai, azure openai, google palm, alpha alpha do you guys know of any other hosted models that i should add support for. https://github.com/dosco/minds.

Message : Claude?

Message : how did i miss that one ü§¶‚Äç‚ôÇÔ∏èalso forgot to mention cohere
Quoted Message : Claude?

Message : Yeah, checked your readme before commenting. Saw cohere was already there so only mentioned Anthropic's Claude.

Message : thanks working on adding claude today. also the library got a mention on twitter from protosphinx https://twitter.com/protosphinx/status/1667557827211063299
Quoted Message : Yeah, checked your readme before commenting. Saw cohere was already there so only mentioned Anthropic's Claude.

Message : This is great, thanks for much for sharing. Just the Lib I needed today for our Sherpa Guide Agents.  Super helpful.  Does it also work with Active Pieces integrations?
Quoted Message : just added support for Palm models we now support openai, azure openai, google palm, alpha alpha do you guys know of any other hosted models that i should add support for. https://github.com/dosco/minds.

Message : could you explain that a bit more. it supports react prompting so yes you can include functions in your prompt that the ai will call as needed similar to chatgpt plugins
Quoted Message : This is great, thanks for much for sharing. Just the Lib I needed today for our Sherpa Guide Agents.  Super helpful.  Does it also work with Active Pieces integrations?

Message : Got it, our team is building flows https://cloud.activepieces.com/flows/ here and extending Agent frameworks further to handle enterprise class use case / error handling .. start, pause, rewind, end, BPM workflows, Decision trees etc

Message : Interesting attack vector for attackers to inject malware when you use gpt4 and other generative ai tools to write code
(Paul Graham just rted this )

https://twitter.com/llm_sec/status/1667573374426701824?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : It‚Äôs a good old script kiddies technique but still works..(llm or not)..when you copy or lift code w/o paying attention to the package imports.
Enterprises have devops security tools and supply chain attack prevention mechanisms to handle such thro whitelist policies.
You can lookup SBOM standards like cycloneDX to know more about this
Quoted Message : Interesting attack vector for attackers to inject malware when you use gpt4 and other generative ai tools to write code\n(Paul Graham just rted this )\n\nhttps://twitter.com/llm_sec/status/1667573374426701824?s=48&t=pt9BgXoRTmqx5FEPyAl9bg

Message : Individual people writing code will be still vulnerable 
so it's a significant attack vector imho.
And with the popularity of gen ai more and more people who are not trained in cs will start writing code, most of it directly lifted from the output of a gen ai tool like GPT4

Message : Yes SBOM standards like CycloneDX and SPDX greatly reduce these attacks in enterprises. We have all released software going through a vulnerability and compliance engine and I would like to think all enterprises alike would be saving millions due to simple but stringent checks like these
Quoted Message : It‚Äôs a good old script kiddies technique but still works..(llm or not)..when you copy or lift code w/o paying attention to the package imports.\nEnterprises have devops security tools and supply chain attack prevention mechanisms to handle such thro whitelist policies.\nYou can lookup SBOM standards like cycloneDX to know more about this

Message : Is there any work actively being done to detect/prevent scams with AI deepfakes and AI generated voices?

Message : There's a lot of research for deep fakes. However, I'm not aware of anything for voice phishing as voice cloning with a neural voice is fairly recent.
Quoted Message : Is there any work actively being done to detect/prevent scams with AI deepfakes and AI generated voices?

Message : I haven‚Äôt seen any ready to use open source tools but there are a few papers. And some commercial tools, https://arxiv.org/abs/2304.13085
Quoted Message : There's a lot of research for deep fakes. However, I'm not aware of anything for voice phishing as voice cloning with a neural voice is fairly recent.

Message : Does anyone know of pretrained models for audio embeddings for song detection?

Message : Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model
https://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/

Very "big if true" energy to it

Message : Does seem like it
Quoted Message : Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model\nhttps://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/\n\nVery \"big if true\" energy to it

Message : Are you for or against this (if true ofcourse)
Quoted Message : Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model\nhttps://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/\n\nVery \"big if true\" energy to it

Message : I think for or against might be too extreme, but you get what I mean right? +ve or -ve

Message : It kind of confirms why we all felt that it got faster and dumber. Most likely GPT4 is going to have the same fate in near future.

This is also why I never liked those Vicuna style evaluations - 90% similar in performance to chatGPT. The ChatGPT you're using is continuously being optimised to be cheaper to run for openai, it can't act as a standard.
Quoted Message : Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model\nhttps://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/\n\nVery \"big if true\" energy to it

Message : How is this very big? Any implications? Maybe I don‚Äôt get it because I don‚Äôt really assume that openai has some secret sauce unknown to the outside world
Quoted Message : Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model\nhttps://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/\n\nVery \"big if true\" energy to it

Message : It's not big.it's quantised
Quoted Message : How is this very big? Any implications? Maybe I don‚Äôt get it because I don‚Äôt really assume that openai has some secret sauce unknown to the outside world

Message : I came across this implementation of Google's musicgen model: https://github.com/lucidrains/musiclm-pytorch
While they say to have used 44M curated videos/captions for _actually_ training it, they've only released https://www.kaggle.com/datasets/googleai/musiccaps.

Seems self-training is the only way forward here
Quoted Message : Does anyone know of pretrained models for audio embeddings for song detection?

Message : big if true if lower than 16 bitsüòõ
Quoted Message : Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model\nhttps://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/\n\nVery \"big if true\" energy to it

Message : I thought this was an old time-series problem.
Quoted Message : There's a lot of research for deep fakes. However, I'm not aware of anything for voice phishing as voice cloning with a neural voice is fairly recent.

Message : Shouldn‚Äôt come as a surprise as #users are continuously growing and CoGS need to be under control in this economic scenario.

I hypothesize OpenAI would prioritize quantization research over GPT-5 any day.
Quoted Message : Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model\nhttps://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/\n\nVery \"big if true\" energy to it

Message : Deployment effectiveness trumps loss function drops
Quoted Message : Shouldn‚Äôt come as a surprise as #users are continuously growing and CoGS need to be under control in this economic scenario.\n\nI hypothesize OpenAI would prioritize quantization research over GPT-5 any day.

Message : Many of the voice banking authentication services have no option but to be up to date.
Quoted Message : There's a lot of research for deep fakes. However, I'm not aware of anything for voice phishing as voice cloning with a neural voice is fairly recent.

Message : https://www.pindrop.com

Message : As an example

Message : Hey thanks üôå. I haven't got an opportunity to explore anti-voice phishing technologies much. I'll check this and the one mentioned above in this thread out.

Message : Audio Visual AI Assistants
TL;DR

https://arxiv.org/abs/2306.02858

Message : How are LLMs with time series data

Message : Please update if you find something good.
Quoted Message : Hey thanks üôå. I haven't got an opportunity to explore anti-voice phishing technologies much. I'll check this and the one mentioned above in this thread out.

Message : Looks like @91982082xxxx started a fund also to be able to build agi in India. Would love to know more @91982082xxxx . 
Some questions this group might have
1. Who gets to use this fund?
2. Who gets to contribute?
3. How to apply to use this?
4. Is it agi directed or yet another foundation model fund?

Message : Not a fund. More a grants program for foundational research. No details firmed up for now. Collaborating with @91876396xxxx to give shape and form in coming week. Looking forward to collaborating and seeking inputs from this group üôèüèº
Quoted Message : Looks like @9198xxxxxxxx started a fund also to be able to build agi in India. Would love to know more @9198xxxxxxxx . \nSome questions this group might have\n1. Who gets to use this fund?\n2. Who gets to contribute?\n3. How to apply to use this? \n4. Is it agi directed or yet another foundation model fund?

Message : Right now it‚Äôs just my personal money . Intent is to back 10 teams/projects that are chasing AGI research. Only clarity is on ask : that works needs to be open source

Message : @91773788xxxx :)

Message : Skepticsim and critique super welcome as well üòÅ

Message : I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don‚Äôt think we have enough talent to even do the former.

And on top of that, agi is fairly research heavy and to make any useful dent, personal endeavours May not be enough üòÖ

Message : A lot of it is early, a lot of the thoughts are evolving

It's probably not going to become like another OpenAI like AGI pursuit, but could well be a trigger that spurs folks to pursue some form of AGI that's relevant to our context
Quoted Message : I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don‚Äôt think we have enough talent to even do the former.\n\nAnd on top of that, agi is fairly research heavy and to make any useful dent, personal endeavours May not be enough üòÖ

Message : Not to miss the fact that none of us really know what‚Äôs agi research and how does it look like. üòÖ

Message : But I think endeavours like this would be enough to spark a conversation
Quoted Message : I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don‚Äôt think we have enough talent to even do the former.\n\nAnd on top of that, agi is fairly research heavy and to make any useful dent, personal endeavours May not be enough üòÖ

Message : Although I agree with the fact that academic help would also be important with monetary

Message : There‚Äôll be all sort of help needed. Enabling and triggering research just seemed like one vector to kick off on
Quoted Message : Although I agree with the fact that academic help would also be important with monetary

Message : I guess the key is "Foundational Research" as opposed to only AGI

Thankfully, we have the only public platform in the world that has 1B+ users

The possibilities of building a Foundational layer on top of it are endless and I'd not be surprised if we get there very, very quickly

I've been very fortunate to have been involved/associated with some of the public sector initiatives

I'd written (what now seems like a dated piece) highlighting some stats - https://open.substack.com/pub/bizit/p/8-reimagining-governments-as-platforms
Quoted Message : Not to miss the fact that none of us really know what‚Äôs agi research and how does it look like. üòÖ

Message : Agreed
Quoted Message : There‚Äôll be all sort of help needed. Enabling and triggering research just seemed like one vector to kick off on


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : @91773788xxxx :)

Message : Skepticsim and critique super welcome as well üòÅ

Message : I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don‚Äôt think we have enough talent to even do the former.

And on top of that, agi is fairly research heavy and to make any useful dent, personal endeavours May not be enough üòÖ

Message : A lot of it is early, a lot of the thoughts are evolving

It's probably not going to become like another OpenAI like AGI pursuit, but could well be a trigger that spurs folks to pursue some form of AGI that's relevant to our context
Quoted Message : I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don‚Äôt think we have enough talent to even do the former.\n\nAnd on top of that, agi is fairly research heavy and to make any useful dent, personal endeavours May not be enough üòÖ

Message : Not to miss the fact that none of us really know what‚Äôs agi research and how does it look like. üòÖ

Message : But I think endeavours like this would be enough to spark a conversation
Quoted Message : I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don‚Äôt think we have enough talent to even do the former.\n\nAnd on top of that, agi is fairly research heavy and to make any useful dent, personal endeavours May not be enough üòÖ

Message : Although I agree with the fact that academic help would also be important with monetary

Message : There‚Äôll be all sort of help needed. Enabling and triggering research just seemed like one vector to kick off on
Quoted Message : Although I agree with the fact that academic help would also be important with monetary

Message : I guess the key is "Foundational Research" as opposed to only AGI

Thankfully, we have the only public platform in the world that has 1B+ users

The possibilities of building a Foundational layer on top of it are endless and I'd not be surprised if we get there very, very quickly

I've been very fortunate to have been involved/associated with some of the public sector initiatives

I'd written (what now seems like a dated piece) highlighting some stats - https://open.substack.com/pub/bizit/p/8-reimagining-governments-as-platforms
Quoted Message : Not to miss the fact that none of us really know what‚Äôs agi research and how does it look like. üòÖ

Message : Agreed
Quoted Message : There‚Äôll be all sort of help needed. Enabling and triggering research just seemed like one vector to kick off on

Message : Certain endeavours don‚Äôt fit a venture investing model.  Enabling research is one of those. In early days for an ecosystem gotta start somewhere. And as i put it out, odds are fully stacked against it, but worth trying

Message : There's a Mariana's trench between 
* being able to use all the advancements AI has seen recently
And
* Cracking AGI

And I feel I don't even see AGI from where we stand. There's a lot of value in solving problems for everyone around us and not immediately worry about AGI.

Message : The triggers to innovation are many and sometimes all we need is an inspiration from somewhere for things to snowball

Not sure how if all here would know but GPT was a 5 year arc

On one end we had OAI push the scaling laws via their DOTA agent effort

And on another end, in 2017, we had the transformer architecture come up

Very crudely put, one trigger was an internal realization and one trigger was external

The culmination of all of it is what makes OAI what it is today and I'm sure we don't know all the internal details so there could be many more
Quoted Message : Certain endeavours don‚Äôt fit a venture investing model.  Enabling research is one of those. In early days for an ecosystem gotta start somewhere. And as i put it out, odds are fully stacked against it, but worth trying

Message : What amount in total, and what number of projects/grants are you considering investing in?

e.g. $1M, 2-4 projects?

Message : It's really great to see folks putting in money into this. Requesting @91970311xxxx Can also comment from their journey with FOSS United, they have been giving FOSS grants for sometime.
Quoted Message : Not a fund. More a grants program for foundational research. No details firmed up for now. Collaborating with @9187xxxxxxxx to give shape and form in coming week. Looking forward to collaborating and seeking inputs from this group üôèüèº

Message : We'll share more deets as they flesh out üôèüèº

Super early
Quoted Message : What amount in total, and what number of projects/grants are you considering investing in?\n\ne.g. $1M, 2-4 projects?

Message : Would lean on saner folks  like @91876396xxxx and other here to help flesh it out. 

Only directional bet for now is on research enablement and backing enterprising folks who aren‚Äôt bogged down by the problem statement / stuck with ‚ÄúXX $ is needed to solve‚Äù
Quoted Message : We'll share more deets as they flesh out üôèüèº\n\nSuper early

Message : Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?

Message : ‚ÄéPOLL:
In the last 90 days ‚Äî have you trained a LoRA, ControlNet or Instruction/RLHF-finetuned a model >= 13B?
‚ÄéOPTION: Yes (16 votes)
‚ÄéOPTION: I'd love to learn how to (32 votes)
‚ÄéOPTION: No (5 votes)

Message : I think you‚Äôre pointing at we don‚Äôt have talent to train a Lora enough forget agi right? üòã

Message : More computational artists/prompt folks over in the group for generative art: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4

Thought Sunday night might not get a good response.

cc Soumyadeep @91740765xxxx, Amogh @91961949xxxx might know folks who can help as well
Quoted Message : Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?

Message : ‚Äé<attached: 00008325-GIF-2023-06-11-23-31-54.mp4>
Quoted Message : I think you‚Äôre pointing at we don‚Äôt have talent to train a Lora enough forget agi right? üòã

Message : Would love to know this. I‚Äôve not seen grants work well outside universities in India.
But then the world does have research only non university ai labs too. Haven‚Äôt heard of any in India though.
Quoted Message : It's really great to see folks putting in money into this. Requesting @9197xxxxxxxx Can also comment from their journey with FOSS United, they have been giving FOSS grants for sometime.

Message : My two cents: I agree slightly (key word slightly) with @91740765xxxx  that you will need to have good mechanisms/mentors to make this work. One of the few ones that worked in Open Source Community was GSoC. You will need mentors who are plugged in the code base, to really review and improve it. Just any mentor might not work. There are few folks who have both technical/math depth but most of those folks are probably slightly older and have jobs etc. So getting them to do this could also be tricky. There are interesting folks who are contributing in OSS, eg: IITG PhD students Zeel Patel (Nipun Batra's students) and Zeel they were doing it in pyprobml and JSL.
Quoted Message : Not a fund. More a grants program for foundational research. No details firmed up for now. Collaborating with @9187xxxxxxxx to give shape and form in coming week. Looking forward to collaborating and seeking inputs from this group üôèüèº

Message : Julia also had some excellent contributions
Quoted Message : My two cents: I agree slightly (key word slightly) with @9174xxxxxxxx  that you will need to have good mechanisms/mentors to make this work. One of the few ones that worked in Open Source Community was GSoC. You will need mentors who are plugged in the code base, to really review and improve it. Just any mentor might not work. There are few folks who have both technical/math depth but most of those folks are probably slightly older and have jobs etc. So getting them to do this could also be tricky. There are interesting folks who are contributing in OSS, eg: IITG PhD students Zeel Patel (Nipun Batra's students) and Zeel they were doing it in pyprobml and JSL.

Message : That was because Viral was based here for quite sometime. And they build the teams over time.
Quoted Message : Julia also had some excellent contributions

Message : Also, I‚Äôll point again. Engineering like Julia or gsoc has far more direction than research. üòÖ

Message : I was thinking of the GSOC model as well. But also hoping the companies focus more on their learning and growth rather than exploiting
Quoted Message : My two cents: I agree slightly (key word slightly) with @9174xxxxxxxx  that you will need to have good mechanisms/mentors to make this work. One of the few ones that worked in Open Source Community was GSoC. You will need mentors who are plugged in the code base, to really review and improve it. Just any mentor might not work. There are few folks who have both technical/math depth but most of those folks are probably slightly older and have jobs etc. So getting them to do this could also be tricky. There are interesting folks who are contributing in OSS, eg: IITG PhD students Zeel Patel (Nipun Batra's students) and Zeel they were doing it in pyprobml and JSL.

Message : I agree. I think there is still a huge gap that exists between Academia and Industry. If we can bridge that gap, there could be lot of interesting possibilities. The work I spoke of, this is Kevin Murphy's library and book's companion code. Tried to get students (senior year undergrad) to learn PGM (Probabilistic Graphical Model) only to realize that their basics of probability was quite lacking. So there will be challanges such as these.
Quoted Message : Also, I‚Äôll point again. Engineering like Julia or gsoc has far more direction than research. üòÖ

Message : Been on a few calls with Kevin Murphy to help GSOC students contribute to OS projects. There‚Äôs always a steep learning curve in the beginning, that‚Äôs where the community always helps :)
Quoted Message : I agree. I think there is still a huge gap that exists between Academia and Industry. If we can bridge that gap, there could be lot of interesting possibilities. The work I spoke of, this is Kevin Murphy's library and book's companion code. Tried to get students (senior year undergrad) to learn PGM (Probabilistic Graphical Model) only to realize that their basics of probability was quite lacking. So there will be challanges such as these.

Message : What project was this?
Quoted Message : Been on a few calls with Kevin Murphy to help GSOC students contribute to OS projects. There‚Äôs always a steep learning curve in the beginning, that‚Äôs where the community always helps :)

Message : it was a jax project. that‚Äôs all I could reveal sadly lol
Quoted Message : What project was this?

Message : I like this https://www.betaworks.com/camp

Message : fun fact: Hugging Face was part of their initial cohort
Quoted Message : I like this https://www.betaworks.com/camp

Message : This is a fab approach for fostering cos. Something on those lines (more elaborate) is being worked on by another friend on this group :)
Quoted Message : I like this https://www.betaworks.com/camp

Message : that‚Äôs amazing. do keep us updated :)
Quoted Message : This is a fab approach for fostering cos. Something on those lines (more elaborate) is being worked on by another friend on this group :)

Message : Hey need some brainstorming - I was working on this idea - what do llms think of other llms quality?

https://github.com/aashay96/HumanModelComparison

But now that I think more on this line - can this dataset (seahorse by google - rated summaries by humans on 6 different parameters) be used to create a frugalGPT kind of system which has a policy network of top (can be llm with in-context learning as well), that given the task and context, redirects to the llm which will give the answer preferred by humans?

Message : If the human preference is quantified, i.e. you've a score given to each LLM as preferred by humans then yes I think it's possible.

I'm thinking of (Preference score)/(api costs) as a metric
Quoted Message : Hey need some brainstorming - I was working on this idea - what do llms think of other llms quality?\n\nhttps://github.com/aashay96/HumanModelComparison\n\nBut now that I think more on this line - can this dataset (seahorse by google - rated summaries by humans on 6 different parameters) be used to create a frugalGPT kind of system which has a policy network of top (can be llm with in-context learning as well), that given the task and context, redirects to the llm which will give the answer preferred by humans?

Message : Instead of simple redirecting to highest preferred LLM response or cheapest api costs, one can normalise preference wrt costs.

Message : Good idea
Quoted Message : Instead of simple redirecting to highest preferred LLM response or cheapest api costs, one can normalise preference wrt costs.

Message : You could also add another layer here, user budget.

Given a user budget of 5 usd, find out the max pref score/costs we can get. As in some cases, a value for human preference will be more given more budget.

Message : Midjourney is fantastic for generating generic output that works as stock images. If you want greater composition control, it‚Äôs Stable Diffusion + its entire ecosystem of support tools that you need.
Quoted Message : Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?

Message : Midjourney is like going to a fancy furniture store and buying the best looking sofa that suits your taste. You can‚Äôt swap out the design of an armrest for another one that you specifically want.
Stable Diffusion on the other hand is like going to the hardware store and buying a hammer, nails, saw, wood and fabric to build the sofa of your dreams, exactly how you want it. The tradeoff is that you must learn carpentry and put in the time and work to learn the craft.
Quoted Message : Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?

Message : Loving the analogy :)

Message : Remember this from the May meetup, great way to put it
Quoted Message : Midjourney is like going to a fancy furniture store and buying the best looking sofa that suits your taste. You can‚Äôt swap out the design of an armrest for another one that you specifically want.\nStable Diffusion on the other hand is like going to the hardware store and buying a hammer, nails, saw, wood and fabric to build the sofa of your dreams, exactly how you want it. The tradeoff is that you must learn carpentry and put in the time and work to learn the craft.

Message : Midjourney can give you jaw dropping results in the generic realm across a broad range of artistic styles. The key to that being ridiculously good RLHF built right into the product. Even with its Discord interface I call Midjourney the most brilliantly designed product I‚Äôve ever seen. Saying this as a product guy. Just by using the product you contribute to its improvement ü§å

Message : For magical composition control with consistent characters and style, Dashtoon beta drops this week!

Message : I want to get my hands onto this üî•
Quoted Message : For magical composition control with consistent characters and style, Dashtoon beta drops this week!

Message : üíØ
Quoted Message : For magical composition control with consistent characters and style, Dashtoon beta drops this week!

Message : Well said. One doesn‚Äôt mean flashy ui to build something exceptional.
Quoted Message : Midjourney can give you jaw dropping results in the generic realm across a broad range of artistic styles. The key to that being ridiculously good RLHF built right into the product. Even with its Discord interface I call Midjourney the most brilliantly designed product I‚Äôve ever seen. Saying this as a product guy. Just by using the product you contribute to its improvement ü§å


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You could also add another layer here, user budget.

Given a user budget of 5 usd, find out the max pref score/costs we can get. As in some cases, a value for human preference will be more given more budget.

Message : Midjourney is fantastic for generating generic output that works as stock images. If you want greater composition control, it‚Äôs Stable Diffusion + its entire ecosystem of support tools that you need.
Quoted Message : Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?

Message : Midjourney is like going to a fancy furniture store and buying the best looking sofa that suits your taste. You can‚Äôt swap out the design of an armrest for another one that you specifically want.
Stable Diffusion on the other hand is like going to the hardware store and buying a hammer, nails, saw, wood and fabric to build the sofa of your dreams, exactly how you want it. The tradeoff is that you must learn carpentry and put in the time and work to learn the craft.
Quoted Message : Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?

Message : Loving the analogy :)

Message : Remember this from the May meetup, great way to put it
Quoted Message : Midjourney is like going to a fancy furniture store and buying the best looking sofa that suits your taste. You can‚Äôt swap out the design of an armrest for another one that you specifically want.\nStable Diffusion on the other hand is like going to the hardware store and buying a hammer, nails, saw, wood and fabric to build the sofa of your dreams, exactly how you want it. The tradeoff is that you must learn carpentry and put in the time and work to learn the craft.

Message : Midjourney can give you jaw dropping results in the generic realm across a broad range of artistic styles. The key to that being ridiculously good RLHF built right into the product. Even with its Discord interface I call Midjourney the most brilliantly designed product I‚Äôve ever seen. Saying this as a product guy. Just by using the product you contribute to its improvement ü§å

Message : For magical composition control with consistent characters and style, Dashtoon beta drops this week!

Message : I want to get my hands onto this üî•
Quoted Message : For magical composition control with consistent characters and style, Dashtoon beta drops this week!

Message : üíØ
Quoted Message : For magical composition control with consistent characters and style, Dashtoon beta drops this week!

Message : Well said. One doesn‚Äôt mean flashy ui to build something exceptional.
Quoted Message : Midjourney can give you jaw dropping results in the generic realm across a broad range of artistic styles. The key to that being ridiculously good RLHF built right into the product. Even with its Discord interface I call Midjourney the most brilliantly designed product I‚Äôve ever seen. Saying this as a product guy. Just by using the product you contribute to its improvement ü§å

Message : Text me with what you want to create Prashant!
Quoted Message : Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?

Message : Amogh are you folks moving from a content company to a  gen ai platform company ?
Quoted Message : For magical composition control with consistent characters and style, Dashtoon beta drops this week!

Message : They were never a content company ‚Äî just look at the folks they've hired and the app üòÖ
Quoted Message : Amogh are you folks moving from a content company to a  gen ai platform company ?

Message : If you used the app, it's arguably the only GenAI business I'd put money in

Message : No
Quoted Message : Amogh are you folks moving from a content company to a  gen ai platform company ?

Message : How are the IP laws for genAI content in india?

Message : Is there a meaning of GenAI Platform which I misunderstood? That phrasing includes creator and reader tools?
Quoted Message : No

Message : The gen AI platform Dashtoon Studio is an enabler for creating fantastic content

Message : So it's an internal tool for Dashtoon ?
Quoted Message : The gen AI platform Dashtoon Studio is an enabler for creating fantastic content

Message : Not really. We are building whatever is needed to make content that folks like. A tool that allows more ppl to create content means more content üòÖ
Quoted Message : Amogh are you folks moving from a content company to a  gen ai platform company ?

Message : Started that way, but it seems good enough to us to be able to let others make content with it.
Quoted Message : So it's an internal tool for Dashtoon ?

Message : Think Pixar and Renderman. Pixar produces great content using Renderman, which started internally as a necessity but is now also open for public to use

Message : Sidenote ‚Äî Engineering focussed events:
1. Github is doing a Copilot focussed online Hackathon
2. Accel's @91994530xxxx is hosting a webinar on RAG and Guided Chat Convos with Limechat and Clevertap folks

Details here:

https://docs.google.com/spreadsheets/d/e/2PACX-1vTftcrqLyUN8N81ekOBsQgWUWqg_t0QKk0Xil49OZKNhSrhHHN3DZRucTo4RJnYGQBYzes0NFxJKAL_/pubhtml

Message : cc @91882678xxxx for any Github/Microsoft Hack questions
Quoted Message : Sidenote ‚Äî Engineering focussed events:\n1. Github is doing a Copilot focussed online Hackathon\n2. Accel's @9199xxxxxxxx is hosting a webinar on RAG and Guided Chat Convos with Limechat and Clevertap folks\n\nDetails here: \n\nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vTftcrqLyUN8N81ekOBsQgWUWqg_t0QKk0Xil49OZKNhSrhHHN3DZRucTo4RJnYGQBYzes0NFxJKAL_/pubhtml

Message : We still believe our core is content. For most ppl, good content is what will attract them to Dashtoon.
Quoted Message : Is there a meaning of GenAI Platform which I misunderstood? That phrasing includes creator and reader tools?

Message : Aaah, fair. 


I'm too deep in the idea that all *great* content products will use GenAI ‚Äî I conflated the two phrasings in my head.
Quoted Message : We still believe our core is content. For most ppl, good content is what will attract them to Dashtoon.

Message : Thanks Nirant , resharing the link here :https://www.fastestcoderfirst.com/
Quoted Message : cc @9188xxxxxxxx for any Github/Microsoft Hack questions

Message : NLP x Academia Webinar from ACM KIDD:

Date of Virtual Event: *15th June 2023, 6:30-8:30 PM*
Website: https://ikdd.acm.org/social-meetups.php
Registration Form: https://forms.gle/cN2hyWksPWLNuLMf7
Application Deadline: *13th June 2023, 5:00 PM*

h/t Lavanya @91937983xxxx for sharing this!

Message : Folks please ping @91961949xxxx for beta access directly
Quoted Message : Think Pixar and Renderman. Pixar produces great content using Renderman, which started internally as a necessity but is now also open for public to use

Message : Hey peeps.. where is the Indic charitra.ai of India? I am sure people want to chat with Jethala and Babita, if not Anupama or Kapil Sharma

Message : cc @91994014xxxx @1267303xxxx are working on this. Additionally, someone of our skill can make this over a weekend: replicate.com/blog/fine-tune-llama-to-speak-like-homer-simpson
Quoted Message : Hey peeps.. where is the Indic charitra.ai of India? I am sure people want to chat with Jethala and Babita, if not Anupama or Kapil Sharma

Message : ‚Äé<attached: 00008382-PHOTO-2023-06-12-11-39-40.jpg>
Quoted Message : Hey peeps.. where is the Indic charitra.ai of India? I am sure people want to chat with Jethala and Babita, if not Anupama or Kapil Sharma

Message : the more famous the character, e.g., dumbledore, the more accurate it is

Message : also funny how it explicitly clarified, "no I can't _speak_ but imitation, sure".

Message : Nice! If it‚Äôs so easy why is it not live yet.
Quoted Message :  2023_06_12_3EB0363D0E0A21A0CD7917.jpeg

Message : Because you ain't gonna pay $20/mo for this
Quoted Message : Nice! If it‚Äôs so easy why is it not live yet.

Message : When I say charitra it means there are many characters available, we can spin up a new one with description, it needs to work well, it needs to work cheap at scale, scalable etc
Quoted Message : cc @9199xxxxxxxx @126xxxxxxxx are working on this. Additionally, someone of our skill can make this over a weekend: replicate.com/blog/fine-tune-llama-to-speak-like-homer-simpson

Message : How do you fine tune the indic language talking style?

Message : With GPT4, you might not need to

With Llama/others ‚Äî just transcribe the entire pirated show with Whisper Larger, run the Replicate script and you'll be 80% there
Quoted Message : How do you fine tune the indic language talking style?

Message : Interesting. Will try and see if its almost there

Message : Monetisation is not a problem if there is traffic
Quoted Message : Because you ain't gonna pay $20/mo for this

Message : @91800556xxxx Hello Aditya, welcome to the group. üòä‚ú®

Message : https://twitter.com/aishwarya_08/status/1668158923990237184

there was a large ai meetup ? did anyone attend ?

Message : Was there, most def less than 100 folks at the main meetup ‚Äî not sure about the After party thing. Same folks as this group were there, 2-5 new faces üòÖ
Quoted Message : https://twitter.com/aishwarya_08/status/1668158923990237184\n\nthere was a large ai meetup ? did anyone attend ?

Message : Are people using Bing instead of Google for search?

I feel it's getting better than Google

Message : I'm just talking about search and ranking / results  articles

Message : Bing has lost market share to Google since Jan 2023
https://searchengineland.com/microsoft-bing-search-market-share-problem-charts-41769
Quoted Message : Are people using Bing instead of Google for search?\n\nI feel it's getting better than Google

Message : I use Google for direct searches that I know definitely exist. And Bing for when I need to jump through multiple links or jot down multiple items in one place or arrive on a conclusion
Quoted Message : Are people using Bing instead of Google for search?\n\nI feel it's getting better than Google

Message : Bing is very slow so definitely not good for direct searches.

Message : Hmm. Interesting. Case where results might not correlate with market share.
Quoted Message : Bing has lost market share to Google since Jan 2023\nhttps://searchengineland.com/microsoft-bing-search-market-share-problem-charts-41769


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Monetisation is not a problem if there is traffic
Quoted Message : Because you ain't gonna pay $20/mo for this

Message : @91800556xxxx Hello Aditya, welcome to the group. üòä‚ú®

Message : https://twitter.com/aishwarya_08/status/1668158923990237184

there was a large ai meetup ? did anyone attend ?

Message : Was there, most def less than 100 folks at the main meetup ‚Äî not sure about the After party thing. Same folks as this group were there, 2-5 new faces üòÖ
Quoted Message : https://twitter.com/aishwarya_08/status/1668158923990237184\n\nthere was a large ai meetup ? did anyone attend ?

Message : Are people using Bing instead of Google for search?

I feel it's getting better than Google

Message : I'm just talking about search and ranking / results  articles

Message : Bing has lost market share to Google since Jan 2023
https://searchengineland.com/microsoft-bing-search-market-share-problem-charts-41769
Quoted Message : Are people using Bing instead of Google for search?\n\nI feel it's getting better than Google

Message : I use Google for direct searches that I know definitely exist. And Bing for when I need to jump through multiple links or jot down multiple items in one place or arrive on a conclusion
Quoted Message : Are people using Bing instead of Google for search?\n\nI feel it's getting better than Google

Message : Bing is very slow so definitely not good for direct searches.

Message : Hmm. Interesting. Case where results might not correlate with market share.
Quoted Message : Bing has lost market share to Google since Jan 2023\nhttps://searchengineland.com/microsoft-bing-search-market-share-problem-charts-41769

Message : The only search engine that seemed to stick for me besides Google was Neeva. But they shut down recently
Quoted Message : Are people using Bing instead of Google for search?\n\nI feel it's getting better than Google

Message : Interesting. Can you elaborate on this?
Quoted Message : Bing is very slow so definitely not good for direct searches.

Message : Official GoI Response on the Sam Altman remark about $10M bet for Foundation Models:
https://twitter.com/chandrarsrikant/status/1668156165774245888

Message : This perhaps makes McKinsey and BCG very happy: https://www.meity.gov.in/tenders/rfp-india-semiconductor-mission-under-ministry-electronics-information-technology-miety-6

cc @91931565xxxx you might find the tender for Semiconductor Mission from GoI interesting

Message : I don't mind using Bing but Googling has become a habit and is the default search page on my browser which probably unconsciously locks me in.
Quoted Message : I use Google for direct searches that I know definitely exist. And Bing for when I need to jump through multiple links or jot down multiple items in one place or arrive on a conclusion

Message : yeah not sure if any india based consultancy would have revenue upwards of 500 crores
Quoted Message : This perhaps makes McKinsey and BCG very happy: https://www.meity.gov.in/tenders/rfp-india-semiconductor-mission-under-ministry-electronics-information-technology-miety-6\n\ncc @9193xxxxxxxx you might find the tender for Semiconductor Mission from GoI interesting

Message : üçøüçø
Sam Altman clarified this yet they continue the bravado.
I actually really liked his reply to the question, it was apt.
Quoted Message : Official GoI Response on the Sam Altman remark about $10M bet for Foundation Models:\nhttps://twitter.com/chandrarsrikant/status/1668156165774245888

Message : I did for 3 months and had to leave. Less ads is a +ve but too many negatives. Doesn't connect well with maps, Wikipedia, doesnt have a panel that summarises things well, etc etc
Quoted Message : Are people using Bing instead of Google for search?\n\nI feel it's getting better than Google

Message : As someone who has worked on govt tender documents, I am sure there is atleast ONE üòÖ
Quoted Message : yeah not sure if any india based consultancy would have revenue upwards of 500 crores

Message : 500 cr for a consulting firm is nothing. Mid sized law firms do 500 cr.

Message : Most of the queries that I do in my daily life are related to just basic recall or quick lookup for something interesting that I've heard. I find that Bing easily takes 5-8s to complete it's answer and tell me something that I can get in a fraction of a second on Google.

For the other stuff that requires any level of research or comprehension, I love to offload to Bing.
Quoted Message : Interesting. Can you elaborate on this?

Message : What is "mid" here?
Quoted Message : 500 cr for a consulting firm is nothing. Mid sized law firms do 500 cr.

Message : 200 partners? Mid by intl standards.
Quoted Message : What is \"mid\" here?

Message : 150 maybe. Even less. Depends on the practice areas.

Message : How does a Govt tender for Semiconductor like this work? It'll go to a consulting agency, which in turn will speak to Intel/Apple/NVIDIA of the world?
Quoted Message : As someone who has worked on govt tender documents, I am sure there is atleast ONE üòÖ

Message : I would strongly suggest using perplexity.ai over Bard, Bing or ChatGPT with Browsing. It has made my "search workflow" so much faster.
Quoted Message : Most of the queries that I do in my daily life are related to just basic recall or quick lookup for something interesting that I've heard. I find that Bing easily takes 5-8s to complete it's answer and tell me something that I can get in a fraction of a second on Google.\n\nFor the other stuff that requires any level of research or comprehension, I love to offload to Bing.

Message : TSMC
Quoted Message : How does a Govt tender for Semiconductor like this work? It'll go to a consulting agency, which in turn will speak to Intel/Apple/NVIDIA of the world?

Message : +1 - superb exp on perplexity
Quoted Message : I would strongly suggest using perplexity.ai over Bard, Bing or ChatGPT with Browsing. It has made my \"search workflow\" so much faster.

Message : The govt usually speaks to Intel, apple etc, and the PMC does everything else, there are some variations. My wife drafts these docs for govts, and would be the expert to speak to on this üòÖ
Quoted Message : How does a Govt tender for Semiconductor like this work? It'll go to a consulting agency, which in turn will speak to Intel/Apple/NVIDIA of the world?

Message : At least one feb with <=7nm put us on the map otherwise it won‚Äôt be worth. It takes so much time and capital to build a fab.

Message : Current plans are for 28-65 nm fabs I guess, at least until the last year's plan.

Message : Yes, I saw that. Even Vedanta was 22nm. US has insentive to have alternative than Taiwan due to tension with China. India should push to get one. Intel is building one in Ohio for 20B and it keeps delaying. This is a very very tough thing. A grain of dust will discard the whole wafer.
Quoted Message : Current plans are for 28-65 nm fabs I guess, at least until the last year's plan.

Message : FinGPT is an open-source LLM for the finance sector. It takes a data-centric approach, providing researchers & practitioners with accessible resources to develop FinLLMs.

paper: arxiv.org/abs/2306.06031
code: github.com/AI4Finance-Fou‚Ä¶

Message : Thoughts on this ?

Message : Thread: https://twitter.com/omarsar0/status/1668060502663077891?s=48&t=_vYiPpaKOpxR0JOyLHFC0A

Message : why not? large number of applications at the trailing edge. haven't heard of a country to get to <20 nm without first getting the lower nodes sorted.

Frankly even US's current weaknesses in semis are linked more to lack of trailing edge in the , where china et al are actually fairly robust
Quoted Message : At least one feb with <=7nm put us on the map otherwise it won‚Äôt be worth. It takes so much time and capital to build a fab.

Message : maybe this needs a separate group though :)

Message : After all these efforts, we shouldn‚Äôt repeat US mistake.
Quoted Message : why not? large number of applications at the trailing edge. haven't heard of a country to get to <20 nm without first getting the lower nodes sorted.\n\nFrankly even US's current weaknesses in semis are linked more to lack of trailing edge in the , where china et al are actually fairly robust

Message : Agree
Quoted Message : maybe this needs a separate group though :)

Message : Yeah, I've been exposed to OS financial LLMs before via Stochastic.

They built a more recent knowledge cut off (Mar 2023) financial LLM using the BloombergGPT technical paper.

I was in the process of going through their implementation to reproduce their efforts.

But they're really bad at marketing their efforts. Now I'll probably look at both xFinance and FinGPT together to learn things.

xFinance from Stochastic - https://www.stochastic.ai/blog/xfinance-vs-bloomberg-gpt
Quoted Message : FinGPT is an open-source LLM for the finance sector. It takes a data-centric approach, providing researchers & practitioners with accessible resources to develop FinLLMs.\n\npaper: arxiv.org/abs/2306.06031\ncode: github.com/AI4Finance-Fou‚Ä¶

Message : Please share here some insights from xFinance too 

:)
Quoted Message : Yeah, I've been exposed to OS financial LLMs before via Stochastic.\n\nThey built a more recent knowledge cut off (Mar 2023) financial LLM using the BloombergGPT technical paper. \n\nI was in the process of going through their implementation to reproduce their efforts.\n\nBut they're really bad at marketing their efforts. Now I'll probably look at both xFinance and FinGPT together to learn things.\n\nxFinance from Stochastic - https://www.stochastic.ai/blog/xfinance-vs-bloomberg-gpt

Message : understandably a fluffy response
Quoted Message : Official GoI Response on the Sam Altman remark about $10M bet for Foundation Models:\nhttps://twitter.com/chandrarsrikant/status/1668156165774245888

Message : The biggest problem that we‚Äôve faced so far has been the lack of quality FOSS projects coming forward claiming the grants!
Quoted Message : It's really great to see folks putting in money into this. Requesting @9197xxxxxxxx Can also comment from their journey with FOSS United, they have been giving FOSS grants for sometime.

Message : https://twitter.com/fabianstelzer/status/1668181498032160769

Wow I'm impressed. Whistle -> Symphony with MusicGen.

Message : By quality do you mean the impact of the problems they're trying to solve?
Quoted Message : The biggest problem that we‚Äôve faced so far has been the lack of quality FOSS projects coming forward claiming the grants!

Message : ~impact~ scope*
Quoted Message : By quality do you mean the impact of the problems they're trying to solve?

Message : hey folks can someone please link that website which was elo rating llms ?

Message : https://lmsys.org/blog/2023-05-03-arena/

Message : What‚Äôs the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys‚Äô experience?
Currently doing 1000 with an overlap of 100.

Message : hit n trial. depends on the text type. 

here 100, 1000 is no. of characters right?
for overlap, i like 3-5 lines overlap. again depends on text. i used 3-5 for substack articles.
Quoted Message : What‚Äôs the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys‚Äô experience?\nCurrently doing 1000 with an overlap of 100.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Please share here some insights from xFinance too 

:)
Quoted Message : Yeah, I've been exposed to OS financial LLMs before via Stochastic.\n\nThey built a more recent knowledge cut off (Mar 2023) financial LLM using the BloombergGPT technical paper. \n\nI was in the process of going through their implementation to reproduce their efforts.\n\nBut they're really bad at marketing their efforts. Now I'll probably look at both xFinance and FinGPT together to learn things.\n\nxFinance from Stochastic - https://www.stochastic.ai/blog/xfinance-vs-bloomberg-gpt

Message : understandably a fluffy response
Quoted Message : Official GoI Response on the Sam Altman remark about $10M bet for Foundation Models:\nhttps://twitter.com/chandrarsrikant/status/1668156165774245888

Message : The biggest problem that we‚Äôve faced so far has been the lack of quality FOSS projects coming forward claiming the grants!
Quoted Message : It's really great to see folks putting in money into this. Requesting @9197xxxxxxxx Can also comment from their journey with FOSS United, they have been giving FOSS grants for sometime.

Message : https://twitter.com/fabianstelzer/status/1668181498032160769

Wow I'm impressed. Whistle -> Symphony with MusicGen.

Message : By quality do you mean the impact of the problems they're trying to solve?
Quoted Message : The biggest problem that we‚Äôve faced so far has been the lack of quality FOSS projects coming forward claiming the grants!

Message : ~impact~ scope*
Quoted Message : By quality do you mean the impact of the problems they're trying to solve?

Message : hey folks can someone please link that website which was elo rating llms ?

Message : https://lmsys.org/blog/2023-05-03-arena/

Message : What‚Äôs the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys‚Äô experience?
Currently doing 1000 with an overlap of 100.

Message : hit n trial. depends on the text type. 

here 100, 1000 is no. of characters right?
for overlap, i like 3-5 lines overlap. again depends on text. i used 3-5 for substack articles.
Quoted Message : What‚Äôs the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys‚Äô experience?\nCurrently doing 1000 with an overlap of 100.

Message : No of tokens.
Quoted Message : hit n trial. depends on the text type. \n\nhere 100, 1000 is no. of characters right?\nfor overlap, i like 3-5 lines overlap. again depends on text. i used 3-5 for substack articles.

Message : ah right üëç. 100 chars would be too low. ‚Äé<This message was edited>
Quoted Message : No of tokens.

Message : Yeah. Have a million documents, some 4-5k tokens each. So can‚Äôt make it lesser than 1000 because of cost issues.
Quoted Message : ah right üëç. 100 chars would be too low.

Message : 3-5 sentences is good
Quoted Message : What‚Äôs the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys‚Äô experience?\nCurrently doing 1000 with an overlap of 100.

Message : sorry i didn't get the cost issue (i.e it's link with 1000 token size)

also, don't you think 1000tokens per chunk is a lot? it's 750 words. assuming 10 words per sentence, 75 lines.

maybe someone with more expertise can fill in but im not sure that's good for search results.

also to reduce your embedding cost, maybe you could first pass these 750 word chunks to gpt3.5 to get a 75 word summary and embed that? again idk about your exact usecase so it may/ may not be useful.

also, since u have a million docs, maybe try out a couple of open-source embedding models. ‚Äé<This message was edited>
Quoted Message : Yeah. Have a million documents, some 4-5k tokens each. So can‚Äôt make it lesser than 1000 because of cost issues.

Message : Storage cost in vector DB cloud. A million vectors is ~ 50 usd. I‚Äôll have somewhere around 5M with 1000 chunk size.

I‚Äôm using an open source embedding model only
Quoted Message : sorry i didn't get the cost issue (i.e it's link with 1000 token size)\n\nalso, don't you think 1000tokens per chunk is a lot? it's 750 words. assuming 10 words per sentence, 75 lines. \n\nmaybe someone with more expertise can fill in but im not sure that's good for search results. \n\nalso to reduce your embedding cost, maybe you could first pass these 750 word chunks to gpt3.5 to get a 75 word summary and embed that? again idk about your exact usecase so it may/ may not be useful. \n\nalso, since u have a million docs, maybe try out a couple of open-source embedding models.

Message : Also considering self hosting a vector db. But db maintenance is always a headache.

Message : Aren't you charged per embedding size in vector db?
Quoted Message : Storage cost in vector DB cloud. A million vectors is ~ 50 usd. I‚Äôll have somewhere around 5M with 1000 chunk size.\n\nI‚Äôm using an open source embedding model only

Message : Depends on the vector db. Pinecone is per pod. 5M in a storage optimized pod. Weaviate and Qdrant is per vector size
Quoted Message : Aren't you charged per embedding size in vector db?

Message : Has anyone built / tried TTS models for Spanish language?

- what works? Are their practical differences between different Spanish speaking markets that breaks the code :-)

- speech to text and voice cloning libraries for Spanish language üôè

Message : Your vector size is fixed right?
Quoted Message : Depends on the vector db. Pinecone is per pod. 5M in a storage optimized pod. Weaviate and Qdrant is per vector size

Message : Regarding splitting documents into chunks, I have a question:

I have chunked up several datas(having unique keys initially) into parts. As a result now, the datas do not have unique keys anymore (they do have a subkey which is unique, but Im not interested in that).

When retrieving top-K by looking into these split-up chunks now with cosine similarity, my retriever gets multiple elements sometimes with same key.
I ideally don‚Äôt want that. I want unique key‚Äôed elements.

Any brainstorming ideas how to deal with this?
Quoted Message : What‚Äôs the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys‚Äô experience?\nCurrently doing 1000 with an overlap of 100.

Message : The main problem here is it looks into each and every chunk after splitting with equal importance.
Quoted Message : Regarding splitting documents into chunks, I have a question:\n\nI have chunked up several datas(having unique keys initially) into parts. As a result now, the datas do not have unique keys anymore (they do have a subkey which is unique, but Im not interested in that).\n\nWhen retrieving top-K by looking into these split-up chunks now with cosine similarity, my retriever gets multiple elements sometimes with same key. \nI ideally don‚Äôt want that. I want unique key‚Äôed elements.\n\nAny brainstorming ideas how to deal with this?

Message : There can be some datastructure manipulation, but I‚Äôm looking if there can be a retriever/embeddings-based solution to this‚Ä¶.without maintaining flags for the keys and storing in hashmaps or something like that.
Quoted Message : Regarding splitting documents into chunks, I have a question:\n\nI have chunked up several datas(having unique keys initially) into parts. As a result now, the datas do not have unique keys anymore (they do have a subkey which is unique, but Im not interested in that).\n\nWhen retrieving top-K by looking into these split-up chunks now with cosine similarity, my retriever gets multiple elements sometimes with same key. \nI ideally don‚Äôt want that. I want unique key‚Äôed elements.\n\nAny brainstorming ideas how to deal with this?

Message : We were talking about this the other day, and here we are - https://github.com/facebookresearch/audiocraft

They've released pretrained models also
Quoted Message : Does anyone know of pretrained models for audio embeddings for song detection?

Message : Thanks
Quoted Message : We were talking about this the other day, and here we are - https://github.com/facebookresearch/audiocraft\n\nThey've released pretrained models also

Message : Zilch to my knowledge.

Although I remember a few years ago a lawyer initiated a case for rejection of their copyright application because of listing an AI as an author. I haven't followed up on the case since
Quoted Message : How are the IP laws for genAI content in india?

Message : What are the advantages of a vector db vs regular postgres/rdbms db ??

Message : We've discussed basics of vector db, libs and so on quite often. Please scroll up. You can see some of the past community discussions too here: https://nirantk.com/ai
Quoted Message : What are the advantages of a vector db vs regular postgres/rdbms db ??

Message : Trying to understand more context, any reason why the composite unique key (unique page key+ unique chunk key within the page) is not desirable?
Quoted Message : Regarding splitting documents into chunks, I have a question:\n\nI have chunked up several datas(having unique keys initially) into parts. As a result now, the datas do not have unique keys anymore (they do have a subkey which is unique, but Im not interested in that).\n\nWhen retrieving top-K by looking into these split-up chunks now with cosine similarity, my retriever gets multiple elements sometimes with same key. \nI ideally don‚Äôt want that. I want unique key‚Äôed elements.\n\nAny brainstorming ideas how to deal with this?

Message : I think it is an opportunity. If multiple chunks are being matched to a query text, it means the original page is more similar to the query. You can group by Page id to and give more importance/score to pages who have more chunks matched
Quoted Message : Regarding splitting documents into chunks, I have a question:\n\nI have chunked up several datas(having unique keys initially) into parts. As a result now, the datas do not have unique keys anymore (they do have a subkey which is unique, but Im not interested in that).\n\nWhen retrieving top-K by looking into these split-up chunks now with cosine similarity, my retriever gets multiple elements sometimes with same key. \nI ideally don‚Äôt want that. I want unique key‚Äôed elements.\n\nAny brainstorming ideas how to deal with this?

Message : This is very smart
Quoted Message : I think it is an opportunity. If multiple chunks are being matched to a query text, it means the original page is more similar to the query. You can group by Page id to and give more importance/score to pages who have more chunks matched

Message : Say you have 10 chunks returned in descending order of cosine similarity

Message : Say threshold of 0.75

Message : Do you just sum the ones from the same page? To see which matches closest?

Message : Is there a better way?

Message : You can count the ones fulfilling the threshold.

Message : https://github.com/ggerganov/llama.cpp/pull/1827

Interesting discussion on the hn thread:
https://news.ycombinator.com/item?id=36304143

Message : Coherence, goal, technical quality, longevity, utility. Just a rule-of-thumb measure of common sense parameters.
Quoted Message : By quality do you mean the impact of the problems they're trying to solve?

Message : Heard about your conversation with Govind and Venky. Fair points, we are planning to address those in the Responsible AI Fellowship Fund being anchored by Omidyar Network
Quoted Message : Coherence, goal, technical quality, longevity, utility. Just a rule-of-thumb measure of common sense parameters.

Message : LMChatGPTFY? https://chat.openai.com/share/1f7d72d3-a26c-4932-96f4-ae8b06ea0e87
Quoted Message : What are the advantages of a vector db vs regular postgres/rdbms db ??

Message : Of the 7, 5 are outright wrong ü§£
Quoted Message : LMChatGPTFY? https://chat.openai.com/share/1f7d72d3-a26c-4932-96f4-ae8b06ea0e87

Message : much better, a bit more targeted https://chat.openai.com/share/5583e307-dfe0-4881-8ef4-8f0ab42ac84f

Message : ... and this is Bard ...

Message : Vector databases are a type of NoSQL database that store data as vectors, which are high-dimensional arrays of numbers. This makes them well-suited for tasks such as retrieval augmented generation, which requires the ability to quickly find similar data points.

Here are some of the advantages of using a vector database for retrieval augmented generation:

Faster search: Vector databases can index data much faster than traditional relational databases, which means that they can be used to find similar data points much more quickly. This is important for retrieval augmented generation, as it allows the system to generate new content that is more likely to be relevant to the user's query.
More efficient storage: Vector databases can store data more efficiently than traditional relational databases, which means that they can be used to store larger datasets. This is important for retrieval augmented generation, as it allows the system to access a wider range of data when generating new content.
Flexible schema: Vector databases do not have a fixed schema, which means that they can be used to store data of any type. This is important for retrieval augmented generation, as it allows the system to store both structured and unstructured data.
However, there are also some disadvantages to using a vector database for retrieval augmented generation:

Less mature technology: Vector databases are a newer technology than traditional relational databases, which means that they are not as mature. This can lead to problems such as bugs and performance issues.
Less support: There is less support for vector databases than for traditional relational databases. This can make it more difficult to find developers who are familiar with vector databases and to get help with problems.
More complex queries: Queries on vector databases can be more complex than queries on traditional relational databases. This is because vector databases store data in a different way.
Overall, vector databases offer a number of advantages for retrieval augmented generation. However, they are also a newer technology with some disadvantages. The best choice for a particular application will depend on the specific requirements of that application.

Message : GPT4 ‚Äî all right in zero shot. Prompt Quality matters! 
https://chat.openai.com/share/26aa5f3b-f099-45c6-95e2-b9a0a765fb09
Quoted Message : much better, a bit more targeted https://chat.openai.com/share/5583e307-dfe0-4881-8ef4-8f0ab42ac84f

Message : Hi everyone, 

I am working on a personal project where I am trying to create new combinations of outfits from existing outfits. I have a corpus of roughly 300 outfits, each outfit can have more than 1 clothing items where a clothing item is a single item and it could be anything one wears. I want to create new outfits that I never wore from the exiting ones. Can any one help me out with already existing solutions which can work out of t he box to can be trained with limited data or a research paper I can dig deeper into. Any help would be useful.
Thanks in advance!

Message : When you say ‚Äúfrom existing ones‚Äù what sort of attributes do you want to inherit?
Quoted Message : Hi everyone, \n\nI am working on a personal project where I am trying to create new combinations of outfits from existing outfits. I have a corpus of roughly 300 outfits, each outfit can have more than 1 clothing items where a clothing item is a single item and it could be anything one wears. I want to create new outfits that I never wore from the exiting ones. Can any one help me out with already existing solutions which can work out of t he box to can be trained with limited data or a research paper I can dig deeper into. Any help would be useful. \nThanks in advance!

Message : I wonder if there will be a separate market & usecase for 
1. basic search queries ( currently dominated by Google)
2. more detailed exploratory search market (with OpenAI emerging as a leader currently)

Will bring/Microsoft try to combine both 1,2 ?
Will Google try to integrate bard into Google.com ?

Had hopes from Neeva, challenging Google in search but they pivoted and got acquired by Snowflake [0]

0. https://www.snowflake.com/blog/snowflake-acquires-neeva-to-accelerate-search-in-the-data-cloud-through-generative-ai/
Quoted Message : GPT4 ‚Äî all right in zero shot. Prompt Quality matters! \nhttps://chat.openai.com/share/26aa5f3b-f099-45c6-95e2-b9a0a765fb09

Message : s.replace("bring", "Bing")
Quoted Message : I wonder if there will be a separate market & usecase for \n1. basic search queries ( currently dominated by Google) \n2. more detailed exploratory search market (with OpenAI emerging as a leader currently)\n\nWill bring/Microsoft try to combine both 1,2 ?\nWill Google try to integrate bard into Google.com ?\n\nHad hopes from Neeva, challenging Google in search but they pivoted and got acquired by Snowflake [0]\n\n0. https://www.snowflake.com/blog/snowflake-acquires-neeva-to-accelerate-search-in-the-data-cloud-through-generative-ai/


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : LMChatGPTFY? https://chat.openai.com/share/1f7d72d3-a26c-4932-96f4-ae8b06ea0e87
Quoted Message : What are the advantages of a vector db vs regular postgres/rdbms db ??

Message : Of the 7, 5 are outright wrong ü§£
Quoted Message : LMChatGPTFY? https://chat.openai.com/share/1f7d72d3-a26c-4932-96f4-ae8b06ea0e87

Message : much better, a bit more targeted https://chat.openai.com/share/5583e307-dfe0-4881-8ef4-8f0ab42ac84f

Message : ... and this is Bard ...

Message : Vector databases are a type of NoSQL database that store data as vectors, which are high-dimensional arrays of numbers. This makes them well-suited for tasks such as retrieval augmented generation, which requires the ability to quickly find similar data points.

Here are some of the advantages of using a vector database for retrieval augmented generation:

Faster search: Vector databases can index data much faster than traditional relational databases, which means that they can be used to find similar data points much more quickly. This is important for retrieval augmented generation, as it allows the system to generate new content that is more likely to be relevant to the user's query.
More efficient storage: Vector databases can store data more efficiently than traditional relational databases, which means that they can be used to store larger datasets. This is important for retrieval augmented generation, as it allows the system to access a wider range of data when generating new content.
Flexible schema: Vector databases do not have a fixed schema, which means that they can be used to store data of any type. This is important for retrieval augmented generation, as it allows the system to store both structured and unstructured data.
However, there are also some disadvantages to using a vector database for retrieval augmented generation:

Less mature technology: Vector databases are a newer technology than traditional relational databases, which means that they are not as mature. This can lead to problems such as bugs and performance issues.
Less support: There is less support for vector databases than for traditional relational databases. This can make it more difficult to find developers who are familiar with vector databases and to get help with problems.
More complex queries: Queries on vector databases can be more complex than queries on traditional relational databases. This is because vector databases store data in a different way.
Overall, vector databases offer a number of advantages for retrieval augmented generation. However, they are also a newer technology with some disadvantages. The best choice for a particular application will depend on the specific requirements of that application.

Message : GPT4 ‚Äî all right in zero shot. Prompt Quality matters! 
https://chat.openai.com/share/26aa5f3b-f099-45c6-95e2-b9a0a765fb09
Quoted Message : much better, a bit more targeted https://chat.openai.com/share/5583e307-dfe0-4881-8ef4-8f0ab42ac84f

Message : Hi everyone, 

I am working on a personal project where I am trying to create new combinations of outfits from existing outfits. I have a corpus of roughly 300 outfits, each outfit can have more than 1 clothing items where a clothing item is a single item and it could be anything one wears. I want to create new outfits that I never wore from the exiting ones. Can any one help me out with already existing solutions which can work out of t he box to can be trained with limited data or a research paper I can dig deeper into. Any help would be useful.
Thanks in advance!

Message : When you say ‚Äúfrom existing ones‚Äù what sort of attributes do you want to inherit?
Quoted Message : Hi everyone, \n\nI am working on a personal project where I am trying to create new combinations of outfits from existing outfits. I have a corpus of roughly 300 outfits, each outfit can have more than 1 clothing items where a clothing item is a single item and it could be anything one wears. I want to create new outfits that I never wore from the exiting ones. Can any one help me out with already existing solutions which can work out of t he box to can be trained with limited data or a research paper I can dig deeper into. Any help would be useful. \nThanks in advance!

Message : I wonder if there will be a separate market & usecase for 
1. basic search queries ( currently dominated by Google)
2. more detailed exploratory search market (with OpenAI emerging as a leader currently)

Will bring/Microsoft try to combine both 1,2 ?
Will Google try to integrate bard into Google.com ?

Had hopes from Neeva, challenging Google in search but they pivoted and got acquired by Snowflake [0]

0. https://www.snowflake.com/blog/snowflake-acquires-neeva-to-accelerate-search-in-the-data-cloud-through-generative-ai/
Quoted Message : GPT4 ‚Äî all right in zero shot. Prompt Quality matters! \nhttps://chat.openai.com/share/26aa5f3b-f099-45c6-95e2-b9a0a765fb09

Message : s.replace("bring", "Bing")
Quoted Message : I wonder if there will be a separate market & usecase for \n1. basic search queries ( currently dominated by Google) \n2. more detailed exploratory search market (with OpenAI emerging as a leader currently)\n\nWill bring/Microsoft try to combine both 1,2 ?\nWill Google try to integrate bard into Google.com ?\n\nHad hopes from Neeva, challenging Google in search but they pivoted and got acquired by Snowflake [0]\n\n0. https://www.snowflake.com/blog/snowflake-acquires-neeva-to-accelerate-search-in-the-data-cloud-through-generative-ai/

Message : So, Let‚Äôs say I have two Images: I1 : an image of a red shit and black pantsI2: an image of green t shirt and white ponts

I want to create a new outfit

I3: with a red shirt and white pants (assume this data point doesn‚Äôt exist in the data)

Does that answer your question? üòÖ
Quoted Message : When you say ‚Äúfrom existing ones‚Äù what sort of attributes do you want to inherit?

Message : FYI WhatsApp now has edit message
Quoted Message : s.replace(\"bring\", \"Bing\")

Message : Have you looked at any image inpainting solution such as interngpt, inpaint-anything ‚Äé<This message was edited>
Quoted Message : So, Let‚Äôs say I have two Images: I1 : an image of a red shit and black pantsI2: an image of green t shirt and white ponts\n\nI want to create a new outfit \n\nI3: with a red shirt and white pants (assume this data point doesn‚Äôt exist in the data)\n\nDoes that answer your question? üòÖ

Message : TIL üòÆ
Quoted Message : FYI WhatsApp now has edit message

Message : I haven‚Äôt. Let me have a look at it and get back! 
Thanks a lot! I really appreciate this!
Quoted Message : Have you looked at any image inpainting solution such as interngpt, inpaint-anything

Message : üëç. Hopefully works for you. There are many inpainting solutions. Challenge will be consistency

Message : I had made this few months back on similar lines https://github.com/ovshake/stable-fashion
Quoted Message : Have you looked at any image inpainting solution such as interngpt, inpaint-anything

Message : I want to a POC and then I can work on making it better from there !
Quoted Message : üëç. Hopefully works for you. There are many inpainting solutions. Challenge will be consistency

Message : Looks pretty good. I will check this out!
Quoted Message : I had made this few months back on similar lines https://github.com/ovshake/stable-fashion

Message : Should be good enough for POC.
Quoted Message : I want to a POC and then I can work on making it better from there !

Message : There you go. Loved it!
Quoted Message : I had made this few months back on similar lines https://github.com/ovshake/stable-fashion

Message : That‚Äôs reasonable and exactly what Im doing right now! But the problem is, say each document can be chunked upto a maximum of 100 chunks, and I want 5 _unique_ elements . There were originally 100 unique page ids. 
That means there can now be a maximum of 10000 chunks. By pigeonhole principle, to get unique 5 page ids, we must retrieve atleast top-401 elements.
Retrieving top-401 elements just for ultimately showing 5 unique page-ids is a slow process right?
Im trying to device a better/faster method here.

Message : That‚Äôs reasonable and exactly what Im doing right now! But the problem is, say each document can be chunked upto a maximum of 100 chunks, and I want 5 _unique_ elements . There were originally 100 unique page ids. \nThat means there can now be a maximum of 10000 chunks. By pigeonhole principle, to get unique 5 page ids, we must retrieve atleast top-401 elements.\nRetrieving top-401 elements just for ultimately showing 5 unique page-ids is a slow process right?\nIm trying to device a better/faster method here.
Quoted Message : I think it is an opportunity. If multiple chunks are being matched to a query text, it means the original page is more similar to the query. You can group by Page id to and give more importance/score to pages who have more chunks matched

Message : I don‚Äôt want to retrieve top-MAX_CHUNKS_PER_DOCUMENT * (k-1) + 1 elements just to be able to finally show k unique elements

Message : I think it‚Äôs naive

Message : Have you considered concatenating all the chunk vectors and then dimensionality reduction , so as to get the most informative pieces from each chunk captured in final dense vector ?
Quoted Message : I don‚Äôt want to retrieve top-MAX_CHUNKS_PER_DOCUMENT * (k-1) + 1 elements just to be able to finally show k unique elements

Message : You can try to employ MMR (maximal marginal relevance) to rerank 

So retrieve top N chunks, then MMR(retrieved_chunks) to rerank for diversity and then take the top K elements from the reranked list
Quoted Message : I don‚Äôt want to retrieve top-MAX_CHUNKS_PER_DOCUMENT * (k-1) + 1 elements just to be able to finally show k unique elements

Message : So here‚Äôs a question: when do you consider a vector optimally dense, and what is the limit you can keep doing dimensional reduction?
Quoted Message : Have you considered concatenating all the chunk vectors and then dimensionality reduction , so as to get the most informative pieces from each chunk captured in final dense vector ?

Message : To my understanding, embeddings-based vectors are already pretty dense

Message : due to attention mechanism of the Transformers

Message : You can experiment to see if this gives reasonable results along with performance that you wanted.

Message : I don‚Äôt get it. 
What is the ‚ÄúN‚Äù here?
That‚Äôs what I‚Äôm trying to optimise to first have enough _diversity_ in the candidate elements Im trying to rerank
Quoted Message : You can try to employ MMR (maximal marginal relevance) to rerank \n\nSo retrieve top N chunks, then MMR(retrieved_chunks) to rerank for diversity and then take the top K elements from the reranked list

Message : the alternate way i like is to use something like elasticsearch with a composite relevance ranking of dense_vector (embeddings) with "terms aggregation" https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html
Quoted Message : You can try to employ MMR (maximal marginal relevance) to rerank \n\nSo retrieve top N chunks, then MMR(retrieved_chunks) to rerank for diversity and then take the top K elements from the reranked list

Message : this is built in

Message : The diversity is hard to get from plain vector search. The documents are already distributed in the embedding space according to their embedding method

Message : But you can rerank a list of (chunk, vector) pairs using MMR which maximises diversity

Message : I‚Äôm trying to build this from scratch to clear my understandings üòõ
Quoted Message : this is built in

Message : So to do that, let‚Äôs say you need 100 items, then fetch top 200 first sorted by similarity then rerank using MMR and then take the top 100

Message : That should get you the maximum intersection of relevance and diversity from your dataset

Message : This also depends on the quality of embeddings

Message : I dont think you get my exact question here.
The *N* you just spoke about, i.e., the candidate elements you need ti fetch first before trying to rerank.
I‚Äôm trying to optimise that.
My claim is N should be atleast MAX_CHUNKS_PER_DOCUMENT *(k-1) + 1 to get k unique elements
Quoted Message : The diversity is hard to get from plain vector search. The documents are already distributed in the embedding space according to their embedding method

Message : But im looking for a better method because that can be slow based on MAX_CHUNKS_PER_DOCUMENT and _k_

Message : The reranking comes after that, and I agree there can be several reranking methods including MRR

Message : top 200 might not guarantee 100 unique elements
Quoted Message : So to do that, let‚Äôs say you need 100 items, then fetch top 200 first sorted by similarity then rerank using MMR and then take the top 100

Message : you should. by building a elasticsearch plugin. doing it in memory will not give you the correct results. u need composite ranking to happen simultaneously.
Quoted Message : I‚Äôm trying to build this from scratch to clear my understandings üòõ

Message : Is there any reading on when to consider a vector optimally dense?
Quoted Message : You can experiment to see if this gives reasonable results along with performance that you wanted.

Message : No no, Im not looking into composite ranking (sparse + dense) at this stage
Quoted Message : you should. by building a elasticsearch plugin. doing it in memory will not give you the correct results. u need composite ranking to happen simultaneously.

Message : What do you mean by optimally dense? Sorry I can‚Äôt seem to find full context here

Message : (Also happy to move this to private chat)

Message : Im just interested in getting top-K unique page ids from chunks split up from the pages


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I dont think you get my exact question here.
The *N* you just spoke about, i.e., the candidate elements you need ti fetch first before trying to rerank.
I‚Äôm trying to optimise that.
My claim is N should be atleast MAX_CHUNKS_PER_DOCUMENT *(k-1) + 1 to get k unique elements
Quoted Message : The diversity is hard to get from plain vector search. The documents are already distributed in the embedding space according to their embedding method

Message : But im looking for a better method because that can be slow based on MAX_CHUNKS_PER_DOCUMENT and _k_

Message : The reranking comes after that, and I agree there can be several reranking methods including MRR

Message : top 200 might not guarantee 100 unique elements
Quoted Message : So to do that, let‚Äôs say you need 100 items, then fetch top 200 first sorted by similarity then rerank using MMR and then take the top 100

Message : you should. by building a elasticsearch plugin. doing it in memory will not give you the correct results. u need composite ranking to happen simultaneously.
Quoted Message : I‚Äôm trying to build this from scratch to clear my understandings üòõ

Message : Is there any reading on when to consider a vector optimally dense?
Quoted Message : You can experiment to see if this gives reasonable results along with performance that you wanted.

Message : No no, Im not looking into composite ranking (sparse + dense) at this stage
Quoted Message : you should. by building a elasticsearch plugin. doing it in memory will not give you the correct results. u need composite ranking to happen simultaneously.

Message : What do you mean by optimally dense? Sorry I can‚Äôt seem to find full context here

Message : (Also happy to move this to private chat)

Message : Im just interested in getting top-K unique page ids from chunks split up from the pages

Message : Sure sure
Quoted Message : (Also happy to move this to private chat)

Message : personally, I'm not too excited about incrementally better search as such, and I believe google will put all it's talent and $ to ensure it continues to dominate search. They have to. Where I am more excited about is the decision making part which today happens post-search. If LLMs can do that reliably with more and more confidence and less and less expertise needed on behalf of the user, it will truly be a game changer. GPT4 is already showing tremendous progress in reasoning/logic/planning/decision making and will only continue to get better. That's where the real gold lies. Concretely, "what to do in srinagar" and "what to do in andaman" are all solved queries. But a complex query like "whether I should go to Srinagar or Andaman if my budget is X and one daughter's birthday is on date D and I like snow but my wife prefers beach and I have airline miles with airline A..." and so on. Now when it comes up with an answer and a reasoning - that is a game changer. It is far beyond a 'search' paradigm. It's a full shift in ways of working and a leap in evolution.
Quoted Message : I wonder if there will be a separate market & usecase for \n1. basic search queries ( currently dominated by Google) \n2. more detailed exploratory search market (with OpenAI emerging as a leader currently)\n\nWill bring/Microsoft try to combine both 1,2 ?\nWill Google try to integrate bard into Google.com ?\n\nHad hopes from Neeva, challenging Google in search but they pivoted and got acquired by Snowflake [0]\n\n0. https://www.snowflake.com/blog/snowflake-acquires-neeva-to-accelerate-search-in-the-data-cloud-through-generative-ai/

Message : Step 1: Using BLIP2 you can generate captions for the clothes you already have.

Step 2: with a prompt to create combinations of clothes based on a certain "look", "style" or "culture", you can ask GPT3/4 to create combinations for you.
Quoted Message : Hi everyone, \n\nI am working on a personal project where I am trying to create new combinations of outfits from existing outfits. I have a corpus of roughly 300 outfits, each outfit can have more than 1 clothing items where a clothing item is a single item and it could be anything one wears. I want to create new outfits that I never wore from the exiting ones. Can any one help me out with already existing solutions which can work out of t he box to can be trained with limited data or a research paper I can dig deeper into. Any help would be useful. \nThanks in advance!

Message : With respect to this original query, I would suggest looking into txtai.

txtai is a SQL driven vector DB implementation featured in HF's 100 fav repos. Though the project is still underrated.

It's founder is named David (also exactly like the underrated David in David vs Goliath)

Can't guarantee it'll help you but David and txtai are awesome and he will most likely be able to sort this out for you.

https://github.com/neuml/txtai
Quoted Message : Regarding splitting documents into chunks, I have a question:\n\nI have chunked up several datas(having unique keys initially) into parts. As a result now, the datas do not have unique keys anymore (they do have a subkey which is unique, but Im not interested in that).\n\nWhen retrieving top-K by looking into these split-up chunks now with cosine similarity, my retriever gets multiple elements sometimes with same key. \nI ideally don‚Äôt want that. I want unique key‚Äôed elements.\n\nAny brainstorming ideas how to deal with this?

Message : thank you v much, ill take a look into this üôÇ
Quoted Message : With respect to this original query, I would suggest looking into txtai.\n\ntxtai is a SQL driven vector DB implementation featured in HF's 100 fav repos. Though the project is still underrated. \n\nIt's founder is named David (also exactly like the underrated David in David vs Goliath)\n\nCan't guarantee it'll help you but David and txtai are awesome and he will most likely be able to sort this out for you.\n\nhttps://github.com/neuml/txtai

Message : A very inspiring vision !

To riff on your usecase,
If making an itinerary involved a conversation with an "intelligent agent" (which mediated all your international with out devices and browsers)


1. Specify your constraints and needs (Kashmir, preference for beaches, snow, daughter's bday, etc )

2. The agent shows you possible options based on the budget

3. You shortlist a few.
At the end, agent shows a brief summary of the shortlisted options ( with the ability to drill down into each of these options- what airline, what seats, ticket price, which hotel, etc)

4. You give the agent the go-ahead to book option X .
Either interactively asking you qs( which CC to use, which dates, which airline miles to use) or using your saved preferences,
the agent proceed to make the payments and bookings

5. Reminds you to do packing and itinerary planning of things to do and sightseeing , a few days before the trip begins, as "contextual" notifications on your mobile device, etc

Travel is just one usecase.
It could be monitoring health ( I am feeling a pain in the abdomen for the last couple of days), prompting you to make an appointment with your family doc , post appointment using an app or service to buy the medicines, make appointments for follow up diagnostic tests.


The possibilities are endless.
Are their open source/  commercial "intelligent agent "efforts out there ?

I guess the best suited players are OS vendors - Siri(apple), Cortana ( a better Cortana powered by GPT4 ? D)

Would be very interesting if there could be open source solutions to this !

p.s. sorry for this long wall of text !
Quoted Message : personally, I'm not too excited about incrementally better search as such, and I believe google will put all it's talent and $ to ensure it continues to dominate search. They have to. Where I am more excited about is the decision making part which today happens post-search. If LLMs can do that reliably with more and more confidence and less and less expertise needed on behalf of the user, it will truly be a game changer. GPT4 is already showing tremendous progress in reasoning/logic/planning/decision making and will only continue to get better. That's where the real gold lies. Concretely, \"what to do in srinagar\" and \"what to do in andaman\" are all solved queries. But a complex query like \"whether I should go to Srinagar or Andaman if my budget is X and one daughter's birthday is on date D and I like snow but my wife prefers beach and I have airline miles with airline A...\" and so on. Now when it comes up with an answer and a reasoning - that is a game changer. It is far beyond a 'search' paradigm. It's a full shift in ways of working and a leap in evolution.

Message : was added to chat

Message : üôÇ I'm devoting nearly all my time in this part of genAI exclusively. And definitely not looking much into RAG and similar stuff at the moment. If you're interested, this is a great place to start (and it's references of course) https://arxiv.org/abs/2212.09597  there are other resources too, of course
Quoted Message : A very inspiring vision !\n\nTo riff on your usecase, \nIf making an itinerary involved a conversation with an \"intelligent agent\" (which mediated all your international with out devices and browsers)\n\n\n1. Specify your constraints and needs (Kashmir, preference for beaches, snow, daughter's bday, etc )\n\n2. The agent shows you possible options based on the budget\n\n3. You shortlist a few.\nAt the end, agent shows a brief summary of the shortlisted options ( with the ability to drill down into each of these options- what airline, what seats, ticket price, which hotel, etc)\n\n4. You give the agent the go-ahead to book option X .\nEither interactively asking you qs( which CC to use, which dates, which airline miles to use) or using your saved preferences, \nthe agent proceed to make the payments and bookings\n\n5. Reminds you to do packing and itinerary planning of things to do and sightseeing , a few days before the trip begins, as \"contextual\" notifications on your mobile device, etc\n\nTravel is just one usecase.\nIt could be monitoring health ( I am feeling a pain in the abdomen for the last couple of days), prompting you to make an appointment with your family doc , post appointment using an app or service to buy the medicines, make appointments for follow up diagnostic tests.\n\n\nThe possibilities are endless.\nAre their open source/  commercial \"intelligent agent \"efforts out there ?\n\nI guess the best suited players are OS vendors - Siri(apple), Cortana ( a better Cortana powered by GPT4 ? D)\n\nWould be very interesting if there could be open source solutions to this !\n\np.s. sorry for this long wall of text !

Message : https://twitter.com/humphd/status/1668266263494242306?s=46&t=URoDrV5X7GPNPYSgYW42Dw
Looking at this tweet I thinking a Co-pilot Nigerian prince scam might work üòÇ.

I am exaggerating obviously. Don't need to share this with outlets like vice

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØKrishna and ‚Ä™+91¬†73562¬†91965‚Ä¨

Message : Let us know how it turns out üôÇ
Quoted Message : thank you v much, ill take a look into this üôÇ

Message : We use https://weaviate.io/
Quoted Message : With respect to this original query, I would suggest looking into txtai.\n\ntxtai is a SQL driven vector DB implementation featured in HF's 100 fav repos. Though the project is still underrated. \n\nIt's founder is named David (also exactly like the underrated David in David vs Goliath)\n\nCan't guarantee it'll help you but David and txtai are awesome and he will most likely be able to sort this out for you.\n\nhttps://github.com/neuml/txtai

Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : Hey guys 
I'm working on streaming apis. So the setup is done with openai apis but some questions are there looking at recent updates from chatgpt  there are options like stop generation and continue generation.

Anyone has idea how it works

Message : I guess they just pass the last generated message as input again

Message : @91882829xxxx do help @91982023xxxx here. Thx
Quoted Message : Hey guys \nI'm working on streaming apis. So the setup is done with openai apis but some questions are there looking at recent updates from chatgpt  there are options like stop generation and continue generation.\n\nAnyone has idea how it works

Message : So from what I know, continue generation is not enabled for the completion API, but to implement the stop generation you can simply make code changes in your BE to stop when user sends stop action to your event stream
Quoted Message : Hey guys \nI'm working on streaming apis. So the setup is done with openai apis but some questions are there looking at recent updates from chatgpt  there are options like stop generation and continue generation.\n\nAnyone has idea how it works

Message : Have a few doubts on this, specifically because server sent events are a one way stream. If this discussion is too far off topic  for the group, we can take this to dms
Quoted Message : So from what I know, continue generation is not enabled for the completion API, but to implement the stop generation you can simply make code changes in your BE to stop when user sends stop action to your event stream

Message : Current solutions on this might be hacky patchy stuff that works. I don't think openAI has anything official supported via their API.
Quoted Message : Hey guys \nI'm working on streaming apis. So the setup is done with openai apis but some questions are there looking at recent updates from chatgpt  there are options like stop generation and continue generation.\n\nAnyone has idea how it works

Message : Has anyone found a way to make chatGPT to give pure JSON responses ?
It starts hallucinating after a while and output erroneous json.

Message : idk if this is the best way
you can use output parsers from langchain or guidance
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : Are you adding the json structure in the prompt?
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : If you're using LangChain you can use their Output parser methods to define a response schema

Otherwise you can also use Guard rails
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : https://shreyar.github.io/guardrails/

Message : On open source model aide, jsonformer works perfectly

Message : Side*

Message : I havnt used guard rails 
as per my knowledge it is similar to guidance ryt
is it better than guidance
Quoted Message : If you're using LangChain you can use their Output parser methods to define a response schema\n\nOtherwise you can also use Guard rails

Message : Very different from Microsoft's Guidance, much more robust and easier to use
Quoted Message : I havnt used guard rails \nas per my knowledge it is similar to guidance ryt\nis it better than guidance

Message : Is it just me or gpt3.5 seems crippled now?

Gpt4 is so much better but latency is killing!

Message : Use a json5 parser.  Works 99% of the time.  When it fails call gpt and ask it to correct the json.
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : This is great , exactly what I was looking for. Is it much better than simply using pydantic?
Quoted Message : https://shreyar.github.io/guardrails/

Message : use lmql.ai
Quoted Message : Use a json5 parser.  Works 99% of the time.  When it fails call gpt and ask it to correct the json.

Message : Explicitly mention that you want json outputs. Provide the structure of JSON with keys and that should do.
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.
Quoted Message : Is it just me or gpt3.5 seems crippled now?\n\nGpt4 is so much better but latency is killing!

Message : There has to be a better way. Perhaps some external agency that measures public model drifts
Quoted Message : I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.

Message : Just curious: is anyone here building a product for the financial markets?

Message : @91989995xxxx mentioned the simplest way is to have a benchmark dataset,  spin up a jupyter notebook and compare.
I saw this library for measuring - https://github.com/ClerkieAI/bettertest
Quoted Message : I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.

Message : That sounds like a great idea. I am surprised we don't have such a thing
Quoted Message : There has to be a better way. Perhaps some external agency that measures public model drifts


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Is it just me or gpt3.5 seems crippled now?

Gpt4 is so much better but latency is killing!

Message : Use a json5 parser.  Works 99% of the time.  When it fails call gpt and ask it to correct the json.
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : This is great , exactly what I was looking for. Is it much better than simply using pydantic?
Quoted Message : https://shreyar.github.io/guardrails/

Message : use lmql.ai
Quoted Message : Use a json5 parser.  Works 99% of the time.  When it fails call gpt and ask it to correct the json.

Message : Explicitly mention that you want json outputs. Provide the structure of JSON with keys and that should do.
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.
Quoted Message : Is it just me or gpt3.5 seems crippled now?\n\nGpt4 is so much better but latency is killing!

Message : There has to be a better way. Perhaps some external agency that measures public model drifts
Quoted Message : I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.

Message : Just curious: is anyone here building a product for the financial markets?

Message : @91989995xxxx mentioned the simplest way is to have a benchmark dataset,  spin up a jupyter notebook and compare.
I saw this library for measuring - https://github.com/ClerkieAI/bettertest
Quoted Message : I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.

Message : That sounds like a great idea. I am surprised we don't have such a thing
Quoted Message : There has to be a better way. Perhaps some external agency that measures public model drifts

Message : If we don't - I'm usually behind whatever's the latest :D

Message : Paras , others 

Does such an agency exist atm ?

2 qs:
1. if such an agency were to exist, would all LLM providers need to share some of their internal details or just a public inferencing API would be enough ?

2. Also how would such an agency be structured ?
Something along the lines of ICANN or RIPE ?
https://www.ripe.net/about-us/what-we-do
Quoted Message : There has to be a better way. Perhaps some external agency that measures public model drifts

Message : 1 - public inferencing should be enough, almost like downtime monitors

2 - I do think this is something any company can build. Would be great marketing
Quoted Message : Paras , others \n\nDoes such an agency exist atm ?\n\n2 qs:\n1. if such an agency were to exist, would all LLM providers need to share some of their internal details or just a public inferencing API would be enough ?\n\n2. Also how would such an agency be structured ? \nSomething along the lines of ICANN or RIPE ?\nhttps://www.ripe.net/about-us/what-we-do

Message : This doesn't really help your question but in my personal experience letting the model do a bit of "thinking" via planning/chain of thought leads to better outputs.

So I was of the opinion that extraction of json from the output rather than desiring strict json output can be a better option. But its probable that this suggestion may not fit your use case.
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : One way that I usually use is chain prompting, using which you provide an example in the initial stage. This works most of the time with less chances of error.
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : Singapore has spun off its efforts into a ppp model through it ‚ÄúAI verify‚Äù foundation..few big corporates committing to the effort (on paper).

They have open sourced a AI verify toolkit that can downloaded and run locally to monitor model governing principles.
Interesting to note that they are opening it up for community collaboration via developer tool plugins.
https://github.com/IMDA-BTG/aiverify
Quoted Message : Paras , others \n\nDoes such an agency exist atm ?\n\n2 qs:\n1. if such an agency were to exist, would all LLM providers need to share some of their internal details or just a public inferencing API would be enough ?\n\n2. Also how would such an agency be structured ? \nSomething along the lines of ICANN or RIPE ?\nhttps://www.ripe.net/about-us/what-we-do

Message : ‚Äé<attached: 00008571-PHOTO-2023-06-13-22-09-03.jpg>

Message : Impressive perk!

Message : Folks this just dropped an hour back - https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/

Message : Wow those are some good numbers üî•

Message : That‚Äôs $100M+ upfront infrastructure investment.

Message : how much money does Nat have?

Message : Like we discussed before OpenAI is reducing cost of already cheap turbo, and increasing context window to 16k.
- function calling capability in the api with updated & more steerable versions of gpt-4 and gpt-3.5-turbo
- 16k context version of gpt-3.5-turbo
- 75% cost reduction on embeddings api
- 25% cost reduction on input tokens for gpt-3.5-turbo - function calling capability in the api with updated & more steerable versions of gpt-4 and gpt-3.5-turbo
- 16k context version of gpt-3.5-turbo
- 75% cost reduction on embeddings api
- 25% cost reduction on input tokens for gpt-3.5-turbo
https://twitter.com/shyamalanadkat/status/1668667693304778752?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw

Message : Regarding the previous JSON discussion ‚Äúgpt-4-0613 and gpt-3.5-turbo-0613, and have the model intelligently choose to output a JSON object containing arguments to call those functions.‚Äù

Message : I have a question regarding https://platform.openai.com/docs/guides/fine-tuning

In ```openai api fine_tunes.create -t <TRAINING_FILE_PATH> -m <BASE_MODEL>``` , where is the fine-tune model stored?
If I close the session, can I access it later from somewhere?

Message : Octoml AWS event tomorrow :
https://www.octoml.ai/introducing-self-optimizing-compute

For SF folks, there is an in person event  as well :
https://lu.ma/3a1gzqre

Message : Anyone knows if function definitions will be part of token counts?
Quoted Message : Like we discussed before OpenAI is reducing cost of already cheap turbo, and increasing context window to 16k.\n- function calling capability in the api with updated & more steerable versions of gpt-4 and gpt-3.5-turbo\n- 16k context version of gpt-3.5-turbo\n- 75% cost reduction on embeddings api\n- 25% cost reduction on input tokens for gpt-3.5-turbo - function calling capability in the api with updated & more steerable versions of gpt-4 and gpt-3.5-turbo\n- 16k context version of gpt-3.5-turbo\n- 75% cost reduction on embeddings api\n- 25% cost reduction on input tokens for gpt-3.5-turbo \nhttps://twitter.com/shyamalanadkat/status/1668667693304778752?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw

Message : May be part of the input tokens
Quoted Message : Anyone knows if function definitions will be part of token counts?

Message : A couple of questions about Azure OpenAI service - a) does anyone here know if they have raised rate limits in the recent past, and by how much? b) Any good practices being used to build rate limiters for Azure OpenAI based apps?

Message : Rate limits I'm interested in are more the token limits, than the request limits.

Message : When I last checked it was still same. I am implementing preemptive method by creating multiple instances, (you can have two in each of the four data ,centers with OpenAI), and then shuffling requests between them.

Message : On Azure you can use two instances max in each tenant I guess. Rate limits have not changed after GPT4 released? 3.5 accepts 90 or 120 reqs/min, GPT4 accepts <20/min
Quoted Message : When I last checked it was still same. I am implementing preemptive method by creating multiple instances, (you can have two in each of the four data ,centers with OpenAI), and then shuffling requests between them.

Message : ‚Äé<attached: 00008587-PHOTO-2023-06-13-23-56-41.jpg>
Quoted Message : Octoml AWS event tomorrow :\nhttps://www.octoml.ai/introducing-self-optimizing-compute\n\nFor SF folks, there is an in person event  as well :\nhttps://lu.ma/3a1gzqre

Message : Token log probabilities
The completions API can provide a limited number of log probabilities associated with the most likely tokens for each output token. This feature is controlled by using the logprobs field. This can be useful in some cases to assess the confidence of the model in its output.

Message : User based rate limits that are then load balanced across all your instances (OpenAI, azure) is something that would work theoretically? We‚Äôre testing this out
Quoted Message : Rate limits I'm interested in are more the token limits, than the request limits.

Message : Yes - you get a name for your fine-tuned model which can then be used
Quoted Message : I have a question regarding https://platform.openai.com/docs/guides/fine-tuning\n\nIn ```openai api fine_tunes.create -t <TRAINING_FILE_PATH> -m <BASE_MODEL>``` , where is the fine-tune model stored? \nIf I close the session, can I access it later from somewhere?

Message : openai api fine_tunes.list should list all the fine-tunes once the job is done. Their CLI has very good DX

Message : DX = ?
Quoted Message : openai api fine_tunes.list should list all the fine-tunes once the job is done. Their CLI has very good DX

Message : developer experience.
Quoted Message : DX = ?

Message : Try threatening it. If you don't get the reference follow Riley goodside on Twitter
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : I give the expected json response object in markdown. It works over 95% of the time
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : markdown ? didnt understand . is this part of the prompt
Quoted Message : I give the expected json response object in markdown. It works over 95% of the time

Message : Yes. Give me an input you want in json format
Quoted Message : markdown ? didnt understand . is this part of the prompt

Message : I'll share some prompt hack

Message : I'm actually being serious here
Quoted Message : Try threatening it. If you don't get the reference follow Riley goodside on Twitter

Message : Haha, yeah I remember this. He tried this on Bard.
Quoted Message : Try threatening it. If you don't get the reference follow Riley goodside on Twitter

Message : https://twitter.com/goodside/status/1657396491676164096?t=BWY3Fp5rMqfNt-8HmOi2PQ&s=08

Message : Chatgpt with browsing has a very error rate in browsing and clicking links

Message : Interesting video about AI in SV - innovation, including generative AI is discussed https://youtu.be/cHXCsVgWHxU

Message : They‚Äôre storing all fine tuned models people are generating? üòÆ
Quoted Message : Yes - you get a name for your fine-tuned model which can then be used


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I give the expected json response object in markdown. It works over 95% of the time
Quoted Message : Has anyone found a way to make chatGPT to give pure JSON responses ?\nIt starts hallucinating after a while and output erroneous json.

Message : markdown ? didnt understand . is this part of the prompt
Quoted Message : I give the expected json response object in markdown. It works over 95% of the time

Message : Yes. Give me an input you want in json format
Quoted Message : markdown ? didnt understand . is this part of the prompt

Message : I'll share some prompt hack

Message : I'm actually being serious here
Quoted Message : Try threatening it. If you don't get the reference follow Riley goodside on Twitter

Message : Haha, yeah I remember this. He tried this on Bard.
Quoted Message : Try threatening it. If you don't get the reference follow Riley goodside on Twitter

Message : https://twitter.com/goodside/status/1657396491676164096?t=BWY3Fp5rMqfNt-8HmOi2PQ&s=08

Message : Chatgpt with browsing has a very error rate in browsing and clicking links

Message : Interesting video about AI in SV - innovation, including generative AI is discussed https://youtu.be/cHXCsVgWHxU

Message : They‚Äôre storing all fine tuned models people are generating? üòÆ
Quoted Message : Yes - you get a name for your fine-tuned model which can then be used

Message : https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/

Message : Why so benevolent

Message : They‚Äôre charging you for it :)
Quoted Message : Why so benevolent

Message : oh so the storage has a separate cost than just calling the finetuning api?
or is keeping it for 2 months the same as keeping it for 2 years?
Quoted Message : They‚Äôre charging you for it :)

Message : Hmm.. not sure if they expire fine tunes at the moment. So you pay to create a fine tuned model and then to use it. Storage doesn‚Äôt cost anything. That‚Äôs benevolent I guess (not sure if this is a large expense somehow though)

Message : Fine tunes don't expire. You need to delete it with owner access login
Quoted Message : Hmm.. not sure if they expire fine tunes at the moment. So you pay to create a fine tuned model and then to use it. Storage doesn‚Äôt cost anything. That‚Äôs benevolent I guess (not sure if this is a large expense somehow though)

Message : We constantly see a drift happening due to the nature of our domain. The idea is to have some representation vector for your dataset (embedding) and monitor the distance based on this. In general a changing confidence score could also indicate drifts. There are some open source packages from IBM and seldom that I have used for offline Alibi, AIX360.
Quoted Message : I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.

Message : ‚Äé<attached: 00008612-PHOTO-2023-06-14-08-13-43.jpg>

Message : I'll DM you, we are planning to build this on E2E and Jio Datacenter infra

Message : So investment of $30M odd ? ..

Message : Arre sir, you'll get enterprise discount. Should be closer to $10M with those?
Quoted Message : So investment of $30M odd ? ..

Message : great
Quoted Message : I'll DM you, we are planning to build this on E2E and Jio Datacenter infra

Message : So the plan with Reliance is to do a in-kind investment of sorts ..  its still under discussions  .. so can't share too much in public

Message : So startups will give equity to Reliance + payment for usage ?
Quoted Message : So the plan with Reliance is to do a in-kind investment of sorts ..  its still under discussions  .. so can't share too much in public

Message : @91773788xxxx : I‚Äôm in

Message : No, it will be an independent Fund ... Reliance might be an in kind LP in that .. no direct startup equity

Message : usage payments etc need to be figured out .. still early in discussions
Quoted Message : So startups will give equity to Reliance + payment for usage ?

Message : Could also be E2E .. or Adani .. we'll see
Quoted Message : No, it will be an independent Fund ... Reliance might be an in kind LP in that .. no direct startup equity

Message : I was in discussion with NIT Raipur (my alma mater) in regards to data center usage for startups. They struggle to provide pay as you go pricing because they don‚Äôt have the right calculation metric.
Quoted Message : usage payments etc need to be figured out .. still early in discussions

Message : I too am in. Happy to contribute.
Quoted Message : @9177xxxxxxxx : I‚Äôm in

Message : For inference .. we are planning to use my portfolio company Qblocks.cloud to aggregate spare capacity in Top Univs .. .my colleague @91995246xxxx can share more details if you DM him
Quoted Message : I was in discussion with NIT Raipur (my alma mater) in regards to data center usage for startups. They struggle to provide pay as you go pricing because they don‚Äôt have the right calculation metric.

Message : Oh great. I can connect them with NIT raipur team as well

Message : That's 400x times of IISc

Message : Thanks, please do .. Qblocks can probably orchestrate a small cluster and we can price according to what capacity the Univ is able to provide
Quoted Message : Oh great. I can connect them with NIT raipur team as well

Message : @91773788xxxx I know a guy who setup Tesla‚Äôs 2 data centers and used to run the show. In case that helps.

Message : If @91990057xxxx can afford to pay him+team, why not?
Quoted Message : @9177xxxxxxxx I know a guy who setup Tesla‚Äôs 2 data centers and used to run the show. In case that helps.

Message : Pls add back of envelope estimates to your call to action tweet to Mr Gurnani
Quoted Message : Arre sir, you'll get enterprise discount. Should be closer to $10M with those?

Message : The guy is an Indian so hopefully he will help us a mentor.
Quoted Message : If @9199xxxxxxxx can afford to pay him+team, why not?

Message : üòÖüòÖ

Message : I'd not insult his team's intelligence by adding my back of the envelope estimate. @91740765xxxx can share better estimates ‚Äî but he's rarely up in IST.
Quoted Message : Pls add back of envelope estimates to your call to action tweet to Mr Gurnani

Message : Yes we can.  Please connect
Quoted Message : If @9199xxxxxxxx can afford to pay him+team, why not?

Message : I don't really think Mr. Gurnani was serious about all theseüòÖ
Quoted Message : Pls add back of envelope estimates to your call to action tweet to Mr Gurnani

Message : $10-20M is easily in the realm of VC investments, but after a year or so when AWS and other cloud providers will give GPU access more readily why will startups use this Indian GPU cluster ?

Message : Why would this be more expensive than AWS? And why would your own folio companies use AWS over this, which will be several times cheaper and better?
Quoted Message : $10-20M is easily in the realm of VC investments, but after a year or so when AWS and other cloud providers will give GPU access more readily why will startups use this Indian GPU cluster ?

Message : It's a fun project, temporary solve for GPU shortage, but how does it make business sense ?

Message : He is retiring in Dec 2023 and this can be his new mission. So, there is a chance that he‚Äôll consider it, particularly if he knows that it doesn‚Äôt cost a lot of money

Message : I don‚Äôt have anything to say except I‚Äôm suuuuuuper happy to see these discussions and planning started. Happy to contribute in whatever way I can. ‚ù§Ô∏è ‚Äé<This message was edited>

Message : I have long believed that the only pending piece in the  Indian ecosystem as a whole is great people coming together. A lot of times smartest of the brains do not want to collaborate with other smart people. (Thoughts in my personal capacity)
Quoted Message : I don't really think Mr. Gurnani was serious about all theseüòÖ

Message : AWS can offer higher uptimes, better security, better tooling etc etc .. today is H100 tomorrow will be Z100

Message : Compute can be >40% of startup burn, you bring it down to 10-20% ‚Äî isn't that better for your folio?
Quoted Message : It's a fun project, temporary solve for GPU shortage, but how does it make business sense ?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Yes we can.  Please connect
Quoted Message : If @9199xxxxxxxx can afford to pay him+team, why not?

Message : I don't really think Mr. Gurnani was serious about all theseüòÖ
Quoted Message : Pls add back of envelope estimates to your call to action tweet to Mr Gurnani

Message : $10-20M is easily in the realm of VC investments, but after a year or so when AWS and other cloud providers will give GPU access more readily why will startups use this Indian GPU cluster ?

Message : Why would this be more expensive than AWS? And why would your own folio companies use AWS over this, which will be several times cheaper and better?
Quoted Message : $10-20M is easily in the realm of VC investments, but after a year or so when AWS and other cloud providers will give GPU access more readily why will startups use this Indian GPU cluster ?

Message : It's a fun project, temporary solve for GPU shortage, but how does it make business sense ?

Message : He is retiring in Dec 2023 and this can be his new mission. So, there is a chance that he‚Äôll consider it, particularly if he knows that it doesn‚Äôt cost a lot of money

Message : I don‚Äôt have anything to say except I‚Äôm suuuuuuper happy to see these discussions and planning started. Happy to contribute in whatever way I can. ‚ù§Ô∏è ‚Äé<This message was edited>

Message : I have long believed that the only pending piece in the  Indian ecosystem as a whole is great people coming together. A lot of times smartest of the brains do not want to collaborate with other smart people. (Thoughts in my personal capacity)
Quoted Message : I don't really think Mr. Gurnani was serious about all theseüòÖ

Message : AWS can offer higher uptimes, better security, better tooling etc etc .. today is H100 tomorrow will be Z100

Message : Compute can be >40% of startup burn, you bring it down to 10-20% ‚Äî isn't that better for your folio?
Quoted Message : It's a fun project, temporary solve for GPU shortage, but how does it make business sense ?

Message : If anything, affordable compute is a huge pull for someone serious about doing AI-heavy features and services in their tech stack

Message : Yes it will be better. We can finance one. But AWS and others offer $200K free credit to our portfolio.. so the startups don't need to go to any other platform
Quoted Message : Compute can be >40% of startup burn, you bring it down to 10-20% ‚Äî isn't that better for your folio?

Message : Only thing is someone or a team needs to own it. Like you putting your face and name to it.
Quoted Message : Compute can be >40% of startup burn, you bring it down to 10-20% ‚Äî isn't that better for your folio?

Message : Saw this tweet earlier today and thought it might be relevant to the discussion https://twitter.com/nathanbenaich/status/1668751988853555201
Quoted Message : Compute can be >40% of startup burn, you bring it down to 10-20% ‚Äî isn't that better for your folio?

Message : Will do. Texted the Director of data
Quoted Message : Yes we can.  Please connect

Message : Rumours: Singapore is hosting a "Come back to SG" program for top tier AI talent with SG connections. @swyx and @eugeneyan should be on the invite list

Message : I'm surprised ME hasn't jumped on this train

Message : Strategically, this seems to be something right up their alley. Cheap power, tons of money to throw about on infra, low marginal tax rate,

Message : And a deep desire to attract talent to reduce oil dependence

Message : Is there some Saudi program of free gpus? :)

Message : They are already winning in the AI game. They did it right.
Quoted Message : I'm surprised ME hasn't jumped on this train

Message : Serious question, how does anyone keep tabs on this group? üòÖ
Away for 15 minutes and there's a 100 messages

Message : There is a genAI summary chrome extension coming for that :/) just joking üôÉ
Quoted Message : Serious question, how does anyone keep tabs on this group? üòÖ\nAway for 15 minutes and there's a 100 messages

Message : Daily morning routine of reading through things to catch up pre sleep. Seriously. No sarcasm

Message : Takes me about 30 mins if i do it properly. But worth it

Message : Just read finLLM paper. Doesn‚Äôt RLSP sound a little weird. They didn‚Äôt release any details also. Instead of focusing on making it give the correct answer, it has to now predict the correct stock price in the future.

Message : Post sleep
Quoted Message : Daily morning routine of reading through things to catch up pre sleep. Seriously. No sarcasm

Message : I'm super curious how do these big data centers get built? And are there easy ways to "provide" compute when you self host? I'm sure there should be platforms already but would love to know more about this @91990057xxxx
Quoted Message : I'll DM you, we are planning to build this on E2E and Jio Datacenter infra

Message : You have to bleed AI bruh .. you will then live and breath this group üòá
Quoted Message : Serious question, how does anyone keep tabs on this group? üòÖ\nAway for 15 minutes and there's a 100 messages

Message : whatsapp needs a search by message reactions featureüòÇ
Quoted Message : Serious question, how does anyone keep tabs on this group? üòÖ\nAway for 15 minutes and there's a 100 messages

Message : I found out that people who personally own Nvidia DGX just share access via SSH to known individuals.
Quoted Message : I'm super curious how do these big data centers get built? And are there easy ways to \"provide\" compute when you self host? I'm sure there should be platforms already but would love to know more about this @9199xxxxxxxx

Message : But then how does the payment come into picture? Is it just manual tracking and then invoicing it later?
Quoted Message : I found out that people who personally own Nvidia DGX just share access via SSH to known individuals.

Message : a16z will say crypto here
Quoted Message : But then how does the payment come into picture? Is it just manual tracking and then invoicing it later?

Message : üòÇ

Message : Also it's wild that people personally own DGXs
Quoted Message : I found out that people who personally own Nvidia DGX just share access via SSH to known individuals.

Message : Probably just landing for free or grant from personal DGX in garage. Folks are not crazy about making money here for personally owned rigs, just let people hack on it.
Quoted Message : But then how does the payment come into picture? Is it just manual tracking and then invoicing it later?

Message : Makes sense
Quoted Message : Probably just landing for free or grant from personal DGX in garage. Folks are not crazy about making money here for personally owned rigs, just let people hack on it.

Message : Isn't that the first condition to move into Hayes valley ü§£
Quoted Message : Also it's wild that people personally own DGXs

Message : Nat and Daniel give huge grants to indie projects, I'm sure that many folks are going to get access to Andromeda nodes as grants.

Message : Yeah, that's for sure going to be a crazy ride
Quoted Message : Nat and Daniel give huge grants to indie projects, I'm sure that many folks are going to get access to Andromeda nodes as grants.

Message : Jokes apart I know there are so many garages with their own rigs and DGXs. You will meet people doing crazy projects from protein molecules to RNA when you go to meetups.

Message : I thought it was clever. although I haven't delved into the details. Also, not our domain so I may not get into it.
Quoted Message : Just read finLLM paper. Doesn‚Äôt RLSP sound a little weird. They didn‚Äôt release any details also. Instead of focusing on making it give the correct answer, it has to now predict the correct stock price in the future.

Message : Any good meetups that you'd recommend? (other than ours)
Quoted Message : Jokes apart I know there are so many garages with their own rigs and DGXs. You will meet people doing crazy projects from protein molecules to RNA when you go to meetups.

Message : I usually go to SF Tinkerer meetup run by Alex (Copilot fame) and Rahul. I have found many others mostly networking events, which I'm not very fond of.

Message : https://forms.clickup.com/8459928/f/825mr-5991/ZM34QXAROUNR0TLZBR

Civitai launching LLMs

Message : Better resource optimization, more scale, less maintenance overhead.
Hardware can become obsolete quite easily, especially with massive spike in GPU tech interest.
Business wise it‚Äôs super risky with minimal returns, but a great academic project nonetheless. Can talk to some profs and alums in IITM (my almamater) to see if there is any interest
Quoted Message : Why would this be more expensive than AWS? And why would your own folio companies use AWS over this, which will be several times cheaper and better?

Message : Not discounting the business risk, but that's why it's called "Venture" Capital and not Fixed Deposits, right? 

I also get that risk is a spectrum. But if it was lower risk than this, even Governments world over get the point of owning chips in inventory now (thanks to Russian sanctions!)
Quoted Message : Better resource optimization, more scale, less maintenance overhead.\nHardware can become obsolete quite easily, especially with massive spike in GPU tech interest. \nBusiness wise it‚Äôs super risky with minimal returns, but a great academic project nonetheless. Can talk to some profs and alums in IITM (my almamater) to see if there is any interest

Message : And if we're saying an Indian cloud will have worse resource utilisation and more maintenance overhead ‚Äî we're anyway accepting that Indian markets are not mature and Indian talent (for infra) is worse than AWS

Message : The J-curve for talent maturity does not start at profitability or insane margins on day 1 or even day 1000

Message : Someone has to absorb the risk of a possible loss for the ecosystem to mature ‚Äî could be GoI as Sandeep @91981048xxxx insists often, or a PPP as Brij @91990057xxxx & friends are trying


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Jokes apart I know there are so many garages with their own rigs and DGXs. You will meet people doing crazy projects from protein molecules to RNA when you go to meetups.

Message : I thought it was clever. although I haven't delved into the details. Also, not our domain so I may not get into it.
Quoted Message : Just read finLLM paper. Doesn‚Äôt RLSP sound a little weird. They didn‚Äôt release any details also. Instead of focusing on making it give the correct answer, it has to now predict the correct stock price in the future.

Message : Any good meetups that you'd recommend? (other than ours)
Quoted Message : Jokes apart I know there are so many garages with their own rigs and DGXs. You will meet people doing crazy projects from protein molecules to RNA when you go to meetups.

Message : I usually go to SF Tinkerer meetup run by Alex (Copilot fame) and Rahul. I have found many others mostly networking events, which I'm not very fond of.

Message : https://forms.clickup.com/8459928/f/825mr-5991/ZM34QXAROUNR0TLZBR

Civitai launching LLMs

Message : Better resource optimization, more scale, less maintenance overhead.
Hardware can become obsolete quite easily, especially with massive spike in GPU tech interest.
Business wise it‚Äôs super risky with minimal returns, but a great academic project nonetheless. Can talk to some profs and alums in IITM (my almamater) to see if there is any interest
Quoted Message : Why would this be more expensive than AWS? And why would your own folio companies use AWS over this, which will be several times cheaper and better?

Message : Not discounting the business risk, but that's why it's called "Venture" Capital and not Fixed Deposits, right? 

I also get that risk is a spectrum. But if it was lower risk than this, even Governments world over get the point of owning chips in inventory now (thanks to Russian sanctions!)
Quoted Message : Better resource optimization, more scale, less maintenance overhead.\nHardware can become obsolete quite easily, especially with massive spike in GPU tech interest. \nBusiness wise it‚Äôs super risky with minimal returns, but a great academic project nonetheless. Can talk to some profs and alums in IITM (my almamater) to see if there is any interest

Message : And if we're saying an Indian cloud will have worse resource utilisation and more maintenance overhead ‚Äî we're anyway accepting that Indian markets are not mature and Indian talent (for infra) is worse than AWS

Message : The J-curve for talent maturity does not start at profitability or insane margins on day 1 or even day 1000

Message : Someone has to absorb the risk of a possible loss for the ecosystem to mature ‚Äî could be GoI as Sandeep @91981048xxxx insists often, or a PPP as Brij @91990057xxxx & friends are trying

Message : Fair, but it‚Äôs a lot more than just setting up GPU rigs. For hosting production grade applications and not just academic projects, a whole lot of things need to be considered such as availability, up time, resource optimization, cloud gtm etc. the investment required would be much more than 30M imo. Even AWS took some ten years to be profitable. 
That being said it‚Äôs not impossible, as we have no dearth of talent here. But a massive push from GoI would be super helpful. Especially in terms of subsidies and and tax write offs.
Happy to help in case something is materializing:)
Quoted Message : Not discounting the business risk, but that's why it's called \"Venture\" Capital and not Fixed Deposits, right? \n\nI also get that risk is a spectrum. But if it was lower risk than this, even Governments world over get the point of owning chips in inventory now (thanks to Russian sanctions!)

Message : I think @91995246xxxx and @91981048xxxx are better informed on how the orchestration would work
Quoted Message : I'm super curious how do these big data centers get built? And are there easy ways to \"provide\" compute when you self host? I'm sure there should be platforms already but would love to know more about this @9199xxxxxxxx

Message : Please check out qblocks.cloud - we are one of the investors with carya ventures. They have been able to build out an asset light GPU platform and a lot of companies are using it for training + deployment (infact they have an api platform as well which comes cheaper than openai‚Äôs whisper api)
Quoted Message : Fair, but it‚Äôs a lot more than just setting up GPU rigs. For hosting production grade applications and not just academic projects, a whole lot of things need to be considered such as availability, up time, resource optimization, cloud gtm etc. the investment required would be much more than 30M imo. Even AWS took some ten years to be profitable. \nThat being said it‚Äôs not impossible, as we have no dearth of talent here. But a massive push from GoI would be super helpful. Especially in terms of subsidies and and tax write offs. \nHappy to help in case something is materializing:)

Message : They said this about rockets btw. And a nuclear program. Scrappy is a superpower
Quoted Message : Fair, but it‚Äôs a lot more than just setting up GPU rigs. For hosting production grade applications and not just academic projects, a whole lot of things need to be considered such as availability, up time, resource optimization, cloud gtm etc. the investment required would be much more than 30M imo. Even AWS took some ten years to be profitable. \nThat being said it‚Äôs not impossible, as we have no dearth of talent here. But a massive push from GoI would be super helpful. Especially in terms of subsidies and and tax write offs. \nHappy to help in case something is materializing:)

Message : More power to the folks actually doing it, and getting started. It's hard to get 100m capital committed immediately, even to get started

Message : Far easier once there's some momentum

Message : Easier to sieve the folks who are actually doing

Message : If there is momentum and need, there is more than enough risk capital availability just within our country.  But we need to do this iteratively and hit milestones methodically
Quoted Message : More power to the folks actually doing it, and getting started. It's hard to get 100m capital committed immediately, even to get started

Message : Okay awesome, will reach out to them! Thanks!!
Quoted Message : I think @9199xxxxxxxx and @9198xxxxxxxx are better informed on how the orchestration would work

Message : I checked this out. Prices were comparable to runpod.io

In such scenarios where we are renting GPUs by the hour, reliability and availability of the platform matter the most. Personally, I would always go for the one with good reviews and relatively low costs irrespective of whether it's hosted in India or outside.
Quoted Message : Please check out qblocks.cloud - we are one of the investors with carya ventures. They have been able to build out an asset light GPU platform and a lot of companies are using it for training + deployment (infact they have an api platform as well which comes cheaper than openai‚Äôs whisper api)

Message : qblocks is not solving for reliability. it is solving for availability. is it being solved is a separate question....but the big problem to solve right now is availability at scale.

Message : Uptime for data center cluster is at par with with cloud providers. You can chat more with @91981126xxxx on this
Quoted Message : qblocks is not solving for reliability. it is solving for availability. is it being solved is a separate question....but the big problem to solve right now is availability at scale.

Message : Agreed. But what scale are we taking about? 1000+ gpus for end to end training I am assuming?
Quoted Message : qblocks is not solving for reliability. it is solving for availability. is it being solved is a separate question....but the big problem to solve right now is availability at scale.

Message : That's for you. There are 1000 teams who need that.

Look even OpenAI is not able to get GPU. So I don't think the insane scarcity of GPU as a limiting factor for LLM dev is even under debate.

You might have 1000 GPU. Not everyone is able to get it. Not even OpenAI. So it is a problem worth solving.

Message : Hey Sandeep. We are solving for reliability as well by pooling in GPUs from tier 2/3 DCs as well across the globe. Would love to do a deep dive.
Quoted Message : qblocks is not solving for reliability. it is solving for availability. is it being solved is a separate question....but the big problem to solve right now is availability at scale.

Message : If your startups are only investing $200-$500K over 3 years in compute, isn't that a reason itself to be worried?
Quoted Message : Yes it will be better. We can finance one. But AWS and others offer $200K free credit to our portfolio.. so the startups don't need to go to any other platform

Message : was added to chat

Message : Well I want to stand a bit apolotically away. However the commonly understood standard for data center reliability is the Tier classification. 
E.g. Netmagic Tier 3. Webwerks Tier 4.
Quoted Message : Hey Sandeep. We are solving for reliability as well by pooling in GPUs from tier 2/3 DCs as well across the globe. Would love to do a deep dive.

Message : If u want to make a claim that you are solving for reliability, you will have to get an independent audit granting you a Tier classification.

Not me. YMMV

Message : Fyi, this is called TIA-942 audits (one among many)

Message : We have partnered with Tier 2/3 and even Tier 4 DCs. And these tiers are not defined by us but the audits they have done at their side prior to onboarding their GPU servers on our network which are further available on demand to users.

Message : If ur GPU span multiple datacenter while training...like 1 GPU is in data center A and another is in B and u stitch them together, then the TIA 942 is invalidated.
Ull have to get it done urself.

If u guarantee all the GPU servers in one batch will sit within one data center, then yes - u get the benefit of the tier classification.

Message : my honest opinion is that this battle is not worth fighting. anyone is willing to accept this non-Tier grade reliability in exchange for aggregate availability. 
i would pay for it without caring...as would many on this group.

Message : It's the first scenario I'd say. Since we are not dependent on a single provider and not only data centers. We have pooled in GPUs from independent small providers and data centers, leading to more optionality as well. From 8GB to 80GB GPUs + in quantity.

Message : @91773788xxxx talked to AI architect at cerebras system

Message : He is willing to help as well

Message : Does anyone have ideas or doing 'governance checks' for their models ? for me is an independent review of the architecture towards what's the focus or what's not the focus - i want to see how models can be helpful for communities; another level can be audit of training data of what's included and what's not (which prompts makes models hallucinate or lie?) and then a strategic/business audit (environmental and social) ... trivially, *are we wanting AI to be our master, slave or friend or somewhere in-between?* grateful for anticipated feedback.

Message : ‚Äé<attached: 00008713-PHOTO-2023-06-14-14-50-59.jpg>

Message : Crypto miners have a moat now

Message : so, there's a GPU shortage?

Message : ‚Äé<attached: 00008716-PHOTO-2023-06-14-15-13-32.jpg>

Message : Nat.dev?

Message : https://aviary.anyscale.com/

Message : For a future project I‚Äôm looking to interact with data scientists / ML specialists who have been involved in developing AI-powered technology to be employed in rural/farming contexts in India. If you have any information to share please let me know. I can also be reached here: baas@eth.mpg.de

Message : https://www.moneycontrol.com/news/business/startup/indian-saas-giant-zoho-joins-the-large-language-model-race-10795551.html

Message : @91773788xxxx you can probably reach out to him instead of Gurnani

Message : ‚Äé~‚ÄØShubhi Saxena added ~‚ÄØSourabh Nolkha

Message : Has anybody started using function calls as published by OpenAI today ? 
https://openai.com/blog/function-calling-and-other-api-updates

Does this seem like an official implementation of ‚Äòtools‚Äô in LangChain ?

By default the interaction with GPT-3.5 seems to assume an interaction with agent with these function calls

I see this is just 1 step away from full fledged agents +tools library

Right now you‚Äôre defining the functions in the model call

Later on you can give list of available functions and GPT-3.5 can decide the best option to select to give desired output

Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw
Quoted Message : Has anybody started using function calls as published by OpenAI today ? \nhttps://openai.com/blog/function-calling-and-other-api-updates\n\nDoes this seem like an official implementation of ‚Äòtools‚Äô in LangChain ? \n\nBy default the interaction with GPT-3.5 seems to assume an interaction with agent with these function calls\n\nI see this is just 1 step away from full fledged agents +tools library \n\nRight now you‚Äôre defining the functions in the model call \n\nLater on you can give list of available functions and GPT-3.5 can decide the best option to select to give desired output

Message : Thanks for sharing this! This is the exact problem I was grappling with 

And damn quick work on putting it out  in < 24 hrs üôåüèª @91773788xxxx

Seems like some non-trivial part of LangChain lib is now redundant with function call utility by OpenAI
Quoted Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00008716-PHOTO-2023-06-14-15-13-32.jpg>

Message : Nat.dev?

Message : https://aviary.anyscale.com/

Message : For a future project I‚Äôm looking to interact with data scientists / ML specialists who have been involved in developing AI-powered technology to be employed in rural/farming contexts in India. If you have any information to share please let me know. I can also be reached here: baas@eth.mpg.de

Message : https://www.moneycontrol.com/news/business/startup/indian-saas-giant-zoho-joins-the-large-language-model-race-10795551.html

Message : @91773788xxxx you can probably reach out to him instead of Gurnani

Message : ‚Äé~‚ÄØShubhi Saxena added ~‚ÄØSourabh Nolkha

Message : Has anybody started using function calls as published by OpenAI today ? 
https://openai.com/blog/function-calling-and-other-api-updates

Does this seem like an official implementation of ‚Äòtools‚Äô in LangChain ?

By default the interaction with GPT-3.5 seems to assume an interaction with agent with these function calls

I see this is just 1 step away from full fledged agents +tools library

Right now you‚Äôre defining the functions in the model call

Later on you can give list of available functions and GPT-3.5 can decide the best option to select to give desired output

Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw
Quoted Message : Has anybody started using function calls as published by OpenAI today ? \nhttps://openai.com/blog/function-calling-and-other-api-updates\n\nDoes this seem like an official implementation of ‚Äòtools‚Äô in LangChain ? \n\nBy default the interaction with GPT-3.5 seems to assume an interaction with agent with these function calls\n\nI see this is just 1 step away from full fledged agents +tools library \n\nRight now you‚Äôre defining the functions in the model call \n\nLater on you can give list of available functions and GPT-3.5 can decide the best option to select to give desired output

Message : Thanks for sharing this! This is the exact problem I was grappling with 

And damn quick work on putting it out  in < 24 hrs üôåüèª @91773788xxxx

Seems like some non-trivial part of LangChain lib is now redundant with function call utility by OpenAI
Quoted Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Message : Yes we did today. Just doing web search now and then next is jira ticket update
Quoted Message : Has anybody started using function calls as published by OpenAI today ? \nhttps://openai.com/blog/function-calling-and-other-api-updates\n\nDoes this seem like an official implementation of ‚Äòtools‚Äô in LangChain ? \n\nBy default the interaction with GPT-3.5 seems to assume an interaction with agent with these function calls\n\nI see this is just 1 step away from full fledged agents +tools library \n\nRight now you‚Äôre defining the functions in the model call \n\nLater on you can give list of available functions and GPT-3.5 can decide the best option to select to give desired output

Message : You can also refer the openai cookbook 
https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb
for additional docs
Quoted Message : Thanks for sharing this! This is the exact problem I was grappling with \n\nAnd damn quick work on putting it out  in < 24 hrs üôåüèª @9177xxxxxxxx\n\nSeems like some non-trivial part of LangChain lib is now redundant with function call utility by OpenAI

Message : @91773788xxxx is a machine ! :)
amazing work Nirant !
Quoted Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Message : If this library continues to integrate more stuff I can see it become a really popular open-source library

Message : If this library continues to integrate more stuff I can see it become a really popular open-source library
Quoted Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Message : Yeah. Although I like it in this type of format where I can write the code in my own style without learning a separate syntax.

Easier to integrate into existing pipeline
Quoted Message : If this library continues to integrate more stuff I can see it become a really popular open-source library

Message : Logan on twitter is great for all openai announcements and updates
https://twitter.com/OfficialLoganK/status/1668668826047721494?s=20
Quoted Message : Has anybody started using function calls as published by OpenAI today ? \nhttps://openai.com/blog/function-calling-and-other-api-updates\n\nDoes this seem like an official implementation of ‚Äòtools‚Äô in LangChain ? \n\nBy default the interaction with GPT-3.5 seems to assume an interaction with agent with these function calls\n\nI see this is just 1 step away from full fledged agents +tools library \n\nRight now you‚Äôre defining the functions in the model call \n\nLater on you can give list of available functions and GPT-3.5 can decide the best option to select to give desired output

Message : @91773788xxxx in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?

Message : ‚ÄúColab notebook to get unchained‚Äù üòÇ
Quoted Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Message : Dev rel at openai. That's his job
Quoted Message : Logan on twitter is great for all openai announcements and updates\nhttps://twitter.com/OfficialLoganK/status/1668668826047721494?s=20

Message : i know, it was a PSA to follow Logan :)
Quoted Message : Dev rel at openai. That's his job

Message : Am still working on that. It's not great. Need to figure out more here whether it's the way the function was defined etc.
Quoted Message : @9177xxxxxxxx in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?

Message : ok figured it out. Need a good system message in my case.
Seems nice
Quoted Message : Am still working on that. It's not great. Need to figure out more here whether it's the way the function was defined etc.

Message : Is there some new way to ask the API for json (by specifying required and optional fields in a schema)? Like through functions or something? Or will old prompts just work better now

Message : Any example or is it secret sauce? (I understand if it‚Äôs the latter)
Quoted Message : ok figured it out. Need a good system message in my case.\nSeems nice

Message : not that much of a secret sauce. If you're in Mumbai and coming to the meetup on Saturday, will share over there üòú. we can actually discuss this on DM because message is specific to type of functions being passed
Quoted Message : Any example or is it secret sauce? (I understand if it‚Äôs the latter)

Message : Nope. JSON is still not guaranteed.
Quoted Message : Is there some new way to ask the API for json (by specifying required and optional fields in a schema)? Like through functions or something? Or will old prompts just work better now

Message : Yeah just saw a tweet reporting the same. Hallucinating placeholder values in the schema
Quoted Message : Nope. JSON is still not guaranteed.

Message : 3.5 gets it right about 3/5 times, which is an improvement from GPT4-0314 of 1/5
Quoted Message : @91773788xxxx in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?

Message : is that what 3.5 stands for
Quoted Message : 3.5 gets it right about 3/5 times, which is an improvement from GPT4-0314 of 1/5

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØSimrat

Message : 3.5 gets it right about 3/5 times, which is an improvement from GPT4-0314 of 1/5

Message : is that what 3.5 stands for

Message : No it‚Äôs an instruction tuned gpt3
Quoted Message : is that what 3.5 stands for

Message : Sarcasm tha
Quoted Message : No it‚Äôs an instruction tuned gpt3

Message : 3.5 3/5

Message : Sarcasm tha

Message : 3.5 3/5

Message : ‚Äé<attached: 00008753-PHOTO-2023-06-14-23-14-22.jpg>
Quoted Message : @9177xxxxxxxx in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?

Message : insane speed of execution!

Message : What is the algorithm here?
Quoted Message : @9177xxxxxxxx in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?

Message : Langchain still seems to have so many issues, the tokentextsplitter is non deterministic and doesn't split evenly and doesn't even confine to token limits imposed, if the input text is too long üíÄ

Message : Agree üíØ
How long did it take to code this Nirant @91773788xxxx ?
Quoted Message : insane speed of execution!

Message : The ReAsk? 3 min to write the code, 2 hours to test it ü§£
Quoted Message : Agree üíØ\nHow long did it take to code this Nirant @9177xxxxxxxx ?

Message : https://hackathon.bio/#projects

Winner took imageBind and applied across all  protein modalities

Message : cc @91740765xxxx since we discussed SAM+ImageBind for Pathology and Radiology
Quoted Message : https://hackathon.bio/#projects\n\nWinner took imageBind and applied across all  protein modalities

Message : This is so cool!

Someone needs to add SAM to this and I think we can get a good direction for pathology based cancer diagnosis.
Quoted Message : https://hackathon.bio/#projects\n\nWinner took imageBind and applied across all  protein modalities

Message : Building on top of this, I shared some of my speculations here - https://twitter.com/177pc/status/1669056794864533504?t=1fJWSKe-x_yBKC-ciZIiig&s=19

Thinking of submitting a formal PR request and if @91773788xxxx sir approves, maybe we all here could collaborate on building some of these things
Quoted Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Message : A good founder friend of mine (please don't ask who) told me a version of this a few hours ago -

"I don't think LlamaIndex and/or LangChain are needed for 90% of the use-cases... At the moment they're all trying to reinvent ETL and might evolve into something unique...I don't know how/what that looks like..."

üòÖ

I don't have a perspective at the moment - happy to learn from others though
Quoted Message : Thanks for sharing this! This is the exact problem I was grappling with \n\nAnd damn quick work on putting it out  in < 24 hrs üôåüèª @9177xxxxxxxx\n\nSeems like some non-trivial part of LangChain lib is now redundant with function call utility by OpenAI

Message : StarCoder ‚Äî my fav code LLM has hit VC-verse: https://twitter.com/AstasiaMyers/status/1669025589213425664


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : What is the algorithm here?
Quoted Message : @9177xxxxxxxx in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?

Message : Langchain still seems to have so many issues, the tokentextsplitter is non deterministic and doesn't split evenly and doesn't even confine to token limits imposed, if the input text is too long üíÄ

Message : Agree üíØ
How long did it take to code this Nirant @91773788xxxx ?
Quoted Message : insane speed of execution!

Message : The ReAsk? 3 min to write the code, 2 hours to test it ü§£
Quoted Message : Agree üíØ\nHow long did it take to code this Nirant @9177xxxxxxxx ?

Message : https://hackathon.bio/#projects

Winner took imageBind and applied across all  protein modalities

Message : cc @91740765xxxx since we discussed SAM+ImageBind for Pathology and Radiology
Quoted Message : https://hackathon.bio/#projects\n\nWinner took imageBind and applied across all  protein modalities

Message : This is so cool!

Someone needs to add SAM to this and I think we can get a good direction for pathology based cancer diagnosis.
Quoted Message : https://hackathon.bio/#projects\n\nWinner took imageBind and applied across all  protein modalities

Message : Building on top of this, I shared some of my speculations here - https://twitter.com/177pc/status/1669056794864533504?t=1fJWSKe-x_yBKC-ciZIiig&s=19

Thinking of submitting a formal PR request and if @91773788xxxx sir approves, maybe we all here could collaborate on building some of these things
Quoted Message : https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw

Message : A good founder friend of mine (please don't ask who) told me a version of this a few hours ago -

"I don't think LlamaIndex and/or LangChain are needed for 90% of the use-cases... At the moment they're all trying to reinvent ETL and might evolve into something unique...I don't know how/what that looks like..."

üòÖ

I don't have a perspective at the moment - happy to learn from others though
Quoted Message : Thanks for sharing this! This is the exact problem I was grappling with \n\nAnd damn quick work on putting it out  in < 24 hrs üôåüèª @9177xxxxxxxx\n\nSeems like some non-trivial part of LangChain lib is now redundant with function call utility by OpenAI

Message : StarCoder ‚Äî my fav code LLM has hit VC-verse: https://twitter.com/AstasiaMyers/status/1669025589213425664

Message : Are you using it with some vscode extension or just checking benchmarks?

Message : Not VSCode, that's still Copilot ‚Äî StarCoder is slower and worse. Copilot changed the experience a bit and gives a lot more coherent output too.
Quoted Message : Are you using it with some vscode extension or just checking benchmarks?

Message : I dont want to renew Copilot as I think it's not worth it anymore and the new WizardML star coder had a better benchmark than 3.5

Message : I don't mind hosting on my GPU but having an extension like Copilot that support oss code model out of box would be next big thing. May be a good startup or project India if someone is looking for it.

Message : Soon almost everything will be better than 3.5, partially because people have started to figure out how to game the leaderboard. Kaggle-mindset trickling in.

Message : cc @658752xxxx @658784xxxx
Quoted Message : I don't mind hosting on my GPU but having an extension like Copilot that support oss code model out of box would be next big thing. May be a good startup or project India if someone is looking for it.

Message : We need eval test for eval tests.
Quoted Message : Soon almost everything will be better than 3.5, partially because people have started to figure out how to game the leaderboard. Kaggle-mindset trickling in.

Message : Same old story, just in a new dress
Quoted Message : Soon almost everything will be better than 3.5, partially because people have started to figure out how to game the leaderboard. Kaggle-mindset trickling in.

Message : Standardization is required to draw a fair comparison between various approaches

But then slowly future approaches start optimising towards that benchmark, instead of the real life

Message : ...applications

Message : Just curious , do you work on cancer related applications ?

If yes, would love to talk and exchange notes.
I am twitter.com/acgt01
Quoted Message : This is so cool!\n\nSomeone needs to add SAM to this and I think we can get a good direction for pathology based cancer diagnosis.

Message : I used to long back on pathology at morphle labs üòÖ
Quoted Message : Just curious , do you work on cancer related applications ?\n\nIf yes, would love to talk and exchange notes. \nI am twitter.com/acgt01

Message : There is a repo for exact use case, someone needs to build a VS code extension around it.

https://github.com/salesforce/CodeTF
Quoted Message : I don't mind hosting on my GPU but having an extension like Copilot that support oss code model out of box would be next big thing. May be a good startup or project India if someone is looking for it.

Message : First release was just two weeks ago, a good opportunity for someone to gain quick fame.
Quoted Message : There is a repo for exact use case, someone needs to build a VS code extension around it.\n\nhttps://github.com/salesforce/CodeTF

Message : ‚Äé<attached: 00008780-PHOTO-2023-06-15-02-50-19.jpg>

Message : But definitely they will improve. and humaneval pass@xxxx is not a very good evaluation too.

Message : https://twitter.com/theblokeai/status/1669032287416066063?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw WizardML 57

Message : I think there's a WizardLM-Starcoder 15B version today from TheBloke that surpassed GPT3.5

Message : Yeah this one.
Quoted Message : https://twitter.com/theblokeai/status/1669032287416066063?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw WizardML 57

Message : But I've not tried it out myself yet.

Message : Alex created CoPilot so can be trusted, if he is right $500k/month commitment for Azure GPT4-32K api access ü§Ø https://twitter.com/alexgraveley/status/1669091417262817280?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw

Message : Any LLM benchmarks so far in the context of mathematical reasoning?

Message : I want to run ggml alpaca eval for this model and see the difference in benchmark performance.
Quoted Message : https://twitter.com/theblokeai/status/1669032287416066063?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw WizardML 57

Message : @91773788xxxx, @658784xxxx and I were discussing this just a couple of days ago. Wouldn‚Äôt that still cost you more than $20/month though? And for a worse experience?
Quoted Message : I don't mind hosting on my GPU but having an extension like Copilot that support oss code model out of box would be next big thing. May be a good startup or project India if someone is looking for it.

Message : Using it against GPT-3.5/4 might be cheaper given you are just paying for the actual usage and I am sure they are dramatically subsidizing the real cost.

Message : Have you tried https://github.com/ai-genie/chatgpt-vscode ?

Message : I have many 3090s at home, If WizardML is beating GPt3.5, it will be better than CoPilot. This setup is to replace the copilot and not GPT4.
Quoted Message : @9177xxxxxxxx, @65xxxxxxxx and I were discussing this just a couple of days ago. Wouldn‚Äôt that still cost you more than $20/month though? And for a worse experience?

Message : https://arxiv.org/pdf/2306.07303.pdf
A COMPREHENSIVE SURVEY ON APPLICATIONS OF
TRANSFORMERS FOR DEEP LEARNING TASKS

Message : https://docs.google.com/document/d/e/2PACX-1vSOgnt4XInS1A6LXM3VZbbcx3ZG-IaRUrBV4Iotnmns0i38IbP5C48mT1eTrmOcxyzUcljIjpFwJaj5/pub

Legal LLM Hackathon

Message : ‚Äé<attached: 00008798-PHOTO-2023-06-15-10-00-53.jpg>

Message : ‚Äé<attached: 00008800-PHOTO-2023-06-15-11-34-54.jpg>

Message : yeah man, it‚Äôs pretty wild

Message : Accelerators are coming in different shapes and sizes hahaha

Message : ‚Äé<attached: 00008803-PHOTO-2023-06-15-11-38-26.jpg>

Message : That's a huge discrepancy in salaries in India and US for AI. Decent ones are earning ~1M, I'm sure many in this group will land that if they are here.

Message : ‚ÄúDecent ones are earning ~1M‚Äù
Quoted Message : That's a huge discrepancy in salaries in India and US for AI. Decent ones are earning ~1M, I'm sure many in this group will land that if they are here.

Message : curious. any resources similar to levels.fyi to read more about it?

Message : I learned from recent tweets that I saw from Emad and some other sources who were struggling to hire.

Message : Has anyone noticed OpenAI APIs throttled for India? I'm having drastic latency issues for servers in India compared to the US. Even 3.5-turbo.

Message : lol


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00008800-PHOTO-2023-06-15-11-34-54.jpg>

Message : yeah man, it‚Äôs pretty wild

Message : Accelerators are coming in different shapes and sizes hahaha

Message : ‚Äé<attached: 00008803-PHOTO-2023-06-15-11-38-26.jpg>

Message : That's a huge discrepancy in salaries in India and US for AI. Decent ones are earning ~1M, I'm sure many in this group will land that if they are here.

Message : ‚ÄúDecent ones are earning ~1M‚Äù
Quoted Message : That's a huge discrepancy in salaries in India and US for AI. Decent ones are earning ~1M, I'm sure many in this group will land that if they are here.

Message : curious. any resources similar to levels.fyi to read more about it?

Message : I learned from recent tweets that I saw from Emad and some other sources who were struggling to hire.

Message : Has anyone noticed OpenAI APIs throttled for India? I'm having drastic latency issues for servers in India compared to the US. Even 3.5-turbo.

Message : lol

Message : Would need to compare to US or other regions for this. What's your reasoning?
Quoted Message : Has anyone noticed OpenAI APIs throttled for India? I'm having drastic latency issues for servers in India compared to the US. Even 3.5-turbo.

Message : No reasoning yet, just asking to confirm.

Message : Yesterday I saw @91986822xxxx having a similar issue.

Message : Not facing such with 3.5. 4 is slow during peak us hours.

Can discuss this in more detail
Quoted Message : No reasoning yet, just asking to confirm.

Message : Not making it up, but pretty sure one can absolutely predict when the US east coast is awake coding just from the API latency üòÖ

Message : Not making it up, but pretty sure one can absolutely predict when the US east coast is awake coding just from the API latency üòÖ
Quoted Message : Would need to compare to US or other regions for this. What's your reasoning?

Message : That's a fact
Quoted Message : Not making it up, but pretty sure one can absolutely predict when the US east coast is awake coding just from the API latency üòÖ

Message : +1 on this 
Typically I‚Äôve seen API performing worse after 4pm IST
Quoted Message : Not making it up, but pretty sure one can absolutely predict when the US east coast is awake coding just from the API latency üòÖ

Message : Interesting video featuring Karpathy - discusses GPT training process https://youtu.be/bZQun8Y4L2A

Message : or by seeing chatgpt response.
Quoted Message : Not making it up, but pretty sure one can absolutely predict when the US east coast is awake coding just from the API latency üòÖ

Message : Stumbled upon Langkit from whylabs, will share my feedback soon. 
https://github.com/whylabs/langkit/blob/main/langkit/examples/Intro_to_Langkit.ipynb

Message : This is quite interesting

Message : ‚ÄéPOLL:
Hi folks, how often do you use ChatGPT plugins? (choose multiple options if you need to). TiA
‚ÄéOPTION: Frequently (5 votes)
‚ÄéOPTION: Infrequently / rarely (30 votes)
‚ÄéOPTION: Use lots of different plugins (0 votes)
‚ÄéOPTION: Use a few select plugins (12 votes)
‚ÄéOPTION: Use plugins but exclusively inside ChatGPT (1 vote)
‚ÄéOPTION: Use plugins & also corresponding product outside ChatGPT (0 votes)
‚ÄéOPTION: Something else (do tell in comments) (0 votes)

Message : The overall LLM ops stack

Message : Which other tools have you used to monitor, observe, test  LLMs
Quoted Message : Stumbled upon Langkit from whylabs, will share my feedback soon. \n https://github.com/whylabs/langkit/blob/main/langkit/examples/Intro_to_Langkit.ipynb

Message : I suspect this will be rarely. Plugins are a poor design primitive.

It should ideally be reversed

The AI should go to the tools. The tools shouldn't come to the AI

Message : Something SamA also mentioned in an interview. Plugins don't have PMF. They went deeper and realised people who were saying they want more functionalities wanted chatGPT inside their tools and not the other way round.
Quoted Message : I suspect this will be rarely. Plugins are a poor design primitive.\n\nIt should ideally be reversed\n\nThe AI should go to the tools. The tools shouldn't come to the AI

Message : ChatGPT is an AI and a SaaS. Sam wants to built AGI but also tonnes of tools, apps
Quoted Message : I suspect this will be rarely. Plugins are a poor design primitive.\n\nIt should ideally be reversed\n\nThe AI should go to the tools. The tools shouldn't come to the AI

Message : I missed that. Noted.
Quoted Message : Something SamA also mentioned in an interview. Plugins don't have PMF. They went deeper and realised people who were saying they want more functionalities wanted chatGPT inside their tools and not the other way round.

Message : Which interview was this? Any link?
Quoted Message : Something SamA also mentioned in an interview. Plugins don't have PMF. They went deeper and realised people who were saying they want more functionalities wanted chatGPT inside their tools and not the other way round.

Message : I think it was in a blog

Message : I'm still collecting offerings and evaluating what they really do. Arize and Truera promise a few things but I'm  picking this because I have used other solutions from whylabs.
Quoted Message : Which other tools have you used to monitor, observe, test  LLMs

Message : Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic

Also noticed that when system response changes, output becomes slower vs when it remains the same

Message : Hey seems it was taken down. This is the best that came up sorry - https://matt-rickard.com/chatgpt-plugins-dont-have-pmf
Quoted Message : Which interview was this? Any link?

Message : First part +1, I'm deep diving into how temp parameter interacts with matrices to change the next word probabilities. Topk and topP are just filtering. My hunch was they just pass that to random selector if it's non zero and for zero it picks the top word. But I don't want to believe that. 

Also, change of model versions changes the probabilities wrt to words, due to newer data. So even temp=0 in ideal scenario will not generate same output if the base model changes, IMO.

Second part, any way to reproduce? I haven't seen that consistently.
Quoted Message : Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic\n\nAlso noticed that when system response changes, output becomes slower vs when it remains the same

Message : Got it! Seems like openai took it down.
Quoted Message : Hey seems it was taken down. This is the best that came up sorry - https://matt-rickard.com/chatgpt-plugins-dont-have-pmf

Message : Found it - https://web.archive.org/web/20230601023730/https://humanloop.com/blog/openai-plans

Message : he said this in person at the IIITD session as well. he touched briefly and then Eleti (openai engg) expanded on this very thing.
Quoted Message : Something SamA also mentioned in an interview. Plugins don't have PMF. They went deeper and realised people who were saying they want more functionalities wanted chatGPT inside their tools and not the other way round.

Message : he said "plugins in its current form". i think thats why they are doing all these functions, etc releases. plugins will come back definitely

Message : It generally is non deterministic. I think temperature is a pseudo parameter - like a loose lever you can play with. Not a proper controller for the nature of the output
Quoted Message : Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic\n\nAlso noticed that when system response changes, output becomes slower vs when it remains the same

Message : it was in one that was deleted
Quoted Message : Which interview was this? Any link?

Message : Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?


Do they compete with and as times, cannabalize each other ?

Would be curious to hear folks' thoughts

Message : I can definitely tell you that they both do compete for same customers
Quoted Message : Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?\n\n\nDo they compete with and as times, cannabalize each other ?\n\nWould be curious to hear folks' thoughts

Message : Microsoft's winning pitch so far has been Open AI APIs inside customers' VPCs

Message : From what I know.. MS product roadmap is more head on with Google. With OpenAI they are ok to go for same customers however their marketing team's mandate is that positioning /promoting MS products should not diss or jeopardize openai.
Quoted Message : Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?\n\n\nDo they compete with and as times, cannabalize each other ?\n\nWould be curious to hear folks' thoughts

Message : True deterministic output using t=0 isn't possible since true t=0 doesn't really happen.
Quoted Message : Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic\n\nAlso noticed that when system response changes, output becomes slower vs when it remains the same

Message : ‚Äé<attached: 00008845-PHOTO-2023-06-15-16-51-36.jpg>

Message : Notice that t=0 is an approaching limit and can't really be 0. So what you get in implementations in all the libraries is high determinism not true determinism.

Message : https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers

(Via https://news.ycombinator.com/item?id=36333321)

Message : Wait, what ‚Äî Obsidian has a way to publish notes to web on a custom domain?
Quoted Message : https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers\n\n(Via https://news.ycombinator.com/item?id=36333321)


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : it was in one that was deleted
Quoted Message : Which interview was this? Any link?

Message : Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?


Do they compete with and as times, cannabalize each other ?

Would be curious to hear folks' thoughts

Message : I can definitely tell you that they both do compete for same customers
Quoted Message : Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?\n\n\nDo they compete with and as times, cannabalize each other ?\n\nWould be curious to hear folks' thoughts

Message : Microsoft's winning pitch so far has been Open AI APIs inside customers' VPCs

Message : From what I know.. MS product roadmap is more head on with Google. With OpenAI they are ok to go for same customers however their marketing team's mandate is that positioning /promoting MS products should not diss or jeopardize openai.
Quoted Message : Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?\n\n\nDo they compete with and as times, cannabalize each other ?\n\nWould be curious to hear folks' thoughts

Message : True deterministic output using t=0 isn't possible since true t=0 doesn't really happen.
Quoted Message : Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic\n\nAlso noticed that when system response changes, output becomes slower vs when it remains the same

Message : ‚Äé<attached: 00008845-PHOTO-2023-06-15-16-51-36.jpg>

Message : Notice that t=0 is an approaching limit and can't really be 0. So what you get in implementations in all the libraries is high determinism not true determinism.

Message : https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers

(Via https://news.ycombinator.com/item?id=36333321)

Message : Wait, what ‚Äî Obsidian has a way to publish notes to web on a custom domain?
Quoted Message : https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers\n\n(Via https://news.ycombinator.com/item?id=36333321)

Message : I didn't even notice that.

I am guessing you are an obsidian user ? ( Or moved to obsidian recently from some other tool ? )
Quoted Message : Wait, what ‚Äî Obsidian has a way to publish notes to web on a custom domain?

Message : Obsidian Puvlish has that option , yes

Message : * publish

Message : https://twitter.com/levelsio/status/1669269424543793153

Message : Virtual Cataloging companies making some good money!

Message : Distribution is the differentiator here
Quoted Message : Virtual Cataloging companies making some good money!

Message : Danny Postma and Levelsio are both chad and top of their AI SAAS game
Quoted Message : https://twitter.com/levelsio/status/1669269424543793153

Message : Why do you say that?
Quoted Message : Distribution is the differentiator here

Message : Pieter levels makes 3M per year as a solo developer, with 300k+ Twitter fillers. His products aren‚Äôt necessarily different- it‚Äôs just that people buy when they see it‚Äôs him.
Quoted Message : Why do you say that?

Message : Does he have 300K follows because he builds cool things?
Quoted Message : Pieter levels makes 3M per year as a solo developer, with 300k+ Twitter fillers. His products aren‚Äôt necessarily different- it‚Äôs just that people buy when they see it‚Äôs him.

Message : Absolutely

Message : And sells it well.

Message : Curious as to what you found as good or better as photoai.com or headshotpro . Org 

Wait did I send some more traffic there :-)
Quoted Message : Pieter levels makes 3M per year as a solo developer, with 300k+ Twitter fillers. His products aren‚Äôt necessarily different- it‚Äôs just that people buy when they see it‚Äôs him.

Message : What I meant was that it compounds now, and so it‚Äôs years of effort that allow him to build stuff that gets traction from day 1 even if not differentiated.

Message : I‚Äôm a fan and subscriber of both of them. Things get better as they get used and get feedback too. So building that early distribution helps them iterate much faster ‚Äî postma literally improves his product every 3rd day and he has earned that rich feedback loop too by being so consistent. Please do not mistake me for detractor of the 2 indie legends ü•≤
Quoted Message : Curious as to what you found as good or better as photoai.com or headshotpro . Org \n\nWait did I send some more traffic there :-)

Message : im not sure if this is the cause, it's like saying true random numbers can't exist what we get is pseudorandom numbers (which is true but a human can't detect that reliably)
Quoted Message : Notice that t=0 is an approaching limit and can't really be 0. So what you get in implementations in all the libraries is high determinism not true determinism.

Message : i use it too https://notes.invertedpassion.com/
Quoted Message : Wait, what ‚Äî Obsidian has a way to publish notes to web on a custom domain?

Message : It's a limitation of implementation. Lack of true randomness isn't there because humans can't detect it reliably but because computers use external sources that are deterministic. As long as the initial seed or source remains the same, the same random sequence can always be produced.
Quoted Message : im not sure if this is the cause, it's like saying true random numbers can't exist what we get is pseudorandom numbers (which is true but a human can't detect that reliably)

Message : maybe you're right, slight floating point differences can get amplified in a deep network
Quoted Message : It's a limitation of implementation. Lack of true randomness isn't there because humans can't detect it reliably but because computers use external sources that are deterministic. As long as the initial seed or source remains the same, the same random sequence can always be produced.

Message : Anyway, given that softmax usage of temperature is the same as the one I shared, how do you think you'll arrive at true value of softmax with t=0? It'll always be a number very close to 0 but never zero. So it'll always be highly deterministic and never true deterministic.

Message : ‚Äé<attached: 00008870-PHOTO-2023-06-15-18-28-33.jpg>

Message : What platform is this? Lambda labs?

Message : Seems andromeda cluster. Not sure what it is though. 
http://andromedacluster.com/
This is the tweet url
https://twitter.com/protosphinx/status/1668843101274664960?s=46

Message : This is lambda lab page.

Message : You just remove T from the equation entirely if T is 0?
Quoted Message : Anyway, given that softmax usage of temperature is the same as the one I shared, how do you think you'll arrive at true value of softmax with t=0? It'll always be a number very close to 0 but never zero. So it'll always be highly deterministic and never true deterministic.

Message : ‚Äé<attached: 00008875-PHOTO-2023-06-15-19-21-37.jpg>

Message : autoevaluator.langchain.com/playground

Message : Peak AI: Calling a grid search with a static front end "Evaluation Platform" 

If it uses hyperopt, we are gonna call it "AI for Systems" now??

Message : When marketing teams go overboard ! :)
Quoted Message : Peak AI: Calling a grid search with a static front end \"Evaluation Platform\" \n\nIf it uses hyperopt, we are gonna call it \"AI for Systems\" now??

Message : Marketing is overboard for everything in gen AI to the extent you need to as well because that's what is getting Rewarded by VC
Quoted Message : When marketing teams go overboard ! :)

Message : ‚Äé<attached: 00008881-PHOTO-2023-06-15-19-30-10.jpg>
Quoted Message : Marketing is overboard for everything in gen AI to the extent you need to as well because that's what is getting Rewarded by VC

Message : looks like a job for jupyter meowbooks

Message : The inspiration we all need :)

On a lighter note, if only more folks were interested in the war against cancer and disease :)

Message : Winning the meme wars is important, not too long ago ‚Äî disease and cancer were seen as "what God ordained"
Quoted Message : The inspiration we all need :)\n\nOn a lighter note, if only more folks were interested in the war against cancer and disease :)

Message : This isn‚Äôt even the first time. 3rd ai wave since 2014 and same story everytime
Quoted Message : Marketing is overboard for everything in gen AI to the extent you need to as well because that's what is getting Rewarded by VC

Message : LOL. We may yet see "steel man the AI" on a gen AI pitch deck sometime soon

Message : Also, 10m seed round - reminds me of "a small loan of a million dollars"

Message : https://www.reddit.com/r/LocalLLaMA/comments/149abrg/creating_a_wiki_for_all_things_local_llm_what_do/

Open source LLMs wiki.

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØSwadeep Pillarisetti

Message : ‚Äé~‚ÄØKaushik Bokka added ‚Ä™+91¬†97489¬†61402‚Ä¨


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00008881-PHOTO-2023-06-15-19-30-10.jpg>
Quoted Message : Marketing is overboard for everything in gen AI to the extent you need to as well because that's what is getting Rewarded by VC

Message : looks like a job for jupyter meowbooks

Message : The inspiration we all need :)

On a lighter note, if only more folks were interested in the war against cancer and disease :)

Message : Winning the meme wars is important, not too long ago ‚Äî disease and cancer were seen as "what God ordained"
Quoted Message : The inspiration we all need :)\n\nOn a lighter note, if only more folks were interested in the war against cancer and disease :)

Message : This isn‚Äôt even the first time. 3rd ai wave since 2014 and same story everytime
Quoted Message : Marketing is overboard for everything in gen AI to the extent you need to as well because that's what is getting Rewarded by VC

Message : LOL. We may yet see "steel man the AI" on a gen AI pitch deck sometime soon

Message : Also, 10m seed round - reminds me of "a small loan of a million dollars"

Message : https://www.reddit.com/r/LocalLLaMA/comments/149abrg/creating_a_wiki_for_all_things_local_llm_what_do/

Open source LLMs wiki.

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØSwadeep Pillarisetti

Message : ‚Äé~‚ÄØKaushik Bokka added ‚Ä™+91¬†97489¬†61402‚Ä¨

Message : https://lab45thinktank.com/genai-accelerator-program/

If you're an AI company selling B2B and looking to expand in the US, you could evaluate this program by Wipro

Learnt about this from @91897169xxxx Swadeep who is helping Wipro with this program

Message : Great intent; most important step here will be introduction to Wipro clients. If it works, pretty fabulous.
Quoted Message : https://lab45thinktank.com/genai-accelerator-program/\n\nIf you're an AI company selling B2B and looking to expand in the US, you could evaluate this program by Wipro\n\nLearnt about this from @9189xxxxxxxx Swadeep who is helping Wipro with this program

Message : Does anyone has expertise in multinode distributed training using Pytorch? Any help would be highly appreciated

Message : https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers

Great article - Nvidia H100 and A100 GPUs - comparing available capacity at GPU cloud providers

Message : Also H100 on lambda labs is 1.99 USD/hr now

Message : Just use accelerator or Lightning
Quoted Message : Does anyone has expertise in multinode distributed training using Pytorch? Any help would be highly appreciated

Message : Accelerate*

Message : Google released virtual try-on today. Interestingly has only the upper body cloths as example and lower body is left for future. Any idea why they might have left that? tough to crack? 

https://blog.google/products/shopping/virtual-try-on-google-generative-ai/?utm_source=tw&utm_medium=social&utm_campaign=og&utm_content=&utm_term=

Message : Ok, I will try. Thanks.
Quoted Message : Just use accelerator or Lightning

Message : I will bug you again if I face any issues. üôÇ

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØSrinivasa Raghavan K M

Message : had a question maybe, a very amateur question , trying to understand why GPU computing power is better than cpu , any good resource on this topic, people have that they can share, i know bandwidth of sharing data in the chip may be a way better in GPU and also the architecture wise there will be difference, but any resource that help u

Message : Concise but not precise answer - ML/DL computations are primarily matrix multiplications on ground level and GPUs allow you to perform 1000s these computations parallely. CPUs can parallelise as well but they usually have way less cores that means way lesser parallelism.

Message : A more detailed answer would involve explaining how modern architectures are also designed to primarily benefit from GPUs and modern GPUs again are designed to get best performance in AI.

Message : GPUs have SIMD architecture i.e. Single instruction multi data. Which enables them to do parallel processing at scale across thousands of smaller cuda cores (cuda cores are in nvidia GPUs). They are smaller than a typical vCPU found in a normal CPU chip but they are in very large quantity and thus they can process a large amount of data in parallel leading to faster results.
Quoted Message : had a question maybe, a very amateur question , trying to understand why GPU computing power is better than cpu , any good resource on this topic, people have that they can share, i know bandwidth of sharing data in the chip may be a way better in GPU and also the architecture wise there will be difference, but any resource that help u

Message : As an example an RTX 3090 GPU has ~ 10,000 cuda cores which is quite a lot.

Message : For very simple question, you can always ask ChatGPT.
Quoted Message : had a question maybe, a very amateur question , trying to understand why GPU computing power is better than cpu , any good resource on this topic, people have that they can share, i know bandwidth of sharing data in the chip may be a way better in GPU and also the architecture wise there will be difference, but any resource that help u

Message : Use the prompt - explain me like I am a 5 year old.
Quoted Message : For very simple question, you can always ask ChatGPT.

Message : a very eli5 way to look at it is a CPU consists of a few very smart workers (cores) that do high quality work extremely fast. a gpu, in comparison, is thousands of not as smart workers, but can now consume larger workloads and operate in parallel. its a quantity over quality thing
Quoted Message : had a question maybe, a very amateur question , trying to understand why GPU computing power is better than cpu , any good resource on this topic, people have that they can share, i know bandwidth of sharing data in the chip may be a way better in GPU and also the architecture wise there will be difference, but any resource that help u

Message : adding to that, due to the recent surge in gpu usage for ML training, it has also been highly optimized for instructions specific to the ML context, at both the hw and sw levels

Message : this simple video explains at a high level: https://www.youtube.com/watch?v=-P28LKWTzrI

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØAman Shenoy

Message : Anyone from this group present at AWS dev day bangalore? Happy to catch up.

Message : folks interested in biomedical, drug discovery applications of ml, might enjoy this interview :
https://www.youtube.com/watch?v=inN2MX0fE5g

Message : Surprised that you can‚Äôt create an enterprise account on Stability AI

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAmbuj Kashyap

Message : Ping hardmaru they‚Äôll implement in the next 1 week
Quoted Message : Surprised that you can‚Äôt create an enterprise account on Stability AI

Message : Alot of people don't know this but Wipro is StabilityAI's distribution partner
Quoted Message : Great intent; most important step here will be introduction to Wipro clients. If it works, pretty fabulous.

Message : Alot of people don't know this but Wipro is StabilityAI's distribution partner

Message : Link is - Eros (yes the Bollywood powerhouse) Investments. They are an investor in StabilityAI

Message : And then https://m.economictimes.com/tech/information-tech/wipro-eros-investments-partner-to-scale-ai-based-solutions-to-global-media-industry/amp_articleshow/92257817.cms

Message : What does distribution partner here mean?
Quoted Message : Alot of people don't know this but Wipro is StabilityAI's distribution partner

Message : Wow
Quoted Message : Link is - Eros (yes the Bollywood powerhouse) Investments. They are an investor in StabilityAI

Message : This is interesting

Message : I don't fully understand it myself but my guess is:
1. Access to Wipro customers
2. Implementation through Wipro because StabilityAi doesn't have a services arm
Quoted Message : What does distribution partner here mean?

Message : @91994014xxxx do they have their own Model ? 
For speech to text , text to speech ?
Quoted Message : And then https://m.economictimes.com/tech/information-tech/wipro-eros-investments-partner-to-scale-ai-based-solutions-to-global-media-industry/amp_articleshow/92257817.cms

Message : You can find Stability's models on their website. I don't think Eros or Wipro have their own models
Quoted Message : @9199xxxxxxxx do they have their own Model ? \nFor speech to text , text to speech ?

Message : Hmm got it

Message : https://www.linkedin.com/posts/metaai_introducing-voicebox-a-new-breakthrough-activity-7075533881214451712--W4g?utm_source=share&utm_medium=member_android

Message : https://www.linkedin.com/posts/metaai_introducing-voicebox-a-new-breakthrough-activity-7075533881214451712--W4g?utm_source=share&utm_medium=member_android


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : And then https://m.economictimes.com/tech/information-tech/wipro-eros-investments-partner-to-scale-ai-based-solutions-to-global-media-industry/amp_articleshow/92257817.cms

Message : What does distribution partner here mean?
Quoted Message : Alot of people don't know this but Wipro is StabilityAI's distribution partner

Message : Wow
Quoted Message : Link is - Eros (yes the Bollywood powerhouse) Investments. They are an investor in StabilityAI

Message : This is interesting

Message : I don't fully understand it myself but my guess is:
1. Access to Wipro customers
2. Implementation through Wipro because StabilityAi doesn't have a services arm
Quoted Message : What does distribution partner here mean?

Message : @91994014xxxx do they have their own Model ? 
For speech to text , text to speech ?
Quoted Message : And then https://m.economictimes.com/tech/information-tech/wipro-eros-investments-partner-to-scale-ai-based-solutions-to-global-media-industry/amp_articleshow/92257817.cms

Message : You can find Stability's models on their website. I don't think Eros or Wipro have their own models
Quoted Message : @9199xxxxxxxx do they have their own Model ? \nFor speech to text , text to speech ?

Message : Hmm got it

Message : https://www.linkedin.com/posts/metaai_introducing-voicebox-a-new-breakthrough-activity-7075533881214451712--W4g?utm_source=share&utm_medium=member_android

Message : https://www.linkedin.com/posts/metaai_introducing-voicebox-a-new-breakthrough-activity-7075533881214451712--W4g?utm_source=share&utm_medium=member_android

Message : Meta AI is literally next level I think

Message : In a week that have MusicGen and now this. Zuck is also talking about making llama2 commercial.

Message : Actually waiting for llama v2 eagerly.
Quoted Message : In a week that have MusicGen and now this. Zuck is also talking about making llama2 commercial.

Message : Very exciting !

My worry is that audio deepfakes are going to get easier to generate for all users including malicious ones
Quoted Message : https://www.linkedin.com/posts/metaai_introducing-voicebox-a-new-breakthrough-activity-7075533881214451712--W4g?utm_source=share&utm_medium=member_android

Message : I think they'll have supplementary detection models too. Meta AI as far as I know is very ethical and safeguarded
Quoted Message : Very exciting !\n\nMy worry is that audio deepfakes are going to get easier to generate for all users including malicious ones

Message : That's what I hope :)

Message : Then there will opportunity for new startups to detect deep fakes.
Quoted Message : Very exciting !\n\nMy worry is that audio deepfakes are going to get easier to generate for all users including malicious ones

Message : Detection is always a one order higher difficulty problem than generation. We really didn't have a very high neural voice generation until few months back. But now it's hard to detect whether the speaker is human or not especially over a call.

Message : Everything we are seeing looked impossible 6-8 months back.

Message : Yes, it's like a fold in time. Everything got pulled in.

Message : The new mission impossible film is going to look so realistic
Quoted Message : Everything we are seeing looked impossible 6-8 months back.

Message : A year back when Netflix had that interactive movie/shows people were impressed, it will possible soon to replace everything Tom Cruz says with my voice. üòÇ

Message : Mission impossible had vision pro 20 years ago. üòÇ

Message : Bander snatch , was a cool concept
Quoted Message : A year back when Netflix had that interactive movie/shows people were impressed, it will possible soon to replace everything Tom Cruz says with my voice. üòÇ

Message : I am not sure how to put this message across, there is a huge inferiority complex associated to this. But here I go.


Is there a possibility to try to do the AI/ML Computation leveraging the crypto world.

Where people are rewarded with a  crypto token when they contribute to  the  computation output.

Since the actual prices are soaring would this even be actually viable?  I am not sure.

But thinking of a MLCoin  where people are paid for their compute.

This way the computation are reasonable in some form and will usher a way to combined new world of tech possibilities.

Thank you. For letting me rant about the idea that I had.

Message : Late night, sleep deprived rant.. üòî

Message : Can't people just be paid real cash for computation instead of a cryptocurrency?
Quoted Message : I am not sure how to put this message across, there is a huge inferiority complex associated to this. But here I go.\n\n\nIs there a possibility to try to do the AI/ML Computation leveraging the crypto world. \n\nWhere people are rewarded with a  crypto token when they contribute to  the  computation output. \n\nSince the actual prices are soaring would this even be actually viable?  I am not sure. \n\nBut thinking of a MLCoin  where people are paid for their compute. \n\nThis way the computation are reasonable in some form and will usher a way to combined new world of tech possibilities. \n\nThank you. For letting me rant about the idea that I had.

Message : Hey guys has anyone experimented with code chunking strategies, I want to create a vector store of cpp files

Message : True, but this  might act as a incentive for those who don't understand the importance of the actual hash calculations but will be rewarded for the compute.
Quoted Message : Can't people just be paid real cash for computation instead of a cryptocurrency?

Message : as far as I understand if I am renting my compute for hash calculations or any other computation, I would mostly prefer to be paid in a currency which is least volatile.
Quoted Message : True, but this  might act as a incentive for those who don't understand the importance of the actual hash calculations but will be rewarded for the compute.

Message : Hey we are doing this already at Q Blocks üëã
Quoted Message : Can't people just be paid real cash for computation instead of a cryptocurrency?

Message : Please dm me, would love to chat
Quoted Message : Hey we are doing this already at Q Blocks üëã

Message : Yeah, there are 2 approaches that I'm aware of and experimenting with whatever limited time I've

* Hierarchical summarisation of code - Recursive Chunking  to build hierarchical, iterative chunked docs
* Content aware chunking
Quoted Message : Hey guys has anyone experimented with code chunking strategies, I want to create a vector store of cpp files

Message : Since you mention cpp files specifically, are you looking for a cpp specialised chunking strategy?
Quoted Message : Hey guys has anyone experimented with code chunking strategies, I want to create a vector store of cpp files

Message : something weird going on with langchain py docs, but here's a link to the code chunking utils in langchain js: https://js.langchain.com/docs/modules/indexes/text_splitters/examples/code#:~:text=/*%0A%20%20%5B%0A%20%20%20%20%27-,cpp,-%27%2C%20%20%20%20%20%20%27go%27%2C%0A%20%20%20%20%27java

Message : https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/code_splitter

Message : Yeah I think chnuking strategy do need to be lang specific. Also, does ada-002 beats all guidance holds true for code retrieval as well.
Quoted Message : Since you mention cpp files specifically, are you looking for a cpp specialised chunking strategy?

Message : In my experience most people seem to do well or not bother in detail about which chunking strategies they are using for code. Maybe you've tried out the python langchain code splitters for cpp?
Have you noticed any issues with that?

Message : https://arxiv.org/abs/2306.08997

Message : Have not experimented much, I am trying to create an agent and creating a tool for that agent to retrieve relevant code. Will definitely use the long-chain cpp implementation and share my findings.
Quoted Message : In my experience most people seem to do well or not bother in detail about which chunking strategies they are using for code. Maybe you've tried out the python langchain code splitters for cpp?\nHave you noticed any issues with that?

Message : This is true, I had a call with Meta's Public Policy team yesterday to potentially have them join as partners for the OSS Fellowship Fund. \n\nWe also had a detailed Q&A on potential concerns from the Developer community on the llama models, licensing, IP ownership on training, data security etc.  \n\nIf people have questions for Meta's AI Team, please share here and I can collate to present to them
Quoted Message : In a week that have MusicGen and now this. Zuck is also talking about making llama2 commercial.

Message : This is true, I had a call with Meta's Public Policy team yesterday to potentially have them join as partners for the OSS Fellowship Fund. 

We also had a detailed Q&A on potential concerns from the Developer community on the llama models, licensing, IP ownership on training, data security etc.

If people have questions for Meta's AI Team, please share here and I can collate to present to them

Message : Hi all, I am new to this group and looking for someone who is working on stable diffusion.  Please connect. Thank you.

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : Goldberg having a field day with GPT4 evaluation "hacks"  
https://twitter.com/yoavgo/status/1669760558436872193
Quoted Message : https://arxiv.org/abs/2306.08997

Message : I love his sense of humour.
From his homepage :
"Jan. 6, 2011, at around 17:34, a girl stepped into my office and offered me to participate in the next season of the Israeli version of Beauty and the Geek. Being dedicated to my academic career, beard and wife, I kindly refused."

We could all use more humour in our lives :)
Quoted Message : Goldberg having a field day with GPT4 evaluation \"hacks\"  \nhttps://twitter.com/yoavgo/status/1669760558436872193

Message : Haha. Reminds me of that incredible foreword in another textbook

‚ÄúTo my wife Marganit and my children Ella Rose and Daniel Adam without whom this book would have been completed two years earlier"

Message : Isnt this the same paper where everyone is being amazed about the ‚Äúexpert prompting ‚Äú strategy ? 

From what I‚Äôve understood,there are some MCQs
GPT-4 is asked to provide answered to the MCQs and self critique until the eval is stopped ?

It‚Äôs just like I‚Äôm given 4 guesses to find an answer for MCQ with 4 optionü§∑üèª‚Äç‚ôÇÔ∏è
Quoted Message : Goldberg having a field day with GPT4 evaluation \"hacks\"  \nhttps://twitter.com/yoavgo/status/1669760558436872193

Message : Context: I am not from a technical background, learning from Google University of Search (üôà) and looking for a mentor / guide.
Quoted Message : Hi all, I am new to this group and looking for someone who is working on stable diffusion.  Please connect. Thank you.

Message : https://lu.ma/genAI-mumbai-june

Who here is going to show-up to this generative AI meet-up in Mumbai today?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This is true, I had a call with Meta's Public Policy team yesterday to potentially have them join as partners for the OSS Fellowship Fund. \n\nWe also had a detailed Q&A on potential concerns from the Developer community on the llama models, licensing, IP ownership on training, data security etc.  \n\nIf people have questions for Meta's AI Team, please share here and I can collate to present to them
Quoted Message : In a week that have MusicGen and now this. Zuck is also talking about making llama2 commercial.

Message : This is true, I had a call with Meta's Public Policy team yesterday to potentially have them join as partners for the OSS Fellowship Fund. 

We also had a detailed Q&A on potential concerns from the Developer community on the llama models, licensing, IP ownership on training, data security etc.

If people have questions for Meta's AI Team, please share here and I can collate to present to them

Message : Hi all, I am new to this group and looking for someone who is working on stable diffusion.  Please connect. Thank you.

Message : PSA: 

General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking "Can I ask questions about X?"

Message : Goldberg having a field day with GPT4 evaluation "hacks"  
https://twitter.com/yoavgo/status/1669760558436872193
Quoted Message : https://arxiv.org/abs/2306.08997

Message : I love his sense of humour.
From his homepage :
"Jan. 6, 2011, at around 17:34, a girl stepped into my office and offered me to participate in the next season of the Israeli version of Beauty and the Geek. Being dedicated to my academic career, beard and wife, I kindly refused."

We could all use more humour in our lives :)
Quoted Message : Goldberg having a field day with GPT4 evaluation \"hacks\"  \nhttps://twitter.com/yoavgo/status/1669760558436872193

Message : Haha. Reminds me of that incredible foreword in another textbook

‚ÄúTo my wife Marganit and my children Ella Rose and Daniel Adam without whom this book would have been completed two years earlier"

Message : Isnt this the same paper where everyone is being amazed about the ‚Äúexpert prompting ‚Äú strategy ? 

From what I‚Äôve understood,there are some MCQs
GPT-4 is asked to provide answered to the MCQs and self critique until the eval is stopped ?

It‚Äôs just like I‚Äôm given 4 guesses to find an answer for MCQ with 4 optionü§∑üèª‚Äç‚ôÇÔ∏è
Quoted Message : Goldberg having a field day with GPT4 evaluation \"hacks\"  \nhttps://twitter.com/yoavgo/status/1669760558436872193

Message : Context: I am not from a technical background, learning from Google University of Search (üôà) and looking for a mentor / guide.
Quoted Message : Hi all, I am new to this group and looking for someone who is working on stable diffusion.  Please connect. Thank you.

Message : https://lu.ma/genAI-mumbai-june

Who here is going to show-up to this generative AI meet-up in Mumbai today?

Message : Does anyone have access to code interpreter in chatgpt? If so can I please get an overview of it's usefulness? AI influencers are going Gung ho over it that it will eat developer jobs, just wanted to know what's the reality.

Message : @91773788xxxx are you aware of any meetups , hackathons in delhi ?

Message : Not very off. Code Interpreter is better than GPT4 at long context code understanding, being able to tell objects and dictionaries apart in Python, getting what a happy path convention is and similar clever things.

The REPL for data analytics is also quite nifty and faster than writing code on my own. E.g. the Users to be removed list for this group was made with CodeInterpreter: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit#gid=0
Quoted Message : Does anyone have access to code interpreter in chatgpt? If so can I please get an overview of it's usefulness? AI influencers are going Gung ho over it that it will eat developer jobs, just wanted to know what's the reality.

Message : I hear a certain AI CEO was there recently. Some great audience questions. 

Don't you think Delhi has embarrassed itself for the entirety of summer? ü§£
Quoted Message : @9177xxxxxxxx are you aware of any meetups , hackathons in delhi ?

Message : Don't you diss my hometown :)
Quoted Message : I hear a certain AI CEO was there recently. Some great audience questions. \n\nDon't you think Delhi has embarrassed itself for the entirety of summer? ü§£

Message : Any idea when this will release for regular chatgpt plus users as they had talked about this in march (it seems to be in the chat.openai.com app). Also is there an equivalent in the API?
Quoted Message : Not very off. Code Interpreter is better than GPT4 at long context code understanding, being able to tell objects and dictionaries apart in Python, getting what a happy path convention is and similar clever things.\n\nThe REPL for data analytics is also quite nifty and faster than writing code on my own. E.g. the Users to be removed list for this group was made with CodeInterpreter: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit#gid=0

Message : And finally is this for gpt 4 only or does gpt 3.5 also have this functionality?

Message : No Code Interpreter API. GPT4 only.

Message : Thanks a lot!
Quoted Message : No Code Interpreter API. GPT4 only.

Message : I‚Äôm desperately waiting for it too. Despite being a paying user (gpt plus)
Quoted Message : Any idea when this will release for regular chatgpt plus users as they had talked about this in march (it seems to be in the chat.openai.com app). Also is there an equivalent in the API?

Message : ‚Äé<attached: 00008985-PHOTO-2023-06-17-10-30-37.jpg>

Message : ‚Äé<attached: 00008986-PHOTO-2023-06-17-10-30-38.jpg>

Message : ‚Äé<attached: 00008987-PHOTO-2023-06-17-10-30-46.jpg>

Message : I don't think that's indicative of much except the High population of 18-25 year Olds in India who are studying in schools and colleges and have the best "academic" use of chatgpt

Message : If you get what I meanü§≠

Message : Lol yes fair point

Message : If there are statistics on chatgpt+ that would be more indicative as openai has not adjusted pricing for PPP

Message : Oh these are search statistics

Message : A permissively licensed implementation of llama's technical paper - OpenLlama finished training it's 13B model on 1T tokens and has released it.
It's performance is on AVG the same as llama 13B.

Message : https://github.com/openlm-research/open_llama

Message : LocalLLama subReddit is quite active https://www.reddit.com/r/LocalLLaMA/comments/147lmku/which_best_uncensored_freespeech_llm_models/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1

Message : It's one of my primary hangout spots recently.
Quoted Message : LocalLLama subReddit is quite active https://www.reddit.com/r/LocalLLaMA/comments/147lmku/which_best_uncensored_freespeech_llm_models/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1

Message : Enjoyed the first episode on generative AI in Black mirror‚Äôs new season

Message : Yeah, the one names ‚ÄúJoan is awful‚Äù, right?

Message : *named

Message : Aw, spolier
Quoted Message : Enjoyed the first episode on generative AI in Black mirror‚Äôs new season

Message : I have seen it

Message : How can it be a spoiler? It's a documentary iykwim

Message : ‚Äé<attached: 00009003-PHOTO-2023-06-17-11-31-28.jpg>

Message : We are living through it ! #cleverjokesftw
Quoted Message : How can it be a spoiler? It's a documentary iykwim

Message : any pro tips for video input in SD animations? runwayML is known, other options please! :)

Message : interesting graph !

my wager : nft & crypto were a flash in the pan, maybe crypto & blockchain were a little ahead of its time;

gen ai on the other hand, is, excuse the hyperbole, revolutionary in the way it will impact all facets of society as we know it -so is going to see a sustained interest over time

my 5 year prediction is : UBI(Universal Basic Income) will gain some serious traction as a lot of jobs will get automated away thanks to ai & robotics, especially in the us & europe

Message : UBI discussions are perhaps best suited for the Policy & Philosophy fork? 
https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Quoted Message : interesting graph !\n\nmy wager : nft & crypto were a flash in the pan, maybe crypto & blockchain were a little ahead of its time; \n\ngen ai on the other hand, is, excuse the hyperbole, revolutionary in the way it will impact all facets of society as we know it -so is going to see a sustained interest over time\n\nmy 5 year prediction is : UBI(Universal Basic Income) will gain some serious traction as a lot of jobs will get automated away thanks to ai & robotics, especially in the us & europe

Message : Now spatial computing will be the most searched term soon

Message : Few others in my to-try list: https://github.com/Scholar01/sd-webui-mov2mov, https://huggingface.co/spaces/fffiloni/ControlNet-Video
Quoted Message : any pro tips for video input in SD animations? runwayML is known, other options please! :)

Message : We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik
Quoted Message : interesting graph !\n\nmy wager : nft & crypto were a flash in the pan, maybe crypto & blockchain were a little ahead of its time; \n\ngen ai on the other hand, is, excuse the hyperbole, revolutionary in the way it will impact all facets of society as we know it -so is going to see a sustained interest over time\n\nmy 5 year prediction is : UBI(Universal Basic Income) will gain some serious traction as a lot of jobs will get automated away thanks to ai & robotics, especially in the us & europe

Message : in the biotech, life sci space, lab automation has been picking up speed, in the US & Europe, even a little bit in India.
Happy to chat more in the policy, philosophy wa group
Quoted Message : We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik

Message : That's not my contention, my contention is that gen AI isn't accelerating industrial automation
Quoted Message : in the biotech, life sci space, lab automation has been picking up speed, in the US & Europe, even a little bit in India.\nHappy to chat more in the policy, philosophy wa group

Message : I would, largely, agree with that.
although who knows what's brewing in boston dynamics & similar research labs
Quoted Message : That's not my contention, my contention is that gen AI isn't accelerating industrial automation

Message : Not true! The work is now towards robotics foundational model -

https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html?m=1
Quoted Message : We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : any pro tips for video input in SD animations? runwayML is known, other options please! :)

Message : interesting graph !

my wager : nft & crypto were a flash in the pan, maybe crypto & blockchain were a little ahead of its time;

gen ai on the other hand, is, excuse the hyperbole, revolutionary in the way it will impact all facets of society as we know it -so is going to see a sustained interest over time

my 5 year prediction is : UBI(Universal Basic Income) will gain some serious traction as a lot of jobs will get automated away thanks to ai & robotics, especially in the us & europe

Message : UBI discussions are perhaps best suited for the Policy & Philosophy fork? 
https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Quoted Message : interesting graph !\n\nmy wager : nft & crypto were a flash in the pan, maybe crypto & blockchain were a little ahead of its time; \n\ngen ai on the other hand, is, excuse the hyperbole, revolutionary in the way it will impact all facets of society as we know it -so is going to see a sustained interest over time\n\nmy 5 year prediction is : UBI(Universal Basic Income) will gain some serious traction as a lot of jobs will get automated away thanks to ai & robotics, especially in the us & europe

Message : Now spatial computing will be the most searched term soon

Message : Few others in my to-try list: https://github.com/Scholar01/sd-webui-mov2mov, https://huggingface.co/spaces/fffiloni/ControlNet-Video
Quoted Message : any pro tips for video input in SD animations? runwayML is known, other options please! :)

Message : We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik
Quoted Message : interesting graph !\n\nmy wager : nft & crypto were a flash in the pan, maybe crypto & blockchain were a little ahead of its time; \n\ngen ai on the other hand, is, excuse the hyperbole, revolutionary in the way it will impact all facets of society as we know it -so is going to see a sustained interest over time\n\nmy 5 year prediction is : UBI(Universal Basic Income) will gain some serious traction as a lot of jobs will get automated away thanks to ai & robotics, especially in the us & europe

Message : in the biotech, life sci space, lab automation has been picking up speed, in the US & Europe, even a little bit in India.
Happy to chat more in the policy, philosophy wa group
Quoted Message : We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik

Message : That's not my contention, my contention is that gen AI isn't accelerating industrial automation
Quoted Message : in the biotech, life sci space, lab automation has been picking up speed, in the US & Europe, even a little bit in India.\nHappy to chat more in the policy, philosophy wa group

Message : I would, largely, agree with that.
although who knows what's brewing in boston dynamics & similar research labs
Quoted Message : That's not my contention, my contention is that gen AI isn't accelerating industrial automation

Message : Not true! The work is now towards robotics foundational model -

https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html?m=1
Quoted Message : We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik

Message : Can't find the lecture right now but iirc Boston dynamics doesn't even use ML and depends heavily on classical control systems algos.
Quoted Message : I would, largely, agree with that.\nalthough who knows what's brewing in boston dynamics & similar research labs

Message : thanks for sending this link.
I was just reading about this yesterday.

Keerthana's twitter tracks this space quite well
https://twitter.com/keerthanpg
Quoted Message : Not true! The work is now towards robotics foundational model -\n\nhttps://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html?m=1

Message : https://github.com/AntonOsika/gpt-engineer

Has anyone tried this one yet?

Message : Yeah, I'm not holding my breath on Google shipping this to a factory near you
Quoted Message : Not true! The work is now towards robotics foundational model -\n\nhttps://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html?m=1

Message : My take. 

When MAANG is fighting to win the battle it's a serious thing going on.

It's literally MAANG at war in sillicon valley. Have never seen either Google or Mera resleea stuff so quickly üòÇ

No comments on NFT and crypto and coin culture. Even if the tech is good people like SBF and others have just brought it back to zero on the trust scale .

Message : https://www.linkedin.com/posts/1rohitagarwal_portkeyai-on-twitter-activity-7075700450926206976-DLVy?utm_source=share&utm_medium=member_ios\n\nVery cool, @9198xxxxxxxx

Message : https://www.linkedin.com/posts/1rohitagarwal_portkeyai-on-twitter-activity-7075700450926206976-DLVy?utm_source=share&utm_medium=member_ios

Very cool, @91989995xxxx

Message : Ability to cache semantically similar prompts seems novel

Message : Spent a lot of time tweaking stuff - works very well now for RAG use cases

Message : Great job, Rohit! Keep slaying

Message : ‚Äé<attached: 00009024-PHOTO-2023-06-17-13-23-31.jpg>

Message : https://youtu.be/DUUTHkQrYy0

Message : Tricking chatGPT to do piracy
Quoted Message : https://youtu.be/DUUTHkQrYy0

Message : Do they work?

Message : What is the correct approach for implementing GPT with analytic reports .
eg of data I‚Äôm working with-

| Content | Score | Date |
|---------|-------|------|
| x       | y     | z    |


I tried using embeddings and it gave me correct responses for prompts like - ‚Äúwhat‚Äôs the score of x content‚Äù or ‚Äúgive me content between this date‚Äù but when I ask ‚Äúgive the top scored content for this date‚Äù , it fails .
Someone in this forum had suggested using text2SQL with langchain instead of embeddings . Which is fine for querying ..

but my end goal is to ask queries like ‚Äúgenerate new content similar to top scoring data from this abc date‚Äù and text2SQL might not be suitable for this type of request.  any insights or suggestions?

Message : im interested in the same. if anyone has prompts, that would be super useful
Quoted Message : What is the correct approach for implementing GPT with analytic reports .\neg of data I‚Äôm working with- \n\n| Content | Score | Date |\n|---------|-------|------|\n| x       | y     | z    |\n\n\nI tried using embeddings and it gave me correct responses for prompts like - ‚Äúwhat‚Äôs the score of x content‚Äù or ‚Äúgive me content between this date‚Äù but when I ask ‚Äúgive the top scored content for this date‚Äù , it fails . \nSomeone in this forum had suggested using text2SQL with langchain instead of embeddings . Which is fine for querying ..\n\nbut my end goal is to ask queries like ‚Äúgenerate new content similar to top scoring data from this abc date‚Äù and text2SQL might not be suitable for this type of request.  any insights or suggestions?

Message : you want a way to generate new content based on a ranked/filtered content piece, did I understand it correctly?
Quoted Message : What is the correct approach for implementing GPT with analytic reports .\neg of data I‚Äôm working with- \n\n| Content | Score | Date |\n|---------|-------|------|\n| x       | y     | z    |\n\n\nI tried using embeddings and it gave me correct responses for prompts like - ‚Äúwhat‚Äôs the score of x content‚Äù or ‚Äúgive me content between this date‚Äù but when I ask ‚Äúgive the top scored content for this date‚Äù , it fails . \nSomeone in this forum had suggested using text2SQL with langchain instead of embeddings . Which is fine for querying ..\n\nbut my end goal is to ask queries like ‚Äúgenerate new content similar to top scoring data from this abc date‚Äù and text2SQL might not be suitable for this type of request.  any insights or suggestions?

Message : yep .

Message : i was thinking a 2 step query , one to sql to sort . other to pass it to llm to refer and create

Message : that's what i can think of too.

Message : in creation step, are you planning to add some more context? around the lines of central themes/main points of the actual content.

Message : yes creation involves - similar central themes + a web browsing agent if content requires the latest context  .

Message : ‚Äé<attached: 00009036-PHOTO-2023-06-17-16-52-53.jpg>

Message : Hopefully Abhinav is not revealing Longshot secret sauce üôÇ

Message : The award for the nerdiest, funniest prompt goes to .....

Message : I can't imagine why we work so hard as a community of AI practitioners and end up making this ü§£
Quoted Message : The award for the nerdiest, funniest prompt goes to .....

Message : Probably some sort of pseudo random generation. But the bypass is clever

Message : Hey guys one quick question: does anyone here have experience hosting python web apps on Replit? Want to understand how well dk they scale and what are the trade offs in terms of performance etc or hosting your api backends on platforms like Replit

Any other alternatives which are easy to setup with good perf feedback?

Message : Cc @91997020xxxx can help perhaps?
Quoted Message : Hey guys one quick question: does anyone here have experience hosting python web apps on Replit? Want to understand how well dk they scale and what are the trade offs in terms of performance etc or hosting your api backends on platforms like Replit\n\nAny other alternatives which are easy to setup with good perf feedback?

Message : Hey my friend is working on a side project, here‚Äôs the intro incase somebody wants to get in touch. :)

Hey, I'm Nehal (+44 7405377827), from IISc, currently in London. I'm hunting for a self-managed software dev to help out with a project (in LLM - autoagents - modular system ). Hit me up for more details.

Message : ‚Äé<attached: 00009045-PHOTO-2023-06-17-20-04-54.jpg>

Message : Any such discussions/talks in Bangalore anytime soon folks? Would love to catch up!

Message : Yupp. Learnt a lot

Message : https://www.reddit.com/r/ChatGPT/comments/14agito/meta_will_make_their_next_llm_free_for_commercial/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=3&utm_content=share_button

Since this was discussed recently

Message : It was a very detailed talk by soumendra on the details of Lora.

Message : Nice, where was this

Message : Anybody into biomedical informatics?? Looking to talk and know more about it .

Message : Mumbai generative AI meetup
Quoted Message : Nice, where was this

Message : Recording or slides please
Quoted Message : It was a very detailed talk by soumendra on the details of Lora.

Message : Yeah will share once we get videos from our photography partner
Quoted Message : Recording or slides please


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00009045-PHOTO-2023-06-17-20-04-54.jpg>

Message : Any such discussions/talks in Bangalore anytime soon folks? Would love to catch up!

Message : Yupp. Learnt a lot

Message : https://www.reddit.com/r/ChatGPT/comments/14agito/meta_will_make_their_next_llm_free_for_commercial/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=3&utm_content=share_button

Since this was discussed recently

Message : It was a very detailed talk by soumendra on the details of Lora.

Message : Nice, where was this

Message : Anybody into biomedical informatics?? Looking to talk and know more about it .

Message : Mumbai generative AI meetup
Quoted Message : Nice, where was this

Message : Recording or slides please
Quoted Message : It was a very detailed talk by soumendra on the details of Lora.

Message : Yeah will share once we get videos from our photography partner
Quoted Message : Recording or slides please

Message : Happens every month. Next Sat likely next one.
Quoted Message : Any such discussions/talks in Bangalore anytime soon folks? Would love to catch up!

Message : Do share deets
Quoted Message : Happens every month. Next Sat likely next one.

Message : In progress üòÖ
Quoted Message : Do share deets

Message : Will share by Monday.

Message : folks, any reading materials or pointers to start learning about the RAG stack?

Message : RAG video on youtube by the researcher itself
Quoted Message : folks, any reading materials or pointers to start learning about the RAG stack?

Message : Totally. Looking fwd to the ebook

Message : Is that an official name now? RAG stack
Quoted Message : folks, any reading materials or pointers to start learning about the RAG stack?

Message : Has anybody used 2markdown.com here?

I am building something that requires parsing html content and then embedding it.

I am currently using BSHTML Loader + RecursiveCharacterSplitter combination. However, I feel that the get_text method does not do justice to breaking down the document content into proper sections.

I am thinking of experimenting 2markdown loader + markdown splitter instead. If anybody has used this combination, would love to listen to your experience.

Message : going by what's being used üòÖ
Quoted Message : Is that an official name now? RAG stack

Message : Uhh, what's RAG? üòÖ
Quoted Message : folks, any reading materials or pointers to start learning about the RAG stack?

Message : retriever augmented generation

Message : retriever == vector database

Message : Retriever I would expand is all the steps to filter out relevant data to send to your LLM model for generation.
Includes vector db and other things
Quoted Message : retriever == vector database

Message : ‚Äé<attached: 00009070-PHOTO-2023-06-17-22-55-01.jpg>
Quoted Message : Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic\n\nAlso noticed that when system response changes, output becomes slower vs when it remains the same

Message : so since you never divide by 0, there's always a chance of a slight variation happening even though its very small

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ~‚ÄØAman Rai

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†76077¬†14483‚Ä¨

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ~‚ÄØNikunj Jagetiya

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†96194¬†01031‚Ä¨

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†97172¬†74996‚Ä¨

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ~‚ÄØManasi

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ~‚ÄØYuvraj Wadhwa

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ~‚ÄØMahalakshmi C

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†98806¬†60620‚Ä¨

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†89709¬†02000‚Ä¨

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†82105¬†79249‚Ä¨

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†83749¬†99651‚Ä¨

Message : ‚Äé‚Ä™+91¬†80055¬†61910‚Ä¨ removed ‚Ä™+91¬†91¬†674¬†694¬†70‚Ä¨

Message : Q - What is the more holistic evaluation metric as of now (from developing apps point of view) and is designing a holistic evaluation metric even a possible goal to chase? More tactically, are we even converging towards it? 

https://twitter.com/ben_golub/status/1670105313406582784?s=48

Message : Some questions have exact answers. This one doesn't - How can we design a perfect evaluation criteria for LLMs? We probably would grow towards that evaluation criteria or make-do with crowd evals for some time.

However, some questions are easy to answer. Like, what shouldn't be a standard for eval or how one shouldn't approach eval in the long term. This MIT EECS 100% performance paper just did all of those "don'ts".
I'll save you from my rant.
Quoted Message : Q - What is the more holistic evaluation metric as of now (from developing apps point of view) and is designing a holistic evaluation metric even a possible goal to chase? More tactically, are we even converging towards it? \n\nhttps://twitter.com/ben_golub/status/1670105313406582784?s=48

Message : ‚Äé<attached: 00009087-PHOTO-2023-06-18-07-51-49.jpg>

Message : Request for speaker - I'm trying to organize a community AI webinar on Thursday. Have requested Nirant to talk about GPT Functions. Need a second speaker to get into a more conceptual topic with learnings from production. 

Thursday 5-7pm, online

Anyone interested to be a speaker, please DM me.

Message : This was pre foundational models era, a company in Estonia was doing it. Ended up pivoting to predict deep fakes in the NFT space. Then raised $25M. I think it's called the NFT port. Take a look at it
Quoted Message : Then there will opportunity for new startups to detect deep fakes.

Message : I love the soft poem to calm the engineer busy debugging

Message : "Growing up in Hyderabad, India, I'd dreamt about being able to read Persian poetry‚Äîin particular the work of Rumi, which has been translated into Urdu and then into English. GPT-4 did it, in one shot. It was not just a machine translation, but something that preserved the sovereignty of poetry across two language boundaries. And that's pretty cool."

https://www.wired.com/story/microsofts-satya-nadella-is-betting-everything-on-ai/

Message : Another quote that really resonated with me :

"Wired q : OpenAI CEO Sam Altman believes that this will indeed happen. Do you agree with him that we're going to hit that AGI superintelligence benchmark?

SN answer :
I'm much more focused on the benefits to all of us. I am haunted by the fact that the industrial revolution didn't touch the parts of the world where I grew up until much later. So I am looking for the thing that may be even bigger than the industrial revolution, and really doing what the industrial revolution did for the West, for everyone in the world. So I'm not at all worried about AGI showing up, or showing up fast. Great, right? That means 8 billion people have abundance. That's a fantastic world to live in."
Quoted Message : \"Growing up in Hyderabad, India, I'd dreamt about being able to read Persian poetry‚Äîin particular the work of Rumi, which has been translated into Urdu and then into English. GPT-4 did it, in one shot. It was not just a machine translation, but something that preserved the sovereignty of poetry across two language boundaries. And that's pretty cool.\"\n\nhttps://www.wired.com/story/microsofts-satya-nadella-is-betting-everything-on-ai/

Message : the road to hell is paved with good intentions
Quoted Message : Another quote that really resonated with me :\n\n\"Wired q : OpenAI CEO Sam Altman believes that this will indeed happen. Do you agree with him that we're going to hit that AGI superintelligence benchmark?\n\nSN answer :\nI'm much more focused on the benefits to all of us. I am haunted by the fact that the industrial revolution didn't touch the parts of the world where I grew up until much later. So I am looking for the thing that may be even bigger than the industrial revolution, and really doing what the industrial revolution did for the West, for everyone in the world. So I'm not at all worried about AGI showing up, or showing up fast. Great, right? That means 8 billion people have abundance. That's a fantastic world to live in.\"

Message : So is the road to heaven
Quoted Message : the road to hell is paved with good intentions

Message : You never know where it forks ;)


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Some questions have exact answers. This one doesn't - How can we design a perfect evaluation criteria for LLMs? We probably would grow towards that evaluation criteria or make-do with crowd evals for some time.

However, some questions are easy to answer. Like, what shouldn't be a standard for eval or how one shouldn't approach eval in the long term. This MIT EECS 100% performance paper just did all of those "don'ts".
I'll save you from my rant.
Quoted Message : Q - What is the more holistic evaluation metric as of now (from developing apps point of view) and is designing a holistic evaluation metric even a possible goal to chase? More tactically, are we even converging towards it? \n\nhttps://twitter.com/ben_golub/status/1670105313406582784?s=48

Message : ‚Äé<attached: 00009087-PHOTO-2023-06-18-07-51-49.jpg>

Message : Request for speaker - I'm trying to organize a community AI webinar on Thursday. Have requested Nirant to talk about GPT Functions. Need a second speaker to get into a more conceptual topic with learnings from production. 

Thursday 5-7pm, online

Anyone interested to be a speaker, please DM me.

Message : This was pre foundational models era, a company in Estonia was doing it. Ended up pivoting to predict deep fakes in the NFT space. Then raised $25M. I think it's called the NFT port. Take a look at it
Quoted Message : Then there will opportunity for new startups to detect deep fakes.

Message : I love the soft poem to calm the engineer busy debugging

Message : "Growing up in Hyderabad, India, I'd dreamt about being able to read Persian poetry‚Äîin particular the work of Rumi, which has been translated into Urdu and then into English. GPT-4 did it, in one shot. It was not just a machine translation, but something that preserved the sovereignty of poetry across two language boundaries. And that's pretty cool."

https://www.wired.com/story/microsofts-satya-nadella-is-betting-everything-on-ai/

Message : Another quote that really resonated with me :

"Wired q : OpenAI CEO Sam Altman believes that this will indeed happen. Do you agree with him that we're going to hit that AGI superintelligence benchmark?

SN answer :
I'm much more focused on the benefits to all of us. I am haunted by the fact that the industrial revolution didn't touch the parts of the world where I grew up until much later. So I am looking for the thing that may be even bigger than the industrial revolution, and really doing what the industrial revolution did for the West, for everyone in the world. So I'm not at all worried about AGI showing up, or showing up fast. Great, right? That means 8 billion people have abundance. That's a fantastic world to live in."
Quoted Message : \"Growing up in Hyderabad, India, I'd dreamt about being able to read Persian poetry‚Äîin particular the work of Rumi, which has been translated into Urdu and then into English. GPT-4 did it, in one shot. It was not just a machine translation, but something that preserved the sovereignty of poetry across two language boundaries. And that's pretty cool.\"\n\nhttps://www.wired.com/story/microsofts-satya-nadella-is-betting-everything-on-ai/

Message : the road to hell is paved with good intentions
Quoted Message : Another quote that really resonated with me :\n\n\"Wired q : OpenAI CEO Sam Altman believes that this will indeed happen. Do you agree with him that we're going to hit that AGI superintelligence benchmark?\n\nSN answer :\nI'm much more focused on the benefits to all of us. I am haunted by the fact that the industrial revolution didn't touch the parts of the world where I grew up until much later. So I am looking for the thing that may be even bigger than the industrial revolution, and really doing what the industrial revolution did for the West, for everyone in the world. So I'm not at all worried about AGI showing up, or showing up fast. Great, right? That means 8 billion people have abundance. That's a fantastic world to live in.\"

Message : So is the road to heaven
Quoted Message : the road to hell is paved with good intentions

Message : You never know where it forks ;)

Message : no good deed ever goes unpunished
Quoted Message : So is the road to heaven

Message : (Let's fork to Philosophy on this one)

Message : Why you got to shine a realistic light on my utopian dreams, Nirant ? :)

p.s. interesting aside : I discovered it on the feed of a pharma vp, who quoted this line in the context of ai drug discovery :


‚Äúit's not about who has capability, it's about who can actually exercise that capability and translate it into tangible products.‚Äù
Quoted Message : the road to hell is paved with good intentions

Message : It was in beta mode for a while now. Only issue was it worked sometimes only, because they would give the message unable to connect with gpt

Message : interestingly, nothing in production is using opensource models. pretty much GPT is a monopoly.

Message : Has anyone figured out if there is a way to get insights from tabular data through gpt-4? I know there is pandas gpt, but looking for papers,tecnhiques etc

Message : nothing in open source even comes close to even GPT3.5-Turbo on absolutely any task which you'd want to put in production
Quoted Message : interestingly, nothing in production is using opensource models. pretty much GPT is a monopoly.

Message : Code Interpreter ftw
Quoted Message : Has anyone figured out if there is a way to get insights from tabular data through gpt-4? I know there is pandas gpt, but looking for papers,tecnhiques etc

Message : Do you mean retrieval of structured data?
Quoted Message : Has anyone figured out if there is a way to get insights from tabular data through gpt-4? I know there is pandas gpt, but looking for papers,tecnhiques etc

Message : Connecting models to work with structured data is a pretty active area of work at the moment.

Message : there isn't a secret sauce to get insights on tabular data. Think of it as a chunking problem and each row is a chunk. Look up the code of yolo-pandas and the prompts they are using, that should be able to give you an insight of how they are doing.
Quoted Message : Has anyone figured out if there is a way to get insights from tabular data through gpt-4? I know there is pandas gpt, but looking for papers,tecnhiques etc

Message : yup. only model that is close on some tasks are more closed models such as claude, in some cases cohere and some cases nlp-cloud's own finetuned models
Quoted Message : nothing in open source even comes close to even GPT3.5-Turbo on absolutely any task which you'd want to put in production

Message : I would say, use techniques of RAG and you can apply them here on tabular data.
Quoted Message : there isn't a secret sauce to get insights on tabular data. Think of it as a chunking problem and each row is a chunk. Look up the code of yolo-pandas and the prompts they are using, that should be able to give you an insight of how they are doing.

Message : this is interesting. so u chunk a whole row - with column labels i presume ?
Quoted Message : I would say, use techniques of RAG and you can apply them here on tabular data.

Message : If each row is a chunk then global context of the data is lost right?
Quoted Message : there isn't a secret sauce to get insights on tabular data. Think of it as a chunking problem and each row is a chunk. Look up the code of yolo-pandas and the prompts they are using, that should be able to give you an insight of how they are doing.

Message : yes, that is a strategy that has worked when we've tried.
Quoted Message : this is interesting. so u chunk a whole row - with column labels i presume ?

Message : Can you elaborate on this?
Quoted Message : If each row is a chunk then global context of the data is lost right?

Message : If I am chunking on row+ column names, and if I ask it a question what does the trend looks like, how will it answer that?
Quoted Message : Can you elaborate on this?

Message : The original q. prompted this gen ai which can do data science wishlist flow 

1. Inputting my data ( a large CSV say 1GB or other tabular data), larger than current prompt window

Either through uploading to an LLM cloud service( which ensures isolation and guarantees that the data would remain private)

Or

Connectors for Google drive, AWS S3, etc where I opt in to give the LLM provider access to my data files

2. I can then ask natutal language, data science queries , of the data I uploaded/ connected to the LLM provider

- generate jupyter notebook code to generate scatter plot,  Churn of customers, most valuable new customer, etc

- most sold item in March 2023 along with a graph of most sold items by month in the last FY
- show me all the possible analysis on my sales numbers in the last month


Does ChatGPT or other solutions exist to doing GPT data science , EDA( exploratory data analysis) today ?

Any papers or articles on this theme ? ‚Äé<This message was edited>
Quoted Message : Do you mean retrieval of structured data?

Message : I don‚Äôt have access, and is that available through api?
Quoted Message : Code Interpreter ftw

Message : GPT Plus users seem to have it by default. No API.
Quoted Message : I don‚Äôt have access, and is that available through api?

Message : see you have to work on constraints anyways which is your context length you can pass to openai.
However for your particular case, there are ways in which libraries have done this thing. Which is yo translate your question to pandas function code execute it and give an answer.
Which is why I recommend looking at yolo-pandas lib. Its open source , on github and is actually pretty good at this
Quoted Message : If I am chunking on row+ column names, and if I ask it a question what does the trend looks like, how will it answer that?

Message : I don't have it. I don't know what's the deal with this by OpenAI. they haven't opened to all plus customers
Quoted Message : GPT Plus users seem to have it by default. No API.

Message : I have access to all plugins minus code interpreter

Message : I dontü§®ü§®
Quoted Message : GPT Plus users seem to have it by default. No API.

Message : Got it. Thanks
Quoted Message : see you have to work on constraints anyways which is your context length you can pass to openai.\nHowever for your particular case, there are ways in which libraries have done this thing. Which is yo translate your question to pandas function code execute it and give an answer.\nWhich is why I recommend looking at yolo-pandas lib. Its open source , on github and is actually pretty good at this

Message : I wonder how manual/AI-driven OpenAI's whitelist system is. Could they be applying GPT-4 to our chat histories to understand who the right customer is to reveal early features :p ‚Äé<This message was edited>

Message : Much like God, OpenAI works in mysterious ways

Message : its manual, influencers get early features. regarding access, I think its heavily based on access history. We got openai gpt-4 access in a day, when it became public, companies like jasper through  connections etc had access a little earler, which goes in line with their access history.
Quoted Message : I wonder how manual/AI-driven OpenAI's whitelist system is. Could they be applying GPT-4 to our chat histories to understand who the right customer is to reveal early features :p

Message : I have a conspiracy theory - openai‚Äôs token generation latency is random to make us believe the model is thinking
Quoted Message : Much like God, OpenAI works in mysterious ways

Message : I have another. someone is manually typing your answers on chatgpt üòú
Quoted Message : I have a conspiracy theory - openai‚Äôs token generation latency is random to make us believe the model is thinking

Message : Can this strategy work if you don‚Äôt have Code Interpreter access ?

-Describe the table and fields in a prompt to GPT-3.5
-Ground it using system prompt for data analysis
-Then ask it to generate python code on the file to answer user questions
-Ex.Based on {table} described answer the {user_query} by generating Python code for data analysis

Chain this LLM process output with a Python agent and it will execute it too and give you answers
Quoted Message : The original q. prompted this gen ai which can do data science wishlist flow \n\n1. Inputting my data ( a large CSV say 1GB or other tabular data), larger than current prompt window\n\nEither through uploading to an LLM cloud service( which ensures isolation and guarantees that the data would remain private)\n\nOr\n\nConnectors for Google drive, AWS S3, etc where I opt in to give the LLM provider access to my data files\n\n2. I can then ask natutal language, data science queries , of the data I uploaded/ connected to the LLM provider\n\n- generate jupyter notebook code to generate scatter plot,  Churn of customers, most valuable new customer, etc \n\n- most sold item in March 2023 along with a graph of most sold items by month in the last FY\n- show me all the possible analysis on my sales numbers in the last month\n\n\nDoes ChatGPT or other solutions exist to doing GPT data science , EDA( exploratory data analysis) today ?\n\nAny papers or articles on this theme ?

Message : Second this. In fact when I took the plus subscription it was jarring to the eyes seeing the 3.5 version too fast.
Quoted Message : I have a conspiracy theory - openai‚Äôs token generation latency is random to make us believe the model is thinking

Message : Open source Multimodal LLM from Tencent

https://huggingface.co/papers/2306.09093
https://github.com/lyuchenyang/Macaw-LLM

Message : update on this - 
using SqlDatabaseChain , and step wise prompt . the response is pretty decent -

sharing the prompt  -

'Step 1: Identify the top 5 posts with the highest overall engagement (likes + comments + shares).\n' +
'Step 2: Analyze these posts and determine the common theme that could have contributed to their high engagement.\n' +
'Step 3: Based on the identified theme, generate a new content for a post.\n' +
"Please provide the information in a structured manner, with each step's outcome clearly stated.",
Quoted Message : im interested in the same. if anyone has prompts, that would be super useful

Message : https://twitter.com/EdenEmarco177/status/1670064627269484545?t=VxZkvzI7oQ0xbUxcB25uTQ&s=08

A nice thread on chunking strategies, something we often discuss here

Message : No üòû
Quoted Message : GPT Plus users seem to have it by default. No API.

Message : Not default
Quoted Message : GPT Plus users seem to have it by default. No API.

Message : I don't :(

Message : ‚Äé‚Äé~‚ÄØSriram changed their phone number to a new number. ‚ÄéTap to message or add the new number.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I have another. someone is manually typing your answers on chatgpt üòú
Quoted Message : I have a conspiracy theory - openai‚Äôs token generation latency is random to make us believe the model is thinking

Message : Can this strategy work if you don‚Äôt have Code Interpreter access ?

-Describe the table and fields in a prompt to GPT-3.5
-Ground it using system prompt for data analysis
-Then ask it to generate python code on the file to answer user questions
-Ex.Based on {table} described answer the {user_query} by generating Python code for data analysis

Chain this LLM process output with a Python agent and it will execute it too and give you answers
Quoted Message : The original q. prompted this gen ai which can do data science wishlist flow \n\n1. Inputting my data ( a large CSV say 1GB or other tabular data), larger than current prompt window\n\nEither through uploading to an LLM cloud service( which ensures isolation and guarantees that the data would remain private)\n\nOr\n\nConnectors for Google drive, AWS S3, etc where I opt in to give the LLM provider access to my data files\n\n2. I can then ask natutal language, data science queries , of the data I uploaded/ connected to the LLM provider\n\n- generate jupyter notebook code to generate scatter plot,  Churn of customers, most valuable new customer, etc \n\n- most sold item in March 2023 along with a graph of most sold items by month in the last FY\n- show me all the possible analysis on my sales numbers in the last month\n\n\nDoes ChatGPT or other solutions exist to doing GPT data science , EDA( exploratory data analysis) today ?\n\nAny papers or articles on this theme ?

Message : Second this. In fact when I took the plus subscription it was jarring to the eyes seeing the 3.5 version too fast.
Quoted Message : I have a conspiracy theory - openai‚Äôs token generation latency is random to make us believe the model is thinking

Message : Open source Multimodal LLM from Tencent

https://huggingface.co/papers/2306.09093
https://github.com/lyuchenyang/Macaw-LLM

Message : update on this - 
using SqlDatabaseChain , and step wise prompt . the response is pretty decent -

sharing the prompt  -

'Step 1: Identify the top 5 posts with the highest overall engagement (likes + comments + shares).\n' +
'Step 2: Analyze these posts and determine the common theme that could have contributed to their high engagement.\n' +
'Step 3: Based on the identified theme, generate a new content for a post.\n' +
"Please provide the information in a structured manner, with each step's outcome clearly stated.",
Quoted Message : im interested in the same. if anyone has prompts, that would be super useful

Message : https://twitter.com/EdenEmarco177/status/1670064627269484545?t=VxZkvzI7oQ0xbUxcB25uTQ&s=08

A nice thread on chunking strategies, something we often discuss here

Message : No üòû
Quoted Message : GPT Plus users seem to have it by default. No API.

Message : Not default
Quoted Message : GPT Plus users seem to have it by default. No API.

Message : I don't :(

Message : ‚Äé‚Äé~‚ÄØSriram changed their phone number to a new number. ‚ÄéTap to message or add the new number.

Message : Go to settings and turn on beta features, if you haven‚Äôt. Then you should see it. Also do this on web, you don‚Äôt see this setting on mobile app.

Message : have done it. its an alpha feature. not there for everyone
Quoted Message : Go to settings and turn on beta features, if you haven‚Äôt. Then you should see it. Also do this on web, you don‚Äôt see this setting on mobile app.

Message : Yeah not available for me either. It isn't rolled out for everyone as yet it seems
Quoted Message : have done it. its an alpha feature. not there for everyone

Message : Stumbled on a cool project danswer (built using qdrant)

https://github.com/danswer-ai/danswer

"Danswer allows you to ask natural language questions against internal documents and get back reliable answers backed by quotes and references from the source material so that you can always trust what you get back. You can connect to a number of common tools such as Slack, GitHub, Confluence, amongst others."

Message : Any cost estimators for compute needed to fine-tune OSS models? Worried about the hole in my wallet due to computeüòÖ

Message : https://github.com/alibaba/Chat2DB

Alibaba released this DB client (non commercial licensing) to connect with multi DBs. Converts SQL queries to natural queries and vice versa.

Message : ‚Äé<attached: 00009144-PHOTO-2023-06-19-08-59-30.jpg>
Quoted Message : Any cost estimators for compute needed to fine-tune OSS models? Worried about the hole in my wallet due to computeüòÖ

Message : might be slightly outdated with llama models in play now

Message : Bytedance (TikTok) has bought $1B of NVIDIA GPUs: Split between A100 and H100 (Chinese fork called H800) 

https://www.tomshardware.com/news/chinas-bytedance-has-gobbled-up-dollar1-billion-of-nvidia-gpus-for-ai-this-year

Message : h/t @abacaj on Twitter

Message : Interesting, have you evaluated it? would you know any other state of the art model for this use case?
Quoted Message : https://github.com/alibaba/Chat2DB\n\nAlibaba released this DB client (non commercial licensing) to connect with multi DBs. Converts SQL queries to natural queries and vice versa.

Message : Thank you!

Message : Anyone working on interface of robotics and LLMs here?

Just curious

Message : Custom schema extraction using openai function from @91773788xxxx 

https://twitter.com/nirantk/status/1670651931398918148?s=46

Message : @91827553xxxx has good experience in m robotics
Quoted Message : Anyone working on interface of robotics and LLMs here?\n\nJust curious

Message : Folks any good read on business side of Google?

Message : https://stratechery.com/company/google/
Quoted Message : Folks any good read on business side of Google?

Message : I also enjoy reading Not Boring by Packy M. He has a couple of recent ones.

https://www.notboring.co/p/the-unbearable-heaviness-of-being
https://www.notboring.co/p/attention-is-all-you-need
Quoted Message : https://stratechery.com/company/google/

Message : I believe Balaji of Mitra Robotics is here in the group, can someone who knows him mention him?
Quoted Message : Anyone working on interface of robotics and LLMs here?\n\nJust curious

Message : Yes. We have been making social robots since 2020 for use in geriatrics.
Quoted Message : Anyone working on interface of robotics and LLMs here?\n\nJust curious

Message : Balaji is my cofounder - happy to answer question about robotics and LLMs - DM me plz.

Message : ‚Äé<attached: 00009163-PHOTO-2023-06-19-15-40-28.jpg>

Message : 1 trillion+ params for gpt-4? The other day I watched zuckerberg estimate that it was around 650B params.

Message : ‚Äé<attached: 00009165-PHOTO-2023-06-19-15-49-11.jpg>

Message : Anyone has the group invite link? Can you please add
+91 98332 96431

Message : Did they use the circle diagram on Twitter as reference
Quoted Message : 1 trillion+ params for gpt-4? The other day I watched zuckerberg estimate that it was around 650B params.

Message : I would trust this, but feel it's smaller
Quoted Message : 1 trillion+ params for gpt-4? The other day I watched zuckerberg estimate that it was around 650B params.

Message : Also for folks in this group. We have tried writing an eBook from what we have learned through our conversations with different enterprises/startups using LLMs
You can find it here
https://www.truefoundry.com/ebook-llm

Message : Plug ü§ô
Quoted Message : Also for folks in this group. We have tried writing an eBook from what we have learned through our conversations with different enterprises/startups using LLMs\nYou can find it here\nhttps://www.truefoundry.com/ebook-llm

Message : 2 questions for model deployment:

1: For deploying a fine tuned  T5 model, where out of box latency on NVidia T4 GPUs (g4dn on AWS) is coming out high (order of 800ms), inputs on what approaches can be tried to reduce the latency without compromising on accuracy too much: Intel neural compressor, deepSpeed MII (in list of models supported T5 not present)?

2: for deploying a production chatbot based on Azure OpenAI, any package which provides the entire chat logging and analysis capability: Truera Trulens?

Message : Use Apache TVM or HuggingFace Optimum to optimize the models. This is not a logical optimisation...just a compiler optimisation. Quite safe in general
Quoted Message : 2 questions for model deployment:\n\n1: For deploying a fine tuned  T5 model, where out of box latency on NVidia T4 GPUs (g4dn on AWS) is coming out high (order of 800ms), inputs on what approaches can be tried to reduce the latency without compromising on accuracy too much: Intel neural compressor, deepSpeed MII (in list of models supported T5 not present)?\n\n2: for deploying a production chatbot based on Azure OpenAI, any package which provides the entire chat logging and analysis capability: Truera Trulens?

Message : I'm interested in #2 - what kind of chat logging functionality do you expect? The standard logging library can be used, with chat and other history stored in DB tables. This is in addition to general app logs I guess
Quoted Message : 2 questions for model deployment:\n\n1: For deploying a fine tuned  T5 model, where out of box latency on NVidia T4 GPUs (g4dn on AWS) is coming out high (order of 800ms), inputs on what approaches can be tried to reduce the latency without compromising on accuracy too much: Intel neural compressor, deepSpeed MII (in list of models supported T5 not present)?\n\n2: for deploying a production chatbot based on Azure OpenAI, any package which provides the entire chat logging and analysis capability: Truera Trulens?

Message : Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library

Message : Just the standard Python logger may work https://pypi.org/project/logging/
Quoted Message : Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library

Message : I use this for logging: loguru.readthedocs.io/en/stable/index.html

This is a thin wrapper around the default Python logger, very parsing friendly, metadata about which function gets logged by default, so quite handy for most analytics and debugging use cases.
Quoted Message : Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library

Message : I don't know if there are purpose built frameworks for logging chat history, that may be worth it.

Message : My primary use case is often debugging logs, analytics logs are secondary

Message : From a design lens, Rasa has a the best logging design for chat (quite expected tbh): https://rasa.com/docs/rasa/tracker-stores/

They call it Tracker Stores for chat storage.

Here are fields you'd care about in any chat log: https://rasa.com/docs/rasa/monitoring/analytics/data-structure-reference

You can parse from file and ETL to a Warehouse for analytics if you're doing at some scale.

Message : Have seen Rasa features/docs referenced at least twice in the last few weeks here. :)

Message : anything similar for JS/TS ?
Quoted Message : From a design lens, Rasa has a the best logging design for chat (quite expected tbh): https://rasa.com/docs/rasa/tracker-stores/\n\nThey call it Tracker Stores for chat storage. \n\nHere are fields you'd care about in any chat log: https://rasa.com/docs/rasa/monitoring/analytics/data-structure-reference\n\nYou can parse from file and ETL to a Warehouse for analytics if you're doing at some scale.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Use Apache TVM or HuggingFace Optimum to optimize the models. This is not a logical optimisation...just a compiler optimisation. Quite safe in general
Quoted Message : 2 questions for model deployment:\n\n1: For deploying a fine tuned  T5 model, where out of box latency on NVidia T4 GPUs (g4dn on AWS) is coming out high (order of 800ms), inputs on what approaches can be tried to reduce the latency without compromising on accuracy too much: Intel neural compressor, deepSpeed MII (in list of models supported T5 not present)?\n\n2: for deploying a production chatbot based on Azure OpenAI, any package which provides the entire chat logging and analysis capability: Truera Trulens?

Message : I'm interested in #2 - what kind of chat logging functionality do you expect? The standard logging library can be used, with chat and other history stored in DB tables. This is in addition to general app logs I guess
Quoted Message : 2 questions for model deployment:\n\n1: For deploying a fine tuned  T5 model, where out of box latency on NVidia T4 GPUs (g4dn on AWS) is coming out high (order of 800ms), inputs on what approaches can be tried to reduce the latency without compromising on accuracy too much: Intel neural compressor, deepSpeed MII (in list of models supported T5 not present)?\n\n2: for deploying a production chatbot based on Azure OpenAI, any package which provides the entire chat logging and analysis capability: Truera Trulens?

Message : Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library

Message : Just the standard Python logger may work https://pypi.org/project/logging/
Quoted Message : Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library

Message : I use this for logging: loguru.readthedocs.io/en/stable/index.html

This is a thin wrapper around the default Python logger, very parsing friendly, metadata about which function gets logged by default, so quite handy for most analytics and debugging use cases.
Quoted Message : Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library

Message : I don't know if there are purpose built frameworks for logging chat history, that may be worth it.

Message : My primary use case is often debugging logs, analytics logs are secondary

Message : From a design lens, Rasa has a the best logging design for chat (quite expected tbh): https://rasa.com/docs/rasa/tracker-stores/

They call it Tracker Stores for chat storage.

Here are fields you'd care about in any chat log: https://rasa.com/docs/rasa/monitoring/analytics/data-structure-reference

You can parse from file and ETL to a Warehouse for analytics if you're doing at some scale.

Message : Have seen Rasa features/docs referenced at least twice in the last few weeks here. :)

Message : anything similar for JS/TS ?
Quoted Message : From a design lens, Rasa has a the best logging design for chat (quite expected tbh): https://rasa.com/docs/rasa/tracker-stores/\n\nThey call it Tracker Stores for chat storage. \n\nHere are fields you'd care about in any chat log: https://rasa.com/docs/rasa/monitoring/analytics/data-structure-reference\n\nYou can parse from file and ETL to a Warehouse for analytics if you're doing at some scale.

Message : It is quite robust so rightly being sited as well üôÇ
Quoted Message : Have seen Rasa features/docs referenced at least twice in the last few weeks here. :)

Message : The data structures/fields we care are similar between JS/TS and Python. The SDK/API for how to use those is quite often specific to workflows e.g. Support bots have the implicit goal of reducing interactions, while goal-oriented bots like sales want to do something different altogether.
Quoted Message : anything similar for JS/TS ?

Message : https://github.com/getzep/zep
Quoted Message : I don't know if there are purpose built frameworks for logging chat history, that may be worth it.

Message : We implemented Rasa for an insurance company in the Middle East a few years ago. The experience was not good. I have not tried it recently with the ChatGPT integration.
Quoted Message : It is quite robust so rightly being sited as well üôÇ

Message : We have had good experience so far with it. Currently experimenting with the "intentless" aka more conversational aspects
Quoted Message : We implemented Rasa for an insurance company in the Middle East a few years ago. The experience was not good. I have not tried it recently with the ChatGPT integration.

Message : Very cool. Thank you
Quoted Message : https://github.com/getzep/zep

Message : how do u use rasa for LLM applications ? is it like langchain - as in, do u tie prompts and chains using rasa proprietary SDK ? 
i can understand when it is classical NLP model training. but how does it come into play in the LLM world ?
Quoted Message : We have had good experience so far with it. Currently experimenting with the \"intentless\" aka more conversational aspects

Message : I‚Äôm thinking of using Rasa only for engineering pieces such as logging. Whereas we rely on langchain and the like for LLM calls and prompt engineering
Quoted Message : how do u use rasa for LLM applications ? is it like langchain - as in, do u tie prompts and chains using rasa proprietary SDK ? \ni can understand when it is classical NLP model training. but how does it come into play in the LLM world ?

Message : We don‚Äôt build intent based chat bots anymore anyway - at least not in the way we used to

Message : Given that RASA is a little heavy, are there not simpler tools for logging purposes? 

I'm still not sure if RASA is relevant now when we can do so many things with Langchain.
Quoted Message : I‚Äôm thinking of using Rasa only for engineering pieces such as logging. Whereas we rely on langchain and the like for LLM calls and prompt engineering

Message : Yeah, I agree. It is easier to build custom frameworks or use Langchain, except perhaps where you're mixing intent based and LLM based bot workflows in the same app
Quoted Message : Given that RASA is a little heavy, are there not simpler tools for logging purposes? \n\nI'm still not sure if RASA is relevant now when we can do so many things with Langchain.

Message : Weights and biases is extremely good here.

Langchain has integration with it and we are building integration with w&b into edgechains for production.
Quoted Message : I‚Äôm thinking of using Rasa only for engineering pieces such as logging. Whereas we rely on langchain and the like for LLM calls and prompt engineering

Message : @91981048xxxx Thanks. Do you use cloud hosted or self-hosted w&b? I guess the personal / free tiers are for non-commercial use, so asking...

Message : We already use Databricks extensively so there's a lot of overlap between what they offer (MLFlow centric) and W&B as well

Message : MLFlow doesn‚Äôt capture 1/10 the info compared to W&B for a training run
Quoted Message : We already use Databricks extensively so there's a lot of overlap between what they offer (MLFlow centric) and W&B as well

Message : If just the parameter, model files, metrics is what you need ML flow is probably the correct fit, but if you want things like gpu/cpu utilisation etc w&b provides that

Message : Yeah, we aren't training LLMs or deep nets from scratch at the moment, so MLFlow suffices for our use cases. That said I see your point. Makes a lot of sense when training something much more involved. Our workflows have shifted to LLM backends almost entirely
Quoted Message : MLFlow doesn‚Äôt capture 1/10 the info compared to W&B for a training run

Message : Integration in databricks is straightforward btw - https://docs.wandb.ai/guides/integrations/databricks

Message : I like W&B Prompts though, seems quite nice.

Message : i personally use self hosted. with some of the NBFC where edgechains is starting to be deployed - it is hosted of course. nobody wants to run infra if they can avoid it.
Quoted Message : @9198xxxxxxxx Thanks. Do you use cloud hosted or self-hosted w&b? I guess the personal / free tiers are for non-commercial use, so asking...

Message : Indeed - even big banks and telcos are cloud users these days anyway and so many use PaaS, very attractive for good reasons despite the expense
Quoted Message : i personally use self hosted. with some of the NBFC where edgechains is starting to be deployed - it is hosted of course. nobody wants to run infra if they can avoid it.

Message : ‚Äé<attached: 00009206-PHOTO-2023-06-19-20-04-03.jpg>

Message : using this extensively right now to debug some perf issues üòÖ

Message : using this extensively right now to debug some perf issues üòÖ

Message : That's really nice. Is there a similar feature in Langchain?

Message : Yes

Message : langchain server comes with tracing

Message : Been a while since I used mlflow (moved to w&b), but I remember being able to fix most of the missing parts by monkey patching the classes. Moved to w&b because didn't wanted to maintain artefacts by myself
Quoted Message : If just the parameter, model files, metrics is what you need ML flow is probably the correct fit, but if you want things like gpu/cpu utilisation etc w&b provides that

Message : Just saw this on hn.

Anyone tried OpenLLM ?

https://github.com/bentoml/OpenLLM

(via https://news.ycombinator.com/item?id=36388219 )

Message : It's an interesting prospect to organise the open sourced LLMs in a single system. But each SoTA model brings something newer with it and the fine-tuning, RL space is especially volatile. 
Most of the support that is in the repo is outdated for my use cases and many popular methods or moduls are also not supported.

But repos like this may become very useful as and when things stabilise a bit.
Quoted Message : Just saw this on hn.\n\nAnyone tried OpenLLM ?\n\nhttps://github.com/bentoml/OpenLLM\n\n(via https://news.ycombinator.com/item?id=36388219 )

Message : Bento has been around in the MLOps space for a while. The OpenLLM capability will really be nice for those building models. Not sure others using commercial APIs will jump on this

Message : OpenLlama vs Falcon. Any opinions here ?

Message : OpenLlama is very good and they've released until 13B parameter versions only but their performance is at parity with Meta's llama release.

There is a bug with the openllm leaderboard which makes llama based models lose 4-6 pts on the leaderboard. Based on that, I'll say OpenLlama is the best option for <13B right now and allows us to create legitimate versions of Vicuna/WizardLM also if we want to try

Message : Unfortunately, they don't seem to be trying to release bigger versions 33B and 65B for now so overall utility remains capped üòî

Message : We may have the llama2 commercial soon, I'm just taking a break from checking new models out and their benchmarks, as everything will reset from there.

Message : ‚Äé<attached: 00009223-PHOTO-2023-06-20-01-44-51.jpg>

Message : He meant this https://arxiv.org/abs/2305.20050 I missed out on it.

Message : Really neat demo !

https://twitter.com/GrantSlatton/status/1670819980105986049

Code not available right now but will be open sourced

Message : Surprised the simple framework mentioned in the abstract wasn't paid attention to (pun intended) before. Quite interesting.
Quoted Message : He meant this https://arxiv.org/abs/2305.20050 I missed out on it.

Message : Zuck will be GOATed
Quoted Message : We may have the llama2 commercial soon, I'm just taking a break from checking new models out and their benchmarks, as everything will reset from there.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Bento has been around in the MLOps space for a while. The OpenLLM capability will really be nice for those building models. Not sure others using commercial APIs will jump on this

Message : OpenLlama vs Falcon. Any opinions here ?

Message : OpenLlama is very good and they've released until 13B parameter versions only but their performance is at parity with Meta's llama release.

There is a bug with the openllm leaderboard which makes llama based models lose 4-6 pts on the leaderboard. Based on that, I'll say OpenLlama is the best option for <13B right now and allows us to create legitimate versions of Vicuna/WizardLM also if we want to try

Message : Unfortunately, they don't seem to be trying to release bigger versions 33B and 65B for now so overall utility remains capped üòî

Message : We may have the llama2 commercial soon, I'm just taking a break from checking new models out and their benchmarks, as everything will reset from there.

Message : ‚Äé<attached: 00009223-PHOTO-2023-06-20-01-44-51.jpg>

Message : He meant this https://arxiv.org/abs/2305.20050 I missed out on it.

Message : Really neat demo !

https://twitter.com/GrantSlatton/status/1670819980105986049

Code not available right now but will be open sourced

Message : Surprised the simple framework mentioned in the abstract wasn't paid attention to (pun intended) before. Quite interesting.
Quoted Message : He meant this https://arxiv.org/abs/2305.20050 I missed out on it.

Message : Zuck will be GOATed
Quoted Message : We may have the llama2 commercial soon, I'm just taking a break from checking new models out and their benchmarks, as everything will reset from there.

Message : https://twitter.com/NirantK/status/1670957393403052032?s=20 - This Saturday, we have GenAI meetup hosting @91970311xxxx and Amod. 
Register here: https://hasgeek.com/generativeAI/june-meetup/

Message : Description says "May meet-up"...
Quoted Message : https://twitter.com/NirantK/status/1670957393403052032?s=20 - This Saturday, we have GenAI meetup hosting @9197xxxxxxxx and Amod. \nRegister here: https://hasgeek.com/generativeAI/june-meetup/

Message : Some edits required I guess.
Cc: @91773788xxxx @91740765xxxx
Quoted Message : Description says \"May meet-up\"...

Message : ‚Äé<attached: 00009234-PHOTO-2023-06-20-11-19-46.jpg>

Message : Can you explain this? Is this specific to code interpretor

Message : Yes, and some specific plugins. 

OpenAI is running some logic which checks if the output got interrupted prematurely, passes that information and continues the in-context generation.
Quoted Message : Can you explain this? Is this specific to code interpretor

Message : Ah yeah. Seen that. For gpt4 
Been trying to figure out this as well
Quoted Message : Yes, and some specific plugins. \n\nOpenAI is running some logic which checks if the output got interrupted prematurely, passes that information and continues the in-context generation.

Message : There's also that "Continue Generating" button which appears for longer answers right?
Quoted Message : Yes, and some specific plugins. \n\nOpenAI is running some logic which checks if the output got interrupted prematurely, passes that information and continues the in-context generation.

Message : Yeah, but the button is almost always jankier. I like it a lot more when it just goes and does the thing in and of itself
Quoted Message : There's also that \"Continue Generating\" button which appears for longer answers right?

Message : Peeps who are intersted in Mechanistic Interpretability might like this conversation: https://twitter.com/MLStreetTalk/status/1670429782616469504

PS: Neel Nanda's blogopsts are also free therapy sessions :p

Message : Doing this in streaming is a challenge so eager to see how they have done it both from AI and software perspective
Quoted Message : Yeah, but the button is almost always jankier. I like it a lot more when it just goes and does the thing in and of itself

Message : Interesting format proposed
Quoted Message : https://twitter.com/NirantK/status/1670957393403052032?s=20 - This Saturday, we have GenAI meetup hosting @9197xxxxxxxx and Amod. \nRegister here: https://hasgeek.com/generativeAI/june-meetup/

Message : There's a tool called Slayer.ai which allows you to generate audio up to five minutes long, using a prompt. This is an example of a "podcast episode" I created with it https://app.slayerai.com/player/3c5983ff-6205-4bef-aaa5-378abd6150c7 - you can choose one of many voices, or a conversational format with 2 voices. The title of the podcast is all I had to provide. As with other generative models, this may suffer from hallucinations and other issues, and the content in it may not be accurate. That said, this was generated in five minutes, and the many YouTube farms which exist for putting content up are only going to benefit from this kind of thing. Worth exploring where the boundaries lie for keeping this kind of tech useful and what can prevent it from being turned into a spam and misinformation machine.

Message : If you've questions for @91970311xxxx or Amod e.g. around AI anxiety, code generation, FOSS vs Closed Source, Hardware optimisation and so on ‚Äî ask! 

@91998208xxxx is the moderator
Quoted Message : Interesting format proposed

Message : Made me think about a number of things here: a) can someone use this to feign subject matter knowledge, b) can this be more useful if I were to supply a transcript to it? c) where do we draw the line in terms of generative AI content for use in public forums, talks, videos, lectures...

Message : cc Samhan @91991655xxxx built https://hackerfm.com/
Quoted Message : Made me think about a number of things here: a) can someone use this to feign subject matter knowledge, b) can this be more useful if I were to supply a transcript to it? c) where do we draw the line in terms of generative AI content for use in public forums, talks, videos, lectures...

Message : Yes but it‚Äôs kind of inactive now. But you can check out the previous episodes

Message : I have thought about this - it‚Äôs actually not easy to make a talk / video that is interesting and engaging. But I do believe it‚Äôs possible to make content that is truly thought provoking.

Message : ‚Äé<attached: 00009249-PHOTO-2023-06-20-14-47-17.jpg>

Message : I‚Äôve tried it.

Message : I think for question generation T5 is better

Message : 7b-instruct was not great with in context learning and ended up repeating things in the prompt even though it was properly instructed. Ended up using Vicu√±a 7B which gave better results.

Message : Falcon 7B instruct base isn't good enough

Message : You need to use Falcon guanaco trained model for 7B or h2o ai trained falcon 7B

Message : https://huggingface.co/h2oai/h2ogpt-gm-oasst1-multilang-2048-falcon-7b

Message : I can't guarantee they will crack your use case perfectly but they're more coherent.

Message : https://huggingface.co/ybelkada/falcon-7b-guanaco-lora

Message : Any 7B model other than MPT 7B chat mostly talks nonsense in various cases. MPT 7B chat can even perform QA given context and thus RAG by extension.

Message : ok thanks guys will try the vicuna and MPT 7B.

Message : Falcon doesnt work with RAG ?
Quoted Message : Any 7B model other than MPT 7B chat mostly talks nonsense in various cases. MPT 7B chat can even perform QA given context and thus RAG by extension.

Message : It works very well actually. And MPT isn't commercially licensed, has worse data, so I wouldn't touch it with a 10 foot pole.
Quoted Message : Falcon doesnt work with RAG ?

Message : As per my tests, Not very well at 7B base or instruct. But instruction tuned falcon 7B by h2o ai or guanaco lora do better.
Quoted Message : Falcon doesnt work with RAG ?

Message : Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style ‚Äî which often makes perf better.

Message : Is there anyone from Adobe here? Esp someone familiar with their document services APIs

Message : Not from Adobe, but I've worked with their WEM platform as a file repository
Quoted Message : Is there anyone from Adobe here? Esp someone familiar with their document services APIs

Message : what do u mean by squad dataset style ?
Quoted Message : Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style ‚Äî which often makes perf better.

Message : Looking at the datasets used and recent papers like orca have highlighted, the need for high quality and diverse data. You have some capital how would you go about organizing this process?
Quoted Message : If you've questions for @9197xxxxxxxx or Amod e.g. around AI anxiety, code generation, FOSS vs Closed Source, Hardware optimisation and so on ‚Äî ask! \n\n@9199xxxxxxxx is the moderator

Message : Yeah 40B is definitely way superior. Actually there's a gulf of quality between the 40B and 7B models.
Quoted Message : Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style ‚Äî which often makes perf better.

Message : SQuAD is basically how we traditionally used to test for QA performance in NLP.
Quoted Message : what do u mean by squad dataset style ?

Message : I believe it means, the finetuning data is in the form of the squad dataset. Squad is an old qa dataset where question context and answer is there
Quoted Message : what do u mean by squad dataset style ?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : It works very well actually. And MPT isn't commercially licensed, has worse data, so I wouldn't touch it with a 10 foot pole.
Quoted Message : Falcon doesnt work with RAG ?

Message : As per my tests, Not very well at 7B base or instruct. But instruction tuned falcon 7B by h2o ai or guanaco lora do better.
Quoted Message : Falcon doesnt work with RAG ?

Message : Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style ‚Äî which often makes perf better.

Message : Is there anyone from Adobe here? Esp someone familiar with their document services APIs

Message : Not from Adobe, but I've worked with their WEM platform as a file repository
Quoted Message : Is there anyone from Adobe here? Esp someone familiar with their document services APIs

Message : what do u mean by squad dataset style ?
Quoted Message : Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style ‚Äî which often makes perf better.

Message : Looking at the datasets used and recent papers like orca have highlighted, the need for high quality and diverse data. You have some capital how would you go about organizing this process?
Quoted Message : If you've questions for @9197xxxxxxxx or Amod e.g. around AI anxiety, code generation, FOSS vs Closed Source, Hardware optimisation and so on ‚Äî ask! \n\n@9199xxxxxxxx is the moderator

Message : Yeah 40B is definitely way superior. Actually there's a gulf of quality between the 40B and 7B models.
Quoted Message : Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style ‚Äî which often makes perf better.

Message : SQuAD is basically how we traditionally used to test for QA performance in NLP.
Quoted Message : what do u mean by squad dataset style ?

Message : I believe it means, the finetuning data is in the form of the squad dataset. Squad is an old qa dataset where question context and answer is there
Quoted Message : what do u mean by squad dataset style ?

Message : sure. but nirant is talking about RAG in the squad style.
Quoted Message : SQuAD is basically how we traditionally used to test for QA performance in NLP.

Message : how do u do RAG with the squad dataset style ?

Message : Rag is basically that but at a higher level.
Quoted Message : sure. but nirant is talking about RAG in the squad style.

Message : If I was to guess, it should mean SQuAD format for QA and additional context for RAG.
Quoted Message : sure. but nirant is talking about RAG in the squad style.

Message : ok. i dont understand what that means. how i (or many people ) use RAG is by stuffing embeddings into context. so i dont understand what using RAG in squad dataset style is

Message : RAG is 

Question:
Context:
Answer from Context:

SQuAD Training is:
Question:
Context:
Answer from Context:

Do you notice the similarity?

Message : so i genuinely dont understand the meaning of word "training" here. are we discussing falcon finetuning ? i didnt know people were doing it. 
if it is pure rag, i get the format. i was not able to understand RAG-finetuning
Quoted Message : RAG is \n\nQuestion: \nContext:\nAnswer from Context:\n\nSQuAD Training is: \nQuestion: \nContext: \nAnswer from Context:\n\nDo you notice the similarity?

Message : Yes, we can finetune Falcon with PEFT
Quoted Message : so i genuinely dont understand the meaning of word \"training\" here. are we discussing falcon finetuning ? i didnt know people were doing it. \nif it is pure rag, i get the format. i was not able to understand RAG-finetuning

Message : PEFT was actually well explained by @91749807xxxx in the meetup
Quoted Message : Yes, we can finetune Falcon with PEFT

Message : interesting. i was NOT aware of this. i thought falcon was not very successful with finetuning. any benchmarks on this ? just checking. playing a lot with falcon these days
Quoted Message : Yes, we can finetune Falcon with PEFT

Message : QLoRA + SFTrainer from TRL fine tuning of Falcon 7B was completed in just 30min on Guanaco dataset with 1x A100 80G GPU.

Message : And it even works with T4 but you'd run out of disk space on free colab. If you've around ~140G disk space, it will take around 3h 45m on T4.

Message : There's no standardisation with fine tuning methods right now so you'll find lightning ai guys using adapter V2 mostly with Lora and some other 4 bit fine tuning methods also exist other than QLora like Falcontune.

Message : I've not tried all but one - QLoRA + SFTrainer

Message : Is Google Colab available or opensource framework for finetuning guidelines
Quoted Message : QLoRA + SFTrainer from TRL fine tuning of Falcon 7B was completed in just 30min on Guanaco dataset with 1x A100 80G GPU.

Message : Falcon has finetuning with PEFT script: https://huggingface.co/blog/falcon#fine-tuning-with-peft
Quoted Message : Is Google Colab available or opensource framework for finetuning guidelines

Message : ElevenLabs ‚Äî which I know lot of projects/startups to be running in production has raised $19M Series A from Gross, a16z:

https://beta.elevenlabs.io/blog/elevenlabs-launches-new-generative-voice-ai-products-and-announces-19m-series-a-round-led-by-nat-friedman-daniel-gross-and-andreessen-horowitz/

Message : https://www.linkedin.com/posts/genai-works_chatgpt-artificialintelligence-activity-7076858659376410624-tVpA?utm_source=share&utm_medium=member_android

Message : Yeah, @9195xxxxxxxx shared this in the morning, I also called it a \"langchain killer\" \n\nhttps://www.linkedin.com/posts/nirant_introducing-azure-openai-service-on-your-activity-7076795328271708161-2178?utm_source=share&utm_medium=member_desktop
Quoted Message : https://www.linkedin.com/posts/genai-works_chatgpt-artificialintelligence-activity-7076858659376410624-tVpA?utm_source=share&utm_medium=member_android

Message : The videos are quite impressive tbh, here is a 59s preview: https://www.youtube.com/watch?v=6SNfeVop4zM

Message : Thought that it was only an infra, they gave a feature to just plug and play it directly. \n\nAm wondering if they will add a feature to connect , confluence, notion etc too
Quoted Message : Yeah, @91955016xxxx shared this in the morning, I also called it a \"langchain killer\" \n\nhttps://www.linkedin.com/posts/nirant_introducing-azure-openai-service-on-your-activity-7076795328271708161-2178?utm_source=share&utm_medium=member_desktop

Message : Yeah, @91955016xxxx shared this in the morning, I also called it a "langchain killer" 

https://www.linkedin.com/posts/nirant_introducing-azure-openai-service-on-your-activity-7076795328271708161-2178?utm_source=share&utm_medium=member_desktop

Message : The videos are quite impressive tbh, here is a 59s preview: https://www.youtube.com/watch?v=6SNfeVop4zM

Message : Thought that it was only an infra, they gave a feature to just plug and play it directly. 

Am wondering if they will add a feature to connect , confluence, notion etc too

Message : Given that it's Microsoft, they'll first build even deeper Microsoft Teams integrations than anything else ü§£
Quoted Message : Thought that it was only an infra, they gave a feature to just plug and play it directly. \n\nAm wondering if they will add a feature to connect , confluence, notion etc too

Message : And they've a Notion alternative of their own

Message : Very interesting. If anyone is interested in building a chatbot that gives you GPT4 interface on your document and have a Telegram bot - voice2voice very quickly they should check jugalbandi.ai 

Upload a document, get a unique ID, access telegram bot accelerator and boom - a chatbot which can do Q&A over a Knowledge Base.
Quoted Message : https://www.linkedin.com/posts/genai-works_chatgpt-artificialintelligence-activity-7076858659376410624-tVpA?utm_source=share&utm_medium=member_android

Message : http://jugalbandi.ai/api

Message : If i am an enterprise trying to build something like this use case ( jira, notion, slack, my drive files, aws files, my proprietary leads, sales data) for internal business teams, this seems way more plug and play & self service compared to running an equally performant app using an open source tool or library.

Plus when back end open ai models improve , all msft openaiservice , get those improvements for "free"

This triggered this q :
1. Is there room for a standalone  streamline like service for gen ai ?

2. If 2 enterprise rivals both use the openai service to build tools like this, how do they differentiate as the backend engine is the same
Quoted Message : Thought that it was only an infra, they gave a feature to just plug and play it directly. \n\nAm wondering if they will add a feature to connect , confluence, notion etc too

Message : Thanks for adding me, Nirant.

Hi everyone,

I was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)
But what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.

Can anyone suggest what I could be missing? or infra upgrade  required?

Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : SageMaker?
Quoted Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : my bad! yes.
Quoted Message : SageMaker?

Message : Better data wins, proprietary data will be king maker in this case
Quoted Message : If i am an enterprise trying to build something like this use case ( jira, notion, slack, my drive files, aws files, my proprietary leads, sales data) for internal business teams, this seems way more plug and play & self service compared to running an equally performant app using an open source tool or library.\n\nPlus when back end open ai models improve , all msft openaiservice , get those improvements for \"free\" \n\nThis triggered this q :\n1. Is there room for a standalone  streamline like service for gen ai ?\n\n2. If 2 enterprise rivals both use the openai service to build tools like this, how do they differentiate as the backend engine is the same

Message : *streamlit like service
Quoted Message : If i am an enterprise trying to build something like this use case ( jira, notion, slack, my drive files, aws files, my proprietary leads, sales data) for internal business teams, this seems way more plug and play & self service compared to running an equally performant app using an open source tool or library.\n\nPlus when back end open ai models improve , all msft openaiservice , get those improvements for \"free\" \n\nThis triggered this q :\n1. Is there room for a standalone  streamline like service for gen ai ?\n\n2. If 2 enterprise rivals both use the openai service to build tools like this, how do they differentiate as the backend engine is the same

Message : Guys has anyone worked on code retrieval tool for an agent. Like agent will get the relevant code from a vector store then it should fetch all the relevant code fragments like headers class def etc. Is there any implementation? Thanks!

Message : This course launched recently https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home - taught by Matei Zaharia (Databricks) among others

Message : sumo

Message : I'm using the exact same GPU and model but interface is databricks. My inference is under 30s for a max of 200 tokens. Happy give your setup a look.
Quoted Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : It's really cool, I had demo with the lead last week. Vector support is coming in July, but when that‚Äôs available and has good perf, it's can be killer for both Langchain and vector dbs. The response time without vector is also impressive right now.
Quoted Message : Yeah, @9195xxxxxxxx shared this in the morning, I also called it a \"langchain killer\" \n\nhttps://www.linkedin.com/posts/nirant_introducing-azure-openai-service-on-your-activity-7076795328271708161-2178?utm_source=share&utm_medium=member_desktop


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : SageMaker?
Quoted Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : my bad! yes.
Quoted Message : SageMaker?

Message : Better data wins, proprietary data will be king maker in this case
Quoted Message : If i am an enterprise trying to build something like this use case ( jira, notion, slack, my drive files, aws files, my proprietary leads, sales data) for internal business teams, this seems way more plug and play & self service compared to running an equally performant app using an open source tool or library.\n\nPlus when back end open ai models improve , all msft openaiservice , get those improvements for \"free\" \n\nThis triggered this q :\n1. Is there room for a standalone  streamline like service for gen ai ?\n\n2. If 2 enterprise rivals both use the openai service to build tools like this, how do they differentiate as the backend engine is the same

Message : *streamlit like service
Quoted Message : If i am an enterprise trying to build something like this use case ( jira, notion, slack, my drive files, aws files, my proprietary leads, sales data) for internal business teams, this seems way more plug and play & self service compared to running an equally performant app using an open source tool or library.\n\nPlus when back end open ai models improve , all msft openaiservice , get those improvements for \"free\" \n\nThis triggered this q :\n1. Is there room for a standalone  streamline like service for gen ai ?\n\n2. If 2 enterprise rivals both use the openai service to build tools like this, how do they differentiate as the backend engine is the same

Message : Guys has anyone worked on code retrieval tool for an agent. Like agent will get the relevant code from a vector store then it should fetch all the relevant code fragments like headers class def etc. Is there any implementation? Thanks!

Message : This course launched recently https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home - taught by Matei Zaharia (Databricks) among others

Message : sumo

Message : I'm using the exact same GPU and model but interface is databricks. My inference is under 30s for a max of 200 tokens. Happy give your setup a look.
Quoted Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : It's really cool, I had demo with the lead last week. Vector support is coming in July, but when that‚Äôs available and has good perf, it's can be killer for both Langchain and vector dbs. The response time without vector is also impressive right now.
Quoted Message : Yeah, @9195xxxxxxxx shared this in the morning, I also called it a \"langchain killer\" \n\nhttps://www.linkedin.com/posts/nirant_introducing-azure-openai-service-on-your-activity-7076795328271708161-2178?utm_source=share&utm_medium=member_desktop

Message : Prob some memory leak
Quoted Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : What does your resource utilization dashboard say?

Message : about the Azure OpenAI service well it is the replit vs enterprise software conversation. it is not unique to generative ai or azure generally speaking. 
for example azure doesnt do prompt routing - switch between gpt 3.5 and 4 based on cost metrics (most common ask ).
it doesnt do caching (second most popular ask for enterprise software when deploying).

I see very different asks and requirements when in the feature requests for edgechains right now - for example data redaction is growing to be number 1. everyone is shit scared of privacy implications.

replit vs enterprise software is a good way to frame it.

Message : Does anyone know what hugging face embeddings do?

Message : I am using instruct from hugging face to generate embeddings and using falcon 7b for query

Message : Am I doing it correctly?

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØArindam Barman

Message : https://twitter.com/soumithchintala/status/1671267150101721090

Is Geohot right about the GPT4 architecture?

Message : ‚Äé<attached: 00009318-PHOTO-2023-06-21-07-16-46.jpg>

Message : Free community bootcamp or a paid event?

Message : Great initiative. 

I would suggest adding a module to show how these different concepts work together to form the stack of a working app.

Something like https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/

but i guess it would be outdated soon, but still worth exploring.

Message : Hi Pratik. There is a free component and a paid component. Most of our course materials we are building would be free, the live classes would be paid.
Quoted Message : Free community bootcamp or a paid event?

Message : Thanks Saurav. One thing about architectures is as you rightly pointed out, things get outdated very quickly. We want to cover more of the foundations and concepts that has more shelf life. For instance, the underlying foundations of LLMs have not changed in years, while a lot of frameworks have arrived. We want to help students focus on the science and practical understanding of it and want to give tools and framerworks as additional reading.
Quoted Message : Great initiative. \n\nI would suggest adding a module to show how these different concepts work together to form the stack of a working app. \n\nSomething like https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/\n\nbut i guess it would be outdated soon, but still worth exploring.

Message : ü§î https://twitter.com/alexgraveley/status/1671213996735594503?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : That title bump must have been worth $100K min? Why is that being rounded to zero?
Quoted Message : ü§î https://twitter.com/alexgraveley/status/1671213996735594503?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : Mostly title bumps are not proportional to level bumps, otherwise he wouldn't bring it up as far as I know him. But then ü§∑‚Äç‚ôÇÔ∏è
Quoted Message : That title bump must have been worth $100K min? Why is that being rounded to zero?

Message : If this is true, then it means OpenAI is running out of ideas. Maybe that's why they have not started GPT-5 training and Sama is going around trying to get regulation in.
Also, it will be hard for them to scale GPT-4 for everyone.

Message : I'll take 4 to 1 odds that Geohot is repeating something he heard from some rumourmill without thinking. 8 MoE and 16 inferences, why?

Message : Frankly, if I was at OpenAI, I'd start 3-4 of such rumours just to see what sticks and for internal lols

Message : If this is true, then it means OpenAI is running out of ideas. Maybe that's why they have not started GPT-5 training and Sama is going around trying to get regulation in.\nAlso, it will be hard for them to scale GPT-4 for everyone.
Quoted Message : https://twitter.com/soumithchintala/status/1671267150101721090\n\nIs Geohot right about the GPT4 architecture?

Message : I'll take 4 to 1 odds that Geohot is repeating something he heard from some rumourmill without thinking. 8 MoE and 16 inferences, why?
Quoted Message : https://twitter.com/soumithchintala/status/1671267150101721090\n\nIs Geohot right about the GPT4 architecture?

Message : Frankly, if I was at OpenAI, I'd start 3-4 of such rumours just to see what sticks and for internal lols

Message : 16 inferences makes sense. That could be the reason why openai dropped `best_of` from the chat completion models - because they‚Äôre already considering 4 candidate completions
Quoted Message : I'll take 4 to 1 odds that Geohot is repeating something he heard from some rumourmill without thinking. 8 MoE and 16 inferences, why?

Message : logits and best_of were dropped to prevent/discourage distillation

Message : How?

Message : I leave Defence Against Dark Arts as an exercise to the reader

Message : Yeah I'm guessing since he's making it public it was probably not worth anything else someone from Github would've called him out from it
Quoted Message : That title bump must have been worth $100K min? Why is that being rounded to zero?

Message : People have been testing GPT4 for almost a year now, and I am surprised how profoundly they are able to keep it secret.

Message : SF rumor mill reports of strict NDAs for anyone leaving.

Message : Friends, we've ~20 slots left in the group. 

Please don't ask admin to add folks. Exceptions: Engineers, data scientists, founders who can and want to contribute to the conversation.

Message : OpenAI has a strong rumour mill game. Look at what they have managed to make it stick. AGI, doomsday scenario etc etc.
Quoted Message : Frankly, if I was at OpenAI, I'd start 3-4 of such rumours just to see what sticks and for internal lols

Message : Making Sam Altman is more dangerous than AGI
Quoted Message : OpenAI has a strong rumour mill game. Look at what they have managed to make it stick. AGI, doomsday scenario etc etc.

Message : Good set of topics. Only suggestion is maybe you could move 8 to 1 or 2. Will make the students appreciate the importance of data much earlier.

Message : https://lu.ma/generativeAIJune - says registration closed

Message : The numbers might be off completely but earlier with GPT3.5, this was like the best guess in the market.

OpenAI's released Instruct GPT in early 2022 and the models were task-wise specialised. So when chatGPT came in Dec, it was worthwhile to guess that there could be a chat layer that breaks down user query to individual tasks and then take a MoE (mixture of experts) approach to execute those tasks and present the final answer.
It also made sense to assume that the jump in architecture in GPT3.5 wouldn't be too much from instruct-GPT.

However with GPT4, I can't say the same, it looks like a different beast. It's much smarter in many ways and hard to tell without experience if it's just MoE with a chat layer.
Quoted Message : https://twitter.com/soumithchintala/status/1671267150101721090\n\nIs Geohot right about the GPT4 architecture?

Message : This is happening too fast. 1.3B parameter code model, phi-1, hitting 50%+ on Human eval, trained for 4 day on 8 A100s. https://twitter.com/_akhaliq/status/1671360619986010112

Message : For wider audience, HumanEval is a dataset, which is part of most training paradigms and not actually Human eval.
Quoted Message : This is happening too fast. 1.3B parameter code model, phi-1, hitting 50%+ on Human eval, trained for 4 day on 8 A100s. https://twitter.com/_akhaliq/status/1671360619986010112

Message : üôè I missing out additional details in excitement. That's like <1K$ on LambdaLab for training. ü§Ø
Quoted Message : For wider audience, HumanEval is a dataset, which is part of most training paradigms and not actually Human eval.

Message : this message has been deleted

Message : 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 2023_06_21_091405_3EB033B84CC2D7F09A5738.jpeg
Quoted Message : üôè I missing out additional details in excitement. That's like <1K$ on LambdaLab for training. ü§Ø


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : OpenAI has a strong rumour mill game. Look at what they have managed to make it stick. AGI, doomsday scenario etc etc.
Quoted Message : Frankly, if I was at OpenAI, I'd start 3-4 of such rumours just to see what sticks and for internal lols

Message : Making Sam Altman is more dangerous than AGI
Quoted Message : OpenAI has a strong rumour mill game. Look at what they have managed to make it stick. AGI, doomsday scenario etc etc.

Message : Good set of topics. Only suggestion is maybe you could move 8 to 1 or 2. Will make the students appreciate the importance of data much earlier.

Message : https://lu.ma/generativeAIJune - says registration closed

Message : The numbers might be off completely but earlier with GPT3.5, this was like the best guess in the market.

OpenAI's released Instruct GPT in early 2022 and the models were task-wise specialised. So when chatGPT came in Dec, it was worthwhile to guess that there could be a chat layer that breaks down user query to individual tasks and then take a MoE (mixture of experts) approach to execute those tasks and present the final answer.
It also made sense to assume that the jump in architecture in GPT3.5 wouldn't be too much from instruct-GPT.

However with GPT4, I can't say the same, it looks like a different beast. It's much smarter in many ways and hard to tell without experience if it's just MoE with a chat layer.
Quoted Message : https://twitter.com/soumithchintala/status/1671267150101721090\n\nIs Geohot right about the GPT4 architecture?

Message : This is happening too fast. 1.3B parameter code model, phi-1, hitting 50%+ on Human eval, trained for 4 day on 8 A100s. https://twitter.com/_akhaliq/status/1671360619986010112

Message : For wider audience, HumanEval is a dataset, which is part of most training paradigms and not actually Human eval.
Quoted Message : This is happening too fast. 1.3B parameter code model, phi-1, hitting 50%+ on Human eval, trained for 4 day on 8 A100s. https://twitter.com/_akhaliq/status/1671360619986010112

Message : üôè I missing out additional details in excitement. That's like <1K$ on LambdaLab for training. ü§Ø
Quoted Message : For wider audience, HumanEval is a dataset, which is part of most training paradigms and not actually Human eval.

Message : this message has been deleted

Message : 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 2023_06_21_091405_3EB033B84CC2D7F09A5738.jpeg
Quoted Message : üôè I missing out additional details in excitement. That's like <1K$ on LambdaLab for training. ü§Ø

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØSaiyam

Message : This is happening too fast. 1.3B parameter code model, phi-1, hitting 50%+ on Human eval, trained for 4 day on 8 A100s. https://twitter.com/_akhaliq/status/1671360619986010112

Message : For wider audience, HumanEval is a dataset, which is part of most training paradigms and not actually Human eval.

Message : üôè I missing out additional details in excitement. That's like <1K$ on LambdaLab for training. ü§Ø

Message : I have a question pertaining to http://jugalbandi.ai and elevenlabs alike. Basically I couldn't find anything which does decent TTS with custom voice cloning. I understand there are legal ramifications to it but I need it for a very legal and useful usecase. Are you guys familiar with something? The closest thing I could find was a fork of suno.ai which works worse than elevenlabs voice cloning.

Message : Tortoise is FOSS and competitive to ElevenLabs for Western accents\nhttps://github.com/neonbjb/tortoise-tts
Quoted Message : I have a question pertaining to http://jugalbandi.ai and elevenlabs alike. Basically I couldn't find anything which does decent TTS with custom voice cloning. I understand there are legal ramifications to it but I need it for a very legal and useful usecase. Are you guys familiar with something? The closest thing I could find was a fork of suno.ai which works worse than elevenlabs voice cloning.

Message : Thanks Nirant. I tried this too. I need it for Indian accents. Fails terribly and just ingests 5 seconds of audio.
Quoted Message : Tortoise is FOSS and competitive to ElevenLabs for Western accents\nhttps://github.com/neonbjb/tortoise-tts

Message : This paper and repofusion are definitely 2 really interesting picks of the day for me as smaller models achieving performance parity with models 70x their size\n\nRepofusion - https://twitter.com/arankomatsuzaki/status/1671345186536816643?t=gKOzHVpoZzbQjSjrcCYQTQ&s=19

Message : ‚Äé~‚ÄØSaiyam was added

Message : ‚Äé<attached: 00009348-PHOTO-2023-06-21-09-14-05.jpg>

Message : I have a question pertaining to http://jugalbandi.ai and elevenlabs alike. Basically I couldn't find anything which does decent TTS with custom voice cloning. I understand there are legal ramifications to it but I need it for a very legal and useful usecase. Are you guys familiar with something? The closest thing I could find was a fork of suno.ai which works worse than elevenlabs voice cloning.

Message : Tortoise is FOSS and competitive to ElevenLabs for Western accents
https://github.com/neonbjb/tortoise-tts

Message : Thanks Nirant. I tried this too. I need it for Indian accents. Fails terribly and just ingests 5 seconds of audio.

Message : This paper and repofusion are definitely 2 really interesting picks of the day for me as smaller models achieving performance parity with models 70x their size

Repofusion - https://twitter.com/arankomatsuzaki/status/1671345186536816643?t=gKOzHVpoZzbQjSjrcCYQTQ&s=19

Message : Models like these along with gglm and quantization are opening up so many possibilities for local inference. I earlier thought it will take couple of years for inference to come native on mobile level silicon, but it is happening so fast.

Message : Yes, inference on edge is totally happening by end of 2023 in commercial capacity ü§û
Quoted Message : Models like these along with gglm and quantization are opening up so many possibilities for local inference. I earlier thought it will take couple of years for inference to come native on mobile level silicon, but it is happening so fast.

Message : I am very skeptically of believing these results. More often than not, they've some data leak or distillation of some other sort going on. Or overfit to a specific task/dataset, not even domain.
Quoted Message : This paper and repofusion are definitely 2 really interesting picks of the day for me as smaller models achieving performance parity with models 70x their size\n\nRepofusion - https://twitter.com/arankomatsuzaki/status/1671345186536816643?t=gKOzHVpoZzbQjSjrcCYQTQ&s=19

Message : *these => 20-30x smaller models, trained from scratch, no arch change kinda ideas

Message : True, that chance is there.
Quoted Message : I am very skeptically of believing these results. More often than not, they've some data leak or distillation of some other sort going on. Or overfit to a specific task/dataset, not even domain.

Message : Took me 10s to find the trick: 

Experiments on *single-line code completion* show that our models trained with *repository context* significantly outperform ...

Message : phi-1 is from Microsoft Research, so hope they are not bluffing.

Message : It's single line code completion, unlike what StarCoder or CodeGen does ‚Äî and is specific to a repo

Message : And the entire test eval is 200 Java repositories ü§¶üèæ‚Äç‚ôÇÔ∏è

Message : I thought they have -https://techcommunity.microsoft.com/t5/integrations-on-azure-blog/integrate-azure-open-ai-in-teams-channel-via-logic-app/ba-p/3776048
Quoted Message : Given that it's Microsoft, they'll first build even deeper Microsoft Teams integrations than anything else ü§£

Message : Are there standard benchmarks to evaluate these models apples-apples? I see each one claiming they are better in some way, but by cherry-picking one evaluation method that they themselves created. ‚Äé<This message was edited>

Message : Highest trust at the moment: 

Open LLM Leaderboard: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
Quoted Message : Are there standard benchmarks to evaluate these models apples-apples? I see each one claiming they are better in some way, but by cherry-picking one evaluation method that they themselves created.

Message : OpenAI Evals is pretty good too, but not trusted for obvious reasons

Message : I track the leaderboards, but they are more through ELO ratings with head-head evaluations than by one standard benchmark applied equally across all of them.
Quoted Message : Highest trust at the moment: \n\nOpen LLM Leaderboard: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard

Message : I take back. I see that they have added more benchmarks now.

Message : I'm confused. Open LLM Leaderboard does not have any ELO or head on comparisons

Message : I'm talking about the Human&GPT evaluations tab.
Quoted Message : I'm confused. Open LLM Leaderboard does not have any ELO or head on comparisons

Message : I'm talking about the Human&GPT evaluations tab.

Message : ‚Äé<attached: 00009371-PHOTO-2023-06-21-09-40-46.jpg>

Message : sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.
Quoted Message : If this is true, then it means OpenAI is running out of ideas. Maybe that's why they have not started GPT-5 training and Sama is going around trying to get regulation in.\nAlso, it will be hard for them to scale GPT-4 for everyone.

Message : Yes, I believe high quality data is going to be the key, and also a big opportunity for tech startups.

Message : and reduce cost of training and inference to enable smaller players to compete with the likes of OpenAI, google, Microsoft
Quoted Message : Yes, I believe high quality data is going to be the key, and also a big opportunity for tech startups.

Message : Without sacrificing performance
Quoted Message : and reduce cost of training and inference to enable smaller players to compete with the likes of OpenAI, google, Microsoft

Message : Scaling can take us far and can result in a lot more emergent properties. There is no evidence against the contrary. However it doesn't make business sense to serve a slower beast.
Quoted Message : sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.

Message : Seems parameter scaling works but data scaling laws are broken and at the least misguiding.

Message : From what I have read, Sam has said the opposite of "he also said scaling still works" publicly.

"I think we're at the end of the era where it's going to be these, like, giant, giant models,‚Äù he told an audience at an event held at MIT late last week. ‚ÄúWe'll make them better in other ways.‚Äù [...]

Keys is "make them better in other ways"

https://www.lesswrong.com/posts/ndzqjR8z8X99TEa4E/sama-says-the-age-of-giant-ai-models-is-already-over
Quoted Message : sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I'm talking about the Human&GPT evaluations tab.
Quoted Message : I'm confused. Open LLM Leaderboard does not have any ELO or head on comparisons

Message : I'm talking about the Human&GPT evaluations tab.

Message : ‚Äé<attached: 00009371-PHOTO-2023-06-21-09-40-46.jpg>

Message : sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.
Quoted Message : If this is true, then it means OpenAI is running out of ideas. Maybe that's why they have not started GPT-5 training and Sama is going around trying to get regulation in.\nAlso, it will be hard for them to scale GPT-4 for everyone.

Message : Yes, I believe high quality data is going to be the key, and also a big opportunity for tech startups.

Message : and reduce cost of training and inference to enable smaller players to compete with the likes of OpenAI, google, Microsoft
Quoted Message : Yes, I believe high quality data is going to be the key, and also a big opportunity for tech startups.

Message : Without sacrificing performance
Quoted Message : and reduce cost of training and inference to enable smaller players to compete with the likes of OpenAI, google, Microsoft

Message : Scaling can take us far and can result in a lot more emergent properties. There is no evidence against the contrary. However it doesn't make business sense to serve a slower beast.
Quoted Message : sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.

Message : Seems parameter scaling works but data scaling laws are broken and at the least misguiding.

Message : From what I have read, Sam has said the opposite of "he also said scaling still works" publicly.

"I think we're at the end of the era where it's going to be these, like, giant, giant models,‚Äù he told an audience at an event held at MIT late last week. ‚ÄúWe'll make them better in other ways.‚Äù [...]

Keys is "make them better in other ways"

https://www.lesswrong.com/posts/ndzqjR8z8X99TEa4E/sama-says-the-age-of-giant-ai-models-is-already-over
Quoted Message : sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.

Message : What are your thoughts on Yanns proposed JEPA - https://youtu.be/OKkEdTchsiE
Quoted Message : From what I have read, Sam has said the opposite of \"he also said scaling still works\" publicly.\n\n\"I think we're at the end of the era where it's going to be these, like, giant, giant models,‚Äù he told an audience at an event held at MIT late last week. ‚ÄúWe'll make them better in other ways.‚Äù [...]\n\nKeys is \"make them better in other ways\"\n\nhttps://www.lesswrong.com/posts/ndzqjR8z8X99TEa4E/sama-says-the-age-of-giant-ai-models-is-already-over

Message : What is your guess on the other top 3 ways?
Quoted Message : From what I have read, Sam has said the opposite of \"he also said scaling still works\" publicly.\n\n\"I think we're at the end of the era where it's going to be these, like, giant, giant models,‚Äù he told an audience at an event held at MIT late last week. ‚ÄúWe'll make them better in other ways.‚Äù [...]\n\nKeys is \"make them better in other ways\"\n\nhttps://www.lesswrong.com/posts/ndzqjR8z8X99TEa4E/sama-says-the-age-of-giant-ai-models-is-already-over

Message : Bigger context, low bit lossless inference, task-based specialisations

Message : Does the first 2 guarantee higher performance for usual text length gen? The last sounds like downstream task based finetuning unless you are referring to training different expert models (although I don‚Äôt understand clearly how do you decide expertise per model for training and routing for inference to these experts(maybe a classifier) or do you just merge all models weights by averaging?)

Message : Wikipedia search using the KE Sieve model. 36 million passages embedded. Small model index embedding size(544 dimensions) 2.3 GB. Large model index embedding size(2224 dimensions)-10GB.
https://speech-kws.ozonetel.com/wiki
We created an embedding space based on mpnet sentence transformer. So this can work as drop in replacement for those embeddings. Cost savings of around 10 times. Some details here, https://gpt3experiments.substack.com/p/building-a-vector-database-in-2gb

Message : Project idea: semantic search on quotes 

I was surprised I wasn‚Äôt able to find a good one yesterday

Was trying to find what plato said about growth mindset

Message : Isn‚Äôt google supposed to do this?
Quoted Message : Project idea: semantic search on quotes \n\nI was surprised I wasn‚Äôt able to find a good one yesterday\n\nWas trying to find what plato said about growth mindset

Message : There's some drop in quality of inference currently for first 2 but that will be one of the ongoing areas of research with improvements like RMT/Longformer. For the third one, we already have routing functions/gating networks approach to first route the subtask to an expert then mix results together (haven't read how they mix it up finally).
Quoted Message : Does the first 2 guarantee higher performance for usual text length gen? The last sounds like downstream task based finetuning unless you are referring to training different expert models (although I don‚Äôt understand clearly how do you decide expertise per model for training and routing for inference to these experts(maybe a classifier) or do you just merge all models weights by averaging?)

Message : It‚Äôs working a bit when you just check the images as google must have indexed emb of text found in image

https://www.google.com/search?rlz=1CDGOYI_enIN867IN867&hl=en-GB&sxsrf=APwXEddFckbkv58OyEaazXJYNgynUe3uBg:1687322990924&q=plato+quotes+on+growth+mindset&tbm=isch&sa=X&ved=2ahUKEwiH8vr7x9P_AhWxwzgGHQgEDlQQ0pQJegQIExAB&biw=428&bih=751&dpr=3

Message : Bard does it pretty well. Bard is good with literature and quote and literature knowledge in general
Quoted Message : Project idea: semantic search on quotes \n\nI was surprised I wasn‚Äôt able to find a good one yesterday\n\nWas trying to find what plato said about growth mindset

Message : Haven't read the I-JEPA paper yet, it's a completely different approach than LLMs

https://arxiv.org/abs/2301.08243

https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/

"At the same time, by predicting representations at a high level of abstraction rather than predicting pixel values directly, the hope is to learn directly useful representations that also avoid the limitations of generative approaches, which underlie the large language models that have generated so much recent excitement.

In contrast, generative architectures learn by removing or distorting portions of the input to the model ‚Äì for example, erasing part of a photo or hiding some of the words in a text passage. They then try to predict the corrupted or missing pixels or words. One significant shortcoming of generative methods, however, is that the model tries to fill-in every bit of missing information, even though the world is inherently unpredictable. As a result, generative methods may be prone to mistakes a person would never make because they focus too much on irrelevant details instead of capturing high-level predictable concepts. For example, it is notoriously difficult for generative models to generate human hands accurately. (They often add extra digits or make other glaring errors.)"


My rough sense is for vision, I-JEPA looks promising but LLMs will rule the roost for nlp stuff
Quoted Message : What are your thoughts on Yanns proposed JEPA - https://youtu.be/OKkEdTchsiE

Message : Thanks. I‚Äôll try
Quoted Message : Bard does it pretty well. Bard is good with literature and quote and literature knowledge in general

Message : Nah, it wasnt doing it

I‚Äôm sure the project exists somewhere
Quoted Message : Isn‚Äôt google supposed to do this?

Message : Nothing is there for Indian accent voice cloning, yet. May be after Meta releases Voicebox weights, there is a possibility.
Quoted Message : Thanks Nirant. I tried this too. I need it for Indian accents. Fails terribly and just ingests 5 seconds of audio.

Message : Thanks Prateek. I will look up what's voicebox is.
Quoted Message : Nothing is there for Indian accent voice cloning, yet. May be after Meta releases Voicebox weights, there is a possibility.

Message : https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/
Quoted Message : Thanks Prateek. I will look up what's voicebox is.

Message : We trained Voicebox with more than 50,000 hours of recorded speech and transcripts from public domain audiobooks in English, French, Spanish, German, Polish, and Portuguese. 
No mention of Hindi or Indian languages. Probably might fail.
Quoted Message : https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/

Message : AI4Bharat has good Indian language corpus. https://ai4bharat.iitm.ac.in/datasets
Quoted Message : We trained Voicebox with more than 50,000 hours of recorded speech and transcripts from public domain audiobooks in English, French, Spanish, German, Polish, and Portuguese. \nNo mention of Hindi or Indian languages. Probably might fail.

Message : Yea meta one is cool but Hindi support not there 

Earlier in the group there were discussions on vakyansh for Hindi. Haven‚Äôt had time to personally try


np , just saw vakyansh has TTS too . https://github.com/Open-Speech-EkStep/vakyansh-tts
Quoted Message : Thanks Prateek. I will look up what's voicebox is.

Message : They also have model endpoints for speech2text, translation and text2speech in Indian languages. Mostly works well, barring some translation issues here and there.

Message : https://github.com/OpenNyAI/jugalbandi-api/blob/main/translator.py 

Here we have written some code to use the AI4Bharat model endpoints for consumption in applications. Works with at least 10 Indian languages including Hindi.

Message : Is gpt-4 just an agent over several gpt-3.5 models? üòú
Quoted Message : Does the first 2 guarantee higher performance for usual text length gen? The last sounds like downstream task based finetuning unless you are referring to training different expert models (although I don‚Äôt understand clearly how do you decide expertise per model for training and routing for inference to these experts(maybe a classifier) or do you just merge all models weights by averaging?)

Message : (1) Let's see if they release weights
(2) If fine tuning is possible, AI4Bharat corpus can be used
Quoted Message : We trained Voicebox with more than 50,000 hours of recorded speech and transcripts from public domain audiobooks in English, French, Spanish, German, Polish, and Portuguese. \nNo mention of Hindi or Indian languages. Probably might fail.

Message : But custom voice cloning is there?
Quoted Message : They also have model endpoints for speech2text, translation and text2speech in Indian languages. Mostly works well, barring some translation issues here and there.

Message : Yeah. Perfect
Quoted Message : (1) Let's see if they release weights\n(2) If fine tuning is possible, AI4Bharat corpus can be used

Message : I have used those models, but have been complaining about production readiness for self-hosting.
Quoted Message : They also have model endpoints for speech2text, translation and text2speech in Indian languages. Mostly works well, barring some translation issues here and there.

Message : Oh it has become quite stable now.
Quoted Message : I have used those models, but have been complaining about production readiness for self-hosting.

Message : They are burning significant amount of GPU and have clusters of it

Message : I think this is possible üòÖ
Could it also be possible that it is agent over Code Interpreter too internally ?

In a recent project I was using GPT-4 for unstructured document parsing and getting output in json

Sometimes instead of json it started giving Python code as output

The logic of the python code was created to follow the parsing instructions given in the prompt

I was not able to get the same output again on multiple runs on the same prompt afterwards ü§∑üèª‚Äç‚ôÇÔ∏è
Quoted Message : Is gpt-4 just an agent over several gpt-3.5 models? üòú

Message : This was either a top quality hallucination or an internal step which was given as output
Quoted Message : I think this is possible üòÖ\nCould it also be possible that it is agent over Code Interpreter too internally ?\n\nIn a recent project I was using GPT-4 for unstructured document parsing and getting output in json \n\nSometimes instead of json it started giving Python code as output \n\nThe logic of the python code was created to follow the parsing instructions given in the prompt\n\nI was not able to get the same output again on multiple runs on the same prompt afterwards ü§∑üèª‚Äç‚ôÇÔ∏è

Message : As someone said (in this group) GPT4 works in mysterious ways üòÖ
Quoted Message : I think this is possible üòÖ\nCould it also be possible that it is agent over Code Interpreter too internally ?\n\nIn a recent project I was using GPT-4 for unstructured document parsing and getting output in json \n\nSometimes instead of json it started giving Python code as output \n\nThe logic of the python code was created to follow the parsing instructions given in the prompt\n\nI was not able to get the same output again on multiple runs on the same prompt afterwards ü§∑üèª‚Äç‚ôÇÔ∏è

Message : [Need help] Have a silly problem that our company's access to GPT4 APIs hasn;t come through. We have applied many times on the website with logical explanation that many things only work on GPT4 but silence .... has anyone else experienced it? Any workarounds or help to get the API access. (yes I have GPT subscription also). We were about to release a product and now this silly issue

Message : I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story
Quoted Message : Is gpt-4 just an agent over several gpt-3.5 models? üòú

Message : Can you link to google style MoE, for a better understanding  of how it actually works
Quoted Message : I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story

Message : https://paperswithcode.com/method/switch-transformer
Quoted Message : Can you link to google style MoE, for a better understanding  of how it actually works

Message : There is also TaskMoE, which is a distillation mechanism
https://arxiv.org/pdf/2110.03742.pdf

Message : Blog: https://ai.googleblog.com/2022/01/learning-to-route-by-task-for-efficient.html

Message : ‚Äé<attached: 00009416-PHOTO-2023-06-21-11-44-15.jpg>
Quoted Message : I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story

Message : This sounds like ensemble rather than Switch MoE

Message : So it is an agent over several 3.5 models. Then GPT-5 will be an agent over an agent. AI bureaucracy
Quoted Message : This sounds like ensemble rather than Switch MoE


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : As someone said (in this group) GPT4 works in mysterious ways üòÖ
Quoted Message : I think this is possible üòÖ\nCould it also be possible that it is agent over Code Interpreter too internally ?\n\nIn a recent project I was using GPT-4 for unstructured document parsing and getting output in json \n\nSometimes instead of json it started giving Python code as output \n\nThe logic of the python code was created to follow the parsing instructions given in the prompt\n\nI was not able to get the same output again on multiple runs on the same prompt afterwards ü§∑üèª‚Äç‚ôÇÔ∏è

Message : [Need help] Have a silly problem that our company's access to GPT4 APIs hasn;t come through. We have applied many times on the website with logical explanation that many things only work on GPT4 but silence .... has anyone else experienced it? Any workarounds or help to get the API access. (yes I have GPT subscription also). We were about to release a product and now this silly issue

Message : I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story
Quoted Message : Is gpt-4 just an agent over several gpt-3.5 models? üòú

Message : Can you link to google style MoE, for a better understanding  of how it actually works
Quoted Message : I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story

Message : https://paperswithcode.com/method/switch-transformer
Quoted Message : Can you link to google style MoE, for a better understanding  of how it actually works

Message : There is also TaskMoE, which is a distillation mechanism
https://arxiv.org/pdf/2110.03742.pdf

Message : Blog: https://ai.googleblog.com/2022/01/learning-to-route-by-task-for-efficient.html

Message : ‚Äé<attached: 00009416-PHOTO-2023-06-21-11-44-15.jpg>
Quoted Message : I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story

Message : This sounds like ensemble rather than Switch MoE

Message : So it is an agent over several 3.5 models. Then GPT-5 will be an agent over an agent. AI bureaucracy
Quoted Message : This sounds like ensemble rather than Switch MoE

Message : GPT-4 is a kaggler
Quoted Message : This sounds like ensemble rather than Switch MoE

Message : @91773788xxxx has asked me to remove this post. Will be doing it in five. If anyone else had a viewpoint to share in this time on posts related to hackathons and meet-ups and where they should go, happy to hear and learn.

Message : One of the ongoing efforts to release 1000hrs of parallel speech to text corpora in 9 Indian languages spanning 38 dialects

https://respin.iisc.ac.in/datasets

Message : Similarly for text to speech in Indian languages
https://syspin.iisc.ac.in/api/v1//Home

Message : Any link to models for these too?
Quoted Message : One of the ongoing efforts to release 1000hrs of parallel speech to text corpora in 9 Indian languages spanning 38 dialects\n\nhttps://respin.iisc.ac.in/datasets

Message : Not yet, but the plan is to publish datasets along with models
Quoted Message : Any link to models for these too?

Message : Whisper models?

Message : I see 2 languages so far. Which others are being worked on ? Is there a way to contribute ?
Quoted Message : One of the ongoing efforts to release 1000hrs of parallel speech to text corpora in 9 Indian languages spanning 38 dialects\n\nhttps://respin.iisc.ac.in/datasets

Message : Language info provided the website  Access to the couple of languages now available through ASRU challenge this year
https://sites.google.com/view/respinasrchallenge2023/home

Message : I see.

Message : Anyone here using WIT to convert user intents into actions for your products?

Message : what is WIT ?
Quoted Message : Anyone here using WIT to convert user intents into actions for your products?

Message : An older Meta AI product that‚Äôs used to understand user intent and convert to actions. Like a basic version of OpenAI functions.

Message : https://wit.ai/

Message : Ohh! Old memories from 2016
Quoted Message : https://wit.ai/

Message : More like nightmares ü§£

Things used to break and the business counterpart would ask "how to fix?" and senior engineers would go "ask Wit.ai" ü§£
Quoted Message : Ohh! Old memories from 2016

Message : https://arxiv.org/pdf/2306.11644.pdf "Textbooks are all you need" - a small model trained on high quality "textbook quality" data

Message : https://www.linkedin.com/posts/metaai_cvpr2023-activity-7076997142204055552-TCIC?utm_source=share&utm_medium=member_android

Message : https://www.linkedin.com/posts/metaai_cvpr2023-activity-7076997142204055552-TCIC?utm_source=share&utm_medium=member_android

Message : ‚Äé<attached: 00009438-PHOTO-2023-06-21-15-02-50.jpg>

Message : Synthesia just raised 90 million for this.
Not sure what future dynamics would look like

Message : Is this similar to how gan.ai trains their model based on a 2minute user video

Message : I use them fairly regularly. Even outside of AI voiceover, their feature set is pretty robust. And the interface is super intuitive and easy to use.
Quoted Message : Synthesia just raised 90 million for this.\nNot sure what future dynamics would look like

Message : is it possible to share a private huggingface space as a demo externally, without exposing the code? Basically, I want to use huggingface hardware instead of self-hosting the gradio/streamlit app

Message : There's a clumsy way I'm aware of. Possibly others know better.

Private spaces belonging to an organisation are visible to members of the organisation only. So you can invite somebody as a collaborator on the organisation and get them to test or use your setup.

Message : yeah I'm thinking of rolling it out publicly

Message : There are ways you can hide your creds, if that's your main concern
Quoted Message : is it possible to share a private huggingface space as a demo externally, without exposing the code? Basically, I want to use huggingface hardware instead of self-hosting the gradio/streamlit app

Message : not just the creds. there's secrets in HF for that. Asking for keeping the code private

Message : There's a workaround - you keep the confidential code in a private repo on git. Then you import the code using your GitHub personal access token which can be kept in hugging face secrets

A link that discusses something similar - https://discuss.huggingface.co/t/share-app-url-without-sharing-the-files-and-version/26182
Quoted Message : not just the creds. there's secrets in HF for that. Asking for keeping the code private

Message : https://twitter.com/MetaAI/status/1671211532599046144?t=IzhQ0OA72FgEadVfRvhx2g&s=19

6 papers by meta for CVPR23.

Message : 11labs works fine for Indian accents. What issues are you facing?
Quoted Message : I have a question pertaining to http://jugalbandi.ai and elevenlabs alike. Basically I couldn't find anything which does decent TTS with custom voice cloning. I understand there are legal ramifications to it but I need it for a very legal and useful usecase. Are you guys familiar with something? The closest thing I could find was a fork of suno.ai which works worse than elevenlabs voice cloning.

Message : Well, I'll dm you. Long discussion. Thanks for the info tho.
Quoted Message : 11labs works fine for Indian accents. What issues are you facing?

Message : Sure

Message : I am building a binary classifier and utilizing the Roberta base model. Interestingly, I have observed instability in its performance when it comes to punctuation marks. The addition of a simple full stop or even special characters seems to alter the predicted labels.

Any advice ?

Message : Is the openai function based on a paper? How to do it for an open model?

Message : Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it

https://tammy.ai/summary/cNfINi5CNbY - 2hr Google I/O 23 summarized into neat bullet points :)

Message : Interesting but might just be a feature on YouTube's roadmap
Quoted Message : Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it\n\nhttps://tammy.ai/summary/cNfINi5CNbY - 2hr Google I/O 23 summarized into neat bullet points :)

Message : In most cases, I've seen that these YouTube summary extensions or apps support limited videos. Does this support every video?
Quoted Message : Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it\n\nhttps://tammy.ai/summary/cNfINi5CNbY - 2hr Google I/O 23 summarized into neat bullet points :)

Message : mistral ai memo.pdf ‚Ä¢ ‚Äé7 pages ‚Äé<attached: 00009457-mistral ai memo.pdf>

Message : Mistral raised its round just days after hiring staff using a Google Doc memo. Here is the doc

No deck. just a 7 pager Memo.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : 11labs works fine for Indian accents. What issues are you facing?
Quoted Message : I have a question pertaining to http://jugalbandi.ai and elevenlabs alike. Basically I couldn't find anything which does decent TTS with custom voice cloning. I understand there are legal ramifications to it but I need it for a very legal and useful usecase. Are you guys familiar with something? The closest thing I could find was a fork of suno.ai which works worse than elevenlabs voice cloning.

Message : Well, I'll dm you. Long discussion. Thanks for the info tho.
Quoted Message : 11labs works fine for Indian accents. What issues are you facing?

Message : Sure

Message : I am building a binary classifier and utilizing the Roberta base model. Interestingly, I have observed instability in its performance when it comes to punctuation marks. The addition of a simple full stop or even special characters seems to alter the predicted labels.

Any advice ?

Message : Is the openai function based on a paper? How to do it for an open model?

Message : Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it

https://tammy.ai/summary/cNfINi5CNbY - 2hr Google I/O 23 summarized into neat bullet points :)

Message : Interesting but might just be a feature on YouTube's roadmap
Quoted Message : Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it\n\nhttps://tammy.ai/summary/cNfINi5CNbY - 2hr Google I/O 23 summarized into neat bullet points :)

Message : In most cases, I've seen that these YouTube summary extensions or apps support limited videos. Does this support every video?
Quoted Message : Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it\n\nhttps://tammy.ai/summary/cNfINi5CNbY - 2hr Google I/O 23 summarized into neat bullet points :)

Message : mistral ai memo.pdf ‚Ä¢ ‚Äé7 pages ‚Äé<attached: 00009457-mistral ai memo.pdf>

Message : Mistral raised its round just days after hiring staff using a Google Doc memo. Here is the doc

No deck. just a 7 pager Memo.

Message : Most of it theory yet the team is great

Message : They are all big names in the founding team - deepmind, llama architect, etc

With pedigree like that and the current craze around gen ai, not that surprising
Quoted Message : Mistral raised its round just days after hiring staff using a Google Doc memo. Here is the doc\n\nNo deck. just a 7 pager Memo.

Message : "At the end of 2023, we will train a family of text-generating models that can beat ChatGPT 3.5 and Bard March 2023 by a large margin, as well as all open source solutions.
Part of this family will be open-sourced; we will engage the community to build on top of it and make it the open standard.
We will service those models with the same endpoints as our competitor for a fee to acquire third-party usage data, and create a few free consumer interfaces for trademark construction and first-party usage data."

Only time will tell but exciting times for sure !

Message : Langchain does similar functionality using React
Quoted Message : Is the openai function based on a paper? How to do it for an open model?

Message : i asked the same question today. i think all base models will need to put this feature as tablestakes. the usability advantage is too high.
Quoted Message : Is the openai function based on a paper? How to do it for an open model?

Message : nope. openai functions magic is not function invocation - it is formatting the JSON to match the function signature. it is insanely hard to do this without the new release of openai. we have all struggled with jsonformer etc to match function signatures and it mismatches very frequently
Quoted Message : Langchain does similar functionality using React

Message : Have you tried this with gpt4? The non function model?
Quoted Message : nope. openai functions magic is not function invocation - it is formatting the JSON to match the function signature. it is insanely hard to do this without the new release of openai. we have all struggled with jsonformer etc to match function signatures and it mismatches very frequently

Message : How consistent is the output json using functions? I was reading somewhere that it still hallucinates
Quoted Message : nope. openai functions magic is not function invocation - it is formatting the JSON to match the function signature. it is insanely hard to do this without the new release of openai. we have all struggled with jsonformer etc to match function signatures and it mismatches very frequently

Message : Yeah these kinda stuff happens a lot. We don‚Äôt rely on a single model for classification. Ensemble your way to glory.
Quoted Message : I am building a binary classifier and utilizing the Roberta base model. Interestingly, I have observed instability in its performance when it comes to punctuation marks. The addition of a simple full stop or even special characters seems to alter the predicted labels.\n\nAny advice ?

Message : not sure, need to explore more
Quoted Message : In most cases, I've seen that these YouTube summary extensions or apps support limited videos. Does this support every video?

Message : Has anyone tried adding, gpt don't train using this data 
In the prompts and seen how the response is?

Message : adding as in "Add 2+2" kind of thing?
Quoted Message : Has anyone tried adding, gpt don't train using this data \nIn the prompts and seen how the response is?

Message : Just append this line to your prompt

Message : These models need their training and inference data to be similar in encoding and patterns. 

I observed this problem and then encoded training data in unicode then inference data was also encoded in unicode before passing to the model otherwise it will drop a lot in accuracy.
Quoted Message : I am building a binary classifier and utilizing the Roberta base model. Interestingly, I have observed instability in its performance when it comes to punctuation marks. The addition of a simple full stop or even special characters seems to alter the predicted labels.\n\nAny advice ?

Message : Maybe other people have better methods but this is what I tried and use in my systems. Also, make sure that your training/inference characters aren't lost in encoding. In most cases, it won't but can't guarantee for everything.

Message : Encode? Convert to utf8 ?
Quoted Message : These models need their training and inference data to be similar in encoding and patterns. \n\nI observed this problem and then encoded training data in unicode then inference data was also encoded in unicode before passing to the model otherwise it will drop a lot in accuracy.

Message : Does anyone have experience doing differential privacy for LLMs (fine-tuning)? I would like to have a chat about your experience.

Message : Yeah *utf-8* is one kind of character encoding, I meant *unicode* character encoding as it has counterparts of it's own for each type of encoding to minimise information loss.
Quoted Message : Encode? Convert to utf8 ?

Message : It's not guaranteed but its possible that you've some issue of having characters from different encoding in training and inference data. If the model doesn't recognise any kind of tokens, it'll go haywire typically. We want to keep the tokenisation of inference time exactly the same as tokenisation of training time.

Message : This is hard because we are gathering data from all kinds of sources like docs, web or just tabular data. So encoding differences are a latent factor sometimes that drop the model performance. Take my word with a grain of salt as it's speculation on my part for what your issue might be.

Message : What do you mean by *Differential privacy*?

Does it mean that documents with different levels of confidentiality are to be trained/fine-tuned on an LLM?
Quoted Message : Does anyone have experience doing differential privacy for LLMs (fine-tuning)? I would like to have a chat about your experience.

Message : Me thinks it has something to do with federated learning
Quoted Message : What do you mean by *Differential privacy*?\n\nDoes it mean that documents with different levels of confidentiality are to be trained/fine-tuned on an LLM?

Message : Differential privacy
(DP) provides a rigorous framework that allows adding noise in
the process of training or fine-tuning LLMs such that extracting
the training data becomes infeasible (i.e., with a cryptograph-
ically small success probability).

Message : 2210.15042.pdf ‚Ä¢ ‚Äé7 pages ‚Äédocument omitted

Message : Thanks a lot üòÑ

Message : ‚Äé<attached: 00009484-PHOTO-2023-06-21-22-09-24.jpg>

Message : Didn‚Äôt expect VisProg to win the Best Paper award at CVPR ü§î
https://prior.allenai.org/projects/visprog

Message : Any pretrained model for legal documents, agreements or contracts i have tried legalbert for QA but not giving good results, i want to get all parties involved persons banks and legal description ?

Message : How many tokens are you generating?

We released Falcon-7b-instruct api under beta on monsterapi yesterday. Inference times are like 4-8 seconds for 200 tokens. Experimenting more.
Quoted Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : There is a paper on cuad dataset, not a perfect match for what you are looking for--but you might find some interesting ideas
Quoted Message : Any pretrained model for legal documents, agreements or contracts i have tried legalbert for QA but not giving good results, i want to get all parties involved persons banks and legal description ?

Message : Yea I have tried it but it's specific for contracts
Quoted Message : There is a paper on cuad dataset, not a perfect match for what you are looking for--but you might find some interesting ideas

Message : Fine tuned deberta v2

Message : ‚Äé<attached: 00009493-PHOTO-2023-06-21-23-04-01.jpg>

Message : How many urls are in the array you're passing? If there's a lot of Javascript in these websites, it can take a while for selenium to load the pages

Message : Just 1

Message : DMing

Message : https://twitter.com/jsngr/status/1671561341893742592?t=w2UURl05_L5aKAndPmT50g&s=08

Message : Figma acquired diagram

Message : We'll see a lot more of this. The big guys who have scale distribution are going to lap up any good tools.

Message : It's a pretty neat exit ramp for small teams building in AI


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Yea I have tried it but it's specific for contracts
Quoted Message : There is a paper on cuad dataset, not a perfect match for what you are looking for--but you might find some interesting ideas

Message : Fine tuned deberta v2

Message : ‚Äé<attached: 00009493-PHOTO-2023-06-21-23-04-01.jpg>

Message : How many urls are in the array you're passing? If there's a lot of Javascript in these websites, it can take a while for selenium to load the pages

Message : Just 1

Message : DMing

Message : https://twitter.com/jsngr/status/1671561341893742592?t=w2UURl05_L5aKAndPmT50g&s=08

Message : Figma acquired diagram

Message : We'll see a lot more of this. The big guys who have scale distribution are going to lap up any good tools.

Message : It's a pretty neat exit ramp for small teams building in AI

Message : How does the selenium url loader work?

Message : I mean how good are the results

Message : How to downalod this? The download button is missing
Quoted Message : One of the ongoing efforts to release 1000hrs of parallel speech to text corpora in 9 Indian languages spanning 38 dialects\n\nhttps://respin.iisc.ac.in/datasets

Message : ‚Äé<attached: 00009504-PHOTO-2023-06-22-01-04-25.jpg>
Quoted Message : How to downalod this? The download button is missing

Message : The other option is trying to contact the jugalbandi.ai folks which ( according to my understanding, others correct me if I am wrong) exposes an API wrapper on top of the Bhashini models[0]


https://www.jugalbandi.ai/mission
https://www.jugalbandi.ai/ecosystem

0.
https://www.bhashini.gov.in/en/ecosystem
Quoted Message : How to downalod this? The download button is missing

Message : Here is a post from Saurabh of jugalbandi.ai team
Quoted Message : https://github.com/OpenNyAI/jugalbandi-api/blob/main/translator.py \n\nHere we have written some code to use the AI4Bharat model endpoints for consumption in applications. Works with at least 10 Indian languages including Hindi.

Message : Bhashini doesn‚Äôt have a bhojpuri model

Message : Hi all, what's the current consensus here on the best ai coding tool extension for IDEs?

Message : You mean excluding copilot?
Quoted Message : Hi all, what's the current consensus here on the best ai coding tool extension for IDEs?

Message : Yeah. Copilot is good at keeping context of your whole codebase. But gpt 4 is way better when it comes to intelligence? Generates better tests etc
Quoted Message : You mean excluding copilot?

Message : There's nothing that is even better than GPT3 in coding except GPT4. If you want to use GPT4 as copilot, try codegpt.co

Message : If you've your own api key then GPT3/4 both are available for use in their extension

Message : Otherwise you can pay and use GPT4 for coding with their extension

Message : Was anyone successful in loading a gpt4all model?

Message : You can load it easily via privateGPT, their chat client or directly via their python bindings.

Message : This is intriguing
https://twitter.com/sparr_ml/status/1671587317075648533?t=vrLceAWiZbFzhBEHsYKQbw&s=19

Message : Okay, this is the most "Sparks of AGI" behaviour I've seen! 

Absolutely hilarious and alarming at the same time
Quoted Message : This is intriguing\nhttps://twitter.com/sparr_ml/status/1671587317075648533?t=vrLceAWiZbFzhBEHsYKQbw&s=19

Message : Azure Quantum Elements is here to work with AI

https://blogs.microsoft.com/blog/2023/06/21/accelerating-scientific-discovery-with-azure-quantum/

Message : Does it have a world view of time ( response time )
Or in the latent space probability of using "apologies" and "delays" was high for this particular prompt input ?

I am inclined to believe the latter :)
Quoted Message : Okay, this is the most \"Sparks of AGI\" behaviour I've seen! \n\nAbsolutely hilarious and alarming at the same time

Message : I don't know either way. But there is definitely some state information which OpenAI passes to the LLM. You can see this when you try to resume a stale Code Interpreter or Bing convo
Quoted Message : Does it have a world view of time ( response time )\nOr in the latent space probability of using \"apologies\" and \"delays\" was high for this particular prompt input ?\n\nI am inclined to believe the latter :)

Message : +1
Quoted Message : Any pretrained model for legal documents, agreements or contracts i have tried legalbert for QA but not giving good results, i want to get all parties involved persons banks and legal description ?

Message : This is to create documents I presume? Or just parse complex legal docs?
Quoted Message : Any pretrained model for legal documents, agreements or contracts i have tried legalbert for QA but not giving good results, i want to get all parties involved persons banks and legal description ?

Message : And to what degree of customization? I've seen it do very well on boilerplate stuff like NDAs, and basic vendor agreements

Message : Actually to create documents, expert analysis out of legal docs. And create line of questioning etc. for the expert analysis
Quoted Message : This is to create documents I presume? Or just parse complex legal docs?

Message : Have you tried a RAG system using one of the GPTs to generate responses?
Quoted Message : Any pretrained model for legal documents, agreements or contracts i have tried legalbert for QA but not giving good results, i want to get all parties involved persons banks and legal description ?

Message : Interesting read on RLHF:
https://www.interconnects.ai/p/how-rlhf-works

Message : https://arxiv.org/abs/2212.08073

TIL about Anthropic's constitutional ai paper.
Very cool idea on first glance.

What do people think about this approach, RLAIF ?

"As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF).
As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them"

Message : Just found out that I have access to chatGPT plugins. But there seem to to too many of them already.  

What are some plugins you find useful or use regularly?

Message : Nothing in plug-in works as well as expected at least for me. I thought web search was going to be good but I the tool fails most of the time and it‚Äôs so slow I would rather use Google or Bard for it :P
Quoted Message : Just found out that I have access to chatGPT plugins. But there seem to to too many of them already.  \n\nWhat are some plugins you find useful or use regularly?

Message : Try perplexity.ai
Quoted Message : Nothing in plug-in works as well as expected at least for me. I thought web search was going to be good but I the tool fails most of the time and it‚Äôs so slow I would rather use Google or Bard for it :P

Message : ü´° Yes sir!
Quoted Message : Try perplexity.ai

Message : open source API key management tool. It is still in developing but you may check it for your openai key management (inside your org). Create multiple keys along with setting up individual rate limits and make your server call openai api.

https://github.com/chronark/unkey

Message : Something for @91989995xxxx to consider adding to his OSS project maybe?

https://twitter.com/177pc/status/1671591721032105985?t=z_tw91n9iK-wCCv45lMAYg&s=19
Quoted Message : open source API key management tool. It is still in developing but you may check it for your openai key management (inside your org). Create multiple keys along with setting up individual rate limits and make your server call openai api.\n\nhttps://github.com/chronark/unkey

Message : Interesting!
Quoted Message : https://arxiv.org/abs/2212.08073\n\nTIL about Anthropic's constitutional ai paper.\nVery cool idea on first glance.\n\nWhat do people think about this approach, RLAIF ?\n\n\"As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF).\nAs a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them\"

Message : Interesting!

Message : This is actually superb for us!
Quoted Message : Something for @9198xxxxxxxx to consider adding to his OSS project maybe?\n\nhttps://twitter.com/177pc/status/1671591721032105985?t=z_tw91n9iK-wCCv45lMAYg&s=19

Message : It is still in the early stage. But it may give a good design idea.
Quoted Message : Something for @9198xxxxxxxx to consider adding to his OSS project maybe?\n\nhttps://twitter.com/177pc/status/1671591721032105985?t=z_tw91n9iK-wCCv45lMAYg&s=19

Message : this message has been deleted

Message : Could it be because the Bing browsing plugin also uses a model trained on "browsing journey" style data?
Quoted Message : This is intriguing\nhttps://twitter.com/sparr_ml/status/1671587317075648533?t=vrLceAWiZbFzhBEHsYKQbw&s=19

Message : ‚Äé~‚ÄØRahul Bhatnagar added ‚Ä™+91¬†6364¬†125¬†737‚Ä¨


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ü´° Yes sir!
Quoted Message : Try perplexity.ai

Message : open source API key management tool. It is still in developing but you may check it for your openai key management (inside your org). Create multiple keys along with setting up individual rate limits and make your server call openai api.

https://github.com/chronark/unkey

Message : Something for @91989995xxxx to consider adding to his OSS project maybe?

https://twitter.com/177pc/status/1671591721032105985?t=z_tw91n9iK-wCCv45lMAYg&s=19
Quoted Message : open source API key management tool. It is still in developing but you may check it for your openai key management (inside your org). Create multiple keys along with setting up individual rate limits and make your server call openai api.\n\nhttps://github.com/chronark/unkey

Message : Interesting!
Quoted Message : https://arxiv.org/abs/2212.08073\n\nTIL about Anthropic's constitutional ai paper.\nVery cool idea on first glance.\n\nWhat do people think about this approach, RLAIF ?\n\n\"As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF).\nAs a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them\"

Message : Interesting!

Message : This is actually superb for us!
Quoted Message : Something for @9198xxxxxxxx to consider adding to his OSS project maybe?\n\nhttps://twitter.com/177pc/status/1671591721032105985?t=z_tw91n9iK-wCCv45lMAYg&s=19

Message : It is still in the early stage. But it may give a good design idea.
Quoted Message : Something for @9198xxxxxxxx to consider adding to his OSS project maybe?\n\nhttps://twitter.com/177pc/status/1671591721032105985?t=z_tw91n9iK-wCCv45lMAYg&s=19

Message : this message has been deleted

Message : Could it be because the Bing browsing plugin also uses a model trained on "browsing journey" style data?
Quoted Message : This is intriguing\nhttps://twitter.com/sparr_ml/status/1671587317075648533?t=vrLceAWiZbFzhBEHsYKQbw&s=19

Message : ‚Äé~‚ÄØRahul Bhatnagar added ‚Ä™+91¬†6364¬†125¬†737‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØShristi

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAs

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØRohit

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØSandeep

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†88611¬†91681‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†88619¬†58921‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØSumit

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØVivek Karna

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†88706¬†88434‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØLavalish

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†89211¬†75485‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØUtsav

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†89717¬†85192‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØSurya Harsha Nunnaguppala

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØPrajwal

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØVaibhav

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAkul Jindal

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96193¬†43276‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØManas Jain

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†80560¬†73151‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØMohnish Landge

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†94323¬†80811‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†94175¬†32928‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØLohith

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØSangeeth

Message : Looks like a busy day for @9177xxxxxxxx today üòÖ

Message : Just angry with Docker, but using it productively üòÇüôà
Quoted Message : Looks like a busy day for @91773788xxxx today üòÖ

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØManoj

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†93443¬†51452‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†97147¬†83884‚Ä¨

Message : Is there an easy way to not be angry about Kubernetes?

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØVinod B

Message : Asking for a friend

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†80986¬†87841‚Ä¨

Message : Looks like a busy day for @91773788xxxx today üòÖ

Message : Just angry with Docker, but using it productively üòÇüôà

Message : Is there an easy way to not be angry about Kubernetes?

Message : Asking for a friend

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98408¬†12021‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†77362¬†65643‚Ä¨


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Is there an easy way to not be angry about Kubernetes?

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØVinod B

Message : Asking for a friend

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†80986¬†87841‚Ä¨

Message : Looks like a busy day for @91773788xxxx today üòÖ

Message : Just angry with Docker, but using it productively üòÇüôà

Message : Is there an easy way to not be angry about Kubernetes?

Message : Asking for a friend

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98408¬†12021‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†77362¬†65643‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†70120¬†69742‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØnilabjo

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†90823¬†02389‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†95973¬†45919‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØShivam

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+65¬†9647¬†7333‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØJaswanth

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98450¬†87647‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†81057¬†60650‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†80509¬†73789‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†75988¬†39846‚Ä¨

Message : Looks like Nirant's spring cleaning day :D

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAnirudh Venu
Quoted Message : Looks like Nirant's spring cleaning day :D

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†79034¬†93855‚Ä¨

Message : Looks like Nirant's spring cleaning day :D

Message : Just when you thought lay-off season is behind us

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØChinmay Singh

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†90088¬†46426‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+1¬†(443)¬†722‚Äë6631‚Ä¨

Message : Feeling anxious :D

Message : Are there folks still waiting for GPT4 API access?\nHad applied slightly late but still quite a while ago and yet to get access :(

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAbhijeet

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+233¬†26¬†371¬†6335‚Ä¨

Message : Cache eviction in progress.. :)

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†87586¬†80586‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†97413¬†39985‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØjvenom ü¶•
Quoted Message : Feeling anxious :D

Message : Woahhhh üòÇüòÇüòÇ

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†70209¬†16027‚Ä¨

Message : Haha, it‚Äôs like am I next?

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†70421¬†05035‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†80970¬†21586‚Ä¨

Message : Yes, you can hire someone else to be angry about it. Side effects, your wallet might not be happy
Quoted Message : Is there an easy way to not be angry about Kubernetes?

Message : But like what is the criteria?

Message : reaching out over email might help. That's what we did
Quoted Message : Are there folks still waiting for GPT4 API access?\nHad applied slightly late but still quite a while ago and yet to get access :(

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96113¬†59972‚Ä¨

Message : Feeling anxious :D

Message : Are there folks still waiting for GPT4 API access?
Had applied slightly late but still quite a while ago and yet to get access :(

Message : Cache eviction in progress.. :)

Message : Frantically checking WhatsApp every 10 seconds


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†70421¬†05035‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†80970¬†21586‚Ä¨

Message : Yes, you can hire someone else to be angry about it. Side effects, your wallet might not be happy
Quoted Message : Is there an easy way to not be angry about Kubernetes?

Message : But like what is the criteria?

Message : reaching out over email might help. That's what we did
Quoted Message : Are there folks still waiting for GPT4 API access?\nHad applied slightly late but still quite a while ago and yet to get access :(

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96113¬†59972‚Ä¨

Message : Feeling anxious :D

Message : Are there folks still waiting for GPT4 API access?
Had applied slightly late but still quite a while ago and yet to get access :(

Message : Cache eviction in progress.. :)

Message : Frantically checking WhatsApp every 10 seconds

Message : Woahhhh üòÇüòÇüòÇ

Message : Haha, it‚Äôs like am I next?

Message : Yes, you can hire someone else to be angry about it. Side effects, your wallet might not be happy

Message : But like what is the criteria?

Message : reaching out over email might help. That's what we did

Message : Wonder how many people are messaging rn to ensure recent activity and avoid being kicked

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†89212¬†90578‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+65¬†8891¬†2936‚Ä¨

Message : who was that marvel guy who snapped half the population out of existence

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†72760¬†42444‚Ä¨
Quoted Message : Wonder how many people are messaging rn to ensure recent activity and avoid being kicked

Message : @9177xxxxxxxx is that guy today

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAakash Kaushik

Message : Wonder how many people are messaging rn to ensure recent activity and avoid being kicked

Message : who was that marvel guy who snapped half the population out of existence

Message : Training data has reached cutoff

Message : @91773788xxxx is that guy today

Message : Niranthanos

Message : No more data can Influence nirantgpt now
Quoted Message : Training data has reached cutoff

Message : <insert nervous laughter noises here/>

Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)\n\nPS: Staying on brand, the entire list is generated by ChatGPT

Message : Squid Games: GenAI edition

Message : This is still open.\n Due to time constraint and my use case faster inference requirement, I opted for a different model (flan t5 xl) on 4x.large which gave no issues. Also the inference is very fast and flant5xl seems stable.\n\nResult quality was far better with falcon 7b.
Quoted Message : Thanks for adding me, Nirant.\n\nHi everyone,\n\nI was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU)\nBut what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.\n\nCan anyone suggest what I could be missing? or infra upgrade  required?

Message : ‚Äé~‚ÄØNirant removed Poobesh

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØUnmesh Raskar

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99740¬†07715‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØSayantan

Message : What's your exact use case? I know flan family is very good but helps to know which use case is better than Falcon series.
Quoted Message : This is still open.\n Due to time constraint and my use case faster inference requirement, I opted for a different model (flan t5 xl) on 4x.large which gave no issues. Also the inference is very fast and flant5xl seems stable.\n\nResult quality was far better with falcon 7b.

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†78385¬†26259‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+1¬†(415)¬†702‚Äë7493‚Ä¨

Message : Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from
Quoted Message : But like what is the criteria?

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†84478¬†49231‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+1¬†(917)¬†345‚Äë7871‚Ä¨

Message : Probably write a script to look for your name to be a forever lurker üòõ
Quoted Message : Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØYG

Message : <insert nervous laughter noises here/>

Message : Hello! 

As I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.

If you see your name or phone number in this "removal" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing

That'd indicate to me that you're at least reading some messages :)

PS: Staying on brand, the entire list is generated by ChatGPT

Message : Squid Games: GenAI edition

Message : This is still open.
Due to time constraint and my use case faster inference requirement, I opted for a different model (flan t5 xl) on 4x.large which gave no issues. Also the inference is very fast and flant5xl seems stable.

Result quality was far better with falcon 7b.

Message : What's your exact use case? I know flan family is very good but helps to know which use case is better than Falcon series.

Message : Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†84478¬†49231‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+1¬†(917)¬†345‚Äë7871‚Ä¨

Message : Probably write a script to look for your name to be a forever lurker üòõ
Quoted Message : Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØYG

Message : <insert nervous laughter noises here/>

Message : Hello! 

As I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.

If you see your name or phone number in this "removal" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing

That'd indicate to me that you're at least reading some messages :)

PS: Staying on brand, the entire list is generated by ChatGPT

Message : Squid Games: GenAI edition

Message : This is still open.
Due to time constraint and my use case faster inference requirement, I opted for a different model (flan t5 xl) on 4x.large which gave no issues. Also the inference is very fast and flant5xl seems stable.

Result quality was far better with falcon 7b.

Message : What's your exact use case? I know flan family is very good but helps to know which use case is better than Falcon series.

Message : Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from

Message : Probably write a script to look for your name to be a forever lurker üòõ

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†72592¬†96814‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØPrithvi

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAshray Iyengar

Message : Ig lurking is still acceptable if you remove the name :)
Quoted Message : Probably write a script to look for your name to be a forever lurker üòõ

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†84488¬†41838‚Ä¨

Message : But then they would be an active member no üëÄüòÇ
Quoted Message : Probably write a script to look for your name to be a forever lurker üòõ

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+1¬†(438)¬†835‚Äë2937‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†79770¬†98212‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†85001¬†89645‚Ä¨
Quoted Message : Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from

Message : Does WhatsApp not provide APIs for user insights? If they don't they really should

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98840¬†32931‚Ä¨

Message : Try applying for Microsoft for founders. You get access to their program, which provides azure credits and openAI as well. Maybe that can work. https://foundershub.startups.microsoft.com/
Quoted Message : Are there folks still waiting for GPT4 API access?\nHad applied slightly late but still quite a while ago and yet to get access :(

Message : Viable Twitter based business model
Quoted Message : Yes, you can hire someone else to be angry about it. Side effects, your wallet might not be happy

Message : I'm in it but that just awards credits
Quoted Message : Try applying for Microsoft for founders. You get access to their program, which provides azure credits and openAI as well. Maybe that can work. https://foundershub.startups.microsoft.com/

Message : Not gpt 4 access afaik

Message : Ig lurking is still acceptable if you remove the name :)

Message : But then they would be an active member no üëÄüòÇ

Message : I mark myself safe during the *Group purge*

Message : Does WhatsApp not provide APIs for user insights? If they don't they really should

Message : Try applying for Microsoft for founders. You get access to their program, which provides azure credits and openAI as well. Maybe that can work. https://foundershub.startups.microsoft.com/

Message : Viable Twitter based business model

Message : I'm in it but that just awards credits

Message : Not gpt 4 access afaik

Message : Keeping access to this group has become more difficult than getting Claude access, thanks to Niranthanos

Message : It awards openai credits (2.5k usd) for use in openais api, and 1k in azure credits which you can use in azure openai service (this is ideate level stage)

Message : @9198xxxxxxxx made his way back üó£Ô∏è

Message : this message has been deleted

Message : Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?

Message : I never received my 2.5k open ai credits
Quoted Message : It awards openai credits (2.5k usd) for use in openais api, and 1k in azure credits which you can use in azure openai service (this is ideate level stage)

Message : You have to avail the benefit in the founders portal I believe
Quoted Message : I never received my 2.5k open ai credits

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†94009¬†45731‚Ä¨

Message : Keeping access to this group has become more difficult than getting Claude access, thanks to Niranthanos

Message : It awards openai credits (2.5k usd) for use in openais api, and 1k in azure credits which you can use in azure openai service (this is ideate level stage)

Message : @91989731xxxx made his way back üó£Ô∏è

Message : Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?

Message : I never received my 2.5k open ai credits

Message : You have to avail the benefit in the founders portal I believe

Message : Use tools like https://nas.io/whatsapp ? (not used, no affiliation)
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)\n\nPS: Staying on brand, the entire list is generated by ChatGPT

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†95584¬†28844‚Ä¨


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You have to avail the benefit in the founders portal I believe
Quoted Message : I never received my 2.5k open ai credits

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†94009¬†45731‚Ä¨

Message : Keeping access to this group has become more difficult than getting Claude access, thanks to Niranthanos

Message : It awards openai credits (2.5k usd) for use in openais api, and 1k in azure credits which you can use in azure openai service (this is ideate level stage)

Message : @91989731xxxx made his way back üó£Ô∏è

Message : Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?

Message : I never received my 2.5k open ai credits

Message : You have to avail the benefit in the founders portal I believe

Message : Use tools like https://nas.io/whatsapp ? (not used, no affiliation)
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)\n\nPS: Staying on brand, the entire list is generated by ChatGPT

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†95584¬†28844‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØManav Shah

Message : yeah I did I also mailed both open ai and Microsoft support\nboth told ETA is not confirmed
Quoted Message : You have to avail the benefit in the founders portal I believe

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†70541¬†24184‚Ä¨

Message : 2023_06_22_133411_80E934819F21614DE5.webp
Quoted Message : yeah I did I also mailed both open ai and Microsoft support\nboth told ETA is not confirmed

Message : Might help to just sort this list alphabetically :)
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)\n\nPS: Staying on brand, the entire list is generated by ChatGPT

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96868¬†11344‚Ä¨

Message : ‚Äé~‚ÄØNirant removed Ved Khandekar

Message : Oh. I actually never availed the openai credits. I thought of saving them for a usecase my startup might need later. Rn I'm just playing around with free credits and gpt+
Quoted Message : yeah I did I also mailed both open ai and Microsoft support\nboth told ETA is not confirmed

Message : ‚Äé~‚ÄØNirant removed Chinmay Talegaonkar

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98116¬†95394‚Ä¨

Message : That's sad

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†88841¬†44494‚Ä¨

Message : yeah I am using azure open ai for all my prototypes
Quoted Message : Oh. I actually never availed the openai credits. I thought of saving them for a usecase my startup might need later. Rn I'm just playing around with free credits and gpt+

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†91¬†00¬†95036¬†8‚Ä¨

Message : there are many ppl facing the same problem
Quoted Message : I thought they provision it like they did the azure credits

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†87660¬†03000‚Ä¨

Message : Use tools like https://nas.io/whatsapp ? (not used, no affiliation)

Message : yeah I did I also mailed both open ai and Microsoft support
both told ETA is not confirmed

Message : ‚Äé<attached: 00009679-STICKER-2023-06-22-13-34-11.webp>

Message : Might help to just sort this list alphabetically :)

Message : Oh. I actually never availed the openai credits. I thought of saving them for a usecase my startup might need later. Rn I'm just playing around with free credits and gpt+

Message : That's sad

Message : I thought they provision it like they did the azure credits

Message : yeah I am using azure open ai for all my prototypes

Message : there are many ppl facing the same problem

Message : Since you're in the foundershub, would you mind telling me which stage you've reached?
Quoted Message : yeah I am using azure open ai for all my prototypes

Message : Same here. Applied from both of my companies with real logical reasons but nothing but silence as dark as deep space :)
Quoted Message : Are there folks still waiting for GPT4 API access?\nHad applied slightly late but still quite a while ago and yet to get access :(

Message : I believe we can reach growth stage but the main barrier for me is incorporation in 2nd stage itself :(

Message : Cluster removal among discussion reminds of the last dinner scene of Don't Look Up ü´®

Message : oh created dummy start up just to get azure credits 
so I am still in the first stage the ideation one
Quoted Message : Since you're in the foundershub, would you mind telling me which stage you've reached?

Message : Ah ok
Quoted Message : oh created dummy start up just to get azure credits \nso I am still in the first stage the ideation one

Message : ‚Äé<attached: 00009692-GIF-2023-06-22-13-38-08.mp4>
Quoted Message : 2023_06_22_80E934819F21614DE5.webp

Message : Yea the credits are definitely useful :). But I believe they require you to use them In a tenant and not personal account

Message : Pausing now. Stopped with 256 people to go. Felt like an shubh number
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)\n\nPS: Staying on brand, the entire list is generated by ChatGPT

Message : seemed fun
Quoted Message : Pausing now. Stopped with 256 people to go. Felt like an shubh number

Message : Not at all üò≠
Quoted Message : seemed fun

Message : You're free to pick up the next 256 and give it a spin üòÖ

Message : You can request higher.
Your app must be doing well to have that many requests. You might need to request
Quoted Message : Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?

Message : any programs where I could apply for Stability AI api credits as a startup?

Similar to Vercel AI accelerator

Message : or wondering if Midjourney has a closed group of folks to use their official api


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Ah ok
Quoted Message : oh created dummy start up just to get azure credits \nso I am still in the first stage the ideation one

Message : ‚Äé<attached: 00009692-GIF-2023-06-22-13-38-08.mp4>
Quoted Message : 2023_06_22_80E934819F21614DE5.webp

Message : Yea the credits are definitely useful :). But I believe they require you to use them In a tenant and not personal account

Message : Pausing now. Stopped with 256 people to go. Felt like an shubh number
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)\n\nPS: Staying on brand, the entire list is generated by ChatGPT

Message : seemed fun
Quoted Message : Pausing now. Stopped with 256 people to go. Felt like an shubh number

Message : Not at all üò≠
Quoted Message : seemed fun

Message : You're free to pick up the next 256 and give it a spin üòÖ

Message : You can request higher.
Your app must be doing well to have that many requests. You might need to request
Quoted Message : Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?

Message : any programs where I could apply for Stability AI api credits as a startup?

Similar to Vercel AI accelerator

Message : or wondering if Midjourney has a closed group of folks to use their official api

Message : Saw this thread reverse engineering gpt-4 speculated param number.. 

https://twitter.com/philipturnerar/status/1671698274246377478?s=20

Message : ‚Äé<attached: 00009702-GIF-2023-06-22-13-52-44.mp4>

Message : Midjourney does have an app that a closed group of folks have been given access to, but an API within it hasn‚Äôt been spoken about in their office hours from my understanding.

Message : Saw this thread reverse engineering gpt-4 speculated param number.. \n\nhttps://twitter.com/philipturnerar/status/1671698274246377478?s=20

Message : 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 2023_06_22_135244_3A6D63F2E60FBFA8BFF3.mp4
Quoted Message : Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?

Message : Midjourney does have an app that a closed group of folks have been given access to, but an API within it hasn‚Äôt been spoken about in their office hours from my understanding.
Quoted Message : or wondering if Midjourney has a closed group of folks to use their official api

Message : edit access is not there how to remove ?
Quoted Message : Hello! \n\nAs I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.\n\nIf you see your name or phone number in this \"removal\" list ‚Äî please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing\n\nThat'd indicate to me that you're at least reading some messages :)\n\nPS: Staying on brand, the entire list is generated by ChatGPT

Message : We're leveraging retrieval augmented generation for our product. Noticed that prompts that work for GPT3.5 don't work for GPT4. Has anyone else seen this? I've seen people mention differences but was a little surprised as this is a fairly simple use case.

Message : yes. there is very less commonality between the prompts that work for 3.5 and 4. 
which is why there is a blow up of prompts X chains X llms.
Quoted Message : We're leveraging retrieval augmented generation for our product. Noticed that prompts that work for GPT3.5 don't work for GPT4. Has anyone else seen this? I've seen people mention differences but was a little surprised as this is a fairly simple use case.

Message : Any suggestions / materials I can look at to tune prompts specifically for each model?

Message : In the article by Humanloop, author wrote OpenAI plans to use quantisation
Quoted Message : Saw this thread reverse engineering gpt-4 speculated param number.. \n\nhttps://twitter.com/philipturnerar/status/1671698274246377478?s=20

Message : There was something shared earlier about the 3.5 turbo models being quantised
Quoted Message : In the article by Humanloop, author wrote OpenAI plans to use quantisation

Message : Thanks, i have not seen that article, can you pls share link? Is this the sama interview article where he mentioned open sourcing a smaller model?
Quoted Message : In the article by Humanloop, author wrote OpenAI plans to use quantisation

Message : This was the article shared by another member of the group earlier - From Sama‚Äôs chat w Co-founder of Humanloop - https://web.archive.org/web/20230531203946/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans

Message : The original article is removed so this one is an archive

Message : Seems you bookmarked üò¨
Quoted Message : This was the article shared by another member of the group earlier - From Sama‚Äôs chat w Co-founder of Humanloop - https://web.archive.org/web/20230531203946/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans

Message : Noicee üëç
Quoted Message : This was the article shared by another member of the group earlier - From Sama‚Äôs chat w Co-founder of Humanloop - https://web.archive.org/web/20230531203946/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans

Message : Thank you
Quoted Message : This was the article shared by another member of the group earlier - From Sama‚Äôs chat w Co-founder of Humanloop - https://web.archive.org/web/20230531203946/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans

Message : Emerging architecture for Llm apps via a16z
https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/

Message : Good read for most people ramping up right now. Strong recommend.
Quoted Message : Emerging architecture for Llm apps via a16z\nhttps://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/

Message : They have also released JS stack for prototyping AI projects - https://github.com/a16z-infra/ai-getting-started
Quoted Message : Emerging architecture for Llm apps via a16z\nhttps://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/

Message : There was one from sequoia a week back which was more business focussed 

https://www.sequoiacap.com/article/llm-stack-perspective/

Message : #openai triton - any idea how much is the interest in writing custom  DL kernels in triton outside openAI? I haven't seen much activity in GitHub on this from folks outside openai. And any comparison between this and mojo from modular.ai(Chris lattner)?

Message : Mojo isn't FOSS, and has no DL kernels yet to the best of my knowledge. They don't even have CUDA support?
Quoted Message : #openai triton - any idea how much is the interest in writing custom  DL kernels in triton outside openAI? I haven't seen much activity in GitHub on this from folks outside openai. And any comparison between this and mojo from modular.ai(Chris lattner)?

Message : https://twitter.com/gokulr/status/1671594605886976000
Quoted Message : They have also released JS stack for prototyping AI projects - https://github.com/a16z-infra/ai-getting-started

Message : They had a few sample dl operator implementations in their YouTube videos,  Reg Cuda support, how are they doing GPU HW abstraction? - Direct metal support?
Quoted Message : Mojo isn't FOSS, and has no DL kernels yet to the best of my knowledge. They don't even have CUDA support?

Message : My guess was they would have a lowering from mojo thru mlir to ptx?
Quoted Message : They had a few sample dl operator implementations in their YouTube videos,  Reg Cuda support, how are they doing GPU HW abstraction? - Direct metal support?

Message : Aah, I'd missed the Youtube video. Would you mind sharing the link if you've it handy?
Quoted Message : They had a few sample dl operator implementations in their YouTube videos,  Reg Cuda support, how are they doing GPU HW abstraction? - Direct metal support?

Message : It was a couple of months ago. Will search and send.
Quoted Message : Aah, I'd missed the Youtube video. Would you mind sharing the link if you've it handy?

Message : Here is the keynote 

https://youtu.be/-3Kf2ZZU-dg?t=1987
Quoted Message : It was a couple of months ago. Will search and send.

Message : Not directly related to GenAI, but has anyone here evaluated Hevo and Fivetran? Wanted first hand feedback / comparison of the two pipeline platforms. Pls DM

Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.
Quoted Message : https://twitter.com/gokulr/status/1671594605886976000

Message : Streamlit and Gradio may cover most of your demo needs in python stack
Quoted Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.

Message : Hf gradio , streamlit

But haven't built anything production grade yet, so curious what others use
Quoted Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.

Message : I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time.
Quoted Message : Streamlit and Gradio may cover most of your demo needs in python stack

Message : I am really in awe of the twitter indie devs (pieter etc) who do all of this single handedly.

Message : also check Atri labs which is an Indian founding team
Quoted Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.

Message : https://github.com/Atri-Labs/atrilabs-engine

Message : https://gradio.app/sharing-your-app
Quoted Message : I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time.

Message : we are trying to build the opensource production-ready SDK here (open source of course). am probably a week away, but happy to send it to you when up.
Quoted Message : I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Not directly related to GenAI, but has anyone here evaluated Hevo and Fivetran? Wanted first hand feedback / comparison of the two pipeline platforms. Pls DM

Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.
Quoted Message : https://twitter.com/gokulr/status/1671594605886976000

Message : Streamlit and Gradio may cover most of your demo needs in python stack
Quoted Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.

Message : Hf gradio , streamlit

But haven't built anything production grade yet, so curious what others use
Quoted Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.

Message : I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time.
Quoted Message : Streamlit and Gradio may cover most of your demo needs in python stack

Message : I am really in awe of the twitter indie devs (pieter etc) who do all of this single handedly.

Message : also check Atri labs which is an Indian founding team
Quoted Message : Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.

Message : https://github.com/Atri-Labs/atrilabs-engine

Message : https://gradio.app/sharing-your-app
Quoted Message : I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time.

Message : we are trying to build the opensource production-ready SDK here (open source of course). am probably a week away, but happy to send it to you when up.
Quoted Message : I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time.

Message : Thanks for all this pointers, I will check them out. Sure @91981048xxxx I am looking forward to that, you will save me a lot of time!

Message : well, i dont know if i can claim to be all that grand !

our only stand is that Gen-AI applications are a configuration management problem. Everyone is probably trying to model it as a UI or a code management problem. prompts X chains X LLMs is where it blows up in config management.
what we are trying to do is base it on the same core as kubernetes, so that we streamline the config and the pipelines first.

Message : Do we get kicked for not interacting here?

Message : This is really frustrating. I miss consistency: given the same inputs (text, and params) will always give you same output
Quoted Message : yes. there is very less commonality between the prompts that work for 3.5 and 4. \nwhich is why there is a blow up of prompts X chains X llms.

Message : Hey does anyone know how to request for more quota for vms in azure ML studios ,to get A10 or A100
every time I request for quota they say the following

```
For the foreseeable future, we are not approving quota requests for these Azure virtual machines: NC Series.‚ÄØThese VMs do not run our latest generation infrastructure and we are directing customers who request additional quota for these v1 VMs to consider creating a new pay-as-you-go subscription to explore expanded access to newer generation VM Series in the US East (EUS) region.
```

Message : Yes
Quoted Message : Do we get kicked for not interacting here?

Message : https://crfm.stanford.edu/2023/06/16/anticipatory-music-transformer.html\n\nTags: Symbolic music generation, infilling. Interesting for people looking to use music-transformers for co-composition.

Message : cc @9188xxxxxxxx can you help?
Quoted Message : Hey does anyone know how to request for more quota for vms in azure ML studios ,to get A10 or A100\nevery time I request for quota they say the following\n\n```\nFor the foreseeable future, we are not approving quota requests for these Azure virtual machines: NC Series.‚ÄØThese VMs do not run our latest generation infrastructure and we are directing customers who request additional quota for these v1 VMs to consider creating a new pay-as-you-go subscription to explore expanded access to newer generation VM Series in the US East (EUS) region.‚ÄØ\n```

Message : Yes

Message : https://crfm.stanford.edu/2023/06/16/anticipatory-music-transformer.html

Tags: Symbolic music generation, infilling. Interesting for people looking to use music-transformers for co-composition.

Message : cc @91882678xxxx can you help?

Message : cc Shubham @91966057xxxx for all questions AWS including Bedrock, Code Whisperer etc

Message : Not just between 3.5 & 4, we‚Äôve had to revamp our prompts with every new update for 3.5. I‚Äôm praying it becomes more consistent soon enough.
Quoted Message : This is really frustrating. I miss consistency: given the same inputs (text, and params) will always give you same output

Message : Gets even worse when you use functions or ask it to return structured outputs
Quoted Message : We're leveraging retrieval augmented generation for our product. Noticed that prompts that work for GPT3.5 don't work for GPT4. Has anyone else seen this? I've seen people mention differences but was a little surprised as this is a fairly simple use case.

Message : The deviations are quite high. Don't have quantifiable data on it, but qualitatively, you need to rework a lot of the prompts

Message : Yes true and they upgrade it without much headroom for you to plan the migration.
Quoted Message : Not just between 3.5 & 4, we‚Äôve had to revamp our prompts with every new update for 3.5. I‚Äôm praying it becomes more consistent soon enough.

Message : Prompt engineering is truly like playing whack a mole :)

Message : You can use the hack to make chatgpt act as prompt gpt. And then it would generate the prompts for you
Quoted Message : Prompt engineering is truly like playing whack a mole :)

Message : Interesting
Quoted Message : Do we get kicked for not interacting here?

Message : I think someone mentioned streamlit already. I use it often and love it. Haven't used gradio as much as I want to though. What is preferable for a production grade app? Let's say that we need a smallish footprint as far as possible, responsive interfaces - which of these two works well? Or do we just use a custom react app of some kind?
Quoted Message : https://gradio.app/sharing-your-app

Message : You can use the hack to make chatgpt act as prompt gpt. And then it would generate the prompts for you

Message : Interesting

Message : I think someone mentioned streamlit already. I use it often and love it. Haven't used gradio as much as I want to though. What is preferable for a production grade app? Let's say that we need a smallish footprint as far as possible, responsive interfaces - which of these two works well? Or do we just use a custom react app of some kind?

Message : Isn't that the expected behavior tho, when you update a model and train it on more recent data?
Quoted Message : We're leveraging retrieval augmented generation for our product. Noticed that prompts that work for GPT3.5 don't work for GPT4. Has anyone else seen this? I've seen people mention differences but was a little surprised as this is a fairly simple use case.

Message : We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon
Quoted Message : I think someone mentioned streamlit already. I use it often and love it. Haven't used gradio as much as I want to though. What is preferable for a production grade app? Let's say that we need a smallish footprint as far as possible, responsive interfaces - which of these two works well? Or do we just use a custom react app of some kind?

Message : Something on streamlit*

Message : Not seen this
Quoted Message : We're leveraging retrieval augmented generation for our product. Noticed that prompts that work for GPT3.5 don't work for GPT4. Has anyone else seen this? I've seen people mention differences but was a little surprised as this is a fairly simple use case.

Message : Streamlit has problems in scaling you may try simple flask or any simple framework on kubernetes container apps aks and blah
Quoted Message : We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon

Message : what problems streamlit has with scaling
Quoted Message : Streamlit has problems in scaling you may try simple flask or any simple framework on kubernetes container apps aks and blah

Message : Try file upload and make aks multiple node you may see errors
Quoted Message : what problems streamlit has with scaling

Message : It is a known error which you will find in forums acknowledged by streamlit

Message : They may solve it later

Message : so the issue is only with file upload, not with scaling ?
Quoted Message : It is a known error which you will find in forums acknowledged by streamlit

Message : I got this problem and switched to flask

Message : I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case. 
But one would need to switch to more robust or popular frameworks if they want to scale and customise.

Message : This was the problem I faced  which was basic .
Quoted Message : so the issue is only with file upload, not with scaling ?

Message : Moreover this is a manifestation of a problem. The root cause is something more than file upload which I should have remembered but forgot

Message : Streamlit I use very extensively for my POC and demos to articulate something
Quoted Message : I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case. \nBut one would need to switch to more robust or popular frameworks if they want to scale and customise.

Message : Much better than presentations

Message : Goodhart‚Äôs law will kick in pretty soon :)
Quoted Message : Yes


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : It is a known error which you will find in forums acknowledged by streamlit

Message : They may solve it later

Message : so the issue is only with file upload, not with scaling ?
Quoted Message : It is a known error which you will find in forums acknowledged by streamlit

Message : I got this problem and switched to flask

Message : I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case. 
But one would need to switch to more robust or popular frameworks if they want to scale and customise.

Message : This was the problem I faced  which was basic .
Quoted Message : so the issue is only with file upload, not with scaling ?

Message : Moreover this is a manifestation of a problem. The root cause is something more than file upload which I should have remembered but forgot

Message : Streamlit I use very extensively for my POC and demos to articulate something
Quoted Message : I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case. \nBut one would need to switch to more robust or popular frameworks if they want to scale and customise.

Message : Much better than presentations

Message : Goodhart‚Äôs law will kick in pretty soon :)
Quoted Message : Yes

Message : Same, very fast uptime for POCs and demo.
Quoted Message : Streamlit I use very extensively for my POC and demos to articulate something

Message : By this time all might.have realised that I am a fan of Streamlit and it is a boon for people who struggle with JS frameworks and HTML CSS
Quoted Message : Same, very fast uptime for POCs and demo.

Message : JS frameworks are my antithesis üòÇ

Message : That‚Äôs awesome. Looking forward to it
Quoted Message : We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon

Message : https://gooey.ai/explore/\n\nStreamlit rewrite üôà
Quoted Message : That‚Äôs awesome. Looking forward to it

Message : Exactly. That‚Äôs my experience with streamlit at least. Plotly dash is interesting too but beyond simple dashboards I haven‚Äôt built anything major with it. There are even very involved and hard core R Shiny apps out there. Depending on the use cases it may suffice for some teams. But streamlit is great for quick prototypes and proof of concepts.
Quoted Message : I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case. \nBut one would need to switch to more robust or popular frameworks if they want to scale and customise.

Message : That‚Äôs awesome. Looking forward to it

Message : https://gooey.ai/explore/

Streamlit rewrite üôà

Message : Exactly. That‚Äôs my experience with streamlit at least. Plotly dash is interesting too but beyond simple dashboards I haven‚Äôt built anything major with it. There are even very involved and hard core R Shiny apps out there. Depending on the use cases it may suffice for some teams. But streamlit is great for quick prototypes and proof of concepts.

Message : There‚Äôs one design flaw with all 3 of these tools, and literally everone who‚Äôs built a python frontend framework has made too - to store per client session state on server over a websocket. This makes scaling impossible and client bundles huge for time to first render
Quoted Message : I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case. \nBut one would need to switch to more robust or popular frameworks if they want to scale and customise.

Message : How do you handle customisation? Is it possible to add responsive new components or modify components without knowledge of React js?
Quoted Message : There‚Äôs one design flaw with all 3 of these tools, and literally everone who‚Äôs built a python frontend framework has made too - to store per client session state on server over a websocket. This makes scaling impossible and client bundles huge for time to first render

Message : https://huggingface.co/mosaicml/mpt-30b

Message : Seems damn cool. 8k context length. And beats almost all other open source LLMs expect WizardCoder on HumanEval.
Quoted Message : https://huggingface.co/mosaicml/mpt-30b

Message : Mosaic has an unreliable history of changing license after release. Buyers beware

Message : Mosaic has an unreliable history of changing license after release. Buyers beware

Message : Checking with my Infra team
Quoted Message : cc @9188xxxxxxxx can you help?

Message : Base model is still apache. Their chat and instruct models are cc-by-nc. Chat model is finetuned for 1.5B tokens for 6 epochs, so total 9B tokens.  Someone else might soon finetune on some other mixture of dataset. Hopefully something like WizardMPT.
Quoted Message : Mosaic has an unreliable history of changing license after release. Buyers beware

Message : Facing an issue with the utilization of the s3boto library in the langchain system. The library's unstructured file loader fails to effectively process files with formats such as PDF or any other file extension. As a result, there is no feasible method to stream S3 files into the system, taking into account their file types, and generate embeddings.

Additionally, the problem persists with the storage of pgvector embeddings within the database. These embeddings are stored in a specific manner, making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component. The data storage approach directly affects the accuracy and effectiveness of the GPT chat system's queries.

Some guidance would be helpful.

Message : And even the base model trained on datasets that have a bundle of licences. 2 of the 3 core datasets are ODC-BY and 1 - stack dedup is a bundle of licences which isn't clear from HF info
Quoted Message : Base model is still apache. Their chat and instruct models are cc-by-nc. Chat model is finetuned for 1.5B tokens for 6 epochs, so total 9B tokens.  Someone else might soon finetune on some other mixture of dataset. Hopefully something like WizardMPT.

Message : The chat and instruct models are still CC by NC so nothing changes there for commercial use.

Message : https://inflection.ai/inflection-1

Message : Wow they're claiming they outperform even GPT3.5 on MMLU, PiQA, Hellaswag, boolq, naturalQA and GSM8k
Quoted Message : https://inflection.ai/inflection-1

Message : Inflection-1.pdf ‚Ä¢ ‚Äé7 pages ‚Äé<attached: 00009798-Inflection-1.pdf>

Message : came across these 2 useful links :
1. bunch of ai related resources in 1 place:
https://llm-utils.org/AI+Learning+Curation

2. hf nlp course
https://huggingface.co/learn/nlp-course/chapter1/1

(via https://news.ycombinator.com/item?id=36432598 )

Message : ‚Äé<attached: 00009800-PHOTO-2023-06-22-23-07-41.jpg>
Quoted Message : Wow they're claiming they outperform even GPT3.5 on MMLU, PiQA, Hellaswag, boolq, naturalQA and GSM8k

Message : 7 pager memos ftw üôå

Message : https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html
Am starting out with knowledge graph indexes, what are some good resources to get started

Message : they should publish the model card instead of marketing keywords.

Message : Have they generated the keywords using the model though?
Quoted Message : they should publish the model card instead of marketing keywords.

Message : They're calling inflection-1 to be in the same compute class as gpt 3.5 and palm 540B. Also 1000s of H100 would mean that their size is huge, probably upwards of 200B? can only speculate.

Message : I'm not sure how many people here are familiar with GOFAI techniques. There is a lot of history to symbolic AI which was powering lots of simple systems before Alex and Ilya showed how to train NNs more efficiently. We have reached a point where there are 2 broad approaches in front of us and it's not clear which one will lead to AGI sooner:
1. *Introduce symbolic AI modules as interfaces to NNs*. This is easy with LLMs because Symbolic methods like KG triplets, classical algorithms (planning/search), on-the fly code generation etc. can output text which can be fed directly into the context window of the LLM. People have started with first order logic and you'll soon witness more classic modules like second and higher order logic being interfaced with LLMs. This is the bleeding edge of AI reasearch as of June 2023.
2. *Train bigger LLMs with more carefully curated datasets like textbooks, code repos*: This is the kind of evolution Ilya talks about - that it might be possible to see reasoning capabilities emerge more strongly as we scale. It is also possible that the data requirements may not be as high as what it took to get to ChatGPT or GPT4. There are a handful of teams who are taking this approach as we speak.
Approach #1 is something many of us in this group can attempt. Classical methods are well defined and the Russell-Norvig textbook is a great place to start. You may also want to look up ideas in GOFAI projects such as Doug Lenat's CYC which took the path from KG to higher order logic modules eventually leading to a sort of semantic web.
Happy to share more info if anyone is interested in this line of research.
Quoted Message : https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html\nAm starting out with knowledge graph indexes, what are some good resources to get started

Message : For #1, I found a overview/survey paper from 2022 - https://academic.oup.com/nsr/article/9/6/nwac035/6542460


Not sure if I can do a toy training with GPT2 with this system but I would like to give it a try sometime

Message : I'm also interested in being able to teach an abstraction to a language model directly, rather than train things via unstructured data or instruction format. A language model is representative of the abstract relationship between different entities and concepts in the training data, so I was thinking if I can draw out the abstraction or update the abstraction directly via some reasoning inputs.

This isn't a well formed or grilled idea.

Message : could u explain the two problems ur facing ? 
what is the issue with s3boto - are u trying to chunk and create embeddings from pdf files in s3 ?

and what did u mean by "making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component" ?
Quoted Message : Facing an issue with the utilization of the s3boto library in the langchain system. The library's unstructured file loader fails to effectively process files with formats such as PDF or any other file extension. As a result, there is no feasible method to stream S3 files into the system, taking into account their file types, and generate embeddings.\n\nAdditionally, the problem persists with the storage of pgvector embeddings within the database. These embeddings are stored in a specific manner, making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component. The data storage approach directly affects the accuracy and effectiveness of the GPT chat system's queries.\n\nSome guidance would be helpful.

Message : Need advice on two things
1. How to implement streaming generation from scratch?

2. Has anyone successfully generated text + code (like chatgpt) with reasonable performance? Does code block identification and generation work for with fine tuning and what models are best for it?

Message : Are you wanting to implement streaming with openai models or with other models
Quoted Message : Need advice on two things\n1. How to implement streaming generation from scratch?\n\n2. Has anyone successfully generated text + code (like chatgpt) with reasonable performance? Does code block identification and generation work for with fine tuning and what models are best for it?

Message : Local model, say falcon or llama
Quoted Message : Are you wanting to implement streaming with openai models or with other models

Message : https://huggingface.co/blog/sagemaker-huggingface-llm
This is there for inference servers.
Quoted Message : Local model, say falcon or llama

Message : I checked this post. It abstract the implementation and gives the container for deployment purposes. I'm interested in learning the mechanics of it but thanks anyway.
Quoted Message : https://huggingface.co/blog/sagemaker-huggingface-llm\nThis is there for inference servers.

Message : ‚Äé<attached: 00009815-PHOTO-2023-06-23-02-01-53.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I'm not sure how many people here are familiar with GOFAI techniques. There is a lot of history to symbolic AI which was powering lots of simple systems before Alex and Ilya showed how to train NNs more efficiently. We have reached a point where there are 2 broad approaches in front of us and it's not clear which one will lead to AGI sooner:
1. *Introduce symbolic AI modules as interfaces to NNs*. This is easy with LLMs because Symbolic methods like KG triplets, classical algorithms (planning/search), on-the fly code generation etc. can output text which can be fed directly into the context window of the LLM. People have started with first order logic and you'll soon witness more classic modules like second and higher order logic being interfaced with LLMs. This is the bleeding edge of AI reasearch as of June 2023.
2. *Train bigger LLMs with more carefully curated datasets like textbooks, code repos*: This is the kind of evolution Ilya talks about - that it might be possible to see reasoning capabilities emerge more strongly as we scale. It is also possible that the data requirements may not be as high as what it took to get to ChatGPT or GPT4. There are a handful of teams who are taking this approach as we speak.
Approach #1 is something many of us in this group can attempt. Classical methods are well defined and the Russell-Norvig textbook is a great place to start. You may also want to look up ideas in GOFAI projects such as Doug Lenat's CYC which took the path from KG to higher order logic modules eventually leading to a sort of semantic web.
Happy to share more info if anyone is interested in this line of research.
Quoted Message : https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html\nAm starting out with knowledge graph indexes, what are some good resources to get started

Message : For #1, I found a overview/survey paper from 2022 - https://academic.oup.com/nsr/article/9/6/nwac035/6542460


Not sure if I can do a toy training with GPT2 with this system but I would like to give it a try sometime

Message : I'm also interested in being able to teach an abstraction to a language model directly, rather than train things via unstructured data or instruction format. A language model is representative of the abstract relationship between different entities and concepts in the training data, so I was thinking if I can draw out the abstraction or update the abstraction directly via some reasoning inputs.

This isn't a well formed or grilled idea.

Message : could u explain the two problems ur facing ? 
what is the issue with s3boto - are u trying to chunk and create embeddings from pdf files in s3 ?

and what did u mean by "making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component" ?
Quoted Message : Facing an issue with the utilization of the s3boto library in the langchain system. The library's unstructured file loader fails to effectively process files with formats such as PDF or any other file extension. As a result, there is no feasible method to stream S3 files into the system, taking into account their file types, and generate embeddings.\n\nAdditionally, the problem persists with the storage of pgvector embeddings within the database. These embeddings are stored in a specific manner, making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component. The data storage approach directly affects the accuracy and effectiveness of the GPT chat system's queries.\n\nSome guidance would be helpful.

Message : Need advice on two things
1. How to implement streaming generation from scratch?

2. Has anyone successfully generated text + code (like chatgpt) with reasonable performance? Does code block identification and generation work for with fine tuning and what models are best for it?

Message : Are you wanting to implement streaming with openai models or with other models
Quoted Message : Need advice on two things\n1. How to implement streaming generation from scratch?\n\n2. Has anyone successfully generated text + code (like chatgpt) with reasonable performance? Does code block identification and generation work for with fine tuning and what models are best for it?

Message : Local model, say falcon or llama
Quoted Message : Are you wanting to implement streaming with openai models or with other models

Message : https://huggingface.co/blog/sagemaker-huggingface-llm
This is there for inference servers.
Quoted Message : Local model, say falcon or llama

Message : I checked this post. It abstract the implementation and gives the container for deployment purposes. I'm interested in learning the mechanics of it but thanks anyway.
Quoted Message : https://huggingface.co/blog/sagemaker-huggingface-llm\nThis is there for inference servers.

Message : ‚Äé<attached: 00009815-PHOTO-2023-06-23-02-01-53.jpg>

Message : I've been working on a few use cases where LLMs can help non profits and charity events, is anyone else working on similar areas? happy to join forces

Message : Would something like chain of thought prompting and ReAct etc be considered to come from symbolic AI?
Quoted Message : I'm not sure how many people here are familiar with GOFAI techniques. There is a lot of history to symbolic AI which was powering lots of simple systems before Alex and Ilya showed how to train NNs more efficiently. We have reached a point where there are 2 broad approaches in front of us and it's not clear which one will lead to AGI sooner:\n1. *Introduce symbolic AI modules as interfaces to NNs*. This is easy with LLMs because Symbolic methods like KG triplets, classical algorithms (planning/search), on-the fly code generation etc. can output text which can be fed directly into the context window of the LLM. People have started with first order logic and you'll soon witness more classic modules like second and higher order logic being interfaced with LLMs. This is the bleeding edge of AI reasearch as of June 2023.\n2. *Train bigger LLMs with more carefully curated datasets like textbooks, code repos*: This is the kind of evolution Ilya talks about - that it might be possible to see reasoning capabilities emerge more strongly as we scale. It is also possible that the data requirements may not be as high as what it took to get to ChatGPT or GPT4. There are a handful of teams who are taking this approach as we speak.\nApproach #1 is something many of us in this group can attempt. Classical methods are well defined and the Russell-Norvig textbook is a great place to start. You may also want to look up ideas in GOFAI projects such as Doug Lenat's CYC which took the path from KG to higher order logic modules eventually leading to a sort of semantic web. \nHappy to share more info if anyone is interested in this line of research.

Message : https://twitter.com/OfirPress/status/1672021765135151107?s=20
on increasing context length of existing models by a brilliant hack

Message : DMing you
Quoted Message : could u explain the two problems ur facing ? \nwhat is the issue with s3boto - are u trying to chunk and create embeddings from pdf files in s3 ?\n\nand what did u mean by \"making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component\" ?

Message : Interesting question, but CoT is not really GOFAI which are highly interpretable. Tree of thoughts is more closer to a GOFAI module where a clear algorithm (just handcrafted heuristics) is driving the control back and forth between the LLM and a DFS/BFS tree parser. ReAct, Flare and other lookup methods help with information reuse. I see them as external memory modules, not compute. Here is an example of how I personally see a successful GOFAI module integrated with an LLM:
1. User sends question to LLM
2. LLM checks if question is mathematical or factual. If Mathematical, it sends it to a plugin(wolfram alpha) or a code generation module and retrieves the answer
3. LLM formats the final output
In this example, the LLM had to rely on an external module to calculate something. Now the LLM could use another external module to store/retrieve this information. For most "system-2" thinking modules (see Kahneman) it is not hard to use a GOFAI method as a plug-and-play module.
This leads to the question: How many such functions are there which require us to supplement the LLMs with external programs? A good place to start thinking about this would be Marvin Minsky's book - The society of mind.
I'm not sure if AGI questions are appropriate in this forum since the discussions tend to dwell on practical applications. But happy to discuss offline with anyone interested in the nature of intelligence, neuroscience basis to AI etc.
Quoted Message : Would something like chain of thought prompting and ReAct etc be considered to come from symbolic AI?

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØKiran Darisi

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØShanthi Vardhan

Message : Not tried yet , any link how to start with RAG plus gpts (one concern here documents are to be  private)
Quoted Message : Have you tried a RAG system using one of the GPTs to generate responses?

Message : You should checkout jugalbandi repo (https://github.com/OpenNyAI/jugalbandi-api)

This uses fastAPI so you can quickly host it on your own server, configure your OpenAI API Key and done. Then what remains to be done is uploading the document and asking query.

The chunking vectorisation and creating prompt to send OpenAI requests to generate response is already written in code base.
Quoted Message : Not tried yet , any link how to start with RAG plus gpts (one concern here documents are to be  private)

Message : Which asr APIs does this use?
Quoted Message : You should checkout jugalbandi repo (https://github.com/OpenNyAI/jugalbandi-api)\n\nThis uses fastAPI so you can quickly host it on your own server, configure your OpenAI API Key and done. Then what remains to be done is uploading the document and asking query.\n\nThe chunking vectorisation and creating prompt to send OpenAI requests to generate response is already written in code base.

Message : Bhashini by default but it support Google and Azure as well
Quoted Message : Which asr APIs does this use?

Message : Wait a  sec, https://asr-api.ai4bharat.org/asr/v1/recognize/ takes no api key?

Message : https://github.com/OpenNyAI/jugalbandi-api/blob/bf28c720719f211d28f3239fc55835e267e0a7cf/translator.py#L58

Message : nope
Quoted Message : Wait a  sec, https://asr-api.ai4bharat.org/asr/v1/recognize/ takes no api key?

Message : Does anyone know if there is a way to export Pinecone indices and/or collections?

Message : We are looking to move out of Pinecone to qdrant and it would be a pain if we have to re-embed all the data again.

Message : I‚Äôm not sure what is @91819726xxxx‚Äôs experience is but for me both on-premise and APIs didn‚Äôt work out in production. Didn‚Äôt work out means consistent latency wise. I‚Äôm not sure if they added more resources after that, so it could have changed.
Quoted Message : Wait a  sec, https://asr-api.ai4bharat.org/asr/v1/recognize/ takes no api key?

Message : Don't know how to but curious what lead you to this decision? Might be useful for others as well.
Quoted Message : We are looking to move out of Pinecone to qdrant and it would be a pain if we have to re-embed all the data again.

Message : I would not recommend Bhashini for APIs for production as it is Govt. of India's project and they are building and hosting a GPU cluster. My recommendation would be to move to Azure for this. It has good coverage of language and has better quality as well.
Quoted Message : I‚Äôm not sure what is @9181xxxxxxxx‚Äôs experience is but for me both on-premise and APIs didn‚Äôt work out in production. Didn‚Äôt work out means consistent latency wise. I‚Äôm not sure if they added more resources after that, so it could have changed.

Message : For production grade, speech models for low resourced indian languages like Bhojpuri or Haryanvi, what would you suggest Saurabh ?
Quoted Message : I would not recommend Bhashini for APIs for production as it is Govt. of India's project and they are building and hosting a GPU cluster. My recommendation would be to move to Azure for this. It has good coverage of language and has better quality as well.

Message : Azure has better speech to text for indic languages? üòµ
Quoted Message : I would not recommend Bhashini for APIs for production as it is Govt. of India's project and they are building and hosting a GPU cluster. My recommendation would be to move to Azure for this. It has good coverage of language and has better quality as well.

Message : It would be useful to have a primary DB where all of the indexed data is stored. Seems you are on OpenAI emb. Moving to open source emb will eliminate reindex cost issue. But that‚Äôs a research effort.
Quoted Message : We are looking to move out of Pinecone to qdrant and it would be a pain if we have to re-embed all the data again.

Message : Na na. Wait. üòÖ multiple things, model quality, GPU availability. My recommendation isn‚Äôt with respect to just model quality but also production readiness
Quoted Message : Azure has better speech to text for indic languages? üòµ

Message : Ok sorry talking about model quality üòÖ
Quoted Message : Na na. Wait. üòÖ multiple things, model quality, GPU availability. My recommendation isn‚Äôt with respect to just model quality but also production readiness

Message : We are not seeing good retrieval quality on Pinecone for a production level system. When embedding thousands of documents, it is giving irrelevant results. 
Same thing with other vector dbs is working well. Also, we need hybrid search.
Quoted Message : Don't know how to but curious what lead you to this decision? Might be useful for others as well.

Message : That's why we moved completely to Azure like two months back, and have Bhasini, and GCP as first and second backups. I have talked to Azure speech research team and also heard from other folks using Azure. Other reason being MS team working closely with Bhasini.
Quoted Message : I would not recommend Bhashini for APIs for production as it is Govt. of India's project and they are building and hosting a GPU cluster. My recommendation would be to move to Azure for this. It has good coverage of language and has better quality as well.

Message : How ever we signed MoU with Intel where they want to help on scale for Bhasini, and then working with some Indie hacker folks to see If I can optimize Bhasini models for production.

Message : Yes, we are using OpenAI embeddings. Haven't tried the other embeddings yet. How does it compare in terms of the quality?
Quoted Message : It would be useful to have a primary DB where all of the indexed data is stored. Seems you are on OpenAI emb. Moving to open source emb will eliminate reindex cost issue. But that‚Äôs a research effort.

Message : why would u need to re-embed the data ? genuine question - does pinecone transform the data formats to make it non portable ?
Quoted Message : We are looking to move out of Pinecone to qdrant and it would be a pain if we have to re-embed all the data again.

Message : I doubt it should be because of the vector DB but probably because of the library you are using or some implementation bug.
Quoted Message : We are not seeing good retrieval quality on Pinecone for a production level system. When embedding thousands of documents, it is giving irrelevant results. \nSame thing with other vector dbs is working well. Also, we need hybrid search.

Message : ‚Äé<attached: 00009846-PHOTO-2023-06-23-11-11-27.jpg>

Message : As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db.
Seems they dont allow exporting the collections, in which case we would have to embed the data again to be put into the new vector db.
Quoted Message : why would u need to re-embed the data ? genuine question - does pinecone transform the data formats to make it non portable ?

Message : And pinecone also has hybrid search
Quoted Message : I doubt it should be because of the vector DB but probably because of the library you are using or some implementation bug.

Message : But openai api does it keep docs private,here concern is they don't want to use chatgpt or openai as it's legal documents it might get leaked..not sure
Quoted Message : You should checkout jugalbandi repo (https://github.com/OpenNyAI/jugalbandi-api)\n\nThis uses fastAPI so you can quickly host it on your own server, configure your OpenAI API Key and done. Then what remains to be done is uploading the document and asking query.\n\nThe chunking vectorisation and creating prompt to send OpenAI requests to generate response is already written in code base.

Message : I don't have bandwidth to work on models for quantization or oprimization, so I am taking help from any where possible. Bhasini should be optimized for production and we should be able to host and run optimally, otherwise all the hoopla after Sama's comment will be just chest bumping.

Message : Similar metrics as per benchmarks but would still require testing to see if it‚Äôs actually true
Quoted Message : Yes, we are using OpenAI embeddings. Haven't tried the other embeddings yet. How does it compare in terms of the quality?

Message : i did NOT know that pinecone doesnt allow export.
Quoted Message : As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db.\nSeems they dont allow exporting the collections, in which case we would have to embed the data again to be put into the new vector db.

Message : That's something we are testing out as well. But also in general pinecone hybrid search is not as seamless to implement as the one on qdrant or weaviate.
Quoted Message : I doubt it should be because of the vector DB but probably because of the library you are using or some implementation bug.

Message : Right, will try that.
Quoted Message : Similar metrics as per benchmarks but would still require testing to see if it‚Äôs actually true

Message : Are you referring to the tokeniser problem? Pinecone also has support for SPLADE which would bump performance hopefully. I don‚Äôt know if others have it
Quoted Message : That's something we are testing out as well. But also in general pinecone hybrid search is not as seamless to implement as the one on qdrant or weaviate.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00009846-PHOTO-2023-06-23-11-11-27.jpg>

Message : As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db.
Seems they dont allow exporting the collections, in which case we would have to embed the data again to be put into the new vector db.
Quoted Message : why would u need to re-embed the data ? genuine question - does pinecone transform the data formats to make it non portable ?

Message : And pinecone also has hybrid search
Quoted Message : I doubt it should be because of the vector DB but probably because of the library you are using or some implementation bug.

Message : But openai api does it keep docs private,here concern is they don't want to use chatgpt or openai as it's legal documents it might get leaked..not sure
Quoted Message : You should checkout jugalbandi repo (https://github.com/OpenNyAI/jugalbandi-api)\n\nThis uses fastAPI so you can quickly host it on your own server, configure your OpenAI API Key and done. Then what remains to be done is uploading the document and asking query.\n\nThe chunking vectorisation and creating prompt to send OpenAI requests to generate response is already written in code base.

Message : I don't have bandwidth to work on models for quantization or oprimization, so I am taking help from any where possible. Bhasini should be optimized for production and we should be able to host and run optimally, otherwise all the hoopla after Sama's comment will be just chest bumping.

Message : Similar metrics as per benchmarks but would still require testing to see if it‚Äôs actually true
Quoted Message : Yes, we are using OpenAI embeddings. Haven't tried the other embeddings yet. How does it compare in terms of the quality?

Message : i did NOT know that pinecone doesnt allow export.
Quoted Message : As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db.\nSeems they dont allow exporting the collections, in which case we would have to embed the data again to be put into the new vector db.

Message : That's something we are testing out as well. But also in general pinecone hybrid search is not as seamless to implement as the one on qdrant or weaviate.
Quoted Message : I doubt it should be because of the vector DB but probably because of the library you are using or some implementation bug.

Message : Right, will try that.
Quoted Message : Similar metrics as per benchmarks but would still require testing to see if it‚Äôs actually true

Message : Are you referring to the tokeniser problem? Pinecone also has support for SPLADE which would bump performance hopefully. I don‚Äôt know if others have it
Quoted Message : That's something we are testing out as well. But also in general pinecone hybrid search is not as seamless to implement as the one on qdrant or weaviate.

Message : SPLADE hybrid > Emb model tokeniser hybrid > simple tokeniser hybrid

Message : https://www.pinecone.io/learn/hybrid-search-intro/

Message : What do u mean by pinecone has support for a tokeniser ? Cos tokenisation and embedding generation would happen BEFORE insert into vector db.
Quoted Message : Are you referring to the tokeniser problem? Pinecone also has support for SPLADE which would bump performance hopefully. I don‚Äôt know if others have it

Message : It seems to be in private preview right? Have you tried it?
Quoted Message : SPLADE hybrid > Emb model tokeniser hybrid > simple tokeniser hybrid

Message : Any db would be agnostic to the input tokeniser u use to split your data right ?

Message : Any db would be agnostic to the input tokeniser u use to split your data right ?

Message : I haven‚Äôt tried it yet. It‚Äôs a 3 month old blog and I think it must be GA now.
Quoted Message : It seems to be in private preview right? Have you tried it?

Message : In my understanding, Pinecone supports sparse vectors which allows indexing with any tokeniser while the other ones does not expose this and handle tokenisation internally for hybrid.
Quoted Message : Any db would be agnostic to the input tokeniser u use to split your data right ?

Message : Yeah, there was also some nvidia research in this area last year. It was SoTA at that time but don't know the current status for eye positioning.

Message : For hybrid you need one hot token vectors also to be indexed
Quoted Message : In my understanding, Pinecone supports sparse vectors which allows indexing with any tokeniser while the other ones does not expose this and handle tokenisation internally for hybrid.

Message : You can come as you please but you can't leave the same üòÇ
If you stay and build everything on pinecone so that migration costs become incredibly high, how would anybody leave
Quoted Message : As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db.\nSeems they dont allow exporting the collections, in which case we would have to embed the data again to be put into the new vector db.

Message : Getting quite costly too
Quoted Message : You can come as you please but you can't leave the same üòÇ\nIf you stay and build everything on pinecone so that migration costs become incredibly high, how would anybody leave

Message : I don't know why anyone will choose Pinecone. Any serious developers I know have left them longtime back. Every other OSS one has enough documentation now.

Message : Do Qdrant and Weaviate allow export?
Quoted Message : You can come as you please but you can't leave the same üòÇ\nIf you stay and build everything on pinecone so that migration costs become incredibly high, how would anybody leave

Message : Qdrant does I believe
Quoted Message : Do Qdrant and Weaviate allow export?

Message : Hi Saman, I'm the co-founder of Typesense (https://github.com/typesense/typesense). We support hybrid vector search in the upcoming version and as well as automatic embedding of content using E5 model (both on CPU and GPU). Happy to chat about it or anything related to embeddings/search.
Quoted Message : As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db.\nSeems they dont allow exporting the collections, in which case we would have to embed the data again to be put into the new vector db.

Message : We just went with them because they seemed the most prod ready but at this point probably a good idea to move out
Quoted Message : I don't know why anyone will choose Pinecone. Any serious developers I know have left them longtime back. Every other OSS one has enough documentation now.

Message : Did not find anything on google!
Quoted Message : Qdrant does I believe

Message : How to solve this issue
Quoted Message : There‚Äôs one design flaw with all 3 of these tools, and literally everone who‚Äôs built a python frontend framework has made too - to store per client session state on server over a websocket. This makes scaling impossible and client bundles huge for time to first render

Message : Which open source solution do they prefer?
Quoted Message : I don't know why anyone will choose Pinecone. Any serious developers I know have left them longtime back. Every other OSS one has enough documentation now.

Message : I like and use weaviate

Message : Dev mentioned this yesterday as what they implemented - "We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon"
Quoted Message : How to solve this issue

Message : Store state on the client and do server side rendering. I‚Äôm using HTML forms too for state so it all works even after disabling Javascript
Quoted Message : How to solve this issue

Message : Hey Kishore, happy to test it out. Is anyone else using this on prod right now?
Quoted Message : Hi Saman, I'm the co-founder of Typesense (https://github.com/typesense/typesense). We support hybrid vector search in the upcoming version and as well as automatic embedding of content using E5 model (both on CPU and GPU). Happy to chat about it or anything related to embeddings/search.

Message : but how to do streaming in that case ?
Quoted Message : Store state on the client and do server side rendering. I‚Äôm using HTML forms too for state so it all works even after disabling Javascript

Message : You underestimate marketing. Also openai pinecone arrangement
Quoted Message : I don't know why anyone will choose Pinecone. Any serious developers I know have left them longtime back. Every other OSS one has enough documentation now.

Message : Redis pub/sub + server sent events
Quoted Message : but how to do streaming in that case ?

Message : Isn't pub/sub a 2 way communication and server sent one way communication?

Message : We have had pure vector search for over a year and so many production users. We've implemented hybrid search for the next version (due for release in a few weeks) and we have been testing the RC build with customers, some of whom are using it on production as well. We also support openai and google vertex embedding integration out of the box. I can share details on DM.
Quoted Message : Hey Kishore, happy to test it out. Is anyone else using this on prod right now?

Message : I was recommended to use weaviate by OpenAI from the early days of KissanAI ü§∑‚Äç‚ôÇÔ∏è
Quoted Message : You underestimate marketing. Also openai pinecone arrangement

Message : When was this? The pinecone partnership came out in March with the launch of plugins
Quoted Message : I was recommended to use weaviate by OpenAI from the early days of KissanAI ü§∑‚Äç‚ôÇÔ∏è

Message : Yes. But only use redis as one way publish to push to clients from long running tasks in the server
Quoted Message : Isn't pub/sub a 2 way communication and server sent one way communication?

Message : Before that

Message : Cool
Quoted Message : Before that

Message : Pinecone had done a huge announcement of their partnership in March and later also raised a ton on money. I'm assuming for marketing purposes

Message : Yes. Had used in an earlier project which involved rabbitmq
Quoted Message : Yes. But only use redis as one way publish to push to clients from long running tasks in the server

Message : What vector db is recommended to use for prod right now?

Message : Also, for open source dbs, are folks self hosting or using hosted versions?

Message : Related question - how does Pinecone compare to the likes of Milvus, Weaviate?

Message : Also, has anyone tried Mongo vector db yet? Any benchmarks?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : When was this? The pinecone partnership came out in March with the launch of plugins
Quoted Message : I was recommended to use weaviate by OpenAI from the early days of KissanAI ü§∑‚Äç‚ôÇÔ∏è

Message : Yes. But only use redis as one way publish to push to clients from long running tasks in the server
Quoted Message : Isn't pub/sub a 2 way communication and server sent one way communication?

Message : Before that

Message : Cool
Quoted Message : Before that

Message : Pinecone had done a huge announcement of their partnership in March and later also raised a ton on money. I'm assuming for marketing purposes

Message : Yes. Had used in an earlier project which involved rabbitmq
Quoted Message : Yes. But only use redis as one way publish to push to clients from long running tasks in the server

Message : What vector db is recommended to use for prod right now?

Message : Also, for open source dbs, are folks self hosting or using hosted versions?

Message : Related question - how does Pinecone compare to the likes of Milvus, Weaviate?

Message : Also, has anyone tried Mongo vector db yet? Any benchmarks?

Message : Is there a good study published on what different GenerativeAI companies are doing currently and what kinds of trends are emerging across? Preferably not from a VC's perspective

Message : Interested for the same, currently using pinecone for testing but want to move out before getting locked in some way
Quoted Message : What vector db is recommended to use for prod right now?

Message : Not sure who else (what persona) will keep track of the market if not VCs
Quoted Message : Is there a good study published on what different GenerativeAI companies are doing currently and what kinds of trends are emerging across? Preferably not from a VC's perspective

Message : redis/elasticsearch thats what we integrate in edgechains
Quoted Message : Which open source solution do they prefer?

Message : Sounds controversial to me
Quoted Message : redis/elasticsearch thats what we integrate in edgechains

Message : oh so u save both the embeddings and the one-hot together ? and then pinecone internally tokenizes the one-hot. this is something i had no idea that was how hybrid search worked.
wouldnt this blow up storage costs
Quoted Message : For hybrid you need one hot token vectors also to be indexed

Message : How does Elasticsearch perform for hybrid search? Any thoughts?
Quoted Message : redis/elasticsearch thats what we integrate in edgechains

Message : Costs are blown up for vector search as well IMO
Quoted Message : oh so u save both the embeddings and the one-hot together ? and then pinecone internally tokenizes the one-hot. this is something i had no idea that was how hybrid search worked.\nwouldnt this blow up storage costs

Message : fairly built in. u can create composite rankings or for advanced usecases create a plugin. 
composite rankings in elasticsearch are a very OLD and classic usecase. I mean we have all used it for zillion years.

it has suddenly got rebranded as hybrid search.
Quoted Message : How does Elasticsearch perform for hybrid search? Any thoughts?

Message : Kindly do not go that path
Quoted Message : How does Elasticsearch perform for hybrid search? Any thoughts?

Message : there's no hybrid search in qdrant. is there?
Quoted Message : That's something we are testing out as well. But also in general pinecone hybrid search is not as seamless to implement as the one on qdrant or weaviate.

Message : i know of several banks and LARGE enterprises that are running this in production. redis and elasticsearch are the only game in town if u need compliance as well. no other db is getting ISO/SOC2 certifications in india.
Quoted Message : Kindly do not go that path

Message : incidentally Elasticsearch is the only exabyte scale infra that i know of. so i will respectfully disagree

Message : Pinecone has soc2 no?
Quoted Message : i know of several banks and LARGE enterprises that are running this in production. redis and elasticsearch are the only game in town if u need compliance as well. no other db is getting ISO/SOC2 certifications in india.

Message : I think both Weaviate and Pinecone must have soc 2 type 2. My disagreement is more because of cost and latency. Selection will depend on how many vectors are indexed & latency. In some cases ES would work out.
Quoted Message : i know of several banks and LARGE enterprises that are running this in production. redis and elasticsearch are the only game in town if u need compliance as well. no other db is getting ISO/SOC2 certifications in india.

Message : wont transitively pass in india. in india, ull have to recertify. they are not passing it. 
also it is potentially violative of India data residency guidelines if u are carrying PII data for lack of india datacenter..but this may not apply to you.

independent of this, redis and elasticsearch are almost 2 decades tested in large scale production. i would take a stand that they are as (if not more) stable

Message : It has Gong as customer. So definitely type 2
Quoted Message : Pinecone has soc2 no?

Message : AI grant has scaled to >$1M per winner, no equity
https://aigrant.org/

Message : again challenge to prove. all of them are using HNSW lib underneath. elasticsearch also. with the added future outlook that Java Panama vector API is being natively built into elasticsearch https://github.com/apache/lucene/pull/12311 

so im taking the stand that it is already best of breed and probably will get better
Quoted Message : I think both Weaviate and Pinecone must have soc 2 type 2. My disagreement is more because of cost and latency. Selection will depend on how many vectors are indexed & latency. In some cases ES would work out.

Message : this means that in a year, we will have GPU SIMD accelerated vector search built into ES via Panama. I think thats a great bet.

Message : Okay I do not have clarity on the PII scrubbing and storage
Quoted Message : wont transitively pass in india. in india, ull have to recertify. they are not passing it. \nalso it is potentially violative of India data residency guidelines if u are carrying PII data for lack of india datacenter..but this may not apply to you.\n\nindependent of this, redis and elasticsearch are almost 2 decades tested in large scale production. i would take a stand that they are as (if not more) stable

Message : How easy/difficult is it to fine tune Whisper for different accents or special terminology?

Message : Interesting take. Maybe later everyone converge to similar and it boils down to implementation efficiency of Rust(Pinecone) Vs Java(ES) Vs Go(Weaviate)
Quoted Message : again challenge to prove. all of them are using HNSW lib underneath. elasticsearch also. with the added future outlook that Java Panama vector API is being natively built into elasticsearch https://github.com/apache/lucene/pull/12311 \n\nso im taking the stand that it is already best of breed and probably will get better

Message : i wouldnt look at it that way. i will say that pgvector has AWS managed support (https://aws.amazon.com/about-aws/whats-new/2023/05/amazon-rds-postgresql-pgvector-ml-model-integration/) and Elasticsearch and redis have the same. 

so u have vendor agnostic, exabyte scale infra supported by even AWS. and potentially self host at some point if u want.

thats the way i would look at it.

Message : I had conversation with Hersh, for Indian startups you will need Delaware corp if selected.
Quoted Message : AI grant has scaled to >$1M per winner, no equity\nhttps://aigrant.org/

Message : How many vectors are you looking at and what are the dimension sizes?
Quoted Message : I think both Weaviate and Pinecone must have soc 2 type 2. My disagreement is more because of cost and latency. Selection will depend on how many vectors are indexed & latency. In some cases ES would work out.

Message : Anyone working on ETL/DevOps automation using GenAI? Have a few ideas would like to discuss

Message : That‚Äôs great! My thinking is more around cost and latency rather than security (assuming all can scale well). It will be helpful if we find any analysis on this front to compare them all.
Quoted Message : i wouldnt look at it that way. i will say that pgvector has AWS managed support (https://aws.amazon.com/about-aws/whats-new/2023/05/amazon-rds-postgresql-pgvector-ml-model-integration/) and Elasticsearch and redis have the same. \n\nso u have vendor agnostic, exabyte scale infra supported by even AWS. and potentially self host at some point if u want. \n\nthats the way i would look at it.

Message : Let‚Äôs say 10M single index no filtering 768 dim
Quoted Message : How many vectors are you looking at and what are the dimension sizes?

Message : Interesting , any other benefits of raising from them over VCs apart from no equity?
Quoted Message : I had conversation with Hersh, for Indian startups you will need Delaware corp if selected.

Message : They are better than most VCs? And compute cluster larger than clouds?
Quoted Message : Interesting , any other benefits of raising from them over VCs apart from no equity?

Message : Compute part is clear .
Was curious to know before applying in what ways are they better than most VC ?
Quoted Message : They are better than most VCs? And compute cluster larger than clouds?

Message : They know what they're talking about? ü´£
Quoted Message : Compute part is clear .\nWas curious to know before applying in what ways are they better than most VC ?

Message : ‚Äé<attached: 00009928-PHOTO-2023-06-23-12-44-23.jpg>
Quoted Message : Compute part is clear .\nWas curious to know before applying in what ways are they better than most VC ?

Message : Makes sense , was hoping if someone could speak from personal experience .
Have been following Nat and Daniel . Does sound exciting üõ§Ô∏è

Message : Happening today, organized by Nathan Benaich

https://raais.co/

livestream :
https://www.youtube.com/watch?v=RHfSBsYOI6Y

Message : Yesterday someone asked about hosting options for an LLM web app, if you dont want to learn a web app framework

i stumbled onto modal.com today

pricing :
https://modal.com/pricing

was curious has anyone tried modal ?
if y, what was your experience like ?

Message : I've tried it. It's amazing when it works,
Quoted Message : Yesterday someone asked about hosting options for an LLM web app, if you dont want to learn a web app framework\n\ni stumbled onto modal.com today\n\npricing :\nhttps://modal.com/pricing\n\nwas curious has anyone tried modal ?\nif y, what was your experience like ?

Message : Aside, for the meetup tomorrow, please ping @91740765xxxx for invites. He's the one making the invite list. Not me. 

I believe about 20 slots are left. Please be kind if he has to say no.

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96876¬†35888‚Ä¨


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : They are better than most VCs? And compute cluster larger than clouds?
Quoted Message : Interesting , any other benefits of raising from them over VCs apart from no equity?

Message : Compute part is clear .
Was curious to know before applying in what ways are they better than most VC ?
Quoted Message : They are better than most VCs? And compute cluster larger than clouds?

Message : They know what they're talking about? ü´£
Quoted Message : Compute part is clear .\nWas curious to know before applying in what ways are they better than most VC ?

Message : ‚Äé<attached: 00009928-PHOTO-2023-06-23-12-44-23.jpg>
Quoted Message : Compute part is clear .\nWas curious to know before applying in what ways are they better than most VC ?

Message : Makes sense , was hoping if someone could speak from personal experience .
Have been following Nat and Daniel . Does sound exciting üõ§Ô∏è

Message : Happening today, organized by Nathan Benaich

https://raais.co/

livestream :
https://www.youtube.com/watch?v=RHfSBsYOI6Y

Message : Yesterday someone asked about hosting options for an LLM web app, if you dont want to learn a web app framework

i stumbled onto modal.com today

pricing :
https://modal.com/pricing

was curious has anyone tried modal ?
if y, what was your experience like ?

Message : I've tried it. It's amazing when it works,
Quoted Message : Yesterday someone asked about hosting options for an LLM web app, if you dont want to learn a web app framework\n\ni stumbled onto modal.com today\n\npricing :\nhttps://modal.com/pricing\n\nwas curious has anyone tried modal ?\nif y, what was your experience like ?

Message : Aside, for the meetup tomorrow, please ping @91740765xxxx for invites. He's the one making the invite list. Not me. 

I believe about 20 slots are left. Please be kind if he has to say no.

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96876¬†35888‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†87095¬†14839‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99582¬†39176‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99016¬†56836‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98276¬†63323‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99118¬†27834‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†93806¬†18232‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAjay

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAkarsh

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†94460¬†39897‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+1¬†(267)¬†503‚Äë3691‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†70839¬†83807‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†75888¬†31185‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAmanMulani

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†74090¬†02027‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAnand V

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†6360¬†090¬†212‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99360¬†80872‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99714¬†98525‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†81781¬†69023‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†72595¬†09827‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAnmol Sonthalia

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†82773¬†73975‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†81291¬†33473‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAnuj

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98345¬†07609‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99325¬†80573‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†94900¬†07575‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAravind

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96051¬†66123‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØArpit Sharma

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØArun

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAryan

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96002¬†55895‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAshutosh Agarwal

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAshwin

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†72043¬†70321‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAvikalp Kumar Gupta

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØBalamurali A R

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99325¬†44235‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØBhaskar


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé~‚ÄØNirant removed ~‚ÄØArun

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAryan

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†96002¬†55895‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAshutosh Agarwal

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAshwin

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†72043¬†70321‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØAvikalp Kumar Gupta

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØBalamurali A R

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†99325¬†44235‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØBhaskar

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†98456¬†75592‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+1¬†(206)¬†319‚Äë8247‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†82374¬†29120‚Ä¨

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØDeepak Khatri

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØDhanush

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†97093¬†63616‚Ä¨

Message : https://twitter.com/karpathy/status/1671587087542530049?t=864c5-CnpaISCvt8vNSYYw&s=19

Message : Does anybody have any reviews about the courses from Nic Renotte?

Message : Or any other beginner friendly course recommendations?

Message : This one is for beginners https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home - nice course by Databricks featuring Matei Zaharia and others

Message : ‚Äé<attached: 00009986-PHOTO-2023-06-23-15-25-06.jpg>

Message : Any product folks here building in Generative AI ? I'd like to pick your brains on an MVP that we are set to launch.

Message : ?

Message : If you're comfortable sharing a quick preview, lot of builders would be happy to share feedback!

Message : We want to think in the direction of Generative AI being a part of our product strategy probably later in time. But for MVP how can we minimally think towards that direction is my question

Message : We're building genAI products in my team, happy to chat
Quoted Message : Any product folks here building in Generative AI ? I'd like to pick your brains on an MVP that we are set to launch.

Message : It'll help to know what Gen AI is capable of first whether in terms of audio, vision or text fields. 
Anything that is currently possible in state of the art can then be tested to be a feature in some of your existing products. For example, an edtech can test if AI can act as a tutor reliably and an e-commerce can test if AI can act as a customer service or shopping assistant reliably or simply offer recommendations in the background.
Quoted Message : We want to think in the direction of Generative AI being a part of our product strategy probably later in time. But for MVP how can we minimally think towards that direction is my question

Message : By knowing what's possible in vision, audio and text you can then chain these things together to create a completely new product as well. For example, given an image of clothes that a person has in their wardrobe we can answer 2 questions easily:
1. What pairs can go together for a certain occasion or mood?
2. What can we shop for to find similar or complementary stuff?

Message : It's just an example. But along these lines, knowing what's possible allows you to think of replacing existing features or add components in your product. Or build a completely new one from the ground.

Message : I lead product. Happy to brainstorm.
Quoted Message : Any product folks here building in Generative AI ? I'd like to pick your brains on an MVP that we are set to launch.

Message : Lead ML at my firm - and we have couple of GenAI products to go to production pretty soon next quarter. 

Happy to walk you through how we went about breaking the problem statement and evaluation steps
Quoted Message : We want to think in the direction of Generative AI being a part of our product strategy probably later in time. But for MVP how can we minimally think towards that direction is my question

Message : Happy to help üëçüèΩ .. currently working on MVPs in financial services
Quoted Message : We want to think in the direction of Generative AI being a part of our product strategy probably later in time. But for MVP how can we minimally think towards that direction is my question

Message : I think for this range almost all vector DBs work fine. ChromaDB with a local file system should also work. I have run it for 1 million index with no issues.
Depending on your use case maybe a regular faiss index works?
Quoted Message : Let‚Äôs say 10M single index no filtering 768 dim

Message : Correct on this.

I only work with large production systems, so my viewpoint is colored by it. But if ur prototyping or small scale, just use FAISS or redis. Both run locally and very lightweight.

FAISS if ur in the python ecosystem since u need c-library to load faiss. Redis/chromadb otherwise.
Quoted Message : I think for this range almost all vector DBs work fine. ChromaDB with a local file system should also work. I have run it for 1 million index with no issues.\nDepending on your use case maybe a regular faiss index works?

Message : For the love of God, please don't use Chroma and shoot your mem utilisation to the roof
Quoted Message : Correct on this.\n\nI only work with large production systems, so my viewpoint is colored by it. But if ur prototyping or small scale, just use FAISS or redis. Both run locally and very lightweight.\n\nFAISS if ur in the python ecosystem since u need c-library to load faiss. Redis/chromadb otherwise.

Message : https://twitter.com/rowancheung/status/1671893629751939077?t=xotImYsHeIRPrJiTcnGw7g&s=19

This is very cool, love this.

Message : https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/

Message : What are some good open source data annotation tools?

Message : CVAT works really well for image annotation
Quoted Message : What are some good open source data annotation tools?

Message : Looking for text.
Looking open source. Idea is to manually add data on my own time. Wanting to create a dataset to try to fine-tune LLMs based on what I learnt over the past years of using them
Quoted Message : CVAT works really well for image annotation

Message : Have you tried doccano?
Quoted Message : Looking for text.\nLooking open source. Idea is to manually add data on my own time. Wanting to create a dataset to try to fine-tune LLMs based on what I learnt over the past years of using them

Message : had tried a while back, will check again.
Quoted Message : Have you tried doccano?

Message : for cloud based nosql dbs , which one gives the best amount of storage on a free tier, like over a GB. Mongodb atlas gives around 512mb

Message : Argilla
Quoted Message : What are some good open source data annotation tools?

Message : also a city in Italy, TIL
Quoted Message : Argilla

Message : TIL too
Quoted Message : also a city in Italy, TIL

Message : https://twitter.com/ericmitchellai/status/1671943972829433856?t=QQK1NbVYt_04XuvWj_Sarg&s=08

Message : Found this implementation for DPO RLHF yesterday. It doesn't need reward models or RL. It's a simpler way to do RLHF or to learn for reference.

Message : If you are doing something related to segmentation you could additionally use Segment Anything Model (SAM) to speed things up
Quoted Message : CVAT works really well for image annotation

Message : AudioPaLM: A Large Language Model That Can Speak and Listen 

https://google-research.github.io/seanet/audiopalm/examples/

abstract : arxiv.org/abs/2306.12925

With voicebox from Meta, whisper from openai, the speech space is heating up ! :)


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Have you tried doccano?
Quoted Message : Looking for text.\nLooking open source. Idea is to manually add data on my own time. Wanting to create a dataset to try to fine-tune LLMs based on what I learnt over the past years of using them

Message : had tried a while back, will check again.
Quoted Message : Have you tried doccano?

Message : for cloud based nosql dbs , which one gives the best amount of storage on a free tier, like over a GB. Mongodb atlas gives around 512mb

Message : Argilla
Quoted Message : What are some good open source data annotation tools?

Message : also a city in Italy, TIL
Quoted Message : Argilla

Message : TIL too
Quoted Message : also a city in Italy, TIL

Message : https://twitter.com/ericmitchellai/status/1671943972829433856?t=QQK1NbVYt_04XuvWj_Sarg&s=08

Message : Found this implementation for DPO RLHF yesterday. It doesn't need reward models or RL. It's a simpler way to do RLHF or to learn for reference.

Message : If you are doing something related to segmentation you could additionally use Segment Anything Model (SAM) to speed things up
Quoted Message : CVAT works really well for image annotation

Message : AudioPaLM: A Large Language Model That Can Speak and Listen 

https://google-research.github.io/seanet/audiopalm/examples/

abstract : arxiv.org/abs/2306.12925

With voicebox from Meta, whisper from openai, the speech space is heating up ! :)

Message : Yea but only if meta and google release api for commercial use. Demos look hot.
Quoted Message : AudioPaLM: A Large Language Model That Can Speak and Listen \n\nhttps://google-research.github.io/seanet/audiopalm/examples/\n\nabstract : arxiv.org/abs/2306.12925\n\nWith voicebox from Meta, whisper from openai, the speech space is heating up ! :)

Message : 100% expect commercial api by Google by the end of the year 
Meta - not so sure, but might just
Quoted Message : Yea but only if meta and google release api for commercial use. Demos look hot.

Message : Absolutely.. this has huge potential in both streaming and podcasting industry
Quoted Message : AudioPaLM: A Large Language Model That Can Speak and Listen \n\nhttps://google-research.github.io/seanet/audiopalm/examples/\n\nabstract : arxiv.org/abs/2306.12925\n\nWith voicebox from Meta, whisper from openai, the speech space is heating up ! :)

Message : On that note, what‚Äôs the best lip synching and face morphing library you guys have seen (to go with text to speech Audio)

Message : You could listen to a French podcast, in Hindi, for example !

Endless possibilities in education & health too.

What if Khan academy videos recorded by Sal Khan ( in a strong American accent) could be heard by a kid in a village in Bihar in bhojpuri ?
Quoted Message : Absolutely.. this has huge potential in both streaming and podcasting industry

Message : And, elevenlabs updated their model as well haha marketing teams fighting out for the voice share 

https://twitter.com/elevenlabsio/status/1672238899874217985?s=46&t=dSB_vXgXsC6qhF1TYEKlZw
Quoted Message : AudioPaLM: A Large Language Model That Can Speak and Listen \n\nhttps://google-research.github.io/seanet/audiopalm/examples/\n\nabstract : arxiv.org/abs/2306.12925\n\nWith voicebox from Meta, whisper from openai, the speech space is heating up ! :)

Message : Indeed.. when Zuck announced first time on his Instagram broadcast channel.. I was shell shocked..because it was done without huge media fanfare or publicity.. I am bullish on Zuck through his open LLMs and such cool features announcements almost every week

Message : In academia, Prof Jawahar's group at IIIT Hyderabad has done amazing work on lip reading and lip syncing in video 

http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild
Quoted Message : On that note, what‚Äôs the best lip synching and face morphing library you guys have seen (to go with text to speech Audio)

Message : Deep Fakes tools does it well.. but that dilutes authenticity.. here with audio Palm it still retains the original with runtime speech or voice modifications and translation
Quoted Message : On that note, what‚Äôs the best lip synching and face morphing library you guys have seen (to go with text to speech Audio)

Message : Do they have an API. Don‚Äôt see on their site.
Quoted Message : In academia, Prof Jawahar's group at IIIT Hyderabad has done amazing work on lip reading and lip syncing in video \n\nhttp://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild

Message : Suggest options with commercial api availability please for lip synching üôè

Message : Yeah and movies wouldn't need to be dubbed in any language at all. Probably not so good for voice actors.
Quoted Message : You could listen to a French podcast, in Hindi, for example !\n\nEndless possibilities in education & health too.\n\nWhat if Khan academy videos recorded by Sal Khan ( in a strong American accent) could be heard by a kid in a village in Bihar in bhojpuri ?

Message : More research-y, less product-y

Not sure if they are trying to commercialize it,
they work with MSR & Zoom among others.

You could try contacting them
Quoted Message : Do they have an API. Don‚Äôt see on their site.

Message : https://www.thehindubusinessline.com/info-tech/way2lip-promises-to-reduce-drudgery-in-video-content-creation/article65388110.ece
Quoted Message : More research-y, less product-y\n\nNot sure if they are trying to commercialize it,\nthey work with MSR & Zoom among others.\n\nYou could try contacting them

Message : https://www.neuralsyncai.com/#products
Quoted Message : https://www.thehindubusinessline.com/info-tech/way2lip-promises-to-reduce-drudgery-in-video-content-creation/article65388110.ece

Message : You could contact him:
https://rudrabha.github.io/

Message : Agree with FAISS
Quoted Message : Correct on this.\n\nI only work with large production systems, so my viewpoint is colored by it. But if ur prototyping or small scale, just use FAISS or redis. Both run locally and very lightweight.\n\nFAISS if ur in the python ecosystem since u need c-library to load faiss. Redis/chromadb otherwise.

Message : *Most curious thing I read today -* https://kaiokendev.github.io/til#extending-context-to-8k

*TLDR -A GitHub user by the name of kaiokendev tried an experiment to increase context length of llama models from 2k to 8k by scaling the frequency window by 0.25, strangely it worked and this is a way to understand how*
RoPE is a technique that allows transformers to handle longer sequences by encoding the position of each token into a vector. This vector is then added to the token‚Äôs representation before feeding it into the transformer. The position encoding is based on a frequency window, which determines how many different positions can be distinguished by the transformer.

The question is about what happens if we change the frequency window of RoPE by scaling it down by a factor of 0.25. This means that the position encoding will have more steps in between, so that each position will look like it is closer to the beginning of the sequence. For example, position 1 will look like position 0.25, position 40 will look like position 10, and position 2048 will look like position 512.

Message : Have tried to use elasticsearch (opensearch, on aws) as vector index with their approx knn plugin. Faced a lot of issues where the knn circuit breaker would get triggered, after which no index operations could be performed and search would slow down significantly. At the peak, for around 12M vectors (with some metadata), we were using r5.2xlarge instances with 6 data nodes and 2 master nodes (with 200gb ebs volumes), costing around ~$2k/month. 

Another thing is opensearch knn plugin does not support prefiltering (filtering out based on some criteria and then doing approx knn).

Shifted to Weaviate and the bill went down drastically + search latency improved as Weaviate supports prefiltering
Quoted Message : How does Elasticsearch perform for hybrid search? Any thoughts?

Message : elasticsearch does have pre-filtering with cosine similarity on dense vectors right ? it uses the SHOULD array and u can combine them both. so "match" will have ur filter query and script_score will have ur cosine similarity
Quoted Message : Have tried to use elasticsearch (opensearch, on aws) as vector index with their approx knn plugin. Faced a lot of issues where the knn circuit breaker would get triggered, after which no index operations could be performed and search would slow down significantly. At the peak, for around 12M vectors (with some metadata), we were using r5.2xlarge instances with 6 data nodes and 2 master nodes (with 200gb ebs volumes), costing around ~$2k/month. \n\nAnother thing is opensearch knn plugin does not support prefiltering (filtering out based on some criteria and then doing approx knn). \n\nShifted to Weaviate and the bill went down drastically + search latency improved as Weaviate supports prefiltering

Message : ‚Äé<attached: 00010037-PHOTO-2023-06-23-23-13-41.jpg>
Quoted Message : elasticsearch does have pre-filtering with cosine similarity on dense vectors right ? it uses the SHOULD array and u can combine them both. so \"match\" will have ur filter query and script_score will have ur cosine similarity

Message : Is there a repository or list for AI tools to make music?

Message : yes. 
I had used the same with ES 6.8 (old days) :')
(by implementing my own cosine sim script_score function)
Quoted Message : elasticsearch does have pre-filtering with cosine similarity on dense vectors right ? it uses the SHOULD array and u can combine them both. so \"match\" will have ur filter query and script_score will have ur cosine similarity

Message : How has the experience with weaveate been?
Quoted Message : Have tried to use elasticsearch (opensearch, on aws) as vector index with their approx knn plugin. Faced a lot of issues where the knn circuit breaker would get triggered, after which no index operations could be performed and search would slow down significantly. At the peak, for around 12M vectors (with some metadata), we were using r5.2xlarge instances with 6 data nodes and 2 master nodes (with 200gb ebs volumes), costing around ~$2k/month. \n\nAnother thing is opensearch knn plugin does not support prefiltering (filtering out based on some criteria and then doing approx knn). \n\nShifted to Weaviate and the bill went down drastically + search latency improved as Weaviate supports prefiltering

Message : yes. ANN is already in. been a year. not sure if this is exactly what you want...but it is the general usecase that many use. 
https://www.elastic.co/blog/introducing-approximate-nearest-neighbor-search-in-elasticsearch-8-0

Message : I am looking for a dataset or service providing company name aliases. For example HP == Hewlett Packard, PWC = Price Waterhouse Coopers.
Is there such a dataset or service?

Message : Pretty good. It has handled whatever load we've thrown at it (around 16M vectors), the community is good, and they're actively releasing new features
Quoted Message : How has the experience with weaveate been?

Message : Nice! Are you using their hosted version or self hosted? 
Also, with or without hybrid search?
Quoted Message : Pretty good. It has handled whatever load we've thrown at it (around 16M vectors), the community is good, and they're actively releasing new features

Message : I think for the hosted version they charge both for vector dimensions as well as queries whereas other dbs only charge for storing N vectors.

Message : Ah, this recent finding has been used many years ago but just in a different context. It's extremely similar to Convolutional Recurrent Neural Network, by authors whose names I don't recall. 

They had a convolutional layer to extract features, followed by an RNN for sequence processing - the same old song, just a different singer.
Quoted Message : *Most curious thing I read today -* https://kaiokendev.github.io/til#extending-context-to-8k\n\n*TLDR -A GitHub user by the name of kaiokendev tried an experiment to increase context length of llama models from 2k to 8k by scaling the frequency window by 0.25, strangely it worked and this is a way to understand how*\nRoPE is a technique that allows transformers to handle longer sequences by encoding the position of each token into a vector. This vector is then added to the token‚Äôs representation before feeding it into the transformer. The position encoding is based on a frequency window, which determines how many different positions can be distinguished by the transformer.\n\nThe question is about what happens if we change the frequency window of RoPE by scaling it down by a factor of 0.25. This means that the position encoding will have more steps in between, so that each position will look like it is closer to the beginning of the sequence. For example, position 1 will look like position 0.25, position 40 will look like position 10, and position 2048 will look like position 512.

Message : Who knew you could achieve that just by changing a line or two in transformers based LLMs

Message : https://arxiv.org/abs/1602.05875

Message : AI of 2016 still relevant today

Message : Hope newcomers in the field take this as great motivation. The field is not moving too fast for you to feel out of control. Significant contributions can be made if you understand the insides of these supposed black boxes.

Message : Convolution layer was pretty much the de facto feature extractor before transformers

Message : Still is, for images
Quoted Message : Convolution layer was pretty much the de facto feature extractor before transformers

Message : ViT hasn‚Äôt been widely adopted, especially for memory/compute constrained edge deployment

Message : ‚Äé<attached: 00010054-PHOTO-2023-06-24-00-18-36.jpg>
Quoted Message : Convolution layer was pretty much the de facto feature extractor before transformers

Message : ‚Äé<attached: 00010056-PHOTO-2023-06-24-00-21-06.jpg>

Message : Which model is being describes here?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Who knew you could achieve that just by changing a line or two in transformers based LLMs

Message : https://arxiv.org/abs/1602.05875

Message : AI of 2016 still relevant today

Message : Hope newcomers in the field take this as great motivation. The field is not moving too fast for you to feel out of control. Significant contributions can be made if you understand the insides of these supposed black boxes.

Message : Convolution layer was pretty much the de facto feature extractor before transformers

Message : Still is, for images
Quoted Message : Convolution layer was pretty much the de facto feature extractor before transformers

Message : ViT hasn‚Äôt been widely adopted, especially for memory/compute constrained edge deployment

Message : ‚Äé<attached: 00010054-PHOTO-2023-06-24-00-18-36.jpg>
Quoted Message : Convolution layer was pretty much the de facto feature extractor before transformers

Message : ‚Äé<attached: 00010056-PHOTO-2023-06-24-00-21-06.jpg>

Message : Which model is being describes here?

Message : Context
Quoted Message : *Most curious thing I read today -* https://kaiokendev.github.io/til#extending-context-to-8k\n\n*TLDR -A GitHub user by the name of kaiokendev tried an experiment to increase context length of llama models from 2k to 8k by scaling the frequency window by 0.25, strangely it worked and this is a way to understand how*\nRoPE is a technique that allows transformers to handle longer sequences by encoding the position of each token into a vector. This vector is then added to the token‚Äôs representation before feeding it into the transformer. The position encoding is based on a frequency window, which determines how many different positions can be distinguished by the transformer.\n\nThe question is about what happens if we change the frequency window of RoPE by scaling it down by a factor of 0.25. This means that the position encoding will have more steps in between, so that each position will look like it is closer to the beginning of the sequence. For example, position 1 will look like position 0.25, position 40 will look like position 10, and position 2048 will look like position 512.

Message : has anyone successfully run HF transformers pipelines on mac m1 chip? whenever I try a model, there's some or the other unsupported pytorch operation

Message : I don't exactly remember my pytorch version but I didn't face any issues on M2 pro. It could be an issue with your config.

Message : This is exactly what we are using and not faced any issue. But we don't have 1M records though. But latency is low and we have all data together in postgresql. Only one component we need to monitor at production.
Quoted Message : i wouldnt look at it that way. i will say that pgvector has AWS managed support (https://aws.amazon.com/about-aws/whats-new/2023/05/amazon-rds-postgresql-pgvector-ml-model-integration/) and Elasticsearch and redis have the same. \n\nso u have vendor agnostic, exabyte scale infra supported by even AWS. and potentially self host at some point if u want. \n\nthats the way i would look at it.

Message : A businessy article from me for a change :)
https://greylock.com/greymatter/the-new-new-moats/

Message : Absolutely. Look at deBERTa eval scores for example and if you‚Äôre use case fits then BERT based models can take you much further, sometimes even more than massive unwieldy LLMs.
Quoted Message : Hope newcomers in the field take this as great motivation. The field is not moving too fast for you to feel out of control. Significant contributions can be made if you understand the insides of these supposed black boxes.

Message : Also https://github.com/BlinkDL/RWKV-LM for old+newer approaches

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØLucifer üòé

Message : ‚Äé~‚ÄØRavi Theja added ‚Ä™+91¬†87670¬†91009‚Ä¨

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØAshish

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØUdit

Message : Hey folks, Udit here! 
Yesterday we launched Supervised AI (a layer 2 AI infra).

3 months ago, I launched Sttabot which now powers 8000+ businesses' AI infra.

I am a solo founder and would love to connect to you guys and share my insights :)

Message : Hey folks, Udit here! \nYesterday we launched Supervised AI (a layer 2 AI infra).\n\n3 months ago, I launched Sttabot which now powers 8000+ businesses' AI infra.\n\nI am a solo founder and would love to connect to you guys and share my insights :)

Message : Congratulations! What‚Äôs layer 2?
Quoted Message : Hey folks, Udit here! \nYesterday we launched Supervised AI (a layer 2 AI infra).\n\n3 months ago, I launched Sttabot which now powers 8000+ businesses' AI infra.\n\nI am a solo founder and would love to connect to you guys and share my insights :)

Message : Where AI's responses are not only limited by GPT's data sources but trains upon your data for precision + GPT for generating answers.
Quoted Message : Congratulations! What‚Äôs layer 2?

Message : You can find more about it on OpenAI docs
Quoted Message : Where AI's responses are not only limited by GPT's data sources but trains upon your data for precision + GPT for generating answers.

Message : Any link to docs &/ casestudies ?
Quoted Message : Hey folks, Udit here! \nYesterday we launched Supervised AI (a layer 2 AI infra).\n\n3 months ago, I launched Sttabot which now powers 8000+ businesses' AI infra.\n\nI am a solo founder and would love to connect to you guys and share my insights :)

Message : Hey, would love to chat more. Ping me :-)
Quoted Message : Hey folks, Udit here! \nYesterday we launched Supervised AI (a layer 2 AI infra).\n\n3 months ago, I launched Sttabot which now powers 8000+ businesses' AI infra.\n\nI am a solo founder and would love to connect to you guys and share my insights :)

Message : "Layer 2" is simultaneously the best and worst branding I've seen for a Colab notebook. Impressed with the mktg chops on this.
Quoted Message : Where AI's responses are not only limited by GPT's data sources but trains upon your data for precision + GPT for generating answers.

Message : Invites are against email ids, no swaps

Message : What‚Äôs the venue?
Quoted Message : Invites are against email ids, no swaps

Message : Shared with invited folks. Will email maps and navigation instructions around 3:30 PM
Quoted Message : What‚Äôs the venue?

Message : Please ping @91740765xxxx for the invites and approvals. He's the one sending them out

Message : https://github.com/OptimalScale/LMFlow

Message : https://github.com/OptimalScale/LMFlow

Message : https://github.com/neuralmagic/deepsparse

Message : Has anyone tried this neural magic ?
Quoted Message : https://github.com/neuralmagic/deepsparse

Message : Sure
Quoted Message : Hey, would love to chat more. Ping me :-)

Message : I‚Äôm not in it seems. But I understand. Hopefully next time.
Quoted Message : Please ping @9174xxxxxxxx for the invites and approvals. He's the one sending them out

Message : This is interesting.
Quoted Message : https://github.com/neuralmagic/deepsparse

Message : Folk's what are the topics for today's meetup ?

Message : https://hasgeek.com/generativeAI/june-meetup/\nah I forgot to register :/

Message : Your mention of deberta reminded me of this list of models trained by Microsoft.\nEverytime you need to fine tune BERT for something general, don't.\nUse this instead - https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table.html
Quoted Message : Absolutely. Look at deBERTa eval scores for example and if you‚Äôre use case fits then BERT based models can take you much further, sometimes even more than massive unwieldy LLMs.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØLakshmi Narayana LN

Message : https://hasgeek.com/generativeAI/june-meetup/
ah I forgot to register :/

Message : Your mention of deberta reminded me of this list of models trained by Microsoft.
Everytime you need to fine tune BERT for something general, don't.
Use this instead - https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table.html

Message : is anyone using Sagemaker Jumpstart for serving models ? https://tinyurl.com/y3pksx73 . how was the experience ?

Message : ‚Äé<attached: 00010099-PHOTO-2023-06-24-18-05-51.jpg>

Message : I got access to LLm powered chatbot.

The funny thing is it's answering any questions i ask.

The developer of said product deals with Fintech.

I'm wondering how does one prevent the abuse of such bots ( which are proxy to mostly chat gpt) to only contextual domain ! ?

Message : ‚Äé<attached: 00010101-PHOTO-2023-06-24-18-09-04.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Folk's what are the topics for today's meetup ?

Message : https://hasgeek.com/generativeAI/june-meetup/\nah I forgot to register :/

Message : Your mention of deberta reminded me of this list of models trained by Microsoft.\nEverytime you need to fine tune BERT for something general, don't.\nUse this instead - https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table.html
Quoted Message : Absolutely. Look at deBERTa eval scores for example and if you‚Äôre use case fits then BERT based models can take you much further, sometimes even more than massive unwieldy LLMs.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØLakshmi Narayana LN

Message : https://hasgeek.com/generativeAI/june-meetup/
ah I forgot to register :/

Message : Your mention of deberta reminded me of this list of models trained by Microsoft.
Everytime you need to fine tune BERT for something general, don't.
Use this instead - https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table.html

Message : is anyone using Sagemaker Jumpstart for serving models ? https://tinyurl.com/y3pksx73 . how was the experience ?

Message : ‚Äé<attached: 00010099-PHOTO-2023-06-24-18-05-51.jpg>

Message : I got access to LLm powered chatbot.

The funny thing is it's answering any questions i ask.

The developer of said product deals with Fintech.

I'm wondering how does one prevent the abuse of such bots ( which are proxy to mostly chat gpt) to only contextual domain ! ?

Message : ‚Äé<attached: 00010101-PHOTO-2023-06-24-18-09-04.jpg>

Message : I doubt such queries will be passed bu their checks if open ais api is used

Message : This could be an older model like da vinci or maybe even a custom model

Message : Yes they're using da vinci-003

Message : It was awesome
Quoted Message : is anyone using Sagemaker Jumpstart for serving models ? https://tinyurl.com/y3pksx73 . how was the experience ?

Message : I tried and deployed cost of inference hardware would be around 7 dollar per hour

Message : were u using ml.m5d.24xlarge ? 
cos on https://aws.amazon.com/sagemaker/pricing/ , it shows all the way from 0.2$ ?
Quoted Message : I tried and deployed cost of inference hardware would be around 7 dollar per hour

Message : Yo can try Serverless deployments for saving infra cost
Quoted Message : I tried and deployed cost of inference hardware would be around 7 dollar per hour

Message : Along with the default "you are a fintech expert ..." prompt, you cab additionally place checks like "for every question asked, evaluate how relevant the question is, answer only when...." etc
Quoted Message : I got access to LLm powered chatbot.\n\nThe funny thing is it's answering any questions i ask.\n\nThe developer of said product deals with Fintech.\n\nI'm wondering how does one prevent the abuse of such bots ( which are proxy to mostly chat gpt) to only contextual domain ! ?

Message : Most likely they're doing this, but this won't work for da Vinci models that well. Which also happens to be the default in langchain...
Quoted Message : Along with the default \"you are a fintech expert ...\" prompt, you cab additionally place checks like \"for every question asked, evaluate how relevant the question is, answer only when....\" etc

Message : Langchain default being terrible is something which escapes me
Quoted Message : Most likely they're doing this, but this won't work for da Vinci models that well. Which also happens to be the default in langchain...

Message : I think we expect too much of a servile  attitude from LLMs. I think I want LLMs which when asked ‚Äúdo you hallucinate‚Äù with ‚Äúdon‚Äôt you?‚Äù as the response
Quoted Message : I got access to LLm powered chatbot.\n\nThe funny thing is it's answering any questions i ask.\n\nThe developer of said product deals with Fintech.\n\nI'm wondering how does one prevent the abuse of such bots ( which are proxy to mostly chat gpt) to only contextual domain ! ?

Message : Microsoft learned from their Tay experience.  iykyk üòÇ
Quoted Message : I think we expect too much of a servile  attitude from LLMs. I think I want LLMs which when asked ‚Äúdo you hallucinate‚Äù with ‚Äúdon‚Äôt you?‚Äù as the response

Message : You want generation to only be restricted to your context. That's prompt engineering
Quoted Message : I got access to LLm powered chatbot.\n\nThe funny thing is it's answering any questions i ask.\n\nThe developer of said product deals with Fintech.\n\nI'm wondering how does one prevent the abuse of such bots ( which are proxy to mostly chat gpt) to only contextual domain ! ?

Message : Prompt validation, may be ?
Quoted Message : You want generation to only be restricted to your context. That's prompt engineering

Message : Prompt engineering works well here. We've done it with prompt engineering for our retrieval based generations to not hallucinate pretty well

Message : A trick I use is to ask the LLM to not use their own knowledge and only the one in the prompt that ensures it's grounded

Message : Provide directions in markup
Quoted Message : Prompt engineering works well here. We've done it with prompt engineering for our retrieval based generations to not hallucinate pretty well

Message : You want generation to only be restricted to your context. That's prompt engineering

Message : Prompt validation, may be ?

Message : Prompt engineering works well here. We've done it with prompt engineering for our retrieval based generations to not hallucinate pretty well

Message : A trick I use is to ask the LLM to not use their own knowledge and only the one in the prompt that ensures it's grounded

Message : Provide directions in markup

Message : May I have the group invitation link ?

Message : May I have the group invitation link ?

Message : Hi, I had a few questions about testing chatbots. We've discussed options here like Rasa's testing capabilities before but I'd like to know if there are any test case or test plan strategies someone is already using for LLM based testing. For instance - how do we deal with variability in LLM output? Does vector / semantic similarity matching work at scale for evaluating such outputs? Are there any other ways to test chat bots?

Message : I built this and we are keeping a count of how many unrelated questions has a user asked and the limit right now is very high so people can enjoy free Chat GPT on WhatsApp


so far it's beneficial when people engage and share more for free access as it unlocks more surface area üòÑ
Quoted Message : I got access to LLm powered chatbot.\n\nThe funny thing is it's answering any questions i ask.\n\nThe developer of said product deals with Fintech.\n\nI'm wondering how does one prevent the abuse of such bots ( which are proxy to mostly chat gpt) to only contextual domain ! ?

Message : BharatGPT is here!

Message : https://www.linkedin.com/posts/amitabh-nag-56039b5_generativeai-conversationalai-ai-activity-7078333831048499200-nh7n?utm_source=share&utm_medium=member_ios

Message : No no. See the post. You will know what I mean.
Quoted Message : BharatGPT is here!

Message : üòÇ
Quoted Message : No no. See the post. You will know what I mean.

Message : ‚Äé~‚ÄØKShivendu added ~‚ÄØAnjineyulu

Message : We are using for finetuning and dev testing - production next quarter. Things are a bit wobbly sometimes but AWS support helps
Quoted Message : is anyone using Sagemaker Jumpstart for serving models ? https://tinyurl.com/y3pksx73 . how was the experience ?

Message : But was it hard to restrict the usage to only fintech domain?
Quoted Message : I built this and we are keeping a count of how many unrelated questions has a user asked and the limit right now is very high so people can enjoy free Chat GPT on WhatsApp\n\n\nso far it's beneficial when people engage and share more for free access as it unlocks more surface area üòÑ

Message : nopes. I'm already categorising everytime what someone has asked into related or not and then letting the model answer if user has asked < N "unrelated questions" yet

so I could set N to 0 and it'll be restricted
Quoted Message : But was it hard to restrict the usage to only fintech domain?

Message : Peak community success, creator is here to explain internal deets!
Quoted Message : I built this and we are keeping a count of how many unrelated questions has a user asked and the limit right now is very high so people can enjoy free Chat GPT on WhatsApp\n\n\nso far it's beneficial when people engage and share more for free access as it unlocks more surface area üòÑ

Message : ‚Äé<attached: 00010147-PHOTO-2023-06-24-21-27-26.jpg>

Message : this message has been deleted

Message : /9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABsbGxscGx4hIR4qLSgtKj04MzM4PV1CR0JHQl2NWGdYWGdYjX2Xe3N7l33gsJycsOD/2c7Z//////////////8BGxsbGxwbHiEhHiotKC0qPTgzMzg9XUJHQkdCXY1YZ1hYZ1iNfZd7c3uXfeCwnJyw4P/Zztn////////////////CABEIAEgAHwMBIgACEQEDEQH/xAAvAAACAwEAAAAAAAAAAAAAAAACBAADBQEBAQEBAQEAAAAAAAAAAAAAAAABAgME/9oADAMBAAIQAxAAAADJnT1miMJjJCQaTKpo1WWeguhtY3M5dWeXc15ODGSO2yJ//8QAJBAAAgEEAgIBBQAAAAAAAAAAAAECAxEhMRJBEyJRFCMyQmH/2gAIAQEAAT8ATcvXocEuyzHIp34n5YGmlnRU3gp2cYlrMzJ2aKqtJop24rJzzs8juybuyjx8P9JLOhwaTwPZQf20cXfoqxagyTTeilK0V6tiqpfqydZSi1YeylJqCL7yPeyphl4dNl18nJfJD6d35Nn/xAAcEQACAAcAAAAAAAAAAAAAAAAAAQIDEBIgIUH/2gAIAQIBAT8AwT0iZwvY4m6//8QAFxEBAQEBAAAAAAAAAAAAAAAAEQEAMP/aAAgBAwEBPwDjYwTf/9k= 2023_06_24_212726_48EF777A6E7D50114D6EE0D9AA6A7364.jpeg
Quoted Message : Peak community success, creator is here to explain internal deets!

Message : It did not give me ICICI bank details, despite following your bot option

Message : ‚Äé<attached: 00010150-PHOTO-2023-06-24-21-29-30.jpg>
Quoted Message : It did not give me ICICI bank details, despite following your bot option


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé~‚ÄØKShivendu added ~‚ÄØAnjineyulu

Message : We are using for finetuning and dev testing - production next quarter. Things are a bit wobbly sometimes but AWS support helps
Quoted Message : is anyone using Sagemaker Jumpstart for serving models ? https://tinyurl.com/y3pksx73 . how was the experience ?

Message : But was it hard to restrict the usage to only fintech domain?
Quoted Message : I built this and we are keeping a count of how many unrelated questions has a user asked and the limit right now is very high so people can enjoy free Chat GPT on WhatsApp\n\n\nso far it's beneficial when people engage and share more for free access as it unlocks more surface area üòÑ

Message : nopes. I'm already categorising everytime what someone has asked into related or not and then letting the model answer if user has asked < N "unrelated questions" yet

so I could set N to 0 and it'll be restricted
Quoted Message : But was it hard to restrict the usage to only fintech domain?

Message : Peak community success, creator is here to explain internal deets!
Quoted Message : I built this and we are keeping a count of how many unrelated questions has a user asked and the limit right now is very high so people can enjoy free Chat GPT on WhatsApp\n\n\nso far it's beneficial when people engage and share more for free access as it unlocks more surface area üòÑ

Message : ‚Äé<attached: 00010147-PHOTO-2023-06-24-21-27-26.jpg>

Message : this message has been deleted

Message : /9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABsbGxscGx4hIR4qLSgtKj04MzM4PV1CR0JHQl2NWGdYWGdYjX2Xe3N7l33gsJycsOD/2c7Z//////////////8BGxsbGxwbHiEhHiotKC0qPTgzMzg9XUJHQkdCXY1YZ1hYZ1iNfZd7c3uXfeCwnJyw4P/Zztn////////////////CABEIAEgAHwMBIgACEQEDEQH/xAAvAAACAwEAAAAAAAAAAAAAAAACBAADBQEBAQEBAQEAAAAAAAAAAAAAAAABAgME/9oADAMBAAIQAxAAAADJnT1miMJjJCQaTKpo1WWeguhtY3M5dWeXc15ODGSO2yJ//8QAJBAAAgEEAgIBBQAAAAAAAAAAAAECAxEhMRJBEyJRFCMyQmH/2gAIAQEAAT8ATcvXocEuyzHIp34n5YGmlnRU3gp2cYlrMzJ2aKqtJop24rJzzs8juybuyjx8P9JLOhwaTwPZQf20cXfoqxagyTTeilK0V6tiqpfqydZSi1YeylJqCL7yPeyphl4dNl18nJfJD6d35Nn/xAAcEQACAAcAAAAAAAAAAAAAAAAAAQIDEBIgIUH/2gAIAQIBAT8AwT0iZwvY4m6//8QAFxEBAQEBAAAAAAAAAAAAAAAAEQEAMP/aAAgBAwEBPwDjYwTf/9k= 2023_06_24_212726_48EF777A6E7D50114D6EE0D9AA6A7364.jpeg
Quoted Message : Peak community success, creator is here to explain internal deets!

Message : It did not give me ICICI bank details, despite following your bot option

Message : ‚Äé<attached: 00010150-PHOTO-2023-06-24-21-29-30.jpg>
Quoted Message : It did not give me ICICI bank details, despite following your bot option

Message : If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any admin (other than me!) for an invite link.\n\nWe'll also ask for your friends Github/Linkedin, since we want to have more makers. \n\ne.g. Soumyadeep @9174xxxxxxxx

Message : ‚ò†Ô∏è

Message : noted - will solve \n\nfor other folks who are going to try this and have some feedback, please DM me\n\nif you have any question on how to LLM hack images, data, etc - feel free to ask on group itself

Message : If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any admin (other than me!) for an invite link.

We'll also ask for your friends Github/Linkedin, since we want to have more makers.

e.g. Soumyadeep @91740765xxxx

Message : ‚ò†Ô∏è

Message : noted - will solve 

for other folks who are going to try this and have some feedback, please DM me

if you have any question on how to LLM hack images, data, etc - feel free to ask on group itself

Message : ‚Äé~‚ÄØPranjal Mehta added ~‚ÄØApurv

Message : performance ok ? which model are u using ? we are planning to use falcon
Quoted Message : We are using for finetuning and dev testing - production next quarter. Things are a bit wobbly sometimes but AWS support helps

Message : why does langchain still use davinci as default? Doesn't 3.5-turbo still work better, even for non chat tasks?

Message : For agents GPT4 works significantly better in our experiments so far.

Message : ‚Äé<attached: 00010161-PHOTO-2023-06-25-01-02-51.jpg>

Message : works with 3.5-turbo as well quite nicely

Message : I generally paste each section, get it to explain it to me and then do the complete reading again. def super helpful for quick parsing/absorption

Message : Falcon, flan T5 and a couple more . Performance is good, but nothing to support real time streaming, so going mostly async
Quoted Message : performance ok ? which model are u using ? we are planning to use falcon

Message : The texbooks are all you need paper and Orca paper both emphasize the need for high quality datasets. But they contradict on a couple of things. Namely size of the model and the amount of high quality data. Textbooks tries to achieve it on a smaller scale compared to Orca paper. Interestingly both by microsoft research.

Message : Of course one thing to note is, the paper focuses on LLMS trained for code.
Quoted Message : The texbooks are all you need paper and Orca paper both emphasize the need for high quality datasets. But they contradict on a couple of things. Namely size of the model and the amount of high quality data. Textbooks tries to achieve it on a smaller scale compared to Orca paper. Interestingly both by microsoft research.

Message : The nuance in the textbook paper is that the model was trained for 7 epochs. Essentially 50B tokens. There was this assumption earlier that the corpus should be entirely unique. https://arxiv.org/abs/2305.16264 this paper showed that upto 4 epochs they saw no issue and the loss kept decreasing. In other words, there was still more signal left in the dataset even after going over it multiple times.
Quoted Message : The texbooks are all you need paper and Orca paper both emphasize the need for high quality datasets. But they contradict on a couple of things. Namely size of the model and the amount of high quality data. Textbooks tries to achieve it on a smaller scale compared to Orca paper. Interestingly both by microsoft research.

Message : Can you explain the second part again?
Quoted Message : The nuance in the textbook paper is that the model was trained for 7 epochs. Essentially 50B tokens. There was this assumption earlier that the corpus should be entirely unique. https://arxiv.org/abs/2305.16264 this paper showed that upto 4 epochs they saw no issue and the loss kept decreasing. In other words, there was still more signal left in the dataset even after going over it multiple times.

Message : In case you dont have a lot of data, you can train a Language model by training it with your data on multiple epochs. This paper showed that upto 4 epochs, the loss for the model decreased in a similar fashion as if you had unique data. Simply put, 50B tokens x 4 epochs loss = 200B unique tokens x 1 epoch loss

Message : Ok got it. Was confused because they also focused on deduplicating the data. Have to read that part closely.

This was also something karpathy and Yan le cunn were talking about  last year I believe.
Quoted Message : In case you dont have a lot of data, you can train a Language model by training it with your data on multiple epochs. This paper showed that upto 4 epochs, the loss for the model decreased in a similar fashion as if you had unique data. Simply put, 50B tokens x 4 epochs loss = 200B unique tokens x 1 epoch loss

Message : The other work the textbook paper took inspiration from is  https://arxiv.org/abs/2305.07759. This paper essentially studies the question ‚Äúhow small can a model be and still produce coherent english‚Äù, they produce a synthetic high quality dataset and train a model less than 10M parameters in size which generates coherent english.
Quoted Message : Of course one thing to note is, the paper focuses on LLMS trained for code.

Message : This paper is still interesting because the Orca paper had significantly more data and also a decent number of epochs, Think it was 4 epochs for 5M data set rows and 1M data set rows . So 8 epochs in total. So am interested to see if this is because this paper focused on code or this model can be generally used as well in other tasks like RAG
Quoted Message : In case you dont have a lot of data, you can train a Language model by training it with your data on multiple epochs. This paper showed that upto 4 epochs, the loss for the model decreased in a similar fashion as if you had unique data. Simply put, 50B tokens x 4 epochs loss = 200B unique tokens x 1 epoch loss

Message : If it does, then boy do I have some good data to fine-tune and test it on. But interesting to see this textbook type data

Message : I like this paper and the Orca paper. They have been pretty easy to read and understand and GPT-4 is also a good assistant here

Message : btw, I wanted to know if anyone has tried building FinTech specific chatbots. My team is currently working on something similar. We are trying to build a ChatBot using GPT4 which can answer user's queries by getting the relevant data from our DB. I can elaborate further if you want any specific details..

Message : btw, I wanted to know if anyone has tried building FinTech specific chatbots. My team is currently working on something similar. We are trying to build a ChatBot using GPT4 which can answer user's queries by getting the relevant data from our DB. I can elaborate further if you want any specific details..

Message : @91838580xxxx
Quoted Message : btw, I wanted to know if anyone has tried building FinTech specific chatbots. My team is currently working on something similar. We are trying to build a ChatBot using GPT4 which can answer user's queries by getting the relevant data from our DB. I can elaborate further if you want any specific details..

Message : Would be curious to learn more on this as well. 

We would like to do the same for Ecommerce use case wherein we want the user to be able to connect their read-only DB or connect their API, get real time data from there and then pass that into an LLM.
Quoted Message : btw, I wanted to know if anyone has tried building FinTech specific chatbots. My team is currently working on something similar. We are trying to build a ChatBot using GPT4 which can answer user's queries by getting the relevant data from our DB. I can elaborate further if you want any specific details..

Message : Hey all! 
We are looking for an AI consultant at GoCodeo. The platform automates software testing through AI. Hit me up if anyone's keen to solve the problem of testing.

Message : Please DM
Quoted Message : Hey all! \nWe are looking for an AI consultant at GoCodeo. The platform automates software testing through AI. Hit me up if anyone's keen to solve the problem of testing.

Message : Ethan Mollick got to try out multimodal GPT4

https://www.oneusefulthing.org/p/on-giving-ai-eyes-and-ears

The Cambrian explosion of progress continues !

Message : ‚Äé<attached: 00010181-PHOTO-2023-06-25-11-04-51.jpg>

Message : Hey Samanyou and Darshan, we can help with this. Will continue on dms
Quoted Message : Would be curious to learn more on this as well. \n\nWe would like to do the same for Ecommerce use case wherein we want the user to be able to connect their read-only DB or connect their API, get real time data from there and then pass that into an LLM.

Message : Use spot vms üòÇ‚ù§Ô∏è

Message : i can be of help. If interested, you can DM me as well
Quoted Message : Hey all! \nWe are looking for an AI consultant at GoCodeo. The platform automates software testing through AI. Hit me up if anyone's keen to solve the problem of testing.

Message : ‚Äé<attached: 00010185-PHOTO-2023-06-25-11-26-57.jpg>

Message : Could apply to any team building on the cloud as well. Even in big companies where you've to go to the CFO and board meetings and make a business case for investing in AI. Infra, GPUs, data collection and processing - all expensive. Not to mention the elephant in the room - AI engineer/dev salaries :D

Message : Anybody here had a chance to try multimodal GPT4 ?
Quoted Message : Ethan Mollick got to try out multimodal GPT4\n\nhttps://www.oneusefulthing.org/p/on-giving-ai-eyes-and-ears\n\nThe Cambrian explosion of progress continues !

Message : Hey Folks, I have a question when using a vector store and embedding for a chat-based product, how do you handle negative queries. For Eg if a user says find me documents which don't contain a particular concept -> how is that handled by vector db and embedding space.  I have had mixed results using open aI embedding model .  Most of the times searching for "not <concept>" in the vector store produces results containing the concept with highest match

Message : Instead of negative prompt will it work if you rank the matching scores in order of least matches first and return top-n least matching ? S
Quoted Message : Hey Folks, I have a question when using a vector store and embedding for a chat-based product, how do you handle negative queries. For Eg if a user says find me documents which don't contain a particular concept -> how is that handled by vector db and embedding space.  I have had mixed results using open aI embedding model .  Most of the times searching for \"not <concept>\" in the vector store produces results containing the concept with highest match


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Ethan Mollick got to try out multimodal GPT4

https://www.oneusefulthing.org/p/on-giving-ai-eyes-and-ears

The Cambrian explosion of progress continues !

Message : ‚Äé<attached: 00010181-PHOTO-2023-06-25-11-04-51.jpg>

Message : Hey Samanyou and Darshan, we can help with this. Will continue on dms
Quoted Message : Would be curious to learn more on this as well. \n\nWe would like to do the same for Ecommerce use case wherein we want the user to be able to connect their read-only DB or connect their API, get real time data from there and then pass that into an LLM.

Message : Use spot vms üòÇ‚ù§Ô∏è

Message : i can be of help. If interested, you can DM me as well
Quoted Message : Hey all! \nWe are looking for an AI consultant at GoCodeo. The platform automates software testing through AI. Hit me up if anyone's keen to solve the problem of testing.

Message : ‚Äé<attached: 00010185-PHOTO-2023-06-25-11-26-57.jpg>

Message : Could apply to any team building on the cloud as well. Even in big companies where you've to go to the CFO and board meetings and make a business case for investing in AI. Infra, GPUs, data collection and processing - all expensive. Not to mention the elephant in the room - AI engineer/dev salaries :D

Message : Anybody here had a chance to try multimodal GPT4 ?
Quoted Message : Ethan Mollick got to try out multimodal GPT4\n\nhttps://www.oneusefulthing.org/p/on-giving-ai-eyes-and-ears\n\nThe Cambrian explosion of progress continues !

Message : Hey Folks, I have a question when using a vector store and embedding for a chat-based product, how do you handle negative queries. For Eg if a user says find me documents which don't contain a particular concept -> how is that handled by vector db and embedding space.  I have had mixed results using open aI embedding model .  Most of the times searching for "not <concept>" in the vector store produces results containing the concept with highest match

Message : Instead of negative prompt will it work if you rank the matching scores in order of least matches first and return top-n least matching ? S
Quoted Message : Hey Folks, I have a question when using a vector store and embedding for a chat-based product, how do you handle negative queries. For Eg if a user says find me documents which don't contain a particular concept -> how is that handled by vector db and embedding space.  I have had mixed results using open aI embedding model .  Most of the times searching for \"not <concept>\" in the vector store produces results containing the concept with highest match

Message : We are doing that with Mandi data for farmers and will integrate soon with platform, so farmers can request by voice in their local language. Lots of challenges though.
Quoted Message : Would be curious to learn more on this as well. \n\nWe would like to do the same for Ecommerce use case wherein we want the user to be able to connect their read-only DB or connect their API, get real time data from there and then pass that into an LLM.

Message : What is the core problem you are facing?
Quoted Message : We are doing that with Mandi data for farmers and will integrate soon with platform, so farmers can request by voice in their local language. Lots of challenges though.

Message : Same here. Building for legal
Quoted Message : Would be curious to learn more on this as well. \n\nWe would like to do the same for Ecommerce use case wherein we want the user to be able to connect their read-only DB or connect their API, get real time data from there and then pass that into an LLM.

Message : So basically, we use chatgpt to parse the response and identify the keywords to be searched from vector store. I can try to include that in the prompt to maybe change the vector store query to order in ascending order by score -> but was wondering if there is a better solution. In my mind i thought that embedding space should be able to resolve the negation factor on its own and do the inverse on its own
Quoted Message : Instead of negative prompt will it work if you rank the matching scores in order of least matches first and return top-n least matching ? S

Message : Some queries can return huge amount of data, we have millions of rows, so working on limiting that by set of questions to start with.
Quoted Message : What is the core problem you are facing?

Message : If its a structured data store, wouldn't adding a limit solve the issue. Just curious to understand since experimenting something similar
Quoted Message : Some queries can return huge amount of data, we have millions of rows, so working on limiting that by set of questions to start with.

Message : Dynamically identifying and inserting limiter is what we will have to solve. I.e. ‚Äògive me latest prize of grapes in Nasik mandi‚Äô vs ‚Äògive me commodity prizes from Nasik Mandi‚Äô
Quoted Message : If its a structured data store, wouldn't adding a limit solve the issue. Just curious to understand since experimenting something similar

Message : We have millions of rows across thousands of commodities and Mandis.

Message : We do have solution for most cases, but will know more the application is in wild, used by real people. ‚Äé<This message was edited>

Message : Is the data source consistent? As in if you are using SQL, the schemas are constant or different per customer?
Quoted Message : We are doing that with Mandi data for farmers and will integrate soon with platform, so farmers can request by voice in their local language. Lots of challenges though.

Message : It is consistent

Message : What db are you using to store your data and embeddings?
Quoted Message : It is consistent

Message : ‚Äé<attached: 00010202-PHOTO-2023-06-25-12-54-06.jpg>
Quoted Message : Hey Folks, I have a question when using a vector store and embedding for a chat-based product, how do you handle negative queries. For Eg if a user says find me documents which don't contain a particular concept -> how is that handled by vector db and embedding space.  I have had mixed results using open aI embedding model .  Most of the times searching for \"not <concept>\" in the vector store produces results containing the concept with highest match

Message : You can handle these via your final LLM prompt. Or if you're only fetching embeddings I had a reply in this tweet where I had passed it via a encoder decoder model to get the score

Message : https://www.producthunt.com/posts/youtalk

Hey guys, @91772808xxxx recently launched YoutTalk. This came out of the deephack hackathon and was one of the winners. So glad to see a production ready version of it. Do check it out and leave your reviews on feedback on product hunt/webstore

https://chrome.google.com/webstore/detail/youtalk/lbhodakkgeilgbgkcbajmillbgphdbga

Message : could you elaborate little more - how can this be handled by prompt
Quoted Message : You can handle these via your final LLM prompt. Or if you're only fetching embeddings I had a reply in this tweet where I had passed it via a encoder decoder model to get the score

Message : LLMs and decoder models are better at figuring out this level of similarity better than the embedding models we use which are more optimized for search.
LLMs can be used for reranking and filtering out relevant passages.
Also if you are using a RAG pipeline, your final LLM layer can have this in the prompt for filteringg out relevant queries
you can take this as inspiration
https://github.com/hwchase17/langchain/blob/master/langchain/retrievers/document_compressors/chain_extract_prompt.py
Quoted Message : could you elaborate little more - how can this be handled by prompt

Message : thanks for the detailed answer. will take a look
Quoted Message : LLMs and decoder models are better at figuring out this level of similarity better than the embedding models we use which are more optimized for search.\nLLMs can be used for reranking and filtering out relevant passages.\nAlso if you are using a RAG pipeline, your final LLM layer can have this in the prompt for filteringg out relevant queries\nyou can take this as inspiration\nhttps://github.com/hwchase17/langchain/blob/master/langchain/retrievers/document_compressors/chain_extract_prompt.py

Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : nan

Message : I'm building an in-browser semantic search product and I was wondering if I could use tiktoken (but in JS), or should I be using the embeddings endpoint (api.openai.com/v1/embeddings)? They both use the same the same tokenizer - cl100k_base. 

Asking so that I can understand if it will cost me to create embeddings (using the API) or if I can use something that never need a network connection.

I know I can run a sentence transformer like all-MiniLM-L6-v2 - huggingface.co/sentence-transformers/all-MiniLM-L6-v2 . But this fails to find certain matches. For example I was searching for "When did Apple start a store in Bombay" for this wiki wikipedia.org/wiki/Apple_Inc, but it failed to find a match.

Message : Ok, so as I understand the tokenization comes before embedding. OpenAI has not released the vector representation of their tokens, and so it means I have to use their API to get embeddings for gpt-3/4. I can always use an open souce pretrained model (sbert.net/docs/pretrained_models.html) if I wish it to be local first.

Message : This particular failure could be because you used Bombay instead of Mumbai.
Quoted Message : I'm building an in-browser semantic search product and I was wondering if I could use tiktoken (but in JS), or should I be using the embeddings endpoint (api.openai.com/v1/embeddings)? They both use the same the same tokenizer - cl100k_base. \n\nAsking so that I can understand if it will cost me to create embeddings (using the API) or if I can use something that never need a network connection.\n\nI know I can run a sentence transformer like all-MiniLM-L6-v2 - huggingface.co/sentence-transformers/all-MiniLM-L6-v2 . But this fails to find certain matches. For example I was searching for \"When did Apple start a store in Bombay\" for this wiki wikipedia.org/wiki/Apple_Inc, but it failed to find a match.

Message : There's a library called gpt-tokens in node which you could use to calculate tokens locally
Quoted Message : I'm building an in-browser semantic search product and I was wondering if I could use tiktoken (but in JS), or should I be using the embeddings endpoint (api.openai.com/v1/embeddings)? They both use the same the same tokenizer - cl100k_base. \n\nAsking so that I can understand if it will cost me to create embeddings (using the API) or if I can use something that never need a network connection.\n\nI know I can run a sentence transformer like all-MiniLM-L6-v2 - huggingface.co/sentence-transformers/all-MiniLM-L6-v2 . But this fails to find certain matches. For example I was searching for \"When did Apple start a store in Bombay\" for this wiki wikipedia.org/wiki/Apple_Inc, but it failed to find a match.

Message : Yes, but I was performing a semantic search anyway

Message : If openAI embeddings find Bombay and Mumbai semantically same, only then it'll succeed with that instead of miniLM sbert embeddings

Message : Yes, but it is a tokenizer, it won't provide vector embeddings
Quoted Message : There's a library called gpt-tokens in node which you could use to calculate tokens locally

Message : Yes, assuming OpenAI's embedding is much better
Quoted Message : If openAI embeddings find Bombay and Mumbai semantically same, only then it'll succeed with that instead of miniLM sbert embeddings

Message : There is transformers.js to run any sentence transformers model locally

Message : Yes, I'm using that

Message : I have a simple version of semantic searching working using miniLM

Message : I mean using a larger model from that like e5-base would probably be better than depending on OpenAI ada

Message : Maybe, will try out all-mpnet-base-v2 (best model available at the moment according to sbert.net/docs/pretrained_models.html)

Message : I think e5 came out on top in recent mteb benchmark
Quoted Message : I mean using a larger model from that like e5-base would probably be better than depending on OpenAI ada

Message : Rely on MTEB leaderboard to make your judgement - https://huggingface.co/spaces/mteb/leaderboard

Message : Even in that, don't go blindly for top performing embeddings for STS (semantic textual similarity) task

Message : You've to consider your performance and cost as well

Message : How do I consider / measure performance?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : There is transformers.js to run any sentence transformers model locally

Message : Yes, I'm using that

Message : I have a simple version of semantic searching working using miniLM

Message : I mean using a larger model from that like e5-base would probably be better than depending on OpenAI ada

Message : Maybe, will try out all-mpnet-base-v2 (best model available at the moment according to sbert.net/docs/pretrained_models.html)

Message : I think e5 came out on top in recent mteb benchmark
Quoted Message : I mean using a larger model from that like e5-base would probably be better than depending on OpenAI ada

Message : Rely on MTEB leaderboard to make your judgement - https://huggingface.co/spaces/mteb/leaderboard

Message : Even in that, don't go blindly for top performing embeddings for STS (semantic textual similarity) task

Message : You've to consider your performance and cost as well

Message : How do I consider / measure performance?

Message : For example, if you want similar speed as miniLM, look for similar model size and dimensions

Message : Ok, thanks

Message : miniLM L6 v2 is 384 dimensions and ~80MB I guess

Message : Yes

Message : So you can find best model for 384 dim first. Since you'll be running it in the browser, you need to consider your performance first. If cost isn't an issue, you can always go with openAI embeddings.

Message : I could run a better model in my infra I suppose. Will it be cheaper than using OpenAI embeddings endpoint?

Message : You can use HuggingFace inference (api is free up to a limit, endpoints for dedicated compute)
Quoted Message : I could run a better model in my infra I suppose. Will it be cheaper than using OpenAI embeddings endpoint?

Message : Thanks, didn't know that. Much easier to compare each model

Message : ‚ÄéPratyush Choudhury added ~‚ÄØOm

Message : Quite unhinged and delightful: https://twitter.com/RoyKishony/status/1672280665264386049

"wrote data analysis codes, interpreted results and wrote 5 transparent, reproducible papers" using LLMs and the CDC data ‚Äé<This message was edited>

Message : https://twitter.com/sauhaarda/status/1672714475659722754?t=iY5uQgXsoyZp_EMAF2aZ_A&s=08

Some interesting updates, paper probably getting redacted

Message : "Paper" is a bit strong. Just an arxiv submission
Quoted Message : https://twitter.com/sauhaarda/status/1672714475659722754?t=iY5uQgXsoyZp_EMAF2aZ_A&s=08\n\nSome interesting updates, paper probably getting redacted

Message : Yeah fair lol
Quoted Message : \"Paper\" is a bit strong. Just an arxiv submission

Message : this should be understood by the models.
Quoted Message : This particular failure could be because you used Bombay instead of Mumbai.

Message : ‚Äé<attached: 00010242-PHOTO-2023-06-25-21-27-00.jpg>

Message : Could be one of these? They're very high quality code embeddings
https://huggingface.co/models?search=salesforce+codegen

Message : Ok, so they might have just taken the first layer of these models

Message : https://www.linkedin.com/posts/dr-jeffrey-funk-a979435_a-critical-look-at-ai-generated-software-activity-7078686623223201792-6ITx

Security?
Reliability?

Message : Do you think openai has merged the gpt4-0613 with the old gpt4 model? Because gpt4 seems fast today

Message : No, it's a Sunday and folks in US, EU have a life unlike you and me
Quoted Message : Do you think openai has merged the gpt4-0613 with the old gpt4 model? Because gpt4 seems fast today

Message : And stop spilling alpha like this üò§

Message : Sounds like AI generated code has the same flaws as human devs? ü§£
Quoted Message : https://www.linkedin.com/posts/dr-jeffrey-funk-a979435_a-critical-look-at-ai-generated-software-activity-7078686623223201792-6ITx\n\nSecurity?\nReliability?

Message : It definitely does. I have to constantly check the AI generated code because sometimes the logic that is supposed to be in the for loop is outside it? I'm like bhai aise kaise chalega and all it does is apologies
Quoted Message : Sounds like AI generated code has the same flaws as human devs? ü§£

Message : GPT3.5 is like a 2nd year intern, writes coherent syntax but has no idea about code placement 
GPT4 is a 3rd year intern, can place code snippets but function calls, object creation, any higher order logic can be random
Code Interpreter is better than most interns and is competitive to many full time devs with prompt engineering
Quoted Message : It definitely does. I have to constantly check the AI generated code because sometimes the logic that is supposed to be in the for loop is outside it? I'm like bhai aise kaise chalega and all it does is apologies

Message : Anyone checked out Zeroscope? https://huggingface.co/cerspense/zeroscope_v2_XL https://twitter.com/mrjonfinger/status/1672809085849468929

Message : This sounds right.
Quoted Message : GPT3.5 is like a 2nd year intern, writes coherent syntax but has no idea about code placement \nGPT4 is a 3rd year intern, can place code snippets but function calls, object creation, any higher order logic can be random\nCode Interpreter is better than most interns and is competitive to many full time devs with prompt engineering

Message : was added to chat

Message : ‚Äé<attached: 00010254-VIDEO-2023-06-25-21-44-20.mp4>

Message : Which model is this?

Message : This is using Kaiber? ‚Äé<This message was edited>

Message : This one which Rajesh shared
Quoted Message : Anyone checked out Zeroscope? https://huggingface.co/cerspense/zeroscope_v2_XL https://twitter.com/mrjonfinger/status/1672809085849468929

Message : These are local nuances and not really part of common English training datasets. I'll be able to 1000s of such instances in the world even with openAI. Plus, this is a common limitation of NLP embeddings where a local or proprietary relationship between entities in the dataset can't be captured with same accuracy as common English terms.
Quoted Message : this should be understood by the models.

Message : I get that. But I think this is there from personal experience although might be missing in the model used
Quoted Message : These are local nuances and not really part of common English training datasets. I'll be able to 1000s of such instances in the world even with openAI. Plus, this is a common limitation of NLP embeddings where a local or proprietary relationship between entities in the dataset can't be captured with same accuracy as common English terms.

Message : @91773788xxxx any examples of Salesforce with finetuned models ? The ones u linked are basemodels
Quoted Message : Could be one of these? They're very high quality code embeddings\nhttps://huggingface.co/models?search=salesforce+codegen

Message : Yeah, take a language like C and try to write secure low resource code with it. Then try to run it on different OSes, you'll change your opinion about developers being replaced by GPT4.
Quoted Message : https://www.linkedin.com/posts/dr-jeffrey-funk-a979435_a-critical-look-at-ai-generated-software-activity-7078686623223201792-6ITx\n\nSecurity?\nReliability?

Message : Yes, random from browser history: https://huggingface.co/sahil2801/instruct-codegen-16B
Quoted Message : @91773788xxxx any examples of Salesforce with finetuned models ? The ones u linked are basemodels

Message : Especially with named entities, this is a very common problem that generally available embeddings can't solve.\nIt's why we build NER and vocab for proprietary systems first for good results. Keyword based approaches often outperform semantic similarity in local nuances or proprietary vocab.
Quoted Message : I get that. But I think this is there from personal experience although might be missing in the model used

Message : Yeah, take a language like C and try to write secure low resource code with it. Then try to run it on different OSes, you'll change your opinion about developers being replaced by GPT4.

Message : Yes, random from browser history: https://huggingface.co/sahil2801/instruct-codegen-16B ‚Äé<This message was edited>

Message : Especially with named entities, this is a very common problem that generally available embeddings can't solve.
It's why we build NER and vocab for proprietary systems first for good results. Keyword based approaches often outperform semantic similarity in local nuances or proprietary vocab.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This one which Rajesh shared
Quoted Message : Anyone checked out Zeroscope? https://huggingface.co/cerspense/zeroscope_v2_XL https://twitter.com/mrjonfinger/status/1672809085849468929

Message : These are local nuances and not really part of common English training datasets. I'll be able to 1000s of such instances in the world even with openAI. Plus, this is a common limitation of NLP embeddings where a local or proprietary relationship between entities in the dataset can't be captured with same accuracy as common English terms.
Quoted Message : this should be understood by the models.

Message : I get that. But I think this is there from personal experience although might be missing in the model used
Quoted Message : These are local nuances and not really part of common English training datasets. I'll be able to 1000s of such instances in the world even with openAI. Plus, this is a common limitation of NLP embeddings where a local or proprietary relationship between entities in the dataset can't be captured with same accuracy as common English terms.

Message : @91773788xxxx any examples of Salesforce with finetuned models ? The ones u linked are basemodels
Quoted Message : Could be one of these? They're very high quality code embeddings\nhttps://huggingface.co/models?search=salesforce+codegen

Message : Yeah, take a language like C and try to write secure low resource code with it. Then try to run it on different OSes, you'll change your opinion about developers being replaced by GPT4.
Quoted Message : https://www.linkedin.com/posts/dr-jeffrey-funk-a979435_a-critical-look-at-ai-generated-software-activity-7078686623223201792-6ITx\n\nSecurity?\nReliability?

Message : Yes, random from browser history: https://huggingface.co/sahil2801/instruct-codegen-16B
Quoted Message : @91773788xxxx any examples of Salesforce with finetuned models ? The ones u linked are basemodels

Message : Especially with named entities, this is a very common problem that generally available embeddings can't solve.\nIt's why we build NER and vocab for proprietary systems first for good results. Keyword based approaches often outperform semantic similarity in local nuances or proprietary vocab.
Quoted Message : I get that. But I think this is there from personal experience although might be missing in the model used

Message : Yeah, take a language like C and try to write secure low resource code with it. Then try to run it on different OSes, you'll change your opinion about developers being replaced by GPT4.

Message : Yes, random from browser history: https://huggingface.co/sahil2801/instruct-codegen-16B ‚Äé<This message was edited>

Message : Especially with named entities, this is a very common problem that generally available embeddings can't solve.
It's why we build NER and vocab for proprietary systems first for good results. Keyword based approaches often outperform semantic similarity in local nuances or proprietary vocab.

Message : Doesn't this also boil down to training data? Going back to the instructGPT paradigm, the model learns to generate code using examples of human code written - not necessarily through full knowledge of the compiler or interpreter underneath
Quoted Message : It definitely does. I have to constantly check the AI generated code because sometimes the logic that is supposed to be in the for loop is outside it? I'm like bhai aise kaise chalega and all it does is apologies

Message : Yeah. The training data is better in gpt than most but not susceptible to mistakes
Quoted Message : Doesn't this also boil down to training data? Going back to the instructGPT paradigm, the model learns to generate code using examples of human code written - not necessarily through full knowledge of the compiler or interpreter underneath

Message : On a related note I've often wondered what the embeddings would look like for models like InstructGPT, Codex and so on. Sequences matter here despite the kind of token you compute because programming languages have significant overlaps in keywords and reserved words.

Message : This is trained on the codegen-salesforce üòÇ.\n\nWhat is the best of class for code generation base models meant for fine-tuning?
Quoted Message : Yes, random from browser history: https://huggingface.co/sahil2801/instruct-codegen-16B

Message : Ohh, I thought you wanted to see if Salesforce models can be finetuned
Quoted Message : This is trained on the codegen-salesforce üòÇ.\n\nWhat is the best of class for code generation base models meant for fine-tuning?

Message : StarCoder Base
Quoted Message : This is trained on the codegen-salesforce üòÇ.\n\nWhat is the best of class for code generation base models meant for fine-tuning?

Message : Something that interested me today - *A ORCA repro effort on OpenLlama 13B base* \nhttps://huggingface.co/psmathur/orca_mini_13b\n\nLeaderboard eval is not shared here so can't say if it's results are similar to orca as in the research paper but the training has used similar methods for custom datasets as mentioned in the research paper.

Message : Speaking of Orca, Emad of Stability.ai disses it because it's not true FOSS:\nhttps://twitter.com/EMostaque/status/1672736494761693184

Message : Isn't the WizardCoder the highest? Or did you mean commercially licensed?
Quoted Message : StarCoder Base

Message : Best which you can finetune. WizardCoder is already kinda finetuned for benchmark overfitting in my mind
Quoted Message : Isn't the WizardCoder the highest? Or did you mean commercially licensed?

Message : Ok, got your context
Quoted Message : Best which you can finetune. WizardCoder is already kinda finetuned for benchmark overfitting in my mind

Message : True, orca and phi both have such wonderful results in the paper that not releasing their datasets and models kind of ruins the impact the papers can have.
Quoted Message : Speaking of Orca, Emad of Stability.ai disses it because it's not true FOSS:\nhttps://twitter.com/EMostaque/status/1672736494761693184

Message : This is trained on the codegen-salesforce üòÇ.

What is the best of class for code generation base models meant for fine-tuning?

Message : Ohh, I thought you wanted to see if Salesforce models can be finetuned

Message : StarCoder Base

Message : Something that interested me today - *A ORCA repro effort on OpenLlama 13B base* 
https://huggingface.co/psmathur/orca_mini_13b

Leaderboard eval is not shared here so can't say if it's results are similar to orca as in the research paper but the training has used similar methods for custom datasets as mentioned in the research paper.

Message : Speaking of Orca, Emad of Stability.ai disses it because it's not true FOSS:
https://twitter.com/EMostaque/status/1672736494761693184

Message : Isn't the WizardCoder the highest? Or did you mean commercially licensed?

Message : Best which you can finetune. WizardCoder is already kinda finetuned for benchmark overfitting in my mind

Message : Ok, got your context

Message : True, orca and phi both have such wonderful results in the paper that not releasing their datasets and models kind of ruins the impact the papers can have.

Message : Haven't begun my deployment of coder models. You'd recommend starting with wizardcoder or starcoder base ?

Message : GPT4 is miles ahead of these and will stay ahead for most of 2023

Message : And perhaps 2024 too

Message : Haven't begun my deployment of coder models. You'd recommend starting with wizardcoder or starcoder base ?
Quoted Message : Best which you can finetune. WizardCoder is already kinda finetuned for benchmark overfitting in my mind

Message : GPT4 is miles ahead of these and will stay ahead for most of 2023
Quoted Message : Haven't begun my deployment of coder models. You'd recommend starting with wizardcoder or starcoder base ?

Message : And perhaps 2024 too

Message : But if you've to do FOSS for any reason, begin with Replit Code and finetune on your code base

Message : Makes sense. 

I wanted to work with large repos. And developing flows to keep brainstorming and write code to expand my codebase.

GPT is too expensive and loses context often unless given the same file / functions again and again.

I'll try this out. Thanks.
Quoted Message : But if you've to do FOSS for any reason, begin with Replit Code and finetune on your code base

Message : ‚Äé<attached: 00010285-PHOTO-2023-06-25-22-23-00.jpg>
Quoted Message : Makes sense. \n\nI wanted to work with large repos. And developing flows to keep brainstorming and write code to expand my codebase. \n\nGPT is too expensive and loses context often unless given the same file / functions again and again. \n\nI'll try this out. Thanks.

Message : You might find these tools interesting as well: 
Code Nav, FOSS project: https://github.com/bloopai/bloop
Code Nav but inline, and does generation,  needs OpenAI Key: https://www.cursor.so/

Message : Thanks a lot.
Quoted Message : You might find these tools interesting as well: \nCode Nav, FOSS project: https://github.com/bloopai/bloop\nCode Nav but inline, and does generation,  needs OpenAI Key: https://www.cursor.so/

Message : Bloop is one of the most interesting works for this problem for sure.
Quoted Message : You might find these tools interesting as well: \nCode Nav, FOSS project: https://github.com/bloopai/bloop\nCode Nav but inline, and does generation,  needs OpenAI Key: https://www.cursor.so/

Message : https://aider.chat/

The ctags approach here actually works wonders. And I've made some modifications to keep sending relevant parts of it to keep establishing context.

Will be better off putting this is a vectorDB for faster and smarter retrieval of the repo map

Message : I'll check this out. I'm interested in the different ways people are approaching the problem of treating source code as a document or database.
Quoted Message : https://aider.chat/\n\nThe ctags approach here actually works wonders. And I've made some modifications to keep sending relevant parts of it to keep establishing context. \n\nWill be better off putting this is a vectorDB for faster and smarter retrieval of the repo map

Message : I've seen multilevel or unilevel summarisation approaches mostly so far.

Message : Why replit code ? Genuinely curious. Asking specifically for fine-tuning.
Quoted Message : But if you've to do FOSS for any reason, begin with Replit Code and finetune on your code base

Message : Small models are easier to finetune frequently and update for auto-complete kinda use cases
Quoted Message : Why replit code ? Genuinely curious. Asking specifically for fine-tuning.

Message : This has been a recent learning
Quoted Message : Small models are easier to finetune frequently and update for auto-complete kinda use cases

Message : Is there a platform though that allows me to it well?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You might find these tools interesting as well: 
Code Nav, FOSS project: https://github.com/bloopai/bloop
Code Nav but inline, and does generation,  needs OpenAI Key: https://www.cursor.so/

Message : Thanks a lot.
Quoted Message : You might find these tools interesting as well: \nCode Nav, FOSS project: https://github.com/bloopai/bloop\nCode Nav but inline, and does generation,  needs OpenAI Key: https://www.cursor.so/

Message : Bloop is one of the most interesting works for this problem for sure.
Quoted Message : You might find these tools interesting as well: \nCode Nav, FOSS project: https://github.com/bloopai/bloop\nCode Nav but inline, and does generation,  needs OpenAI Key: https://www.cursor.so/

Message : https://aider.chat/

The ctags approach here actually works wonders. And I've made some modifications to keep sending relevant parts of it to keep establishing context.

Will be better off putting this is a vectorDB for faster and smarter retrieval of the repo map

Message : I'll check this out. I'm interested in the different ways people are approaching the problem of treating source code as a document or database.
Quoted Message : https://aider.chat/\n\nThe ctags approach here actually works wonders. And I've made some modifications to keep sending relevant parts of it to keep establishing context. \n\nWill be better off putting this is a vectorDB for faster and smarter retrieval of the repo map

Message : I've seen multilevel or unilevel summarisation approaches mostly so far.

Message : Why replit code ? Genuinely curious. Asking specifically for fine-tuning.
Quoted Message : But if you've to do FOSS for any reason, begin with Replit Code and finetune on your code base

Message : Small models are easier to finetune frequently and update for auto-complete kinda use cases
Quoted Message : Why replit code ? Genuinely curious. Asking specifically for fine-tuning.

Message : This has been a recent learning
Quoted Message : Small models are easier to finetune frequently and update for auto-complete kinda use cases

Message : Is there a platform though that allows me to it well?

Message : For me, there's a bigger question of what approach do you take to build the fine tuning dataset for code gen cases for specific repos or source codes.

Message : Replicate should be launching this soon
Quoted Message : Is there a platform though that allows me to it well?

Message : Nice
Quoted Message : Replicate should be launching this soon

Message : Do you take the individual functions and modules and turn them into instruction response pairs? Or do you take the commit messages as Instructions and the commits as responses? Or do you take an unstructured approach and just rely on next token prediction to do the trick?
Quoted Message : For me, there's a bigger question of what approach do you take to build the fine tuning dataset for code gen cases for specific repos or source codes.

Message : In my mind, an ideal setup would be something that has access to data so that it allows me to switch between models and also automatically fine-tunes those

Something like this exists?
Quoted Message : Replicate should be launching this soon

Message : nan

Message : nan

Message : was added to chat

Message : A "camera" that, instead of capturing light, captures your GPS coordinates, looks up some information about your location, plugs those bits into some sentences like Mad-Libs, and sends the whole thing off to an AI to generate an image.

The "camera" is incapable of actually looking at the world.

https://bjoernkarmann.dk/project/paragraphica

Message : Little too broad, but for text in particular ‚Äî AutoNLP-way of thinking was a thing, and that can still be extended to support these use cases. If I spend enough brain cycles, should be able to do this for code too

Message : Interesting that you call it broad,

Would you be able to elaborate please?

Message : My summary of textbooks are all you need paper
https://averma12.notion.site/Textbooks-are-all-you-Need-d5d2c0451b1d40ffa06739fe6defde6f?pvs=4

Also here is the summary for the Orca paper.
https://averma12.notion.site/Orca-paper-Explained-136fbed4b1cc40e28f56fdab2755b6fd?pvs=4

Message : That was a great summary of the textbooks are all you need paper. This paper makes me think that current advances are not merely about scale. A relatively small amount of tokens (billions) and fine tuning (millions) on a model that is not particularly large (1 B or smaller) is remarkably good at things like coding and would have been unthinkable a few years ago.

Message : If the task is narrowly scoped it seems quite doable for anyone in this group with some months of effort to train a model that is competitive with GPT-3. The bottleneck is actually putting together 5-10B ‚Äúhigh quality tokens‚Äù

Message : Neither scale nor architecture changes. Primarily a change in quality of coherence of data.

Message : Who knows maybe even the order in which data is fed can make a difference

Message : Do you mean we are back to handcrafting high quality dataset on tasks?
Quoted Message : If the task is narrowly scoped it seems quite doable for anyone in this group with some months of effort to train a model that is competitive with GPT-3. The bottleneck is actually putting together 5-10B ‚Äúhigh quality tokens‚Äù

Message : In my eyes, it's the same thing as creating a "small monopoly". Not everyone needs to have a model rivalling GPT3 locally in everything. In most cases, beating it in one or two areas, even if it's your home ground, may add significant value.
Quoted Message : If the task is narrowly scoped it seems quite doable for anyone in this group with some months of effort to train a model that is competitive with GPT-3. The bottleneck is actually putting together 5-10B ‚Äúhigh quality tokens‚Äù

Message : Not quite but it looks we are headed there. The more you hand craft and with more expertise the more results it seems to yield

Message : So the bottleneck will become the availability of expertise and effort to make really excellent data sets

Message : See this for eg https://openai.com/research/improving-mathematical-reasoning-with-process-supervision

Message : We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.
Quoted Message : See this for eg https://openai.com/research/improving-mathematical-reasoning-with-process-supervision

Message : What if you extend this to math problems from old textbooks.

Message : I will add, excellent datasets without API distillation from GPT4. Clean commercial excellent dataset.

Message : Imagine doing this on top of text books are all you need. You will get even further improvement
Quoted Message : We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.

Message : Is there a framework to follow for this because I think with enough people combined you can get 5-6 gb of high quality data which can give good performance
Quoted Message : I will add, excellent datasets without API distillation from GPT4. Clean commercial excellent dataset.

Message : I think we've a 1T dataset that's completely clean since it's crowd created. I think Red pajama is one.

Message : But now we've new dataset methodologies that we may want to try out like the ones shared in LIMA, Orca, phi-1.

Message : Correct
Quoted Message : But now we've new dataset methodologies that we may want to try out like the ones shared in LIMA, Orca, phi-1.

Message : i always thought gpt4 was ensemble of models. the moe paper sort of proved this theory
Quoted Message : In my eyes, it's the same thing as creating a \"small monopoly\". Not everyone needs to have a model rivalling GPT3 locally in everything. In most cases, beating it in one or two areas, even if it's your home ground, may add significant value.

Message : There is no single "fine-tuning" ‚Äî it depends on:

Quality: data quality, data size, domain, task
Cost: Talent, compute, data size
Quoted Message : Interesting that you call it broad,\n\nWould you be able to elaborate please?

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØSaravanan Balakrishnan

Message : https://news.ycombinator.com/item?id=36460082

Message : Yes, sir - which is why thinking if having some/all of these functionalities on one platform will be helpful

Anecdotal conversations suggest me that this could be a good idea
Quoted Message : There is no single \"fine-tuning\" ‚Äî it depends on:\n\nQuality: data quality, data size, domain, task\nCost: Talent, compute, data size

Message : was added to chat

Message : Good afternoon everyone. My name is Saravanan. I am from a healthcare startup called Amura.

Thanks to the mods for adding me to the group and SRK for leading me to it.

üôè

Message : ‚Äé<attached: 00010328-PHOTO-2023-06-26-12-12-57.jpg>

Message : it works - succinct answers for busy parents

Message : from a "credible" source

Message : I've been there and there is so much content out there it can be overwhelming


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : There is no single "fine-tuning" ‚Äî it depends on:

Quality: data quality, data size, domain, task
Cost: Talent, compute, data size
Quoted Message : Interesting that you call it broad,\n\nWould you be able to elaborate please?

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØSaravanan Balakrishnan

Message : https://news.ycombinator.com/item?id=36460082

Message : Yes, sir - which is why thinking if having some/all of these functionalities on one platform will be helpful

Anecdotal conversations suggest me that this could be a good idea
Quoted Message : There is no single \"fine-tuning\" ‚Äî it depends on:\n\nQuality: data quality, data size, domain, task\nCost: Talent, compute, data size

Message : was added to chat

Message : Good afternoon everyone. My name is Saravanan. I am from a healthcare startup called Amura.

Thanks to the mods for adding me to the group and SRK for leading me to it.

üôè

Message : ‚Äé<attached: 00010328-PHOTO-2023-06-26-12-12-57.jpg>

Message : it works - succinct answers for busy parents

Message : from a "credible" source

Message : I've been there and there is so much content out there it can be overwhelming

Message : It is retrieval augmented generation. Fetch the relevant results into one helpful snippet

Message : Summarization, done well, can be a killer app
Quoted Message : I've been there and there is so much content out there it can be overwhelming

Message : Long snippet

Message : its a really good move IMO - as new parents are always looking for relevant information and as a gneartion we are not interested in the advice of the older generation

Message : Google search May work for everything probably, but then the user is responsible for the cognitive load of processing and reasoning.

Message : This is the big draw to ChatGPT for a lot of folks. Lower cognitive load.
Quoted Message : Google search May work for everything probably, but then the user is responsible for the cognitive load of processing and reasoning.

Message : Just like Google was for directory based search engines.
Quoted Message : This is the big draw to ChatGPT for a lot of folks. Lower cognitive load.

Message : That‚Äôs where LLM apps are different. With search there was a chance of misinformation or bias and certainly it was highlighted. But with LLMs everyone knows that there‚Äôs a bigger possibility of this and that as a generative model it is likely to hallucinate- and still end up using it
Quoted Message : Just like Google was for directory based search engines.

Message : A topic for Philosophy group
Quoted Message : That‚Äôs where LLM apps are different. With search there was a chance of misinformation or bias and certainly it was highlighted. But with LLMs everyone knows that there‚Äôs a bigger possibility of this and that as a generative model it is likely to hallucinate- and still end up using it

Message : Join the philosophy group for this discussion.
Quoted Message : A topic for Philosophy group

Message : You can join the philosophy group for this discussion
Quoted Message : That‚Äôs where LLM apps are different. With search there was a chance of misinformation or bias and certainly it was highlighted. But with LLMs everyone knows that there‚Äôs a bigger possibility of this and that as a generative model it is likely to hallucinate- and still end up using it

Message : These risks can be mitigated
Quoted Message : That‚Äôs where LLM apps are different. With search there was a chance of misinformation or bias and certainly it was highlighted. But with LLMs everyone knows that there‚Äôs a bigger possibility of this and that as a generative model it is likely to hallucinate- and still end up using it

Message : Speaking of RAG, people are working on Enterprise-readiness for RAG systems e.g. came across this https://github.com/danswer-ai/danswer which looks promising from a design PoV
Quoted Message : It is retrieval augmented generation. Fetch the relevant results into one helpful snippet

Message : Was noodling on this - very helpful
Quoted Message : Speaking of RAG, people are working on Enterprise-readiness for RAG systems e.g. came across this https://github.com/danswer-ai/danswer which looks promising from a design PoV

Message : Yes. There have been a few tools like this that have come up. This space is heating up now

Message : ‚Äé<attached: 00010347-PHOTO-2023-06-26-13-43-28.jpg>

Message : ‚Äé<attached: 00010348-PHOTO-2023-06-26-13-43-29.jpg>

Message : What‚Äôs the infrastructure running this?

Message : t3.2xlarge
Quoted Message : What‚Äôs the infrastructure running this?

Message : is there a difference in performance of running these on t3a (amd processors) or the aws internal graviton processors( constraint of this is that it only supports ARM architecture so diff docker images might be required)
Quoted Message : t3.2xlarge

Message : Haven't tried t3a

Message : this is just the indian in me, trying to reduce costs even further. t3a is 60% of price of t3
Quoted Message : Haven't tried t3a

Message : He'll flip the code to FOSS, go ahead and try!

Message : cool

Message : Are you using Wiki embeddings for testing?

Message : https://huggingface.co/datasets/kshivendu/dbpedia-entities-openai-1m
Quoted Message : Are you using Wiki embeddings for testing?

Message : I think doing next token prediction with fill in the middle technique will help the model learn a lot about your codebase
Quoted Message : Do you take the individual functions and modules and turn them into instruction response pairs? Or do you take the commit messages as Instructions and the commits as responses? Or do you take an unstructured approach and just rely on next token prediction to do the trick?

Message : OpenAI has a fill in middle model and a paper on this as well. Can't remember the paper, read it last year
Quoted Message : I think doing next token prediction with fill in the middle technique will help the model learn a lot about your codebase

Message : Both codex and gpt3 have this on the playground and inside copilot
Quoted Message : OpenAI has a fill in middle model and a paper on this as well. Can't remember the paper, read it last year

Message : correct
Quoted Message : Both codex and gpt3 have this on the playground and inside copilot

Message : Yes, that's how it has been done in multiple cases. That's why I mentioned it as the third option in my comment. 

I found multiple papers that talk about the same but the fill in the middle approaches typically generate one line and are also limited by context length.

Given these constraints with this approach, it's actually easier using vector DBs to fetch hierarchical schema of the code and complete a given code generation task. But overall, both options leave a lot to be desired.

Some existing researches:
*Repofusion* https://arxiv.org/abs/2306.10998
*Repocoder* https://arxiv.org/abs/2303.12570
*Prompt proposal on repository level* https://arxiv.org/abs/2206.12839
Quoted Message : I think doing next token prediction with fill in the middle technique will help the model learn a lot about your codebase

Message : copilot even had a neat way of being able to configure how much to take as prefix and how to much to take as suffix
Quoted Message : Both codex and gpt3 have this on the playground and inside copilot

Message : Yeah, you mean this - https://arxiv.org/abs/2207.14255
Quoted Message : OpenAI has a fill in middle model and a paper on this as well. Can't remember the paper, read it last year

Message : When will a nobody like me get it :(
Quoted Message : GPT3.5 is like a 2nd year intern, writes coherent syntax but has no idea about code placement \nGPT4 is a 3rd year intern, can place code snippets but function calls, object creation, any higher order logic can be random\nCode Interpreter is better than most interns and is competitive to many full time devs with prompt engineering

Message : yeah. this one
Quoted Message : Yeah, you mean this - https://arxiv.org/abs/2207.14255

Message : Code interpretor

Message : Interpreter*
Quoted Message : Code interpretor

Message : Maybe not as good as code interpretor, but I saw some plugins today that talk to your code given the GitHub repo, check these out and see if you like them.
Quoted Message : Code interpretor

Message : arrey chill, many people haven't got it. Solution is to make your 3rd year intern work extra hard
Quoted Message : When will a nobody like me get it :(

Message : I'll probably be that 3rd year intern in a few years.
Quoted Message : arrey chill, many people haven't got it. Solution is to make your 3rd year intern work extra hard


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Yes, that's how it has been done in multiple cases. That's why I mentioned it as the third option in my comment. 

I found multiple papers that talk about the same but the fill in the middle approaches typically generate one line and are also limited by context length.

Given these constraints with this approach, it's actually easier using vector DBs to fetch hierarchical schema of the code and complete a given code generation task. But overall, both options leave a lot to be desired.

Some existing researches:
*Repofusion* https://arxiv.org/abs/2306.10998
*Repocoder* https://arxiv.org/abs/2303.12570
*Prompt proposal on repository level* https://arxiv.org/abs/2206.12839
Quoted Message : I think doing next token prediction with fill in the middle technique will help the model learn a lot about your codebase

Message : copilot even had a neat way of being able to configure how much to take as prefix and how to much to take as suffix
Quoted Message : Both codex and gpt3 have this on the playground and inside copilot

Message : Yeah, you mean this - https://arxiv.org/abs/2207.14255
Quoted Message : OpenAI has a fill in middle model and a paper on this as well. Can't remember the paper, read it last year

Message : When will a nobody like me get it :(
Quoted Message : GPT3.5 is like a 2nd year intern, writes coherent syntax but has no idea about code placement \nGPT4 is a 3rd year intern, can place code snippets but function calls, object creation, any higher order logic can be random\nCode Interpreter is better than most interns and is competitive to many full time devs with prompt engineering

Message : yeah. this one
Quoted Message : Yeah, you mean this - https://arxiv.org/abs/2207.14255

Message : Code interpretor

Message : Interpreter*
Quoted Message : Code interpretor

Message : Maybe not as good as code interpretor, but I saw some plugins today that talk to your code given the GitHub repo, check these out and see if you like them.
Quoted Message : Code interpretor

Message : arrey chill, many people haven't got it. Solution is to make your 3rd year intern work extra hard
Quoted Message : When will a nobody like me get it :(

Message : I'll probably be that 3rd year intern in a few years.
Quoted Message : arrey chill, many people haven't got it. Solution is to make your 3rd year intern work extra hard

Message : Do they randomly roll interpreter out or is it some kind of wait list?

Message : I'm interested in knowing which companies keep people in internship position for 3 years üòÇ
Quoted Message : arrey chill, many people haven't got it. Solution is to make your 3rd year intern work extra hard

Message : @91773788xxxx  @91961640xxxx

Message : I was assuming, 3rd year ya final year student doing internship
Quoted Message : I'm interested in knowing which companies keep people in internship position for 3 years üòÇ

Message : Please, none of these are anywhere near any good intern. A good intern is capable of googling the right answer
Quoted Message : GPT3.5 is like a 2nd year intern, writes coherent syntax but has no idea about code placement \nGPT4 is a 3rd year intern, can place code snippets but function calls, object creation, any higher order logic can be random\nCode Interpreter is better than most interns and is competitive to many full time devs with prompt engineering

Message : By this definition, a good intern is harder to find than a unicorn paying 50 LPA salary in BLR

Message : My intern raised white flag in a week, after getting overwhelmed looking at the codebase. Good interns are really like unicorns.

Message : ‚Äé~‚ÄØNirant changed the group description

Message : There should be a tag by which one can filter HuggingFace datasets to just embeddings dumps. Anyone know of a way to do it?
Quoted Message : https://huggingface.co/datasets/kshivendu/dbpedia-entities-openai-1m

Message : Was looking for the same. Didn't find anything reliable. The best bets are certain tags and keywords. I can tell you those if you want.
Quoted Message : There should be a tag by which one can filter HuggingFace datasets to just embeddings dumps. Anyone know of a way to do it?

Message : Is the embeddings title+string or just string?
Quoted Message : https://huggingface.co/datasets/kshivendu/dbpedia-entities-openai-1m

Message : What are the different methods to use transliteration from Hinglish to Hindi??

Message : Ok got it. Thanks for this. Will try to experiment and see if we can create a compressed embedding space on top of this.

Message : ‚Äé<attached: 00010387-PHOTO-2023-06-26-17-26-11.jpg>

Message : Yeah, it's been 5 weeks I guess since it moved from 0-1 to 0-2

Message : check this out, works well for transliteration in the Indic context

https://github.com/libindic/indic-trans
Quoted Message : What are the different methods to use transliteration from Hinglish to Hindi??

Message : https://twitter.com/alighodsi/status/1673300587419701249?s=46

Databricks is now a genAI company

Message : Are there any chatgpt plugins making money? How do you even do distribution? I've been thinking about building one but haven't really seen anything useful.

Message : sama has said that plugins have no PMF. they did a v good job taking the learnings and building openai functions.
Quoted Message : Are there any chatgpt plugins making money? How do you even do distribution? I've been thinking about building one but haven't really seen anything useful.

Message : one man army
Quoted Message : https://twitter.com/alighodsi/status/1673300587419701249?s=46\n\nDatabricks is now a genAI company

Message : plugins themselves aren't making money yet. but it can happen. ones like zapier etc
Quoted Message : sama has said that plugins have no PMF. they did a v good job taking the learnings and building openai functions.

Message : They had this capability already with Dolly - but great to see this.
Quoted Message : https://twitter.com/alighodsi/status/1673300587419701249?s=46\n\nDatabricks is now a genAI company

Message : My card charged 5% TCS for the ChatGPT plus subscription. :(

Message : Anyone aware of cards/ bank that dont charge this?
Quoted Message : My card charged 5% TCS for the ChatGPT plus subscription. :(

Message : non indian  cards
Quoted Message : Anyone aware of cards/ bank that dont charge this?

Message : amex probably doesn't

Message : My card didn't levy any taxes other than the 18% govt levied GST.

Message : Hi folks, I'm building a chat bot which produces canned responses half the time, and good responses (based on a chunked knowledge base) the remaining portion of the time. How would I troubleshoot this? Embedding computation is my first hypothesis for root cause analysis, but could there be anything else I should look at?

Message : The ranking algorithm that's being used in your vector store isn't working that great? Maybe the search query term is matching a vast surface area of objects from your knowledge base ... and the valuable matches are not ranked to top?
Quoted Message : Hi folks, I'm building a chat bot which produces canned responses half the time, and good responses (based on a chunked knowledge base) the remaining portion of the time. How would I troubleshoot this? Embedding computation is my first hypothesis for root cause analysis, but could there be anything else I should look at?

Message : This sparked another thought. This is probably the oldest and most mature usecase. It seems people are still building this in-house. Are there not good enough services for this already? What are the factors apart from prices that might be forcing people to build this in-house than buying a third party solution
Quoted Message : Hi folks, I'm building a chat bot which produces canned responses half the time, and good responses (based on a chunked knowledge base) the remaining portion of the time. How would I troubleshoot this? Embedding computation is my first hypothesis for root cause analysis, but could there be anything else I should look at?

Message : What is your chunk suze maybe playing with chunk size may help , by that i mean reducing it to 2000 or 1500
Quoted Message : Hi folks, I'm building a chat bot which produces canned responses half the time, and good responses (based on a chunked knowledge base) the remaining portion of the time. How would I troubleshoot this? Embedding computation is my first hypothesis for root cause analysis, but could there be anything else I should look at?

Message : Hi all,
I am trying to create a large dataset for fine-tuning, analysis, etc.

It involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.

What would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)

Message : Try to store I parquet formats

Message : *in

Message : This looks more like a data engineering problem. Are you trying to do all of this on the fly and where are you going to use ai ?

Message : I am essentially intending on collecting Indian patent data. Aside from days analysis, Initially i would hope to use the data for fine-tuning existing open source models from a document automation point of view.

Message : Data analysis*

Message : Thanks, that makes sense. I‚Äôll explore it

Message : Do you know what frameworks are out there?

Message : Try to store I parquet formats
Quoted Message : Hi all,\nI am trying to create a large dataset for fine-tuning, analysis, etc.\n\nIt involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.\n\nWhat would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : What is your chunk suze maybe playing with chunk size may help , by that i mean reducing it to 2000 or 1500
Quoted Message : Hi folks, I'm building a chat bot which produces canned responses half the time, and good responses (based on a chunked knowledge base) the remaining portion of the time. How would I troubleshoot this? Embedding computation is my first hypothesis for root cause analysis, but could there be anything else I should look at?

Message : Hi all,
I am trying to create a large dataset for fine-tuning, analysis, etc.

It involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.

What would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)

Message : Try to store I parquet formats

Message : *in

Message : This looks more like a data engineering problem. Are you trying to do all of this on the fly and where are you going to use ai ?

Message : I am essentially intending on collecting Indian patent data. Aside from days analysis, Initially i would hope to use the data for fine-tuning existing open source models from a document automation point of view.

Message : Data analysis*

Message : Thanks, that makes sense. I‚Äôll explore it

Message : Do you know what frameworks are out there?

Message : Try to store I parquet formats
Quoted Message : Hi all,\nI am trying to create a large dataset for fine-tuning, analysis, etc.\n\nIt involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.\n\nWhat would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)

Message : *in

Message : This looks more like a data engineering problem. Are you trying to do all of this on the fly and where are you going to use ai ?
Quoted Message : Hi all,\nI am trying to create a large dataset for fine-tuning, analysis, etc.\n\nIt involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.\n\nWhat would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)

Message : I am essentially intending on collecting Indian patent data. Aside from days analysis, Initially i would hope to use the data for fine-tuning existing open source models from a document automation point of view.
Quoted Message : This looks more like a data engineering problem. Are you trying to do all of this on the fly and where are you going to use ai ?

Message : Data analysis*

Message : Thanks, that makes sense. I‚Äôll explore it
Quoted Message : This sparked another thought. This is probably the oldest and most mature usecase. It seems people are still building this in-house. Are there not good enough services for this already? What are the factors apart from prices that might be forcing people to build this in-house than buying a third party solution

Message : Do you know what frameworks are out there?
Quoted Message : Thanks, that makes sense. I‚Äôll explore it

Message : I had estimated this sometime back. You should be able to outsource this task to any of the companies which builds scraper if you don‚Äôt intend to maintain the pipeline of newly granted patents. Speak to Arbdossier who I know were working to get this data. 

Good thing is that data is public. Second, what the usecase to fine tune? Are you wanting to create a patent application search or generation application?
Quoted Message : I am essentially intending on collecting Indian patent data. Aside from days analysis, Initially i would hope to use the data for fine-tuning existing open source models from a document automation point of view.

Message : If you're just running your script on a remote server and need access to GPU as well, try modal.
Quoted Message : Hi all,\nI am trying to create a large dataset for fine-tuning, analysis, etc.\n\nIt involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.\n\nWhat would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)

Message : Search is something i do intend to work on, but not at the moment.

Generating parts of specification, claims, drafting prototypical versions of certain intentions, etc are my use cases
Quoted Message : I had estimated this sometime back. You should be able to outsource this task to any of the companies which builds scraper if you don‚Äôt intend to maintain the pipeline of newly granted patents. Speak to Arbdossier who I know were working to get this data. \n\nGood thing is that data is public. Second, what the usecase to fine tune? Are you wanting to create a patent application search or generation application?

Message : Then I would suggest to separate data collection and analysis. Here data collection is more complex owing to different issues you mentioned. Handling data can be done in many ways.
Quoted Message : I am essentially intending on collecting Indian patent data. Aside from days analysis, Initially i would hope to use the data for fine-tuning existing open source models from a document automation point of view.

Message : Then public data might not work. I filed a patent application last year and your best shot at sourcing this is some patent filing firm or a lawyer
Quoted Message : Search is something i do intend to work on, but not at the moment.\n\nGenerating parts of specification, claims, drafting prototypical versions of certain intentions, etc are my use cases

Message : If there's GPU required in this pipeline then feel free to try Q Blocks as well.
Quoted Message : Hi all,\nI am trying to create a large dataset for fine-tuning, analysis, etc.\n\nIt involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.\n\nWhat would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)

Message : Or sqlite
Quoted Message : Try to store I parquet formats

Message : Has anyone worked on analyzing amazon reviews using open ai or any open source models? I would like to talk to anyone as I am trying to build a product based on it.

Message : Yes. I did realise my technical wouldn't sufficient to do them simultaneously either
Quoted Message : Then I would suggest to separate data collection and analysis. Here data collection is more complex owing to different issues you mentioned. Handling data can be done in many ways.

Message : I would like to avoid that due to reasons, despite being a patent lawyer at a firm.

Unreliability aside, my current pain seems to be handling the data i retrieve. I can't handle it my laptop ( sending requests and storing data) and i am relatively new to cloud.
Quoted Message : Then public data might not work. I filed a patent application last year and your best shot at sourcing this is some patent filing firm or a lawyer

Message : I was going to understand preferred stack for the task

Message : ‚Äé~‚ÄØSoumyadeep Mukherjee added ‚Ä™+91¬†81590¬†63404‚Ä¨

Message : We (https://oraika.com) did it. DM
Quoted Message : Has anyone worked on analyzing amazon reviews using open ai or any open source models? I would like to talk to anyone as I am trying to build a product based on it.

Message : Had created a small chrome extension to summarise the comments into pros and cons.
Quoted Message : Has anyone worked on analyzing amazon reviews using open ai or any open source models? I would like to talk to anyone as I am trying to build a product based on it.

Message : was added to chat

Message : ‚Äé~‚ÄØZainab Bawa added ‚Ä™+91¬†91¬†76480¬†297‚Ä¨

Message : We (https://oraika.com) did it. DM

Message : Had created a small chrome extension to summarise the comments into pros and cons.

Message : https://twitter.com/DimitrisPapail/status/1673331620034625537?t=oS6eoprFL_3vmvUvwlsw0A&s=08

Message : Using chunk sizes of around 2000, right now
Quoted Message : What is your chunk suze maybe playing with chunk size may help , by that i mean reducing it to 2000 or 1500

Message : With Redis, I see HNSW and FLAT, no implementation of FAISS available. Anyone has any recommendations on which similarity measures to consider?
Quoted Message : The ranking algorithm that's being used in your vector store isn't working that great? Maybe the search query term is matching a vast surface area of objects from your knowledge base ... and the valuable matches are not ranked to top?

Message : FAISS seems quite popular, HNSW is also

Message : AFAIK FAISS is a library
Quoted Message : FAISS seems quite popular, HNSW is also

Message : Did someone experiment Colbert V2 retrieval ?

Message : There are trade offs between flat and hnsw. Don‚Äôt remember from the top of my head, with more points hnsw does better
Quoted Message : With Redis, I see HNSW and FLAT, no implementation of FAISS available. Anyone has any recommendations on which similarity measures to consider?

Message : Yes! Colebert does better than DPR when the k is small but with larger k-s DPR does better.
Quoted Message : Did someone experiment Colbert V2 retrieval ?

Message : https://www.databricks.com/company/newsroom/press-releases/databricks-signs-definitive-agreement-acquire-mosaicml-leading-generative-ai-platform

For $1.3 Billion

Message : Has anyone evaluated their models? seems the recent one is MPT-30B

Message : Has to be the fastest journey to a billion dollar acquisition https://twitter.com/NaveenGRao/status/1333965556496560129
Quoted Message : https://www.databricks.com/company/newsroom/press-releases/databricks-signs-definitive-agreement-acquire-mosaicml-leading-generative-ai-platform\n\nFor $1.3 Billion

Message : wiz.io would like to enter this conversation
Quoted Message : Has to be the fastest journey to a billion dollar acquisition https://twitter.com/NaveenGRao/status/1333965556496560129

Message : haha. Wiz isn't acquired yet! But given the growth, they might soon send up with an IPO
Quoted Message : wiz.io would like to enter this conversation

Message : I'm just getting prepared for side effects from the new gpt4 model rolling out tommorow

Message : One basic noob question 

For a query to find similar queries from a set of data does different embeddings have different meanings?

For example if I am using the cohere embedding or HF embeddings or OpenAI embeddings. How much this matter?
Has anyone done any evaluation for these different embedding techniques?

Message : The scores differ slightly. So your thresholds need to be adjusted accordingly for what is considered similar
Quoted Message : One basic noob question \n\nFor a query to find similar queries from a set of data does different embeddings have different meanings? \n\nFor example if I am using the cohere embedding or HF embeddings or OpenAI embeddings. How much this matter? \nHas anyone done any evaluation for these different embedding techniques?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : There are trade offs between flat and hnsw. Don‚Äôt remember from the top of my head, with more points hnsw does better
Quoted Message : With Redis, I see HNSW and FLAT, no implementation of FAISS available. Anyone has any recommendations on which similarity measures to consider?

Message : Yes! Colebert does better than DPR when the k is small but with larger k-s DPR does better.
Quoted Message : Did someone experiment Colbert V2 retrieval ?

Message : https://www.databricks.com/company/newsroom/press-releases/databricks-signs-definitive-agreement-acquire-mosaicml-leading-generative-ai-platform

For $1.3 Billion

Message : Has anyone evaluated their models? seems the recent one is MPT-30B

Message : Has to be the fastest journey to a billion dollar acquisition https://twitter.com/NaveenGRao/status/1333965556496560129
Quoted Message : https://www.databricks.com/company/newsroom/press-releases/databricks-signs-definitive-agreement-acquire-mosaicml-leading-generative-ai-platform\n\nFor $1.3 Billion

Message : wiz.io would like to enter this conversation
Quoted Message : Has to be the fastest journey to a billion dollar acquisition https://twitter.com/NaveenGRao/status/1333965556496560129

Message : haha. Wiz isn't acquired yet! But given the growth, they might soon send up with an IPO
Quoted Message : wiz.io would like to enter this conversation

Message : I'm just getting prepared for side effects from the new gpt4 model rolling out tommorow

Message : One basic noob question 

For a query to find similar queries from a set of data does different embeddings have different meanings?

For example if I am using the cohere embedding or HF embeddings or OpenAI embeddings. How much this matter?
Has anyone done any evaluation for these different embedding techniques?

Message : The scores differ slightly. So your thresholds need to be adjusted accordingly for what is considered similar
Quoted Message : One basic noob question \n\nFor a query to find similar queries from a set of data does different embeddings have different meanings? \n\nFor example if I am using the cohere embedding or HF embeddings or OpenAI embeddings. How much this matter? \nHas anyone done any evaluation for these different embedding techniques?

Message : https://huggingface.co/spaces/mteb/leaderboard
Quoted Message : One basic noob question \n\nFor a query to find similar queries from a set of data does different embeddings have different meanings? \n\nFor example if I am using the cohere embedding or HF embeddings or OpenAI embeddings. How much this matter? \nHas anyone done any evaluation for these different embedding techniques?

Message : I believe there are 2 parts of your question.
1. How do different embeddings differ and what should be considered before choosing one?
2. Is there an eval to understand the differences in performance between embeddings?
Quoted Message : One basic noob question \n\nFor a query to find similar queries from a set of data does different embeddings have different meanings? \n\nFor example if I am using the cohere embedding or HF embeddings or OpenAI embeddings. How much this matter? \nHas anyone done any evaluation for these different embedding techniques?

Message : #1 Embeddings differ in
* Training corpus and vocab
* Task on which they're optimised - semantic similarity/classification
* Dimensions of embeddings - this is important for how big your document size is that you're going to process with the embeddings
* Method of generating embeddings - sparse/dense/contextual or word vs sentence embeddings

#2 - The eval to identify which embeddings of which dimension perform best on a given task is MTEB leaderboard

Message : For all practical purposes, it'll be ok for you to go to MTEB leaderboard and just sort for best embeddings for the task you want and budget yourself to the size of embeddings based on how much compute and data you've to work with.
Or just use a paid api service to manage all of that for you.

Message : Existing Prompts will break or have silent failures starting today!

Short Term Fix:
‚úÖ gpt-4 ‚Üí  gpt-4-0314
‚úÖgpt-3.5-turbo ‚Üí gpt-3.5-turbo-0301

Message : Thanks a lot nirant. Is there a link to a blog or changelog? Or is today the cutoff date for the functions update launched a couple of weeks ago

Message : Hardmaru left StabilityAI. Things heating up.

Message : Cutoff date
Quoted Message : Thanks a lot nirant. Is there a link to a blog or changelog? Or is today the cutoff date for the functions update launched a couple of weeks ago

Message : üí°use a rapid writing format like short hand to convert user input into that format>send to GPT>Instruct GPT to respond in the same format>convert to normal text for user output.

Not sure if can work on production yet but very niche solution to a niche pain point. This reduces the token cost directly.

Any thoughts? ChatGPT Thoughts: https://chat.openai.com/share/cfb8bbba-41f3-4d24-b39f-d6398615c39a

Message : ‚Äé<attached: 00010454-PHOTO-2023-06-27-07-07-59.jpg>

Message : ‚Äé<attached: 00010455-PHOTO-2023-06-27-07-08-00.jpg>

Message : Need something better than short hand. However reducing every input into a a shorter token input and getting output also such has potential. 

Even 15-20% savings per call is great.

Message : QQ: Is OpenAI Whisper still the reigning publicly accessible top-tier model for audio-to-text conversion, or has a new contender taken its place? tx üôÇ

Message : Try https://deepgram.com/ once
Quoted Message : QQ: Is OpenAI Whisper still the reigning publicly accessible top-tier model for audio-to-text conversion, or has a new contender taken its place? tx üôÇ

Message : Register here for the panel with Chief Scientist of MosaicML, Jonathan Frankle! its a little late for India (230am), but it will be recorded as well. 

https://lu.ma/g4asrvqy
Quoted Message : https://www.databricks.com/company/newsroom/press-releases/databricks-signs-definitive-agreement-acquire-mosaicml-leading-generative-ai-platform\n\nFor $1.3 Billion

Message : Models are okay but they are great to fine tune on.
Quoted Message : Has anyone evaluated their models? seems the recent one is MPT-30B

Message : https://lilianweng.github.io/posts/2023-06-23-agent/ - detailed blog post on 'LLM Powered Autonomous Agents' from Lilian Weng.

Message : Excellent read, just finished it
Quoted Message : https://lilianweng.github.io/posts/2023-06-23-agent/ - detailed blog post on 'LLM Powered Autonomous Agents' from Lilian Weng.

Message : it just popped up on my twitter feed, was just about to post that,
excellent read !
Quoted Message : https://lilianweng.github.io/posts/2023-06-23-agent/ - detailed blog post on 'LLM Powered Autonomous Agents' from Lilian Weng.

Message : How are you or others finding the new model
Quoted Message : Existing Prompts will break or have silent failures starting today!\n\nShort Term Fix: \n‚úÖ gpt-4 ‚Üí  gpt-4-0314 \n‚úÖgpt-3.5-turbo ‚Üí gpt-3.5-turbo-0301

Message : btw, quick question
How does anyone join this community?
Is there a link to the group or something or shall I tag the admins here along with the contact number?

Message : DM any of the admins, the contact number they will help you out.
Quoted Message : btw, quick question\nHow does anyone join this community?\nIs there a link to the group or something or shall I tag the admins here along with the contact number?

Message : DM one of the admins, that's the easiest way for noe
Quoted Message : btw, quick question\nHow does anyone join this community?\nIs there a link to the group or something or shall I tag the admins here along with the contact number?

Message : Hey guys, Has anyone here done multi-node distributed training using Pytorch on E2E?

Message : We have been struggling with this for some time.

Message : Using gpt-4-0613 for few days now. Longer & complex prompts run much better. 8k is great, but some loss happens when you run 8k vs 4k. Claude seems too far behind when compared to this.
Quoted Message : How are you or others finding the new model

Message : Or anywhere else where we can get multiple H100s at the same price as E2E
Quoted Message : Hey guys, Has anyone here done multi-node distributed training using Pytorch on E2E?

Message : 4k? Are you talking of 3.5 turbo?
Quoted Message : Using gpt-4-0613 for few days now. Longer & complex prompts run much better. 8k is great, but some loss happens when you run 8k vs 4k. Claude seems too far behind when compared to this.

Message : no i meant using gpt-4-0613 itself. it supports upto 8912 tokens. found 4k to be a little better at capturing some nuances that the model glosses over at 8k.
Quoted Message : 4k? Are you talking of 3.5 turbo?

Message : Ok so you mean context length
Quoted Message : no i meant using gpt-4-0613 itself. it supports upto 8912 tokens. found 4k to be a little better at capturing some nuances that the model glosses over at 8k.

Message : I was a bit shocked at first. I was like did they reduce context length window as well? Then a lot of my prompts would break

Message : that'd be a nightmare :)
Quoted Message : I was a bit shocked at first. I was like did they reduce context length window as well? Then a lot of my prompts would break

Message : How are Mosaic's text models in terms of quality and cost? https://docs.mosaicml.com/en/latest/inference.html

Message : ‚Äé<attached: 00010483-PHOTO-2023-06-27-13-03-17.jpg>

Message : Looking for a reviewer for this PR, I've never done JS/TS ‚Äî so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:  
https://github.com/hwchase17/langchainjs/pull/1771

Message : by building the lib from source and using in a ts test? https://blog.logrocket.com/testing-typescript-apps-using-jest/
Quoted Message : Looking for a reviewer for this PR, I've never done JS/TS ‚Äî so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:  \nhttps://github.com/hwchase17/langchainjs/pull/1771

Message : I couldn't find a docker-compose which starts a local qdrant instance, and therefore it seems that the integration test for qdrant has been intentionally skipped: https://github.com/hwchase17/langchainjs/blob/main/langchain/src/vectorstores/tests/qdrant.int.test.ts#L23

So, upto you whether you'd like to include all that testing infrastructure and then try test the api-key based auth for the local server itself (https://qdrant.tech/documentation/guides/security/#authentication - its supported). But that might be too much for this PR's scope üôà
Quoted Message : Looking for a reviewer for this PR, I've never done JS/TS ‚Äî so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:  \nhttps://github.com/hwchase17/langchainjs/pull/1771

Message : Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?

Message : Yup, sounds like a job for next PR
Quoted Message : I couldn't find a docker-compose which starts a local qdrant instance, and therefore it seems that the integration test for qdrant has been intentionally skipped: https://github.com/hwchase17/langchainjs/blob/main/langchain/src/vectorstores/tests/qdrant.int.test.ts#L23\n\nSo, upto you whether you'd like to include all that testing infrastructure and then try test the api-key based auth for the local server itself (https://qdrant.tech/documentation/guides/security/#authentication - its supported). But that might be too much for this PR's scope üôà

Message : Maybe Elasticsearch
Quoted Message : Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I was a bit shocked at first. I was like did they reduce context length window as well? Then a lot of my prompts would break

Message : that'd be a nightmare :)
Quoted Message : I was a bit shocked at first. I was like did they reduce context length window as well? Then a lot of my prompts would break

Message : How are Mosaic's text models in terms of quality and cost? https://docs.mosaicml.com/en/latest/inference.html

Message : ‚Äé<attached: 00010483-PHOTO-2023-06-27-13-03-17.jpg>

Message : Looking for a reviewer for this PR, I've never done JS/TS ‚Äî so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:  
https://github.com/hwchase17/langchainjs/pull/1771

Message : by building the lib from source and using in a ts test? https://blog.logrocket.com/testing-typescript-apps-using-jest/
Quoted Message : Looking for a reviewer for this PR, I've never done JS/TS ‚Äî so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:  \nhttps://github.com/hwchase17/langchainjs/pull/1771

Message : I couldn't find a docker-compose which starts a local qdrant instance, and therefore it seems that the integration test for qdrant has been intentionally skipped: https://github.com/hwchase17/langchainjs/blob/main/langchain/src/vectorstores/tests/qdrant.int.test.ts#L23

So, upto you whether you'd like to include all that testing infrastructure and then try test the api-key based auth for the local server itself (https://qdrant.tech/documentation/guides/security/#authentication - its supported). But that might be too much for this PR's scope üôà
Quoted Message : Looking for a reviewer for this PR, I've never done JS/TS ‚Äî so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:  \nhttps://github.com/hwchase17/langchainjs/pull/1771

Message : Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?

Message : Yup, sounds like a job for next PR
Quoted Message : I couldn't find a docker-compose which starts a local qdrant instance, and therefore it seems that the integration test for qdrant has been intentionally skipped: https://github.com/hwchase17/langchainjs/blob/main/langchain/src/vectorstores/tests/qdrant.int.test.ts#L23\n\nSo, upto you whether you'd like to include all that testing infrastructure and then try test the api-key based auth for the local server itself (https://qdrant.tech/documentation/guides/security/#authentication - its supported). But that might be too much for this PR's scope üôà

Message : Maybe Elasticsearch
Quoted Message : Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?

Message : Weaviate supports this
Quoted Message : Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?

Message : Every VectorDB does if you've IDs from the metadata query/filter

Message : Did you try Chroma?
Quoted Message : Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?

Message : Good question - I think Weaviate does that (from anecdotal conversations) 

1/ It allows storing data objects and vector embeddings from various ML models

2/ It enables combining multiple search techniques such as keyword-based and vector search

Might be a little off - would let other practitioners contribute/correct
Quoted Message : Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?

Message : Hashnode (https://hashnode.com/rix) will speaking about Anthropic in Production and Llama Index contributor Ravi @91955016xxxx will be speaking about Llama Index in production including evaluation: https://lu.ma/ai-talks-4

Message : Appied- looking forward to attending this - Also does anyone know the average wait time for getting api access approval for anthropic ?
Quoted Message : Hashnode (https://hashnode.com/rix) will speaking about Anthropic in Production and Llama Index contributor Ravi @9195xxxxxxxx will be speaking about Llama Index in production including evaluation: https://lu.ma/ai-talks-4

Message : Took almost a month for us ‚Äé<This message was edited>
Quoted Message : Appied- looking forward to attending this - Also does anyone know the average wait time for getting api access approval for anthropic ?

Message : OpenAI competes for the same $$ as MSFT ü§Ø

https://twitter.com/frantzfries/status/1673410118246105088

Message : MS owns 75% of openAI's profits until it's 10B investment is paid off.

Message : So it's like heads I win, tails you lose.

Message : Were you given access to all the models ? I have applied yesterday, fingers crossed.
Quoted Message : Took almost a month for us

Message : which gives OpenAI lot of incentive to either never declare profit or declare profits and dividend it out asap
Quoted Message : MS owns 75% of openAI's profits until it's 10B investment is paid off.

Message : How to get access to the Langchain platform?

Message : OpenAI brand is way cooler than MSFT in consumer. If I was Microsoft, I would let OpenAi go consumer and then buy them out while maintaining the brand

Message : Interesting !
https://twitter.com/soumithchintala/status/1671267150101721090

Message : Microsoft consumer is way bigger. It has windows and MSN and Bing (which is also profitable) and LinkedIn and Skype and even teams launching for consumers
Quoted Message : OpenAI brand is way cooler than MSFT in consumer. If I was Microsoft, I would let OpenAi go consumer and then buy them out while maintaining the brand

Message : MS owns 49% of openAI anyway, they would not mind openAI increasing itself in valuation. MS is a giant and a household name, so it's not easy for anybody to replace them willy nilly in the short term. Plus they've rights to use openAI products in their own products. Quite a brilliant deal for 10B actually.

Message : Yeah, they can continue spending on infra. But guess who provides them infra primarily - Azure üòÇ
Quoted Message : which gives OpenAI lot of incentive to either never declare profit or declare profits and dividend it out asap

Message : Which begs the question - why would OpenAI do a deal like this, where they give away the first rights to all tech they develop to MS.
Quoted Message : MS owns 49% of openAI anyway, they would not mind openAI increasing itself in valuation. MS is a giant and a household name, so it's not easy for anybody to replace them willy nilly in the short term. Plus they've rights to use openAI products in their own products. Quite a brilliant deal for 10B actually.

Message : I guess at the time, access to capital and compute was important
Quoted Message : Which begs the question - why would OpenAI do a deal like this, where they give away the first rights to all tech they develop to MS.

Message : ChatGPT was not a sure shot.
They took in the Microsoft deal and investment when they had a vague goal to work on AGI and no idea how lucrative it could become
Quoted Message : Which begs the question - why would OpenAI do a deal like this, where they give away the first rights to all tech they develop to MS.

Message : I am talking about the 1 billion $ investment in 2019

When OpenAI transitioned from non profit to capped for profit
Quoted Message : ChatGPT was not a sure shot.\nThey took in the Microsoft deal and investment when they had a vague goal to work on AGI and no idea how lucrative it could become

Message : july 22, 2019
https://openai.com/blog/microsoft-invests-in-and-partners-with-openai
Quoted Message : I am talking about the 1 billion $ investment in 2019\n\nWhen OpenAI transitioned from non profit to capped for profit

Message : I remember a video about OpenAI where they discussed Musk's early involvement - before the MSFT partnership. Musk pumped in about a billion each year, if I'm correct
Quoted Message : july 22, 2019\nhttps://openai.com/blog/microsoft-invests-in-and-partners-with-openai

Message : He said he would but the actual money quite merger. He asked for sole  control If they wanted more money. Sam refused and went with MSFT
Quoted Message : I remember a video about OpenAI where they discussed Musk's early involvement - before the MSFT partnership. Musk pumped in about a billion each year, if I'm correct

Message : the _next_ cage fight will be Musk v Altman

Message : Given Musk's recent behaviour at twitter over the last year or so, very wise decion by Sama ! :)
Quoted Message : He said he would but the actual money quite merger. He asked for sole  control If they wanted more money. Sam refused and went with MSFT

Message : *decision
Quoted Message : Given Musk's recent behaviour at twitter over the last year or so, very wise decion by Sama ! :)

Message : ‚Äé~‚ÄØRavi Theja added ‚Ä™+91¬†98663¬†63381‚Ä¨

Message : Despite his behaviour I think Twitter got better thanks to Musk's acquisition - they actually generate revenue these days, and some features are welcome. Some like sketchy validated accounts are still an issue but also proved that you don't need a huge team like Twitter had to run that scale of application. I could be wrong though - time will tell.
Quoted Message : *decision

Message : I'm very tempted to chime in, but this is most def off topic for this forum üôè
Quoted Message : Despite his behaviour I think Twitter got better thanks to Musk's acquisition - they actually generate revenue these days, and some features are welcome. Some like sketchy validated accounts are still an issue but also proved that you don't need a huge team like Twitter had to run that scale of application. I could be wrong though - time will tell.

Message : Thanks, Nirant for keeping me on track.

Message : Nah... Nowhere close to a bil a year...
Quoted Message : I remember a video about OpenAI where they discussed Musk's early involvement - before the MSFT partnership. Musk pumped in about a billion each year, if I'm correct

Message : https://techcrunch.com/2023/05/17/elon-musk-used-to-say-he-put-100m-in-openai-but-now-its-50m-here-are-the-receipts/

Message : I am sure msft have considered this prior to investment and later promoting. What are the msft products likely to be disrupted by openai, not immediately but in 3-5 years span? ‚Äé<This message was edited>

Message : Claude & Claude Instant v1
Quoted Message : Were you given access to all the models ? I have applied yesterday, fingers crossed.

Message : yes, looks like proper execution
Quoted Message : I am sure msft have considered this prior to investment and later promoting. What are the msft products likely to be disrupted by openai, not immediately but in 3-5 years span?

Message : Does anyone have any rough numbers / guesstimates on what revenue openAI and FM companies are currently run rating at? Similarly, any numbers for other Infra providers?
Quoted Message : MS owns 75% of openAI's profits until it's 10B investment is paid off.

Message : Applied 3-4 days back. But go no confirmation mail about being on the waitlist either. Was it case with you guys as well?
Quoted Message : Took almost a month for us

Message : was added to chat


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I'm very tempted to chime in, but this is most def off topic for this forum üôè
Quoted Message : Despite his behaviour I think Twitter got better thanks to Musk's acquisition - they actually generate revenue these days, and some features are welcome. Some like sketchy validated accounts are still an issue but also proved that you don't need a huge team like Twitter had to run that scale of application. I could be wrong though - time will tell.

Message : Thanks, Nirant for keeping me on track.

Message : Nah... Nowhere close to a bil a year...
Quoted Message : I remember a video about OpenAI where they discussed Musk's early involvement - before the MSFT partnership. Musk pumped in about a billion each year, if I'm correct

Message : https://techcrunch.com/2023/05/17/elon-musk-used-to-say-he-put-100m-in-openai-but-now-its-50m-here-are-the-receipts/

Message : I am sure msft have considered this prior to investment and later promoting. What are the msft products likely to be disrupted by openai, not immediately but in 3-5 years span? ‚Äé<This message was edited>

Message : Claude & Claude Instant v1
Quoted Message : Were you given access to all the models ? I have applied yesterday, fingers crossed.

Message : yes, looks like proper execution
Quoted Message : I am sure msft have considered this prior to investment and later promoting. What are the msft products likely to be disrupted by openai, not immediately but in 3-5 years span?

Message : Does anyone have any rough numbers / guesstimates on what revenue openAI and FM companies are currently run rating at? Similarly, any numbers for other Infra providers?
Quoted Message : MS owns 75% of openAI's profits until it's 10B investment is paid off.

Message : Applied 3-4 days back. But go no confirmation mail about being on the waitlist either. Was it case with you guys as well?
Quoted Message : Took almost a month for us

Message : was added to chat

Message : Yup
Quoted Message : Applied 3-4 days back. But go no confirmation mail about being on the waitlist either. Was it case with you guys as well?

Message : Dealroom estimates $200M for OpenAI in 2023 and $1B in 2024. Source not available.

https://twitter.com/dealroomco/status/1672189846373138432?t=qBgCuvmGjyLS-ClkX0I8Hg&s=19
Quoted Message : Does anyone have any rough numbers / guesstimates on what revenue openAI and FM companies are currently run rating at? Similarly, any numbers for other Infra providers?

Message : They've taken an integration approach. Generative AI for powerpoint, word, stuff like that.
Quoted Message : I am sure msft have considered this prior to investment and later promoting. What are the msft products likely to be disrupted by openai, not immediately but in 3-5 years span?

Message : "Now Demis Hassabis, DeepMind‚Äôs cofounder and CEO, says his engineers are using techniques from AlphaGo to make an AI system dubbed Gemini that will be more capable than that behind OpenAI‚Äôs ChatGPT." Looks like they are experimenting to improve RLHF as they are vastly experienced on RL..

https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/

Message : Oh look, someone who was signing a petition to not do any agi development for 6 months is not keeping his wordüòÇüòÇüòÇ ‚Äé<This message was edited>
Quoted Message : \"Now Demis Hassabis, DeepMind‚Äôs cofounder and CEO, says his engineers are using techniques from AlphaGo to make an AI system dubbed Gemini that will be more capable than that behind OpenAI‚Äôs ChatGPT.\" Looks like they are experimenting to improve RLHF as they are vastly experienced on RL..\n\nhttps://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/

Message : typical hype adoption cycle ü´°
Quoted Message : Oh look, someone who was signing a petition to not do any agi development for 6 months is not keeping his wordüòÇüòÇüòÇ

Message : How is langchain plus different from langchain

Message : If you add CSS to something, it's called Plus
If you add SSO to something, it's called Pro
If you add both, it's called Enterprise Ready

ü§£
Quoted Message : How is langchain plus different from langchain

Message : ‚Äé<attached: 00010538-PHOTO-2023-06-27-19-00-38.jpg>

Message : interesting eval work from graham neubig of cmu
https://github.com/zeno-ml/zeno-build

Message : ‚Äé~‚ÄØNirant removed ‚Ä™+91¬†74010¬†77634‚Ä¨

Message : Come to think of it, even chatgpt doesn't have RBAC, team management, reporting

Message : There are lot of errors which are forgiven if you build something exceptional üôè

It's profitable for most folks to assume that they're not Ilya or Greg or Sam Altman, then to assume that they're
Quoted Message : Come to think of it, even chatgpt doesn't have RBAC, team management, reporting

Message : Folks, we've confirmed multiple spam reports from Wyse founders and teammates. We do not tolerate spam.

I've removed everyone I could find right now, from both the community and WhatsApp group.
We've also reported the number to WhatsApp.

Sincerest apologies for the inconvenience, trying our best üôè

- Nirant, on behalf of the GenerativeAI Community

Message : talk about pre-pmf distribution :P
Quoted Message : Folks, we've confirmed multiple spam reports from Wyse founders and teammates. We do not tolerate spam.\n\nI've removed everyone I could find right now, from both the community and WhatsApp group. \nWe've also reported the number to WhatsApp. \n\nSincerest apologies for the inconvenience, trying our best üôè\n\n- Nirant, on behalf of the GenerativeAI Community

Message : novel idea though?

Message : shh, that's for others to implement
Quoted Message : Come to think of it, even chatgpt doesn't have RBAC, team management, reporting

Message : Nirant is the moderator we need, but don't deserve :P
Quoted Message : Folks, we've confirmed multiple spam reports from Wyse founders and teammates. We do not tolerate spam.\n\nI've removed everyone I could find right now, from both the community and WhatsApp group. \nWe've also reported the number to WhatsApp. \n\nSincerest apologies for the inconvenience, trying our best üôè\n\n- Nirant, on behalf of the GenerativeAI Community

Message : Hello Everyone,
I am actively looking for communities or teams who are building something really impactful for society. I want to be part of such a team, let me know if anyone is looking for backend developer for their team.

About Me:- i am Anuja and I am proficient in python and have worked with golang microservices. I am one year experienced and i am just keen to learn, not getting paid is okay for me. DM me if anyone is looking a really motivated team member.

Message : For SM companies, critical distribution is the PMF üòÄ
Quoted Message : talk about pre-pmf distribution :P

Message : You might want to check this, has open jobs and upcoming events (which are often sponsored by companies looking to hire): 
https://nirantk.com/community
Quoted Message : Hello Everyone,\n          I am actively looking for communities or teams who are building something really impactful for society. I want to be part of such a team, let me know if anyone is looking for backend developer for their team. \n\nAbout Me:- i am Anuja and I am proficient in python and have worked with golang microservices. I am one year experienced and i am just keen to learn, not getting paid is okay for me. DM me if anyone is looking a really motivated team member.

Message : You might find ragas: https://github.com/explodinggradients/ragas from Jithin and friends @91944622xxxx interesting
Quoted Message : interesting eval work from graham neubig of cmu\nhttps://github.com/zeno-ml/zeno-build

Message : was removed from chat

Message : this is gold üòÇüî•
Quoted Message : If you add CSS to something, it's called Plus\nIf you add SSO to something, it's called Pro\nIf you add both, it's called Enterprise Ready\n\nü§£

Message : Have a perspective on this actually, thinking how best to share it

A lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG

Usually, that starts with a land in smaller companies and then growing into org wide adoption

Enterprise grade features were required at a much later stage

In fact, there's SaaS for enabling SaaS companies to be enterprise ready

Gen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster

Message : It's one of those tech which customers are demanding ( and expecting ) and hence, orgs are looking for a solution. It's very much a Pull than a push for this sort of solutions.
Quoted Message : Have a perspective on this actually, thinking how best to share it\n\nA lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG\n\nUsually, that starts with a land in smaller companies and then growing into org wide adoption\n\nEnterprise grade features were required at a much later stage\n\nIn fact, there's SaaS for enabling SaaS companies to be enterprise ready\n\nGen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster

Message : Absolutely, pre-product PMF ü´£
Quoted Message : It's one of those tech which customers are demanding ( and expecting ) and hence, orgs are looking for a solution. It's very much a Pull than a push for this sort of solutions.

Message : What types of SaaS gets you enterprise ready? Specifically, any good resources on enabling SSO/SAML?
Quoted Message : Have a perspective on this actually, thinking how best to share it\n\nA lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG\n\nUsually, that starts with a land in smaller companies and then growing into org wide adoption\n\nEnterprise grade features were required at a much later stage\n\nIn fact, there's SaaS for enabling SaaS companies to be enterprise ready\n\nGen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster

Message : Also, there's a question of liability that's often coming up. Given how non deterministic the outputs are. If anyone has a perspective on how enterprises are tackling this with vendors, that would be great

Message : For example, if there's an erroneous response or action given by the AI, is there any liability on the vendor? And, to what degree

Message : https://workos.com

Have you checked them out? Solid developer Experience
Quoted Message : What types of SaaS gets you enterprise ready? Specifically, any good resources on enabling SSO/SAML?

Message : Nope. But saw them on a few Google ads. Thanks. Will do
Quoted Message : https://workos.com\n\nHave you checked them out? Solid developer Experience

Message : And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up

This is typically done by separating control plane and data plane

Replicated is a solid Product here

Message : Interesting. Will check them out. This is going to be even more relevant now. Given lots of folks are paranoid about data leakage to external models
Quoted Message : And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up\n\nThis is typically done by separating control plane and data plane\n\nReplicated is a solid Product here

Message : was added to chat

Message : There's one more product that allows enterprises to interface their data with LLMs in a Privacy preserved manner

This is another vector of becoming enterprise ready when it comes to LLMs

Happy to share more deets about it 1:1 for those who are interested

Message : To PCs point - I had chat with head of AI for a top 3 services company in India. He mentioned the same thing. The pace of AI adoption among enterprises is truly surprising to them. They are expecting 6m to 12m windows for org wide deployment which in the enterprise world is very short. Also service companies are going to make a lot of money helping enterprises in building internal LLMs üí≤üí≤
Quoted Message : Have a perspective on this actually, thinking how best to share it\n\nA lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG\n\nUsually, that starts with a land in smaller companies and then growing into org wide adoption\n\nEnterprise grade features were required at a much later stage\n\nIn fact, there's SaaS for enabling SaaS companies to be enterprise ready\n\nGen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster

Message : Get connected to FOSSUnited. They have a FOSS for Good mandate. Lovely opportunity for Devs looking to contribute to society in real ways. 

Needless to say, guidance from Kailash Nadh is a propellant.
Quoted Message : Hello Everyone,\n          I am actively looking for communities or teams who are building something really impactful for society. I want to be part of such a team, let me know if anyone is looking for backend developer for their team. \n\nAbout Me:- i am Anuja and I am proficient in python and have worked with golang microservices. I am one year experienced and i am just keen to learn, not getting paid is okay for me. DM me if anyone is looking a really motivated team member.

Message : Got quite a few pings 1:1 from folks post this and hence sharing it here for everyone in case it helps a broader audience 

From my vantage point (which might be limited and/or a sampling bias), there aren't many companies that have found PMF following a Bottoms-up/PLG strategy in the last few years

Where it's worked out well is where the product is core infrastructure that is usually sold as an OSS layer

Some people put it on the macro with tightening budgets et al

My sense is that it's more about the channel - akin to something like your home screen on your mobile. There's only so much space for so many apps there.

Happy to learn from others üôèüèº
Quoted Message : Have a perspective on this actually, thinking how best to share it\n\nA lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG\n\nUsually, that starts with a land in smaller companies and then growing into org wide adoption\n\nEnterprise grade features were required at a much later stage\n\nIn fact, there's SaaS for enabling SaaS companies to be enterprise ready\n\nGen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster

Message : FOSSUnited has an active job board too
https://fossunited.org/jobs
Quoted Message : Get connected to FOSSUnited. They have a FOSS for Good mandate. Lovely opportunity for Devs looking to contribute to society in real ways. \n\nNeedless to say, guidance from Kailash Nadh is a propellant.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://workos.com

Have you checked them out? Solid developer Experience
Quoted Message : What types of SaaS gets you enterprise ready? Specifically, any good resources on enabling SSO/SAML?

Message : Nope. But saw them on a few Google ads. Thanks. Will do
Quoted Message : https://workos.com\n\nHave you checked them out? Solid developer Experience

Message : And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up

This is typically done by separating control plane and data plane

Replicated is a solid Product here

Message : Interesting. Will check them out. This is going to be even more relevant now. Given lots of folks are paranoid about data leakage to external models
Quoted Message : And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up\n\nThis is typically done by separating control plane and data plane\n\nReplicated is a solid Product here

Message : was added to chat

Message : There's one more product that allows enterprises to interface their data with LLMs in a Privacy preserved manner

This is another vector of becoming enterprise ready when it comes to LLMs

Happy to share more deets about it 1:1 for those who are interested

Message : To PCs point - I had chat with head of AI for a top 3 services company in India. He mentioned the same thing. The pace of AI adoption among enterprises is truly surprising to them. They are expecting 6m to 12m windows for org wide deployment which in the enterprise world is very short. Also service companies are going to make a lot of money helping enterprises in building internal LLMs üí≤üí≤
Quoted Message : Have a perspective on this actually, thinking how best to share it\n\nA lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG\n\nUsually, that starts with a land in smaller companies and then growing into org wide adoption\n\nEnterprise grade features were required at a much later stage\n\nIn fact, there's SaaS for enabling SaaS companies to be enterprise ready\n\nGen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster

Message : Get connected to FOSSUnited. They have a FOSS for Good mandate. Lovely opportunity for Devs looking to contribute to society in real ways. 

Needless to say, guidance from Kailash Nadh is a propellant.
Quoted Message : Hello Everyone,\n          I am actively looking for communities or teams who are building something really impactful for society. I want to be part of such a team, let me know if anyone is looking for backend developer for their team. \n\nAbout Me:- i am Anuja and I am proficient in python and have worked with golang microservices. I am one year experienced and i am just keen to learn, not getting paid is okay for me. DM me if anyone is looking a really motivated team member.

Message : Got quite a few pings 1:1 from folks post this and hence sharing it here for everyone in case it helps a broader audience 

From my vantage point (which might be limited and/or a sampling bias), there aren't many companies that have found PMF following a Bottoms-up/PLG strategy in the last few years

Where it's worked out well is where the product is core infrastructure that is usually sold as an OSS layer

Some people put it on the macro with tightening budgets et al

My sense is that it's more about the channel - akin to something like your home screen on your mobile. There's only so much space for so many apps there.

Happy to learn from others üôèüèº
Quoted Message : Have a perspective on this actually, thinking how best to share it\n\nA lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG\n\nUsually, that starts with a land in smaller companies and then growing into org wide adoption\n\nEnterprise grade features were required at a much later stage\n\nIn fact, there's SaaS for enabling SaaS companies to be enterprise ready\n\nGen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster

Message : FOSSUnited has an active job board too
https://fossunited.org/jobs
Quoted Message : Get connected to FOSSUnited. They have a FOSS for Good mandate. Lovely opportunity for Devs looking to contribute to society in real ways. \n\nNeedless to say, guidance from Kailash Nadh is a propellant.

Message : Amazing. Is there a good playbook you've seen to sell to enterprises? Specifically, how do you get that first client

I assume one of the reasons bottom up worked well is a land and expand route seems to be the natural way

Plus, your product is also more mature when it comes to POCs

But how do you bag that first enterprise client seems to be quite daunting

Message : Adding to this conversation,

We met a bunch of CXOs across enterprises in EU last week.

The biggest standout point for us was that they don't trust Microsoft with their data when it comes to AI. While they are enthusiastic about the possibilities of having an 'internal ChatGPT', they would want it to be deployed on premise.

My co-founder Vignesh shared some of the insights we got interacting with these CXOs:

https://www.linkedin.com/posts/vigneshbaskaran0123_last-week-i-co-moderated-a-session-with-activity-7078680450033979392-W4vp? ‚Äé<This message was edited>

Message : Any reason why they don't trust Microsoft?
Quoted Message : Adding to this conversation,\n\nWe met a bunch of CXOs across enterprises in EU last week. \n\nThe biggest standout point for us was that they don't trust Microsoft with their data when it comes to AI. While they are enthusiastic about the possibilities of having an 'internal ChatGPT', they would want it to be deployed on premise.\n\nMy co-founder Vignesh shared some of the insights we got interacting with these CXOs:\n\nhttps://www.linkedin.com/posts/vigneshbaskaran0123_last-week-i-co-moderated-a-session-with-activity-7078680450033979392-W4vp?

Message : Seems to be a perception issue around MS leveraging client's  data to train their models which can be used by competition as well

Message : Wow, will be very, very surprised if this is the case üò≥

Understandable if it's an EU thing/preference
Quoted Message : Seems to be a perception issue around MS leveraging client's  data to train their models which can be used by competition as well

Message : +1

Experience has been opposite
Quoted Message : Wow, will be very, very surprised if this is the case üò≥\n\nUnderstandable if it's an EU thing/preference

Message : Have some US / East asia F500 clients and folks were eager to experiment. 

Infact, there was inbound request to explore generative features.

Message : Eager to experiment with MS AI features or GenAI in general?
Quoted Message : Have some US / East asia F500 clients and folks were eager to experiment. \n\nInfact, there was inbound request to explore generative features.

Message : Some were already using Azure AI. 

Wanted us to even add generative features to our pane since they saw the benefits through their other experiments.

One learning I personally had was : there is still lack of clarity as to how they can actually use generative features. Customer is still not clear about what gen AI can and cannot do. So super high expectations sometimes.
Quoted Message : Eager to experiment with MS AI features or GenAI in general?

Message : That‚Äôs so true. To take it to enterprise grade, an entire architectural composition is required.
Consumption patterns, stakeholders interests, auth controls, re-bac, Multi-tenancy, delivery models, the triad of security , day-2 ops, DR, BC and what not. No sane enterprise is going to let another one (say msft) consume all their data and end up in a transitive relationship with their competitors.
Quoted Message : To PCs point - I had chat with head of AI for a top 3 services company in India. He mentioned the same thing. The pace of AI adoption among enterprises is truly surprising to them. They are expecting 6m to 12m windows for org wide deployment which in the enterprise world is very short. Also service companies are going to make a lot of money helping enterprises in building internal LLMs üí≤üí≤

Message : I actually have a hot take here üôä

Haven't given it much thought but sharing it colloquially with the community

The reason could be because Microsoft and OpenAI have trained their current models on copy righted data

Companies in EU might just not like the idea of using the outputs of something like thay
Quoted Message : Adding to this conversation,\n\nWe met a bunch of CXOs across enterprises in EU last week. \n\nThe biggest standout point for us was that they don't trust Microsoft with their data when it comes to AI. While they are enthusiastic about the possibilities of having an 'internal ChatGPT', they would want it to be deployed on premise.\n\nMy co-founder Vignesh shared some of the insights we got interacting with these CXOs:\n\nhttps://www.linkedin.com/posts/vigneshbaskaran0123_last-week-i-co-moderated-a-session-with-activity-7078680450033979392-W4vp?

Message : Guys, I'm planning a Responsible AI Fellowship Fund that will give grants of $5K-$75K to individuals and projects building Open Source Software that address the both Ethical and Societal issues in AI, and / or those building the base tools / frameworks / models / research that others can use. 

Currently, we have strong interest from Omidyar Network and Meta's AI Public Policy team to anchor this, hopefully we can close this in the coming weeks and announce in July / Aug.

If anyone comes across teams / individuals working in this area, please refer them to me directly and we would be happy to consider.
Quoted Message : Hello Everyone,\n          I am actively looking for communities or teams who are building something really impactful for society. I want to be part of such a team, let me know if anyone is looking for backend developer for their team. \n\nAbout Me:- i am Anuja and I am proficient in python and have worked with golang microservices. I am one year experienced and i am just keen to learn, not getting paid is okay for me. DM me if anyone is looking a really motivated team member.

Message : In most companies, MS already owns their corporate ecosystem with office 365, GitHub, Azure. Almost everything that's business critical is often present in internal SharePoints and enterprise repos. I can understand how some companies that aren't using this ecosystem may deliberate over this choice. But any company that already uses MS services and products may just sign NDAs and join the gen AI products and services as well.

Message : *many not most
Quoted Message : In most companies, MS already owns their corporate ecosystem with office 365, GitHub, Azure. Almost everything that's business critical is often present in internal SharePoints and enterprise repos. I can understand how some companies that aren't using this ecosystem may deliberate over this choice. But any company that already uses MS services and products may just sign NDAs and join the gen AI products and services as well.

Message : Unpopular personal opinion:
Enterprises (anyone with serious scale and proprietary customer/noncustomer data wanting to protect moat) in the long run, will gravitate to using LLMs on Sagemaker/AzureML/VertexAI.

First principles: At large scale, the only things that matter are: best performance, lowest cost at lowest latency.

Nothing can beat CSPs on either of the 3 at scale, given how open source models have flooded the mkt. Enterprise capabilities are a given with at least 2 of the big 3 CSPs. Also, relationships are already forged and quite strategically positioned.
Quoted Message : To PCs point - I had chat with head of AI for a top 3 services company in India. He mentioned the same thing. The pace of AI adoption among enterprises is truly surprising to them. They are expecting 6m to 12m windows for org wide deployment which in the enterprise world is very short. Also service companies are going to make a lot of money helping enterprises in building internal LLMs üí≤üí≤

Message : was added to chat

Message : I'd extend it to 6 - adding Databricks, Salesforce and Snowflake there

But there's also another interesting (hot) take where there's ongoing debate in closed groups

The question is "Is there something really proprietary in general purpose industry data? And what happens if one of them partners with a vendor to train their general purpose LLM?"

Say the largest petroleum or Commercial Real Estate law firm enters into a data sharing partnership with OpenAI - what does that mean?
Quoted Message : Unpopular personal opinion:\nEnterprises (anyone with serious scale and proprietary customer/noncustomer data wanting to protect moat) in the long run, will gravitate to using LLMs on Sagemaker/AzureML/VertexAI. \n\nFirst principles: At large scale, the only things that matter are: best performance, lowest cost at lowest latency. \n\nNothing can beat CSPs on either of the 3 at scale, given how open source models have flooded the mkt. Enterprise capabilities are a given with at least 2 of the big 3 CSPs. Also, relationships are already forged and quite strategically positioned.

Message : this is a super neat demo !

https://twitter.com/joshm/status/1673689963303514114

longer video :
https://www.youtube.com/watch?v=5p8UGSyT7a8

web dev folks might get a kick out of it !

Message : üëè

Some potential research areas:
- Steerability
- Data privacy / data sovereignty
- Explainability
- AI to supervise other AIs (constitutional AI)
Quoted Message : Guys, I'm planning a Responsible AI Fellowship Fund that will give grants of $5K-$75K to individuals and projects building Open Source Software that address the both Ethical and Societal issues in AI, and / or those building the base tools / frameworks / models / research that others can use. \n\nCurrently, we have strong interest from Omidyar Network and Meta's AI Public Policy team to anchor this, hopefully we can close this in the coming weeks and announce in July / Aug. \n\nIf anyone comes across teams / individuals working in this area, please refer them to me directly and we would be happy to consider.

Message : its just half the truth with regard to "enterprise" capabilities of big 6. The "shared responsibility" term scares a lot of business, especially large ones. While it could be tactical TTM pressures that drive most of them to CSPs, objective evaluation later puts them back to on-prem and colos. The paranoia in some cases went to such levels that we saw a potential in building segmentation at the lowest level ( link layer -eg.  GWLB svcs from all the CSPs and L2-NV from OCI). May be you are right for the SME, mid-mkt players that their core functions are cSP driven. But the large ones are still super paranoid about their infra & data. The levers of data propagation into sharepoints/githubs/boxes are well  established, controlled and monitored to mitigate DL mishaps.
Quoted Message : Unpopular personal opinion:\nEnterprises (anyone with serious scale and proprietary customer/noncustomer data wanting to protect moat) in the long run, will gravitate to using LLMs on Sagemaker/AzureML/VertexAI. \n\nFirst principles: At large scale, the only things that matter are: best performance, lowest cost at lowest latency. \n\nNothing can beat CSPs on either of the 3 at scale, given how open source models have flooded the mkt. Enterprise capabilities are a given with at least 2 of the big 3 CSPs. Also, relationships are already forged and quite strategically positioned.

Message : I'll try it out. Maybe it'll help blur LinkedIn cringe posts in my feed. ‚Äé<This message was edited>
Quoted Message : this is a super neat demo !\n\nhttps://twitter.com/joshm/status/1673689963303514114\n\nlonger video :\nhttps://www.youtube.com/watch?v=5p8UGSyT7a8\n\nweb dev folks might get a kick out of it !

Message : Didn't see it coming that 'Inspect Element' will get productized
Quoted Message : this is a super neat demo !\n\nhttps://twitter.com/joshm/status/1673689963303514114\n\nlonger video :\nhttps://www.youtube.com/watch?v=5p8UGSyT7a8\n\nweb dev folks might get a kick out of it !

Message : Creator of PaLM-2, UL2, Flan, Bard has announced a new $58M seed funded AI Lab called "Reka" reka.ai

https://twitter.com/YiTayML/status/1673722977882611712 ‚Äé<This message was edited>

Message : extremely apt productization though
Quoted Message : Didn't see it coming that 'Inspect Element' will get productized

Message : Wow. 58M$ for seed round. Is this the biggest one in history? üòÇ
Quoted Message : Creator of PaLM-2, UL2, Flan, Bard has announced a new $58M seed funded AI Lab called \"Reka\" reka.ai\n\nhttps://twitter.com/YiTayML/status/1673722977882611712

Message : Nahi, Mistral had $150M no? Or $113M or something like that
Quoted Message : Wow. 58M$ for seed round. Is this the biggest one in history? üòÇ

Message : Ahh yes. 113M $
Quoted Message : Nahi, Mistral had $150M no? Or $113M or something like that

Message : Not large enough rounds tbh. Anything less than $500M, hard to build the companies these folks are trying to build. 

I'd expect many of these to fold or raise more in next 24 months

Message : Has anyone tried inference on Falcon model by loading it in 8 bit ?

It just generates only token 0 for me.

Message : ‚Äé~‚ÄØNirant removed ~‚ÄØNishant Shukla

Message : https://www.linkedin.com/posts/clementdelangue_this-is-my-5-minute-testimony-before-the-activity-7079114622133264384-Ml3K?utm_source=share&utm_medium=member_android

What do y'all think of hugging face ceo's testimony?

Message : I've only heard his piece and not the questions he was asked. 
I think this is something for the philosophy group
Quoted Message : https://www.linkedin.com/posts/clementdelangue_this-is-my-5-minute-testimony-before-the-activity-7079114622133264384-Ml3K?utm_source=share&utm_medium=member_android\n\nWhat do y'all think of hugging face ceo's testimony?

Message : I'll move it there, thanks.
Quoted Message : I've only heard his piece and not the questions he was asked. \nI think this is something for the philosophy group

Message : Hey guys so is it a accepted fact that ada-002 works better than any other opanai embedding for code as well. Mostly for similarity detection? Thanks

Message : Don't have any benchmarks but that's what they recommend. 

There's even an example for code search in their docs where they used ```text-embedding-ada-002```
https://platform.openai.com/docs/guides/embeddings/use-cases
Quoted Message : Hey guys so is it a accepted fact that ada-002 works better than any other opanai embedding for code as well. Mostly for similarity detection? Thanks

Message : I agree. My experience has been different compared to what was discussed here, while building enterprise version of our application for Agri MNCs. There are concerns about data but there many use cases just to build on top their public data. Many already uses Azure, and using Azure OpenAI instead of OpenAI already addressed few concerns.
Quoted Message : In most companies, MS already owns their corporate ecosystem with office 365, GitHub, Azure. Almost everything that's business critical is often present in internal SharePoints and enterprise repos. I can understand how some companies that aren't using this ecosystem may deliberate over this choice. But any company that already uses MS services and products may just sign NDAs and join the gen AI products and services as well.

Message : Thanks for the suggestions Nilesh, will add them to the list of topics at our launch hackathon.
Quoted Message : üëè\n\nSome potential research areas:\n- Steerability\n- Data privacy / data sovereignty\n- Explainability\n- AI to supervise other AIs (constitutional AI)

Message : TIL about MLPerf[0] and MLCommons[1]

https://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/

0. https://arxiv.org/abs/1910.01500
1. https://mlcommons.org/en/training-normal-30/
https://mlcommons.org/en/inference-tiny-11/

I think we will see a rise of tiny models especially embedded in hardware(on device inference without internet)

Message : Anyone here has insights on what ChatGPT for business will look like?

Message : Apart from these few, more are based on industry and customers
- Certifications like SoC2, ISMS, PCI DSS, etc
- Data isolation: creating separate infra adds to the unit cost and if customers are not ready to pay it then how intelligently do you design arch to provide separation
- SLAs/SLOs (based on availability, service, latency, data sync period, MTTR, or some other KPIs)
- Disaster recovery
- Security compliances
- customizations capabilities like on UI (themes, logo, dashboard, etc) or infra like data sync period
- data processing agreement like not using data for training etc

There is an endless list so it all depends on who your customers are and need to gauge if they need it.

These points are all based on my research as an ex-founder so please take them with a pinch of salt.

And I stop before being kicked out of this group as it is off-topic. üòÖ
Quoted Message : And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up\n\nThis is typically done by separating control plane and data plane\n\nReplicated is a solid Product here


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://www.linkedin.com/posts/clementdelangue_this-is-my-5-minute-testimony-before-the-activity-7079114622133264384-Ml3K?utm_source=share&utm_medium=member_android

What do y'all think of hugging face ceo's testimony?

Message : I've only heard his piece and not the questions he was asked. 
I think this is something for the philosophy group
Quoted Message : https://www.linkedin.com/posts/clementdelangue_this-is-my-5-minute-testimony-before-the-activity-7079114622133264384-Ml3K?utm_source=share&utm_medium=member_android\n\nWhat do y'all think of hugging face ceo's testimony?

Message : I'll move it there, thanks.
Quoted Message : I've only heard his piece and not the questions he was asked. \nI think this is something for the philosophy group

Message : Hey guys so is it a accepted fact that ada-002 works better than any other opanai embedding for code as well. Mostly for similarity detection? Thanks

Message : Don't have any benchmarks but that's what they recommend. 

There's even an example for code search in their docs where they used ```text-embedding-ada-002```
https://platform.openai.com/docs/guides/embeddings/use-cases
Quoted Message : Hey guys so is it a accepted fact that ada-002 works better than any other opanai embedding for code as well. Mostly for similarity detection? Thanks

Message : I agree. My experience has been different compared to what was discussed here, while building enterprise version of our application for Agri MNCs. There are concerns about data but there many use cases just to build on top their public data. Many already uses Azure, and using Azure OpenAI instead of OpenAI already addressed few concerns.
Quoted Message : In most companies, MS already owns their corporate ecosystem with office 365, GitHub, Azure. Almost everything that's business critical is often present in internal SharePoints and enterprise repos. I can understand how some companies that aren't using this ecosystem may deliberate over this choice. But any company that already uses MS services and products may just sign NDAs and join the gen AI products and services as well.

Message : Thanks for the suggestions Nilesh, will add them to the list of topics at our launch hackathon.
Quoted Message : üëè\n\nSome potential research areas:\n- Steerability\n- Data privacy / data sovereignty\n- Explainability\n- AI to supervise other AIs (constitutional AI)

Message : TIL about MLPerf[0] and MLCommons[1]

https://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/

0. https://arxiv.org/abs/1910.01500
1. https://mlcommons.org/en/training-normal-30/
https://mlcommons.org/en/inference-tiny-11/

I think we will see a rise of tiny models especially embedded in hardware(on device inference without internet)

Message : Anyone here has insights on what ChatGPT for business will look like?

Message : Apart from these few, more are based on industry and customers
- Certifications like SoC2, ISMS, PCI DSS, etc
- Data isolation: creating separate infra adds to the unit cost and if customers are not ready to pay it then how intelligently do you design arch to provide separation
- SLAs/SLOs (based on availability, service, latency, data sync period, MTTR, or some other KPIs)
- Disaster recovery
- Security compliances
- customizations capabilities like on UI (themes, logo, dashboard, etc) or infra like data sync period
- data processing agreement like not using data for training etc

There is an endless list so it all depends on who your customers are and need to gauge if they need it.

These points are all based on my research as an ex-founder so please take them with a pinch of salt.

And I stop before being kicked out of this group as it is off-topic. üòÖ
Quoted Message : And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up\n\nThis is typically done by separating control plane and data plane\n\nReplicated is a solid Product here

Message : 12K+ ChatGPT credentials from India are on darkweb

https://tryhackme.com/r/resources/blog/month-in-cyber-june-2023

Message : For folks looking for speaking opportunities, FifthEl is India's best ML/Deep Learning conference, Aug 11 this time: 

Sumod Mohan @91990072xxxx from the group is curating the speakers for the conference.

Confirmed speakers include Saurabh @91819726xxxx from Jugalbandi, Arjun (also in this group)

Proposal Submission Deadline is 30th June I think

Link: https://hasgeek.com/fifthelephant/2023/

PS: I'm not affiliated with FifthElephant 2023, HasGeek is the co-organiser for all meetups we've done as a community since Feb

Message : cc @91955016xxxx @91797731xxxx @91750785xxxx thought you might want to speak here
Quoted Message : For folks looking for speaking opportunities, FifthEl is India's best ML/Deep Learning conference, Aug 11 this time: \n\nSumod Mohan @9199xxxxxxxx from the group is curating the speakers for the conference.\n\nConfirmed speakers include Saurabh @9181xxxxxxxx from Jugalbandi, Arjun (also in this group) \n\nProposal Submission Deadline is 30th June I think\n\nLink: https://hasgeek.com/fifthelephant/2023/\n\nPS: I'm not affiliated with FifthElephant 2023, HasGeek is the co-organiser for all meetups we've done as a community since Feb

Message : @91955016xxxx is talking about LlamaIndex. And hopefully convert you all to LlamaIndex users ;).

Message : Hey guys, what's the best open-source language agnostic model for speaker diarization? We have already tried a few but love to know any good recommendations. Audio Video types would be long (1-2 hours) and short form (10-15 secs).

Message : Whisper.cpp is adding diarization in next 2-3 months
Quoted Message : Hey guys, what's the best open-source language agnostic model for speaker diarization? We have already tried a few but love to know any good recommendations. Audio Video types would be long (1-2 hours) and short form (10-15 secs).

Message : Hi have any of you come across a project which covers an agent for iOS commands, enabled by llms?

Message : I doubt Apple would allow external automation on their platform, tools like Tasker have never existed for iOS
Quoted Message : Hi have any of you come across a project which covers an agent for iOS commands, enabled by llms?

Message : Apple has a native automation tool for both ios and macos
Quoted Message : I doubt Apple would allow external automation on their platform, tools like Tasker have never existed for iOS

Message : ‚Äé<attached: 00010623-PHOTO-2023-06-28-11-07-31.jpg>

Message : ‚Äé<attached: 00010624-PHOTO-2023-06-28-11-07-58.jpg>

Message : Haaa, really ... damn. But can it do stuff like intercept calls, notifications et al?
Quoted Message : Apple has a native automation tool for both ios and macos

Message : Probably not, apple is too pedantic about notifications
Quoted Message : Haaa, really ... damn. But can it do stuff like intercept calls, notifications et al?

Message : Nice one @91876402xxxx

Message : You can even use chatGPT like Siri using apple shortcuts https://twitter.com/mckaywrigley/status/1640414764852711425

Message : We don't have 2-3 months ü•≤, need something for now. We can train it with some data.
Quoted Message : Whisper.cpp is adding diarization in next 2-3 months

Message : This and function calling ‚ù§Ô∏è
Quoted Message : You can even use chatGPT like Siri using apple shortcuts https://twitter.com/mckaywrigley/status/1640414764852711425

Message : I think the diagram in this article has a typo. They advertise mask R-CNN training in under 1.5 minutes. That doesn't seem right. If it was the correct number, I wonder how they optimized I/O.
Quoted Message : TIL about MLPerf[0] and MLCommons[1]\n\nhttps://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/\n\n0. https://arxiv.org/abs/1910.01500\n1. https://mlcommons.org/en/training-normal-30/\nhttps://mlcommons.org/en/inference-tiny-11/\n\nI think we will see a rise of tiny models especially embedded in hardware(on device inference without internet)

Message : Has anyone implemented Microsoft guidance?
I want to generate a perfect list of JSON responses. gpt-3.5-turbo is failing to do it many times.
Is Microsoft Guidance able to do it properly, or is there any other library to get control of the output?

https://github.com/microsoft/guidance

Message : Are u using the new model 0613 version of 3.5 ? The json formatting should work
Quoted Message : Has anyone implemented Microsoft guidance?\nI want to generate a perfect list of JSON responses. gpt-3.5-turbo is failing to do it many times.\nIs Microsoft Guidance able to do it properly, or is there any other library to get control of the output?\n\nhttps://github.com/microsoft/guidance

Message : Check this if not done already

https://github.com/pyannote/pyannote-audio
Quoted Message : We don't have 2-3 months ü•≤, need something for now. We can train it with some data.

Message : I am using gpt-3.5-turbo-0613
Quoted Message : Are u using the new model 0613 version of 3.5 ? The json formatting should work

Message : Just wrap with Guardrails? https://github.com/ShreyaR/guardrails/

Message : Also, I am controlling the output using prompt, not using any external package yet.
Quoted Message : I am using gpt-3.5-turbo-0613

Message : In this case, give OpenAI Functions a chance
Quoted Message : Also, I am controlling the output using prompt, not using any external package yet.

Message : ok will implement.
Quoted Message : Just wrap with Guardrails? https://github.com/ShreyaR/guardrails/

Message : If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which @91982023xxxx uses as well: 

https://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : Meta released a paper on the recent method to increase context length using position interpolation. *The 2k context LLMs are now shown to be well functioning in various tasks like retrieval, modelling, long form summarisation with just fine tuning. A pretraining from scratch wasn't needed to increase context length to 8k, just fine tuning was enough (even LoRA).*

This method is the same as what got popular by a GitHub user named kaiokendev.

Paper - https://arxiv.org/abs/2306.15595
Independent Blog post by kaiokendev - https://kaiokendev.github.io/context

Message : Tried this
Quoted Message : Check this if not done already\n\nhttps://github.com/pyannote/pyannote-audio

Message : Or if you are feeling brave and experimental try this one: https://tinyurl.com/5n8rpu23

It structures the text data into a scheme.
Quoted Message : If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which @9198xxxxxxxx uses as well: \n\nhttps://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : I endorse this.
Quoted Message : If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which @9198xxxxxxxx uses as well: \n\nhttps://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : kor uses ReAsk while the lib I wrote use OpenAI functions, so in latency and cost terms ‚Äî this can be a difference of about 3-10x
Quoted Message : Or if you are feeling brave and experimental try this one: https://tinyurl.com/5n8rpu23\n\nIt structures the text data into a scheme.

Message : Ramsri @91630952xxxx I recall you had worked a bit on diarization and alignment challenges, do you know what could help Anubhav at Dubdub?
Quoted Message : Hey guys, what's the best open-source language agnostic model for speaker diarization? We have already tried a few but love to know any good recommendations. Audio Video types would be long (1-2 hours) and short form (10-15 secs).

Message : I would use ReAsk sort of framework to do more document preprocessing and storing kind of tasks. For example making the implicit structure explicit in legal Acts documents. So even if one uses the most expensive model since it‚Äôs write once read many times sort of a situation it tends to spread the cost overall. 

But I agree, it‚Äôs very much dependent on what someone is trying to achieve.
Quoted Message : kor uses ReAsk while the lib I wrote use OpenAI functions, so in latency and cost terms ‚Äî this can be a difference of about 3-10x

Message : Of course there are nuances I have skipped here but some internal work is happening on this.
Quoted Message : I would use ReAsk sort of framework to do more document preprocessing and storing kind of tasks. For example making the implicit structure explicit in legal Acts documents. So even if one uses the most expensive model since it‚Äôs write once read many times sort of a situation it tends to spread the cost overall. \n\nBut I agree, it‚Äôs very much dependent on what someone is trying to achieve.

Message : We have tried, and the results are not great, and each has its own challenges. 
- Resemblyzer
- coqui
- pyannote
- TitaNet (NeMo)
Quoted Message : Ramsri @9163xxxxxxxx I recall you had worked a bit on diarization and alignment challenges, do you know what could help Anubhav at Dubdub?

Message : Analog Diffusion (iphone)

Message : Open-source LLM-based theorem prover: https://leandojo.org/

Message : Hi all, can anyone point me to or give tips on how to compress or paginate large code snippets so as to not exceed token limits? What's the current best known way to go about this?

Message : aider.chat/docs/ctags.html
Quoted Message : Hi all, can anyone point me to or give tips on how to compress or paginate large code snippets so as to not exceed token limits? What's the current best known way to go about this?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I endorse this.
Quoted Message : If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which @9198xxxxxxxx uses as well: \n\nhttps://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : kor uses ReAsk while the lib I wrote use OpenAI functions, so in latency and cost terms ‚Äî this can be a difference of about 3-10x
Quoted Message : Or if you are feeling brave and experimental try this one: https://tinyurl.com/5n8rpu23\n\nIt structures the text data into a scheme.

Message : Ramsri @91630952xxxx I recall you had worked a bit on diarization and alignment challenges, do you know what could help Anubhav at Dubdub?
Quoted Message : Hey guys, what's the best open-source language agnostic model for speaker diarization? We have already tried a few but love to know any good recommendations. Audio Video types would be long (1-2 hours) and short form (10-15 secs).

Message : I would use ReAsk sort of framework to do more document preprocessing and storing kind of tasks. For example making the implicit structure explicit in legal Acts documents. So even if one uses the most expensive model since it‚Äôs write once read many times sort of a situation it tends to spread the cost overall. 

But I agree, it‚Äôs very much dependent on what someone is trying to achieve.
Quoted Message : kor uses ReAsk while the lib I wrote use OpenAI functions, so in latency and cost terms ‚Äî this can be a difference of about 3-10x

Message : Of course there are nuances I have skipped here but some internal work is happening on this.
Quoted Message : I would use ReAsk sort of framework to do more document preprocessing and storing kind of tasks. For example making the implicit structure explicit in legal Acts documents. So even if one uses the most expensive model since it‚Äôs write once read many times sort of a situation it tends to spread the cost overall. \n\nBut I agree, it‚Äôs very much dependent on what someone is trying to achieve.

Message : We have tried, and the results are not great, and each has its own challenges. 
- Resemblyzer
- coqui
- pyannote
- TitaNet (NeMo)
Quoted Message : Ramsri @9163xxxxxxxx I recall you had worked a bit on diarization and alignment challenges, do you know what could help Anubhav at Dubdub?

Message : Analog Diffusion (iphone)

Message : Open-source LLM-based theorem prover: https://leandojo.org/

Message : Hi all, can anyone point me to or give tips on how to compress or paginate large code snippets so as to not exceed token limits? What's the current best known way to go about this?

Message : aider.chat/docs/ctags.html
Quoted Message : Hi all, can anyone point me to or give tips on how to compress or paginate large code snippets so as to not exceed token limits? What's the current best known way to go about this?

Message : this is a very very smart usage of ctags. ctags-as-a-vector-db. 
pretty cool!
Quoted Message : aider.chat/docs/ctags.html

Message : I am low key sad that I didn't think of this
Quoted Message : this is a very very smart usage of ctags. ctags-as-a-vector-db. \npretty cool!

Message : Has someone experimented with any models to generate TV ad quality video content?

Message : cc Shubham @91874202xxxx from TVF might know more about this
Quoted Message : Has someone experimented with any models to generate TV ad quality video content?

Message : Would love to collaborate on this
Quoted Message : Has someone experimented with any models to generate TV ad quality video content?

Message : Doing a lot of things at LangFlix but it‚Äôs not just one model, but a pipeline of multiple models.
Quoted Message : Has someone experimented with any models to generate TV ad quality video content?

Message : What is LangFlix?

Message : Side project https://youtube.com/@LangflixAI

Message : Bringing books summaries in Indian languages, complete AI pipeline

Message : Terrible name, great idea!
Quoted Message : Side project https://youtube.com/@LangflixAI

Message : There‚Äôs a lot of content being made lile joe rogan ai experience that @91988060xxxx made me aware of. I was living under the rock

Message : I‚Äôm becoming rebranding expert
Quoted Message : Terrible name, great idea!

Message : Nirant got Langchain Trauma seeing the name.üòÇüòÇ
Quoted Message : Terrible name, great idea!

Message : Say more, what did I miss?
Quoted Message : There‚Äôs a lot of content being made lile joe rogan ai experience that @9198xxxxxxxx made me aware of. I was living under the rock

Message : I've seen these AI 30 min hypothetical interviews on Spotify
Quoted Message : Say more, what did I miss?

Message : Aee, I just got my first PR merged yesterday: https://github.com/hwchase17/langchainjs/pull/1771

(thanks to @91943220xxxx @91797731xxxx for the review)
Quoted Message : Nirant got Langchain Trauma seeing the name.üòÇüòÇ

Message : I was referring to the Readme on aiagent. "Unchained"
Quoted Message : Aee, I just got my first PR merged yesterday: https://github.com/hwchase17/langchainjs/pull/1771\n\n(thanks to @9194xxxxxxxx @9179xxxxxxxx for the review)

Message : Fully AI Generated Podcast bringing the guests that will never get the chance to go on the real Joe Rogan Experience
Quoted Message : Say more, what did I miss?

Message : https://t.co/pNqa1JMZMt
Quoted Message : Fully AI Generated Podcast bringing the guests that will never get the chance to go on the real Joe Rogan Experience

Message : Langchain trauma - working on langchain after the era of crypto?
Quoted Message : Nirant got Langchain Trauma seeing the name.üòÇüòÇ

Message : Is it automated end-to-end? What exactly do you still have to do manually?
Quoted Message : Bringing books summaries in Indian languages, complete AI pipeline

Message : Some folks use gooey every now and then to create a music video / short explainers - not tv quality though - just passable

https://www.instagram.com/reel/Cns6Wubua81/?igshid=MTI1ZDU5ODQ3Yw==
Quoted Message : Has someone experimented with any models to generate TV ad quality video content?

Message : Enter book name
Quoted Message : Is it automated end-to-end? What exactly do you still have to do manually?

Message : I think they added MusicML for background music too recently. I started the project and handed over to friends as I am focusing on KissanAI

Message : Also everything is done on 3090s, almost no cost.

Message : wow.. will check it out.. i had similar idea for niche regional books.. but haven't started any work on it yet
Quoted Message : Bringing books summaries in Indian languages, complete AI pipeline

Message : Send suggestions in DMs
Quoted Message : wow.. will check it out.. i had similar idea for niche regional books.. but haven't started any work on it yet

Message : This is one of few unique ideas for source code handling, especially with LLMs. 

I've implemented a symbolic/hard link relationship between SW changes and test case definitions in BIOS.
SW changes include any feature, requirement or bug fix. It allows us to perform code coverage, test case recommendation and impact analysis for every PR easily.

Ctags allow name indexing in files but don't have linking information between files to index. But it's still very clean and one of the better ways to do it. I see myself taking a page out of this book for languages other than C/C++
Quoted Message : aider.chat/docs/ctags.html

Message : Copyright issues?
Quoted Message : Bringing books summaries in Indian languages, complete AI pipeline

Message : Summaries, images, everything is AI generated
Quoted Message : Copyright issues?

Message : How'd you extend this for Python/Java/JS?
Quoted Message : This is one of few unique ideas for source code handling, especially with LLMs. \n\nI've implemented a symbolic/hard link relationship between SW changes and test case definitions in BIOS. \nSW changes include any feature, requirement or bug fix. It allows us to perform code coverage, test case recommendation and impact analysis for every PR easily.\n\nCtags allow name indexing in files but don't have linking information between files to index. But it's still very clean and one of the better ways to do it. I see myself taking a page out of this book for languages other than C/C++

Message : I use this and am able to generate perfect json response every time. works great.
Quoted Message : If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which @9198xxxxxxxx uses as well: \n\nhttps://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : There's already a general map of repo with aider using ctags. I'll extend it to include symbolic links with the help of namespace and import commands, but I'll have to explore it in detail. 
I may stub my toe in many ways doing that.
Quoted Message : How'd you extend this for Python/Java/JS?

Message : Not many tools that work for us gpt-3.5 peasants üòÖ , gpt 4 is just way better.

Message : To set fair expectations, there is a failure rate of about 7 in 1000 right now.
Quoted Message : I use this and am able to generate perfect json response every time. works great.

Message : Interesting, how did you measure that ?
Quoted Message : To set fair expectations, there is a failure rate of about 7 in 1000 right now.

Message : Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times
Quoted Message : Interesting, how did you measure that ?

Message : Trying to ~measure~ estimate hallucination rate next ‚Äé<This message was edited>

Message : That's some grind üòÇ üëç for a valuable statistic. ‚Äé<This message was edited>
Quoted Message : Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times

Message : GoCodeo AI helps automate the testing process üòÅ
Quoted Message : Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : How'd you extend this for Python/Java/JS?
Quoted Message : This is one of few unique ideas for source code handling, especially with LLMs. \n\nI've implemented a symbolic/hard link relationship between SW changes and test case definitions in BIOS. \nSW changes include any feature, requirement or bug fix. It allows us to perform code coverage, test case recommendation and impact analysis for every PR easily.\n\nCtags allow name indexing in files but don't have linking information between files to index. But it's still very clean and one of the better ways to do it. I see myself taking a page out of this book for languages other than C/C++

Message : I use this and am able to generate perfect json response every time. works great.
Quoted Message : If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which @9198xxxxxxxx uses as well: \n\nhttps://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : There's already a general map of repo with aider using ctags. I'll extend it to include symbolic links with the help of namespace and import commands, but I'll have to explore it in detail. 
I may stub my toe in many ways doing that.
Quoted Message : How'd you extend this for Python/Java/JS?

Message : Not many tools that work for us gpt-3.5 peasants üòÖ , gpt 4 is just way better.

Message : To set fair expectations, there is a failure rate of about 7 in 1000 right now.
Quoted Message : I use this and am able to generate perfect json response every time. works great.

Message : Interesting, how did you measure that ?
Quoted Message : To set fair expectations, there is a failure rate of about 7 in 1000 right now.

Message : Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times
Quoted Message : Interesting, how did you measure that ?

Message : Trying to ~measure~ estimate hallucination rate next ‚Äé<This message was edited>

Message : That's some grind üòÇ üëç for a valuable statistic. ‚Äé<This message was edited>
Quoted Message : Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times

Message : GoCodeo AI helps automate the testing process üòÅ
Quoted Message : Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times

Message : Hallucinations are also taken care of

Message : I am very skeptic that AI solutions can do better than Code Interpreter, given how far behind even WizardCoder is. 

And I don't want to add the meta-work of verifying the test cases to verify the libs Hallucination, Error and Failure rate.
Quoted Message : GoCodeo AI helps automate the testing process üòÅ

Message : The base layer of GoCodeo is GPT and the in-house algorithms on top of it ensure code context and intelligence. Which means reduced errors and failure.
Also, when you say Code Interpreter, is it on the test generation or the analysis use case?
Quoted Message : I am very skeptic that AI solutions can do better than Code Interpreter, given how far behind even WizardCoder is. \n\nAnd I don't want to add the meta-work of verifying the test cases to verify the libs Hallucination, Error and Failure rate.

Message : I interested in knowing how we can use AI to identify AI hallucinations
Quoted Message : I am very skeptic that AI solutions can do better than Code Interpreter, given how far behind even WizardCoder is. \n\nAnd I don't want to add the meta-work of verifying the test cases to verify the libs Hallucination, Error and Failure rate.

Message : A separate instance of LLM can segment the generated result and fact check it with the database.
Quoted Message : I interested in knowing how we can use AI to identify AI hallucinations

Message : Code Interpreter is amazing at code generation including test writing. It often generates test cases which I have missed when I ask it to use fuzz testing in particular. 

Would love to know what safeguards/guarantees can the solution give against hallucinations (checked on website, didn't find anything)
Quoted Message : The base layer of GoCodeo is GPT and the in-house algorithms on top of it ensure code context and intelligence. Which means reduced errors and failure.\nAlso, when you say Code Interpreter, is it on the test generation or the analysis use case?

Message : So fact checking is still based on human curated db
Quoted Message : A separate instance of LLM can segment the generated result and fact check it with the database.

Message : Yeah there has to be some grounding. But to some extent we can avoid manual labour of fact checking at least.
Quoted Message : So fact checking is still based on human curated db

Message : There is a new "Pair Programmer" feature on Phind.com, I found it pretty powerful! Do try it out.
It is the best implementation of chain-of-thought / step-by-step thinking I found in a coding agent.

Don't have access to CodeInterpreter, but found it to be much much more powerful than GPT-4+Bing ...

Message : üòû I thought I missed out on a breakthrough. No Ouroboros, yet. We got a long way to go.
Quoted Message : Yeah there has to be some grounding. But to some extent we can avoid manual labour of fact checking at least.

Message : Hallucinations until now have been identified by our enterprise partners and with those learnings we are building AI models for rectification and further identification.
Quoted Message : Code Interpreter is amazing at code generation including test writing. It often generates test cases which I have missed when I ask it to use fuzz testing in particular. \n\nWould love to know what safeguards/guarantees can the solution give against hallucinations (checked on website, didn't find anything)

Message : Interesting name for fine tuning a model optimised for fact checking. Instead of RAG, fine tune an LLM for fact checking given a generated answer and retrieved context 

Considering the level of papers circulating nowadays, this can be a very good paper ü§£
Quoted Message : üòû I thought I missed out on a breakthrough. No Ouroboros, yet. We got a long way to go.

Message : EMNLP for Industry track is still open ü§£
Quoted Message : Interesting name for fine tuning a model optimised for fact checking. Instead of RAG, fine tune an LLM for fact checking given a generated answer and retrieved context \n\nConsidering the level of papers circulating nowadays, this can be a very good paper ü§£

Message : @91773788xxxx see I‚Äôm not that bad at naming. ü§£
Quoted Message : Interesting name for fine tuning a model optimised for fact checking. Instead of RAG, fine tune an LLM for fact checking given a generated answer and retrieved context \n\nConsidering the level of papers circulating nowadays, this can be a very good paper ü§£

Message : Is it integrated into vscode?
Quoted Message : There is a new \"Pair Programmer\" feature on Phind.com, I found it pretty powerful! Do try it out.\nIt is the best implementation of chain-of-thought / step-by-step thinking I found in a coding agent.\n\nDon't have access to CodeInterpreter, but found it to be much much more powerful than GPT-4+Bing ...

Message : My biggest pain is switching from here to the browser and copying it back, then modifying it

Message : Or copying the error stack over and asking for an explanation

Message : True that Phind's not into any IDEs, but the web interface gets the work really well done ‚Äé<This message was edited>
Quoted Message : Is it integrated into vscode?

Message : many such cases üòú
Quoted Message : EMNLP for Industry track is still open ü§£

Message : Did quite a few experiments which ended up going in production, with multiple models in a single flow though.
Quoted Message : Has someone experimented with any models to generate TV ad quality video content?

Message : Is there a good guide on creating QnA bot on Notion knowledge base using Langchain? I created the most basic one but it is not giving statisfactory answers.

Message : "Pyannote had the best open source performance." 
This from my colleague who was building diarization internally at Swiggy.
Quoted Message : Hey guys, what's the best open-source language agnostic model for speaker diarization? We have already tried a few but love to know any good recommendations. Audio Video types would be long (1-2 hours) and short form (10-15 secs).

Message : Have been playing out recently with pdfs. Basic RetrievalQA works decent. Rest is all chunking and routing logic that you can build on top.
Quoted Message : Is there a good guide on creating QnA bot on Notion knowledge base using Langchain? I created the most basic one but it is not giving statisfactory answers.

Message : Thbks. How do I learn chunking and routing logic thing? Both fundamentals and application! :)
Quoted Message : Have been playing out recently with pdfs. Basic RetrievalQA works decent. Rest is all chunking and routing logic that you can build on top.

Message : Routing logic has some introduction in llamaindex docs. But mostly diving into code. 
Chunking has a lot of research literature around it.
Maybe folks from the community can point to some good resources they have come across for these.

Message : Thanks. Will start with chunking.
Quoted Message : Routing logic has some introduction in llamaindex docs. But mostly diving into code. \nChunking has a lot of research literature around it. \nMaybe folks from the community can point to some good resources they have come across for these.

Message : My understanding is that this would take quite sometime to get to TV ad quality for videos. Given the state of image generation and the number of times it fails to match expectations, it is difficult for me to expect video generation to be TV quality. 

Would love to know if you found anything workable in this space.
Quoted Message : Has someone experimented with any models to generate TV ad quality video content?

Message : Crucially the GenAI models for images are great for exploration, but if you already know what you want and are trying to get that image done quicker, then there are still issues.

Message : I guess specific parts of the ad can be generated. Most of the magic will still have to be done by a video editor though. Even with the coke ad (although publicised as Generative AI), most was traditional CGI and good editing

Message : You can make zoom in and zoom out reels. They can work with out painting and then adding them to video editor, but temporal consistency between scenes are not yet solved to my knowledge.

Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : ‚ÄéPOLL:
Folks I'm trying to get international speakers for AI .. but are you willing to attend online meetings at 9.30pm IST on Thursdays ? Please DM me if you have a different solution.
‚ÄéOPTION: Yes (74 votes)
‚ÄéOPTION: No (0 votes)

Message : How long does it take to generate a video?
Quoted Message : Bringing books summaries in Indian languages, complete AI pipeline

Message : was added to chat

Message : We have been doing aspects of fact checking (Grammarly style check worthy claim detection, generation using existing sources, FactCheck wrt existing sources, etc).

Found that simple techniques works better and also explainable to clients.

Most imp question we're asked is reliability of the sources (to verify against). There's no neat answer here but things like DA/DR, nutrition labels from some independent media orgs is a good proxy
Quoted Message : Yeah there has to be some grounding. But to some extent we can avoid manual labour of fact checking at least.

Message : Reliability of source will lead you down the same road as Google - Experience, Expertise, Authority, Trustworthiness to build up reliability of a source. Platforms or sources with reputation get maximum brownie points, reputation again is an associative entity (EEAT as mentioned above).

What do you mean by DA/DR? Are these data related acronyms?
Quoted Message : We have been doing aspects of fact checking (Grammarly style check worthy claim detection, generation using existing sources, FactCheck wrt existing sources, etc).\n\nFound that simple techniques works better and also explainable to clients.\n\nMost imp question we're asked is reliability of the sources (to verify against). There's no neat answer here but things like DA/DR, nutrition labels from some independent media orgs is a good proxy

Message : My answer was also more on the side of *given that we can trust the database from where retrieval is happening, how to fact check the generated output using an AI?*

I'm also of the mind that simple fact checking algorithms may work very well for the bulk of the time.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : ‚ÄéPOLL:
Folks I'm trying to get international speakers for AI .. but are you willing to attend online meetings at 9.30pm IST on Thursdays ? Please DM me if you have a different solution.
‚ÄéOPTION: Yes (74 votes)
‚ÄéOPTION: No (0 votes)

Message : How long does it take to generate a video?
Quoted Message : Bringing books summaries in Indian languages, complete AI pipeline

Message : was added to chat

Message : We have been doing aspects of fact checking (Grammarly style check worthy claim detection, generation using existing sources, FactCheck wrt existing sources, etc).

Found that simple techniques works better and also explainable to clients.

Most imp question we're asked is reliability of the sources (to verify against). There's no neat answer here but things like DA/DR, nutrition labels from some independent media orgs is a good proxy
Quoted Message : Yeah there has to be some grounding. But to some extent we can avoid manual labour of fact checking at least.

Message : Reliability of source will lead you down the same road as Google - Experience, Expertise, Authority, Trustworthiness to build up reliability of a source. Platforms or sources with reputation get maximum brownie points, reputation again is an associative entity (EEAT as mentioned above).

What do you mean by DA/DR? Are these data related acronyms?
Quoted Message : We have been doing aspects of fact checking (Grammarly style check worthy claim detection, generation using existing sources, FactCheck wrt existing sources, etc).\n\nFound that simple techniques works better and also explainable to clients.\n\nMost imp question we're asked is reliability of the sources (to verify against). There's no neat answer here but things like DA/DR, nutrition labels from some independent media orgs is a good proxy

Message : My answer was also more on the side of *given that we can trust the database from where retrieval is happening, how to fact check the generated output using an AI?*

I'm also of the mind that simple fact checking algorithms may work very well for the bulk of the time.

Message : DA = Domain Authority. DR = Domain Rating. Introduced by SEO folks. Ahrefs, Moz, etc

That's why I mentioned non SEO ratings, for example media auditors (NewsGuard, IFCN (international fact check network) can be important)
Quoted Message : Reliability of source will lead you down the same road as Google - Experience, Expertise, Authority, Trustworthiness to build up reliability of a source. Platforms or sources with reputation get maximum brownie points, reputation again is an associative entity (EEAT as mentioned above).\n\nWhat do you mean by DA/DR? Are these data related acronyms?

Message : https://youtu.be/Wc22W3bos64

Could someone help break down the mechanics behind how this package was generated.

Message : Generate individual characters from midjourney -> convert them in video form by just animating faces for voice over using D-ID - > text to speech via elevenlabs

This info is slightly outdated (apr), you may have better methods now
Quoted Message : https://youtu.be/Wc22W3bos64\n\nCould someone help break down the mechanics behind how this package was generated.

Message : but what about the sound signatures ?

Message : You mean the accents from different languages or something else?
Quoted Message : but what about the sound signatures ?

Message : Yes, exactly

Message : Accents

Message : have you seen anything which works well for csv/tables/sheets/xls? Embedding breaks the file in chunks for context size(16K) and then information is lost for queries which need something across many rows (ie different chunks)

Message : It's where claim detection comes in. You select passages / sentences which are then sent for fact checking
Quoted Message : My answer was also more on the side of *given that we can trust the database from where retrieval is happening, how to fact check the generated output using an AI?*\n\nI'm also of the mind that simple fact checking algorithms may work very well for the bulk of the time.

Message : There isn't a TTS model trained for latin, mayan, greco-roman accents. My trick to crack it would be to use phonetics.
Quoted Message : Accents

Message : If you notice in the video, it's like 1 or 2 words are being pronounced separately rather than the complete sentence in a fluent manner. You can pick up a language close to the ancient versions and use phonetic spellings in that language to force a different sound with same accent

Message : You mean the accents from different languages or something else?

Message : Yes, exactly

Message : Accents

Message : have you seen anything which works well for csv/tables/sheets/xls? Embedding breaks the file in chunks for context size(16K) and then information is lost for queries which need something across many rows (ie different chunks)

Message : It's where claim detection comes in. You select passages / sentences which are then sent for fact checking

Message : There isn't a TTS model trained for latin, mayan, greco-roman accents. My trick to crack it would be to use phonetics.

Message : If you notice in the video, it's like 1 or 2 words are being pronounced separately rather than the complete sentence in a fluent manner. You can pick up a language close to the ancient versions and use phonetic spellings in that language to force a different sound with same accent

Message : Part II has Sanskrit so yes this indeed is super convincing!! https://youtu.be/wC0UG-Oq_90?t=60
Quoted Message : https://youtu.be/Wc22W3bos64\n\nCould someone help break down the mechanics behind how this package was generated.

Message : was added to chat

Message : If you move over to Old Chinese, you'll notice each sound being enunciated separately, looks like a clear use of phonetic pronounciation. Sanskrit one is very convincing.
Quoted Message : Part II has Sanskrit so yes this indeed is super convincing!! https://youtu.be/wC0UG-Oq_90?t=60

Message : The way people are going about it is to generate multiple variations and handpick the nearby ones to show small motions or gif‚Ä¶ but that‚Äôs about it
Quoted Message : You can make zoom in and zoom out reels. They can work with out painting and then adding them to video editor, but temporal consistency between scenes are not yet solved to my knowledge.

Message : Is there any literature / post about insurance policies (rise in their sale) to protect businesses against downside of bad stuff happening to them

Message : Don‚Äôt know in Indian context but recently JP Morgan in UK context has been trying to make an insurance company pay for a multimillion dollar deal that did not go through.
Quoted Message : Is there any literature / post about insurance policies (rise in their sale) to protect businesses against downside of bad stuff happening to them

Message : There was a use-case where ChatGPT was used to summarise research papers. Is it still around? could someone please point me to it, pls?

Message : Have you used SciSpace? It's very good. They have a chrome extension as well.

You can also find plugins on ChatGPT to fetch urls from arxiv and chat with it.
Quoted Message : There was a use-case where ChatGPT was used to summarise research papers. Is it still around? could someone please point me to it, pls?

Message : https://twitter.com/soumithchintala/status/1674045982298841094?s=20

Message : i have used chatpdf.com
works quite well.

there is also other tools like
https://elicit.org/
https://www.explainpaper.com/
Quoted Message : There was a use-case where ChatGPT was used to summarise research papers. Is it still around? could someone please point me to it, pls?

Message : shameless plug - https://pensieve.springworks.in/ - chat with any document (pdf, doc, csv etc)

Message : Research papers have an "Abstract" section right? That's usually the summary of the paper. Any specific kind of summary you are looking for?
Quoted Message : There was a use-case where ChatGPT was used to summarise research papers. Is it still around? could someone please point me to it, pls?

Message : Consensus also
Quoted Message : i have used chatpdf.com\nworks quite well.\n\nthere is also other tools like \nhttps://elicit.org/\nhttps://www.explainpaper.com/

Message : looks pretty neat !
do you know what is the index cut off date ? do they continue to index new papers as they get published, every so often ?
Quoted Message : Consensus also

Message : i am surprised i had never heard of it.
just tried it on a local pdf, looks amazing !
Quoted Message : Have you used SciSpace? It's very good. They have a chrome extension as well.\n\nYou can also find plugins on ChatGPT to fetch urls from arxiv and chat with it.

Message : It was the most feature rich product for reading research papers even back in November. They had options to directly answer questions on tables as well as mathematical equations as well. But they aren't very good at promoting themselves üòÖ

Message : Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?

Message : Go for advanced
Quoted Message : Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?

Message : Go for an M1 Pro atleast
In a mini or a macbook

Now there‚Äôs M2 Pro so you can buy M1 Pro off the refurbished lot too

Message : it may be cheaper for you in the long run just to use vast.ai
Quoted Message : Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?

Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : I'm keenly following answers to this question too.
Quoted Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Consensus also
Quoted Message : i have used chatpdf.com\nworks quite well.\n\nthere is also other tools like \nhttps://elicit.org/\nhttps://www.explainpaper.com/

Message : looks pretty neat !
do you know what is the index cut off date ? do they continue to index new papers as they get published, every so often ?
Quoted Message : Consensus also

Message : i am surprised i had never heard of it.
just tried it on a local pdf, looks amazing !
Quoted Message : Have you used SciSpace? It's very good. They have a chrome extension as well.\n\nYou can also find plugins on ChatGPT to fetch urls from arxiv and chat with it.

Message : It was the most feature rich product for reading research papers even back in November. They had options to directly answer questions on tables as well as mathematical equations as well. But they aren't very good at promoting themselves üòÖ

Message : Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?

Message : Go for advanced
Quoted Message : Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?

Message : Go for an M1 Pro atleast
In a mini or a macbook

Now there‚Äôs M2 Pro so you can buy M1 Pro off the refurbished lot too

Message : it may be cheaper for you in the long run just to use vast.ai
Quoted Message : Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?

Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : I'm keenly following answers to this question too.
Quoted Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : ‚Äé~‚ÄØPranjal Mehta added ‚Ä™+91¬†89035¬†88964‚Ä¨

Message : For QnA bots I just ask my friends to try out demos and pray that it works 9 out of 10 times. The same cannot be said for apps built for finance or medical matters though. I am still figuring it out
Quoted Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : Prompt engineering in my experience is way tougher than it looks at the outset
Quoted Message : For QnA bots I just ask my friends to try out demos and pray that it works 9 out of 10 times. The same cannot be said for apps built for finance or medical matters though. I am still figuring it out

Message : I am actually looking for assets in this layer.. in fact I cannot imagine what an asset in this layer should look like. How can we design a module that can be configured to handle validation for gpt responses from a target set... Or a module that handles malicious qns...

Message : Or even a modular approach to designing that prompt layer that serves numerous use cases

Message : Yeah, i got really excited in Mar and bought M2 pro just a day after llama.cpp was released. Now it's not useful for anything other than some toy runs with GPT4all and privateGPT.

Just buy a good laptop and do all tutorials/inference/training on cheap GPU providers. ‚Äé<This message was edited>
Quoted Message : it may be cheaper for you in the long run just to use vast.ai

Message : Old thinkpads suddenly become very valuable
Quoted Message : Yeah, i got really excited in Mar and bought M2 pro just a day after llama.cpp was released. Now it's not useful for anything other than some toy runs with GPT4all and privateGPT.\n\nJust buy a good laptop and do all tutorials/inference/training on cheap GPU providers.

Message : Not sure. Can't handle that red button as a mouse
Quoted Message : Old thinkpads suddenly become very valuable

Message : Ah trackpoints. But any older laptop decent enough to code on + cloud based infra = viable dev environment. cheap and cheerful sometimes works well.
Quoted Message : Not sure. Can't handle that red button as a mouse

Message : Having a Colab TPU instance or some cloud instance has changed the game

Message : This I agree. I'm still in my old 2015 Mac
Quoted Message : Having a Colab TPU instance or some cloud instance has changed the game

Message : Jeremy Howard (FastAI) once wrote about training a SOTA CNN model (several years ago) with $28 on AWS

Message : Game changing value for small (and big) teams

Message : Ya those were trained without colab pro on free gpu in 5 minutes.   Simple times
Quoted Message : Jeremy Howard (FastAI) once wrote about training a SOTA CNN model (several years ago) with $28 on AWS

Message : Finetuning not pretraining
Quoted Message : Ya those were trained without colab pro on free gpu in 5 minutes.   Simple times

Message : Yes, the age of deep learning before LLMs... *clears cobwebs*
Quoted Message : Finetuning not pretraining

Message : There was a Twitter subculture some time ago for GPU based PCs - it looked as though anyone working on DL stuff had to have this big fancy RGB laden powerhouse. We're reaching the *ahem* plateau of productivity...

Message : Ya. @91875456xxxx can shine light on this. He has a lot of useful experience here
Quoted Message : There was a Twitter subculture some time ago for GPU based PCs - it looked as though anyone working on DL stuff had to have this big fancy RGB laden powerhouse. We're reaching the *ahem* plateau of productivity...

Message : I only have 12 GPUs. I don‚Äôt have a lot of compute compared to other Kagglers ü•∫

Message : Some people on Twitter want to come after you. They think more than 10 should be made illegal üòÇüòÇ
Quoted Message : I only have 12 GPUs. I don‚Äôt have a lot of compute compared to other Kagglers ü•∫

Message : was added to chat

Message : Me: <you have GPUs?>
Quoted Message : I only have 12 GPUs. I don‚Äôt have a lot of compute compared to other Kagglers ü•∫

Message : For context: some Kagglers use 40+ GPUs freely everyday^

Message : (Provided by their orgs)

Message : ‚Äé<attached: 00010788-GIF-2023-06-28-21-54-41.mp4>
Quoted Message : I only have 12 GPUs. I don‚Äôt have a lot of compute compared to other Kagglers ü•∫

Message : ‚Äé<attached: 00010789-PHOTO-2023-06-28-21-55-25.jpg>
Quoted Message : Me: <you have GPUs?>

Message : Eggjactly, too lazy to find the pic

Message : ‚Äé<attached: 00010791-GIF-2023-06-28-22-23-30.mp4>
Quoted Message : I only have 12 GPUs. I don‚Äôt have a lot of compute compared to other Kagglers ü•∫

Message : Please do not post on social media, early community preview (needs Github Sign in): 
https://integrations.langchain.com/

Message : ‚Äé<attached: 00010793-GIF-2023-06-28-22-29-31.mp4>

Message : this feels like a topper in clg saying I got 9.5/10 CGPA and still sad üòÇ
Quoted Message : I only have 12 GPUs. I don‚Äôt have a lot of compute compared to other Kagglers ü•∫

Message : Imagine if Kagglers who have 40 gpus only do xgboost.

Message : I say this as hypothetical only. I know we have some gun kagglers in this group

Message : Good area to explore.
Quoted Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : What happens if a question is asked over and over again. 

If an ontology boundary is created and validated that the LLM doesn't cross this, that may decide if the question should be added to permissible set. Just a layman thought. üê¢
Quoted Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : https://twitter.com/siddarthpaim/status/1674108143037448200?s=20

Message : https://twitter.com/Suhail/status/1674124521543192578?s=20

Playground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative

Message : We can use SAM to identify objects and instruct to modify them via voice or text also. But maybe this makes for a cooler demo? It just feels like it'll be no effort to prepare my own images for almost any task now.
Quoted Message : https://twitter.com/Suhail/status/1674124521543192578?s=20\n\nPlayground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative

Message : Love this idea. Lets do this for a hackathon!
Quoted Message : We can use SAM to identify objects and instruct to modify them via voice or text also. But maybe this makes for a cooler demo? It just feels like it'll be no effort to prepare my own images for almost any task now.

Message : Here's another, and it has recs from the godfather of Shaders Patrizio. Who is also responsible for some key developments in runwayml
Quoted Message : https://twitter.com/Suhail/status/1674124521543192578?s=20\n\nPlayground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : this feels like a topper in clg saying I got 9.5/10 CGPA and still sad üòÇ
Quoted Message : I only have 12 GPUs. I don‚Äôt have a lot of compute compared to other Kagglers ü•∫

Message : Imagine if Kagglers who have 40 gpus only do xgboost.

Message : I say this as hypothetical only. I know we have some gun kagglers in this group

Message : Good area to explore.
Quoted Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : What happens if a question is asked over and over again. 

If an ontology boundary is created and validated that the LLM doesn't cross this, that may decide if the question should be added to permissible set. Just a layman thought. üê¢
Quoted Message : Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?

Message : https://twitter.com/siddarthpaim/status/1674108143037448200?s=20

Message : https://twitter.com/Suhail/status/1674124521543192578?s=20

Playground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative

Message : We can use SAM to identify objects and instruct to modify them via voice or text also. But maybe this makes for a cooler demo? It just feels like it'll be no effort to prepare my own images for almost any task now.
Quoted Message : https://twitter.com/Suhail/status/1674124521543192578?s=20\n\nPlayground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative

Message : Love this idea. Lets do this for a hackathon!
Quoted Message : We can use SAM to identify objects and instruct to modify them via voice or text also. But maybe this makes for a cooler demo? It just feels like it'll be no effort to prepare my own images for almost any task now.

Message : Here's another, and it has recs from the godfather of Shaders Patrizio. Who is also responsible for some key developments in runwayml
Quoted Message : https://twitter.com/Suhail/status/1674124521543192578?s=20\n\nPlayground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative

Message : https://www.modyfi.com/

Message : Q: we review legal documents using GPT 4. What is the best way to run a QC on the results outside of having people looking at it?

Message : Pass the output to gpt 4 again to proofread / verify?
Quoted Message : Q: we review legal documents using GPT 4. What is the best way to run a QC on the results outside of having people looking at it?

Message : GPT-4 can you verify whether the answer you've generated is correct?
Quoted Message : Pass the output to gpt 4 again to proofread / verify?

Message : Depends on your standard of QC too. Proofreading does not avoid hallucinations in many models.

Message : On a more serious notes, I've found this approach works to an extent

Message : Recently, there was a case in the US where a lawyer submitted a legal doc generated by GPT and asked it multiple times to ensure everything was correct. It still made up cases out of thin air, leading to the lawyer receiving disciplinary action for not manually verifying the info

Message : No I think you need to RAG over here.
Quoted Message : Recently, there was a case in the US where a lawyer submitted a legal doc generated by GPT and asked it multiple times to ensure everything was correct. It still made up cases out of thin air, leading to the lawyer receiving disciplinary action for not manually verifying the info

Message : https://www.cnbc.com/2023/06/22/judge-sanctions-lawyers-whose-ai-written-filing-contained-fake-citations.html

Message : legal documents are tricky. A word modified here and there and  the client finds himself hanging at  the court with the opponent tearing at them.
Quoted Message : Q: we review legal documents using GPT 4. What is the best way to run a QC on the results outside of having people looking at it?

Message : ideally, yes, to avoid such cases
Quoted Message : No I think you need to RAG over here.

Message : also GPT-4 ko poocho agar poochna hi hai

Message : https://github.com/salesforce/xgen - 7B models from salesforce with 8K context length.

Message : I really like Salesforce from the time they've been releasing codegen and BLIP models. Looks like they want to give Meta some company in open source gen AI research.
Quoted Message : https://github.com/salesforce/xgen - 7B models from salesforce with 8K context length.

Message : In my field, biology and medicine , they have published quite a bit on generative protein design

https://www.nature.com/articles/s41587-022-01618-2

Quite impressive !
Quoted Message : I really like Salesforce from the time they've been releasing codegen and BLIP models. Looks like they want to give Meta some company in open source gen AI research.

Message : Now I like them more.

Message : Assuming no external sources and the doc only has to be analysed for what it contains.
Quoted Message : Recently, there was a case in the US where a lawyer submitted a legal doc generated by GPT and asked it multiple times to ensure everything was correct. It still made up cases out of thin air, leading to the lawyer receiving disciplinary action for not manually verifying the info

Message : came across this older but very exciting neurips 2021 paper on learning from videos !
anybody here used merlot ?

https://rowanzellers.com/merlot/
https://arxiv.org/abs/2106.02636

"As humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. We introduce MERLOT, a model that learns multimodal script knowledge by watching 6 million YouTube videos with transcribed speech -- in an entirely label-free, self-supervised manner. By pretraining with a mix of both frame-level (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time."

Message : Anyone tried elastic search to host and perform the vector search, if yes what are the downsides compared to other vector DB out there in the market?

Idea is to index large numbers of text files(~ half million) and perform similarity search and further use this results to feed LLM models.

Message : Done it
Quoted Message : Anyone tried elastic search to host and perform the vector search, if yes what are the downsides compared to other vector DB out there in the market?\n\nIdea is to index large numbers of text files(~ half million) and perform similarity search and further use this results to feed LLM models.

Message : You need to be careful with chunking, add metadata and perform hybrid search (tfidf + vector) for results that need high accuracy
Quoted Message : Done it

Message : Downsides : every once in a while the es cluster will kill a node bc Java oom. Correct configuration for your specific use case is an art

Message : Happy to connect you with folks who've done it

The anecdotal feedback I've heard is that the nodes in the ES cluster keep going down, maintenance/configuration is a pain and the overall workload is brittle

Might be a good idea to consider a dedicated VectorDB
Quoted Message : Anyone tried elastic search to host and perform the vector search, if yes what are the downsides compared to other vector DB out there in the market?\n\nIdea is to index large numbers of text files(~ half million) and perform similarity search and further use this results to feed LLM models.

Message : There are no downsides. Have used ES for vectors at scale.

The only pain is getting the ES cluster right in one go. If you have $$ you can use cloud offerings easily.

One tip would be to keep a somewhat larger refresh interval for ES index if you are making frequent inserts.
Quoted Message : Anyone tried elastic search to host and perform the vector search, if yes what are the downsides compared to other vector DB out there in the market?\n\nIdea is to index large numbers of text files(~ half million) and perform similarity search and further use this results to feed LLM models.

Message : New Technique Gives Designers Added Capabilities by Incorporating Engineering Constraints Into Generative AI Models

https://pressroom.toyota.com/toyota-research-institute-unveils-new-generative-ai-technique-for-vehicle-design/

Wpw this is cool

Message : Really interesting. Karen Willcox (and Olivier de Weck) have been talking about AI models for digital twins a bit. What's interesting about this space is the realm of physically based modeling - that dovetails into generative AI capabilities. The article has a video that discusses optimizations of the structure, performance, aerodynamics around the main exterior design provided - De Weck and Willcox did a lot of work at MIT (and published OCW courses) on multi disciplinary optimization - a highly underrated field of systems design and optimization amidst all this AI hype
Quoted Message : New Technique Gives Designers Added Capabilities by Incorporating Engineering Constraints Into Generative AI Models\n\nhttps://pressroom.toyota.com/toyota-research-institute-unveils-new-generative-ai-technique-for-vehicle-design/\n\nWpw this is cool

Message : Any resource to read about fine tuning Diffusion models for industrial designs ?
Quoted Message : Really interesting. Karen Willcox (and Olivier de Weck) have been talking about AI models for digital twins a bit. What's interesting about this space is the realm of physically based modeling - that dovetails into generative AI capabilities. The article has a video that discusses optimizations of the structure, performance, aerodynamics around the main exterior design provided - De Weck and Willcox did a lot of work at MIT (and published OCW courses) on multi disciplinary optimization - a highly underrated field of systems design and optimization amidst all this AI hype

Message : Based on engineering specifications ?

Message : I know very little about diffusion models, and haven't explored this line of thinking but they may be relevant for topology optimization. Thanks for the note. But MDO and MDSO are practiced at least with low fidelity in aerospace and automotive engineering design (concurrent - across digital engineering, manufacturing and verification/validation). Related work https://arxiv.org/abs/2208.09591

Message : ‚Äé<attached: 00010834-PHOTO-2023-06-29-09-55-29.jpg>

Message : I've sometimes thought of topology optimization as an n-sample sign test (akin to the 1 sample sign test in statistical inference) subject to results by simulation, with an objective function. If that makes sense and is not an oversimplification.

Message : Hi folks, 

Has anyone here connected your data with google search APIs or web crawling for webpages?

I'm trying to do the same but unable to find ways to do it effectively, been thinking about using: https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt as a starting point

Would love to know if anyone has built something with search+OpenAI, thanks!

Message : cc @91982023xxxx runs a business on search+LLM
Quoted Message : Hi folks, \n\nHas anyone here connected your data with google search APIs or web crawling for webpages? \n\nI'm trying to do the same but unable to find ways to do it effectively, been thinking about using: https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt as a starting point\n\nWould love to know if anyone has built something with search+OpenAI, thanks!

Message : If you just want to search the Google page, SerpAPI is way easier to implement. 
And then maybe a react style agent to go through the webpages?
Quoted Message : Hi folks, \n\nHas anyone here connected your data with google search APIs or web crawling for webpages? \n\nI'm trying to do the same but unable to find ways to do it effectively, been thinking about using: https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt as a starting point\n\nWould love to know if anyone has built something with search+OpenAI, thanks!

Message : Autodesk has been working using AI for engineering design for quite some time now

Message : Thanks @91773788xxxx, dropped you a DM @91982023xxxx
Quoted Message : cc @9198xxxxxxxx runs a business on search+LLM

Message : Yes, they first made a splash with it in 2020 or so, there was a TED talk
Quoted Message : Autodesk has been working using AI for engineering design for quite some time now

Message : I attended Autodesk‚Äôs AI for Engineering Summer School in Toronto 2019. So even earlier than that. They already had made a lot of progress in terms of research.
Quoted Message : Yes, they first made a splash with it in 2020 or so, there was a TED talk

Message : I'd love to hear about what you explored here. It promises to be interesting
Quoted Message : I attended Autodesk‚Äôs AI for Engineering Summer School in Toronto 2019. So even earlier than that. They already had made a lot of progress in terms of research.

Message : Sure
Quoted Message : I'd love to hear about what you explored here. It promises to be interesting


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I've sometimes thought of topology optimization as an n-sample sign test (akin to the 1 sample sign test in statistical inference) subject to results by simulation, with an objective function. If that makes sense and is not an oversimplification.

Message : Hi folks, 

Has anyone here connected your data with google search APIs or web crawling for webpages?

I'm trying to do the same but unable to find ways to do it effectively, been thinking about using: https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt as a starting point

Would love to know if anyone has built something with search+OpenAI, thanks!

Message : cc @91982023xxxx runs a business on search+LLM
Quoted Message : Hi folks, \n\nHas anyone here connected your data with google search APIs or web crawling for webpages? \n\nI'm trying to do the same but unable to find ways to do it effectively, been thinking about using: https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt as a starting point\n\nWould love to know if anyone has built something with search+OpenAI, thanks!

Message : If you just want to search the Google page, SerpAPI is way easier to implement. 
And then maybe a react style agent to go through the webpages?
Quoted Message : Hi folks, \n\nHas anyone here connected your data with google search APIs or web crawling for webpages? \n\nI'm trying to do the same but unable to find ways to do it effectively, been thinking about using: https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt as a starting point\n\nWould love to know if anyone has built something with search+OpenAI, thanks!

Message : Autodesk has been working using AI for engineering design for quite some time now

Message : Thanks @91773788xxxx, dropped you a DM @91982023xxxx
Quoted Message : cc @9198xxxxxxxx runs a business on search+LLM

Message : Yes, they first made a splash with it in 2020 or so, there was a TED talk
Quoted Message : Autodesk has been working using AI for engineering design for quite some time now

Message : I attended Autodesk‚Äôs AI for Engineering Summer School in Toronto 2019. So even earlier than that. They already had made a lot of progress in terms of research.
Quoted Message : Yes, they first made a splash with it in 2020 or so, there was a TED talk

Message : I'd love to hear about what you explored here. It promises to be interesting
Quoted Message : I attended Autodesk‚Äôs AI for Engineering Summer School in Toronto 2019. So even earlier than that. They already had made a lot of progress in terms of research.

Message : Sure
Quoted Message : I'd love to hear about what you explored here. It promises to be interesting

Message : Sure

Message : https://vimeo.com/372439670
Quoted Message : I'd love to hear about what you explored here. It promises to be interesting

Message : Thanks! :)
Quoted Message : https://vimeo.com/372439670

Message : was added to chat

Message : Here's a benchmark of ANN algorithms and implementations across various vector databases: https://github.com/erikbern/ann-benchmarks - might be helpful to understand tradeoffs for this choice!
Quoted Message : Anyone tried elastic search to host and perform the vector search, if yes what are the downsides compared to other vector DB out there in the market?\n\nIdea is to index large numbers of text files(~ half million) and perform similarity search and further use this results to feed LLM models.

Message : This is great. Seems like a good way to bring AI to real world problems, rather than just building another chat bot or image generation app...
Quoted Message : https://vimeo.com/372439670

Message : Not to belittle the challenges behind these things of course, but there are other problems to solve too, in engg and systems design

Message : ‚Äé<attached: 00010852-PHOTO-2023-06-29-12-22-55.jpg>

Message : Nice. Saw your tweet as well. Do we have a way of checking GPU usage by the model akin to Nvidia SMI?

Message : This is CPU sir
Quoted Message : Nice. Saw your tweet as well. Do we have a way of checking GPU usage by the model akin to Nvidia SMI?

Message : I'm tempted to try it now. Thank you :)

Message : ‚Äé<attached: 00010856-PHOTO-2023-06-29-12-25-20.jpg>

Message : The inference is very slow for 30B models on M2 pro, what's your token gen speed? Plus, this Yann Lecunn question stumbles even GPT3/4, it will be interesting how the 30B answers it though.

Message : Share details of the magic :)
Are you planning to document the step by step setup ?
I bet a lot of us here would love to reproduce it

Message : was added to chat

Message : You can guys also do this demo at your PC:

https://www.youtube.com/watch?v=SFdth6cYZdo

Message : It's a captivating demo!

I'm helping an Indian startup in a similar space on image understanding models beyond SAM. Quite a few interesting pieces under the hood to make these apps work.
Quoted Message : https://twitter.com/Suhail/status/1674124521543192578?s=20\n\nPlayground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative

Message : abacaj on Twitter is wrapping it in a script, should be out tonight
Quoted Message : Share details of the magic :)\nAre you planning to document the step by step setup ?\nI bet a lot of us here would love to reproduce it

Message : Thanks bud
Looking forward to it
Quoted Message : abacaj on Twitter is wrapping it in a script, should be out tonight

Message : Pretty neat, thanks
Quoted Message : You can guys also do this demo at your PC:\n\nhttps://www.youtube.com/watch?v=SFdth6cYZdo

Message : Meanwhile, koboldcpp, ctransformers have mpt 30B 4 bit inference support. You should be able to find a simple guide to test it out even on Windows, provided you've ~30G free RAM

Message : https://github.com/abacaj/mpt-30B-inference
Quoted Message : Share details of the magic :)\nAre you planning to document the step by step setup ?\nI bet a lot of us here would love to reproduce it

Message : @91773788xxxx  
What was the script you were referring to ?
Was it to make it even easier to try using docker or such ?

https://github.com/abacaj/mpt-30B-inference/issues/5#issuecomment-1612221080
Quoted Message : https://github.com/abacaj/mpt-30B-inference

Message : The best way is to pre-qualify each of the datapoint and analyze for parts that matter to you - like correctness, coherence etc. Would love to know more about how are you doing it currently.
Quoted Message : Q: we review legal documents using GPT 4. What is the best way to run a QC on the results outside of having people looking at it?

Message : I'm not using Docker
Quoted Message : @9177xxxxxxxx  \nWhat was the script you were referring to ?\nWas it to make it even easier to try using docker or such ?\n\nhttps://github.com/abacaj/mpt-30B-inference/issues/5#issuecomment-1612221080

Message : https://erichartford.com/openorca

Message : I'm looking at the same code / script. Slow as molasses for first inference. Mine is an older Mac. Perhaps I should try this on Colab
Quoted Message : I'm not using Docker

Message : They claim to be "The first WebGPU enabled image editing platform." Has anyone been able to work with webGPU here? How was the experience ?
Quoted Message : https://www.modyfi.com/

Message : ‚Äé<attached: 00010872-PHOTO-2023-06-29-14-35-54.jpg>
Quoted Message : https://erichartford.com/openorca

Message : Yeah, I like him but I can't say that OpenOrca would be useful for anything other than his personal or his sponsor's advertisements.

Message : Their first release for OpenOrca is on Llama 7B and it includes a semi-GPT4 guided dataset, so even that is kind of a blurry line.

Message : You'll need a high RAM instance or you may try the GPU offloading version for inference.
Quoted Message : I'm looking at the same code / script. Slow as molasses for first inference. Mine is an older Mac. Perhaps I should try this on Colab

Message : Yeah, I will try that. I have 24GB on one machine, getting the model downloaded on it now
Quoted Message : You'll need a high RAM instance or you may try the GPU offloading version for inference.

Message : Apple uses shared memory and better integration means this may run better on Macs, but I have a Linux machine (Thinkpad) with 24 GB. If it doesn't work, there's always Colab

Message : ~30G is recommended minimum for decent speed
Quoted Message : Yeah, I will try that. I have 24GB on one machine, getting the model downloaded on it now

Message : Colab pro par chalega?
Quoted Message : ~30G is recommended minimum for decent speed

Message : Try and find out!
Quoted Message : Colab pro par chalega?

Message : I've not had a chance to try

Message : Supabase CEO on pgvector's lackluster performance in the ann-benchmark

1. Wait 6 months, a lot of development is happening on pgvector
2. Use hybrid search
3. Use filters on other indexed columns
4. Use partitions

My opinion: I think pg will grow to be good enough. Like it has in the past with full text search. Frankly I didn't expect it to do so poorly.

https://twitter.com/kiwicopple/status/1674395364441350145?t=U-dgxSV1KoC42-9T_zdKXQ

Message : Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Their first release for OpenOrca is on Llama 7B and it includes a semi-GPT4 guided dataset, so even that is kind of a blurry line.

Message : You'll need a high RAM instance or you may try the GPU offloading version for inference.
Quoted Message : I'm looking at the same code / script. Slow as molasses for first inference. Mine is an older Mac. Perhaps I should try this on Colab

Message : Yeah, I will try that. I have 24GB on one machine, getting the model downloaded on it now
Quoted Message : You'll need a high RAM instance or you may try the GPU offloading version for inference.

Message : Apple uses shared memory and better integration means this may run better on Macs, but I have a Linux machine (Thinkpad) with 24 GB. If it doesn't work, there's always Colab

Message : ~30G is recommended minimum for decent speed
Quoted Message : Yeah, I will try that. I have 24GB on one machine, getting the model downloaded on it now

Message : Colab pro par chalega?
Quoted Message : ~30G is recommended minimum for decent speed

Message : Try and find out!
Quoted Message : Colab pro par chalega?

Message : I've not had a chance to try

Message : Supabase CEO on pgvector's lackluster performance in the ann-benchmark

1. Wait 6 months, a lot of development is happening on pgvector
2. Use hybrid search
3. Use filters on other indexed columns
4. Use partitions

My opinion: I think pg will grow to be good enough. Like it has in the past with full text search. Frankly I didn't expect it to do so poorly.

https://twitter.com/kiwicopple/status/1674395364441350145?t=U-dgxSV1KoC42-9T_zdKXQ

Message : Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.

Message : Please react to this message if you‚Äôre okay with me reaching out

Message : https://arxiv.org/abs/2008.09820 

What can I help with?
Quoted Message : Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.

Message : Yes, I have used xlmr.
Quoted Message : Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.

Message : I‚Äôm trying to use that only
Quoted Message : Colab pro par chalega?

Message : Colab pro you get more ram if you use advanced gpu setting

Message : Just fewer hours

Message : I've used XLM quite a bit for text classification (https://arxiv.org/abs/1901.07291). happy to help!
Quoted Message : Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.

Message : +1 for XLM
Quoted Message : I've used XLM quite a bit for text classification (https://arxiv.org/abs/1901.07291). happy to help!

Message : ‚Äé<attached: 00010892-PHOTO-2023-06-29-19-31-26.jpg>

Message : It's a franchise!

Message : My prediction was ChaatGPT but close enough

Message : Thinking about scale from day 0. Scaling is all you need, no? üòú
Quoted Message : It's a franchise!

Message : I know this has been slightly discussed before but is there any document or page comparing Redis and Qdrant? any place people have shared their experience in production?

Message : Hi all, Is anyone closely following Inflection AI Pi? Wanted to understand how it is so fast in responding? Btw if you want to regularly use it they have it everywhere. Insta, WA, Messenger ‚Äé<This message was edited>

Message : I'll suggest trying out HingRobertaMixed and HingRoberta via HF inference. They are xlm-roberta fine tuned for code switching (Hindi+english) tasks. You may not need to fine tune specifically for tasks such as sentiment analysis, hate speech detection and other NLP subtasks.
Code switching NLU with a mix of Roman + Devnagari scripts is  challenging in general. But based on what I've read, they are SoTA.

I was doubtful if they have overfitted with fine tuning but their model holds ground in independent cross validation metrics.
Quoted Message : Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.

Message : What‚Äôs the prompt for this one ?

Message : Sorry guys!

Message : There is a chaatgpt here in Mumbai
Quoted Message : My prediction was ChaatGPT but close enough

Message : With all specialised LLMs in place for different use cases, do you think being able to switch from 1 LLM to the other along with context developed previously would be important? Basically communication between 2 or more LLMs

Message : I‚Äôm here at the wolfram hq for a month. If anyone has any questions related to the wolfram plugin, or to stephen, feel free to drop them here; I can redirect :-) ‚Äé<This message was edited>

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØAnkit Kumar Pandey

Message : https://twitter.com/mustafasuleymn/status/1674418106738044929?s=20 - Inflection AI raises $1.3 billion funding

Message : Well, looks like Microsoft wants their hands in every piece of Pi.
Satya is one of the people leading this round of investment along with Nvidia and some top tech billionaires like Bill Gates, Eric Schmidt.
Quoted Message : https://twitter.com/mustafasuleymn/status/1674418106738044929?s=20 - Inflection AI raises $1.3 billion funding

Message : They solely do not depend on OpenAI only. Let's see which company is next on their list. Any guess ? ‚Äé<This message was edited>
Quoted Message : Well, looks like Microsoft wants their hands in every piece of Pi.\nSatya is one of the people leading this round of investment along with Nvidia and some top tech billionaires like Bill Gates, Eric Schmidt.

Message : Yeah man! They have nailed it.
Quoted Message : https://twitter.com/mustafasuleymn/status/1674418106738044929?s=20 - Inflection AI raises $1.3 billion funding

Message : I guess, they might have invested in companies working on genAI videos as well
Quoted Message : They solely do not depend on OpenAI only. Let's see which company is next on their list. Any guess ?

Message : I think there are two components here.
* Promising sector - Personal Assistant space
* Ability to train their own LLMs of right competency

If I was to guess, any company that may showcase ability to build in their own space and be from a promising sector may get picked up. But if I picked which companies it'll be, I'll most likely be wrong ü§£
Quoted Message : They solely do not depend on OpenAI only. Let's see which company is next on their list. Any guess ?

Message : was added to chat

Message : Has anyone used Pi? Curious to hear what others think
Quoted Message : https://twitter.com/mustafasuleymn/status/1674418106738044929?s=20 - Inflection AI raises $1.3 billion funding

Message : Think @91702215xxxx has applied for access for this. So waiting..
Quoted Message : Has anyone used Pi? Curious to hear what others think

Message : More empathy, friendliness and comfort in conversation. Not very high in reasoning when I checked it out but conversations flow very well.

Message : ‚Äé<attached: 00010916-PHOTO-2023-06-30-00-23-13.jpg>

Message : I shared this as it highlights one of the important things I've mentioned while working with similarity detection or information retrieval, 

When do keyword based methods perform really well or outperform vector embeddings?

Message : In all the cases BM25 beats the famed miniLM-L6-v2 and mpnet-v2 embeddings, we find following patterns
* The dataset is domain driven and has lots of terminology that generally trained vector embeddings will lack by itself
* The dataset requires reasoning for IR between multiple documents or sources instead of a single doc containing most relevance
* The dataset contains argumentative statements where the information can be positive or negative with respect to a term but relevant argument fetching can be tricky

Message : Interesting! https://twitter.com/AnthropicAI/status/1674461614056292353?s=20

Message : That reminds me, what do folks think of Poe ( from the quora founder ) ?
Quoted Message : Has anyone used Pi? Curious to hear what others think

Message : Isn‚Äôt that a skin on chatgpt
Quoted Message : That reminds me, what do folks think of Poe ( from the quora founder ) ?

Message : Its open, I dont think you need to request access
Quoted Message : Think @9170xxxxxxxx has applied for access for this. So waiting..

Message : https://twitter.com/lmsysorg/status/1674562017410297856?s=20

LongChat with 16K tokens context and LongEval for testing long context chatbots.

Message : There was a guide on prompt engineering that was shared a while ago on the group. Not able to find it. Can anyone pls share resources to get better with prompting?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : More empathy, friendliness and comfort in conversation. Not very high in reasoning when I checked it out but conversations flow very well.

Message : ‚Äé<attached: 00010916-PHOTO-2023-06-30-00-23-13.jpg>

Message : I shared this as it highlights one of the important things I've mentioned while working with similarity detection or information retrieval, 

When do keyword based methods perform really well or outperform vector embeddings?

Message : In all the cases BM25 beats the famed miniLM-L6-v2 and mpnet-v2 embeddings, we find following patterns
* The dataset is domain driven and has lots of terminology that generally trained vector embeddings will lack by itself
* The dataset requires reasoning for IR between multiple documents or sources instead of a single doc containing most relevance
* The dataset contains argumentative statements where the information can be positive or negative with respect to a term but relevant argument fetching can be tricky

Message : Interesting! https://twitter.com/AnthropicAI/status/1674461614056292353?s=20

Message : That reminds me, what do folks think of Poe ( from the quora founder ) ?
Quoted Message : Has anyone used Pi? Curious to hear what others think

Message : Isn‚Äôt that a skin on chatgpt
Quoted Message : That reminds me, what do folks think of Poe ( from the quora founder ) ?

Message : Its open, I dont think you need to request access
Quoted Message : Think @9170xxxxxxxx has applied for access for this. So waiting..

Message : https://twitter.com/lmsysorg/status/1674562017410297856?s=20

LongChat with 16K tokens context and LongEval for testing long context chatbots.

Message : There was a guide on prompt engineering that was shared a while ago on the group. Not able to find it. Can anyone pls share resources to get better with prompting?

Message : If there are more than 10 folks interested in this, can do a curated compilation of all community resources around prompting for text. 

Leave a üôå against this message if you'd find it useful.
Quoted Message : There was a guide on prompt engineering that was shared a while ago on the group. Not able to find it. Can anyone pls share resources to get better with prompting?

Message : Am also wondering how to package reusable prompting strategies like a layer designed for reuse to many use cases above it

Message : These are some of the prompt engg guides links I had kept if anyone is interested. It includes the one shared here : https://crocus-almanac-be9.notion.site/Prompt-Engineering-002d00ac83074a45adfdd4263cff573f
Quoted Message : If there are more than 10 folks interested in this, can do a curated compilation of all community resources around prompting for text. \n\nLeave a üôå against this message if you'd find it useful.

Message : https://forms.gle/aTLXNo3QXQyhmi9g9

For api access.

1st impression : more conversational compared to other AI bots
Quoted Message : Its open, I dont think you need to request access

Message : You mean this one - http://nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Quoted Message : There was a guide on prompt engineering that was shared a while ago on the group. Not able to find it. Can anyone pls share resources to get better with prompting?

Message : Basics of Prompt Engg https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction  

A bit more depth on prompt engg (video, more interesting 15m onwards) https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/prompt-engineering/

Elvis prompt engineering guide, fairly exhaustive https://github.com/dair-ai/Prompt-Engineering-Guide

Prompt engg stuff by brex https://github.com/brexhq/prompt-engineering

A lot of prompt engineering tips https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77

Lilian Weng‚Äôs guide https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/
Quoted Message : There was a guide on prompt engineering that was shared a while ago on the group. Not able to find it. Can anyone pls share resources to get better with prompting?

Message : Sometimes going there for only conversation not for knowledge
Quoted Message : Has anyone used Pi? Curious to hear what others think

Message : Do you know what kind of things they do to make conversation interesting?

What makes you go to it? When you‚Äôre bored? Curious
Quoted Message : Sometimes going there for only conversation not for knowledge

Message : great compilation! cc community resources @91773788xxxx
Quoted Message : Basics of Prompt Engg https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction  \n\nA bit more depth on prompt engg (video, more interesting 15m onwards) https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/prompt-engineering/  \n\nElvis prompt engineering guide, fairly exhaustive https://github.com/dair-ai/Prompt-Engineering-Guide \n\nPrompt engg stuff by brex https://github.com/brexhq/prompt-engineering  \n\nA lot of prompt engineering tips https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77  \n\nLilian Weng‚Äôs guide https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/

Message : 1. Conversation like Friendly Human

2. When I'm bored.
Quoted Message : Do you know what kind of things they do to make conversation interesting?\n\nWhat makes you go to it? When you‚Äôre bored? Curious

Message : ‚Äé<attached: 00010935-PHOTO-2023-06-30-11-18-51.jpg>

Message : link share kar do. This one looks like a Railway reservation chart

Message : Pi is distinctively good for those late night convo you‚Äôd have with a friend - stuff that‚Äôs on your mind, anxieties, etc.

One interesting thing is, after some convos, I wanted it to be agentic.. like do more things than just chat. Set up timers, create tasks, and more
Quoted Message : Do you know what kind of things they do to make conversation interesting?\n\nWhat makes you go to it? When you‚Äôre bored? Curious

Message : But damn the number of events. Shows where its at

Message : https://docs.google.com/spreadsheets/d/1P6ut7vL-gXKbeDeh3nuPqBjoCupjIt87Sw7TnhumBSU/htmlview#gid=1781893986

Message : You guys missed to have an event on June 5 üòû ‚Äé<This message was edited>

Message : ‚Äé<attached: 00010941-GIF-2023-06-30-11-24-45.mp4>
Quoted Message : You guys missed to have an event on June 5 üòû

Message : Events are not a proxy for great companies or problem statements although they can sometimes be. There‚Äôs lots of AI opportunity and work done in East Asia as well without as many events
Quoted Message : But damn the number of events. Shows where its at

Message : That‚Äôs surprising
Quoted Message : You guys missed to have an event on June 5 üòû

Message : yes true. If you're only attending events , then you're not working. But still interesting to see this.
Quoted Message : Events are not a proxy for great companies or problem statements although they can sometimes be. There‚Äôs lots of AI opportunity and work done in East Asia as well without as many events

Message : Actually they are. Those silent warriors of East Asia are moving where they are heard.
Quoted Message : Events are not a proxy for great companies or problem statements although they can sometimes be. There‚Äôs lots of AI opportunity and work done in East Asia as well without as many events

Message : It‚Äôs different feeling when you can bump into Karpathy, Fridman, or others here and there

Message : There‚Äôs also a cottage industry of influencers also that just want to organise these events. And give away awards like 40 under 40. Someday we will even see 90 under 90 awards in AI. Not to downplay the importance of these events

Message : That‚Äôs because they have media empires in addition to being or having been technical leaders in their fields.
Quoted Message : It‚Äôs different feeling when you can bump into Karpathy, Fridman, or others here and there

Message : https://twitter.com/EMostaque/status/1674509839458791431?t=EtblykAzDT4d6EpdDiZesA&s=19

Good AMA by Emad

Message : How many will come if Ishan Mishra or Szegedy are invited as key speakers? Maybe some but not as many as Friedman or Ng. Just the way things are with media empires and tech gurus

Message : Call it a tech guy's bias, but I find others only useful as news reporters. Very few folks like karpathy but ü§Ø and üßµüëá is what is everywhere
Quoted Message : How many will come if Ishan Mishra or Szegedy are invited as key speakers? Maybe some but not as many as Friedman or Ng. Just the way things are with media empires and tech gurus

Message : Is this a rant for missing out or do you have exact engagement numbers for other events. In SF, you may be sitting beside Anthropic CEO and you may not know. That‚Äôs talent concentration.
Quoted Message : How many will come if Ishan Mishra or Szegedy are invited as key speakers? Maybe some but not as many as Friedman or Ng. Just the way things are with media empires and tech gurus

Message : Question for me is more practical - would you sit through a Sam Altman monologue in person or online at your convenience, while you get work done wherever else you are. Do you have to be in the city and in person to really get the best out of the event? Is Anthropic the only source of inspirational ideas for me or can I get them from elsewhere by attending an event remotely, or elsewhere? We do live in a world where a lot of teams are remote, great work is done remotely and distributed, so is there a reason to drool over SF events?
Quoted Message : Is this a rant for missing out or do you have exact engagement numbers for other events. In SF, you may be sitting beside Anthropic CEO and you may not know. That‚Äôs talent concentration.

Message : Many of us who are working with the tech may get more out of a (Lex Fridman podcast) with Ishan Misra in it or someone else than a highly marketed event. So it depends.

Message : Question for me is more practical - would you sit through a Sam Altman monologue in person or online at your convenience, while you get work done wherever else you are. Do you have to be in the city and in person to really get the best out of the event? Is Anthropic the only source of inspirational ideas for me or can I get them from elsewhere by attending an event remotely, or elsewhere? We do live in a world where a lot of teams are remote, great work is done remotely and distributed, so is there a reason to drool over SF events?

Message : Many of us who are working with the tech may get more out of a (Lex Fridman podcast) with Ishan Misra in it or someone else than a highly marketed event. So it depends.

Message : Why are you trying attend all 84 events? ü§∑‚Äç‚ôÇÔ∏è

Message : Like, do you watch every podcast ever produced on tech?

Message : Who is attending all 84? And who is watching every podcast? You have arguably more choice online as events stream, than if you were in person - and I agree if you're a business leader you may need to be in person for some things. Your focus then is different.

Message : This seems like a good idea for MeetupGPT. Summarize every meetup , do q&A on different things discussed
Quoted Message : Why are you trying attend all 84 events? ü§∑‚Äç‚ôÇÔ∏è

Message : There is a different level of connection when meet people in person and exchange ideas. Remote is overrated.

Message : Great idea. Meeting summarization is a superb idea in general
Quoted Message : This seems like a good idea for MeetupGPT. Summarize every meetup , do q&A on different things discussed

Message : Which tech podcast do you listen to? Can you recommend some.
Quoted Message : Like, do you watch every podcast ever produced on tech?

Message : Podcast is a one way street for learning, have a good hot discussion in person with few folks who know their things and not just asking questions.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Question for me is more practical - would you sit through a Sam Altman monologue in person or online at your convenience, while you get work done wherever else you are. Do you have to be in the city and in person to really get the best out of the event? Is Anthropic the only source of inspirational ideas for me or can I get them from elsewhere by attending an event remotely, or elsewhere? We do live in a world where a lot of teams are remote, great work is done remotely and distributed, so is there a reason to drool over SF events?

Message : Many of us who are working with the tech may get more out of a (Lex Fridman podcast) with Ishan Misra in it or someone else than a highly marketed event. So it depends.

Message : Why are you trying attend all 84 events? ü§∑‚Äç‚ôÇÔ∏è

Message : Like, do you watch every podcast ever produced on tech?

Message : Who is attending all 84? And who is watching every podcast? You have arguably more choice online as events stream, than if you were in person - and I agree if you're a business leader you may need to be in person for some things. Your focus then is different.

Message : This seems like a good idea for MeetupGPT. Summarize every meetup , do q&A on different things discussed
Quoted Message : Why are you trying attend all 84 events? ü§∑‚Äç‚ôÇÔ∏è

Message : There is a different level of connection when meet people in person and exchange ideas. Remote is overrated.

Message : Great idea. Meeting summarization is a superb idea in general
Quoted Message : This seems like a good idea for MeetupGPT. Summarize every meetup , do q&A on different things discussed

Message : Which tech podcast do you listen to? Can you recommend some.
Quoted Message : Like, do you watch every podcast ever produced on tech?

Message : Podcast is a one way street for learning, have a good hot discussion in person with few folks who know their things and not just asking questions.

Message : I guess Rewind added this feature recently, they record your meetings and gets you minute of meetings.
Quoted Message : Great idea. Meeting summarization is a superb idea in general

Message : Remote is great for certain things, and in-person great for other things, IMHO. To each his own.
Quoted Message : There is a different level of connection when meet people in person and exchange ideas. Remote is overrated.

Message : ‚Äé<attached: 00010966-GIF-2023-06-30-11-45-13.mp4>

Message : Strata used to be doing conferences left and right, spoke at one of them some years ago - and for 2016 they had a good experience in playing back the meetings and so on. I don't think they did summarization back then though
Quoted Message : I guess Rewind added this feature recently, they record your meetings and gets you minute of meetings.

Message : meetups make more sense with remote work now.
Quoted Message : There is a different level of connection when meet people in person and exchange ideas. Remote is overrated.

Message : Even modest human generated summaries would have been good.

Message : Not to strech the topic, but I personally go to only few meetups where only hackers shows up, and demo their projects. I know that I saw Shreya for Guardrail presenting there. I was allowed to demo two of mine. Other great demos and people everytime. ‚Äé<This message was edited>

Message : ...that nobody readsüòÖ
Quoted Message : I guess Rewind added this feature recently, they record your meetings and gets you minute of meetings.

Message : all the more reason to offload the task üòÑ
Quoted Message : ...that nobody readsüòÖ

Message : Need to say this louderüíØ
Quoted Message : There is a different level of connection when meet people in person and exchange ideas. Remote is overrated.

Message : was added to chat

Message : https://towardsdatascience.com/vllm-pagedattention-for-24x-faster-llm-inference-fdfb1b80f83

guys what are your thoughts on thisüëç

Message : https://pi.ai/s/14R8gbnGNeM9Fo75qLH4p
Quoted Message : Pi is distinctively good for those late night convo you‚Äôd have with a friend - stuff that‚Äôs on your mind, anxieties, etc.\n\nOne interesting thing is, after some convos, I wanted it to be agentic.. like do more things than just chat. Set up timers, create tasks, and more

Message : Yes I've studied the vLLM method. It uses continuous batching to reduce memory footprint by avoiding loading model parameters every time on every conversation.
Quoted Message : https://towardsdatascience.com/vllm-pagedattention-for-24x-faster-llm-inference-fdfb1b80f83\n\nguys what are your thoughts on thisüëç

Message : It's not for a peasant like me who has 1 machine to work on and not 100s of parallel running instances

Message : Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?

Message : Initially felt like every company is doing this... surprisingly can't even find one!
Quoted Message : Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?

Message : It's for guys who are api providers or have to maintain conversations using the LLMs across multiple chat sessions (best if 50-100).
Quoted Message : It's not for a peasant like me who has 1 machine to work on and not 100s of parallel running instances

Message : https://lmql.ai might come close?
Quoted Message : Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?

Message : cool... I'll check it out
Quoted Message : https://lmql.ai might come close?

Message : we also take our different approach here. instead of inventing a new language/sql, we use jsonnet - which is a config format used at Google Borg/Kubernetes. we specify the chain + prompt in jsonnet so no multiple layers of libraries/functions to navigate through. 
anything written in edgechains is automatically api-fied, supports streaming, retry/backoffs, etc.

https://github.com/arakoodev/EdgeChains/releases/tag/0.2.0
Quoted Message : Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?

Message : Wow, Pi is beautifully put together
Quoted Message : https://pi.ai/s/14R8gbnGNeM9Fo75qLH4p

Message : thoroughly useless. kind of like nat.dev for mobile. I'm disappointed that Quora with all of their data and ML expertise are not actually innovating on LLMs. ‚Äé<This message was edited>
Quoted Message : That reminds me, what do folks think of Poe ( from the quora founder ) ?

Message : Interesting... Will check it out
Quoted Message : we also take our different approach here. instead of inventing a new language/sql, we use jsonnet - which is a config format used at Google Borg/Kubernetes. we specify the chain + prompt in jsonnet so no multiple layers of libraries/functions to navigate through. \nanything written in edgechains is automatically api-fied, supports streaming, retry/backoffs, etc. \n\nhttps://github.com/arakoodev/EdgeChains/releases/tag/0.2.0

Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : ‚Äé<attached: 00010988-PHOTO-2023-06-30-13-10-13.jpg>

Message : Wow is this your chat?
Quoted Message : https://pi.ai/s/14R8gbnGNeM9Fo75qLH4p

Message : yeah .. just horsing around
Quoted Message : Wow is this your chat?

Message : Bot handelled it well I must say
Quoted Message : yeah .. just horsing around

Message : but again the guy behined the company is co founder of Deep Mind

Message : @91989995xxxx is the founder and here üëã

Message : way too safely hidden behind the waitlist... as of now, cant wait to try it actually
Quoted Message : @9198xxxxxxxx is the founder and here üëã

Message : ‚Äé<attached: 00010996-PHOTO-2023-06-30-13-17-17.jpg>
Quoted Message : Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?

Message : Damn! Sorry, can you send me a DM and I‚Äôll give you access right away?
Quoted Message : way too safely hidden behind the waitlist... as of now, cant wait to try it actually

Message : ‚Äé<attached: 00010998-PHOTO-2023-06-30-13-23-01.jpg>
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : Thanks! And true - this has been a big thing to manage for us as well. Costs of all models, newer ones and discounts and credits at times

Message : In the future, we‚Äôll try opening up an API just for easy pricing.

Message : Azure openai service seems to have a way of doing this. I‚Äôm not sure about openai‚Äô own endpoints
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : Custom product just for this one use case

https://puddl.io/
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : I think langchain or llama index support some functions ro monitor cost
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : @91989995xxxx is the founder and here üëã

Message : way too safely hidden behind the waitlist... as of now, cant wait to try it actually
Quoted Message : @9198xxxxxxxx is the founder and here üëã

Message : ‚Äé<attached: 00010996-PHOTO-2023-06-30-13-17-17.jpg>
Quoted Message : Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?

Message : Damn! Sorry, can you send me a DM and I‚Äôll give you access right away?
Quoted Message : way too safely hidden behind the waitlist... as of now, cant wait to try it actually

Message : ‚Äé<attached: 00010998-PHOTO-2023-06-30-13-23-01.jpg>
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : Thanks! And true - this has been a big thing to manage for us as well. Costs of all models, newer ones and discounts and credits at times

Message : In the future, we‚Äôll try opening up an API just for easy pricing.

Message : Azure openai service seems to have a way of doing this. I‚Äôm not sure about openai‚Äô own endpoints
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : Custom product just for this one use case

https://puddl.io/
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : I think langchain or llama index support some functions ro monitor cost
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : just played with it,

what i observed:

- their differentiation is in RLHF (they seem to have trained on dataset where asking good questions and conversation length is rewarded, not just right answers)
- They seem to have specialized flows (like "20 questions"), and LLM switches between those, so maybe specialized tokens indicate flows perhaps

Message : thanks, using this seems to be the best option, since folks will ensure it remains up to date
Quoted Message : I think langchain or llama index support some functions ro monitor cost

Message : We‚Äôre building a solution around this at quolum.io
Quoted Message : Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes.

Message : ohk, I was asking since I'm open sourcing a related library myself haha

Message : Id be happy to show you a demo

Message : Xd no demo then
Quoted Message : ohk, I was asking since I'm open sourcing a related library myself haha

Message : Helpful , thanks :)
Quoted Message : just played with it,\n\nwhat i observed:\n\n- their differentiation is in RLHF (they seem to have trained on dataset where asking good questions and conversation length is rewarded, not just right answers)\n- They seem to have specialized flows (like \"20 questions\"), and LLM switches between those, so maybe specialized tokens indicate flows perhaps

Message : blown away by pi !
feels like i am talking to a fellow human !

i was feeling a little distracted today and tried talking to pi honestly :
https://pi.ai/s/UmEj8XDASD4sqmL4EviNz

if they could add voice input & output, it could potentially be a coach or therapist too !

really really impressive !

Message : Did you end up acting on its suggestions?
Quoted Message : blown away by pi !\nfeels like i am talking to a fellow human !\n\ni was feeling a little distracted today and tried talking to pi honestly :\nhttps://pi.ai/s/UmEj8XDASD4sqmL4EviNz\n\nif they could add voice input & output, it could potentially be a coach or therapist too !\n\nreally really impressive !

Message : Very interesting!
I need to play around with it more I guess
Quoted Message : blown away by pi !\nfeels like i am talking to a fellow human !\n\ni was feeling a little distracted today and tried talking to pi honestly :\nhttps://pi.ai/s/UmEj8XDASD4sqmL4EviNz\n\nif they could add voice input & output, it could potentially be a coach or therapist too !\n\nreally really impressive !

Message : But the Greylock podcast about it was insightful too. Stressed on how they're trying to build the emotional core first!

Message : It's a wonderful conversation partner. It'll be a shame to prompt hack it and force it's creators to perform RLHF lobotomy on it.

Message : has anyone self-hosted weaviate on azure/gcp before? wanted to get some info

Message : I don't agree with building the emotional core first, but that's also a personal belief on the Planning-Memory-Execution trifecta
Quoted Message : But the Greylock podcast about it was insightful too. Stressed on how they're trying to build the emotional core first!

Message : ‚Äé<attached: 00011020-PHOTO-2023-06-30-14-14-08.jpg>

Message : hi , this might be a dumb question but while I'm doing SqlDatabaseChain calls in langchain , how do ensure the query doesn't respond to some unwanted/sensitive data . 

eg - i have a table with a column for email id , and i wanna return only values for xyz@mail.com . i can append in the prompt ".. only give the values for xyz@mail.com" , but theres always a chance of prompt injection , and it returning values for other emails...

currently im appending   `WHERE users.email = ${email}` at the end of each user generated prompt , before calling the sqlChain , and it seems to be working fine , but feels like a hacky way.

Message : Hi. Do you have the original Excel sheet ?

Message : do you have a link?
Quoted Message : But the Greylock podcast about it was insightful too. Stressed on how they're trying to build the emotional core first!

Message : why not?

it's solving a different use case than chatgpt
Quoted Message : I don't agree with building the emotional core first, but that's also a personal belief on the Planning-Memory-Execution trifecta

Message : https://open.spotify.com/episode/67MBhAISm2aB6wwzjROJjs - this one

Message : Thanks was just searching
Quoted Message : https://open.spotify.com/episode/67MBhAISm2aB6wwzjROJjs - this one

Message : Shared Google docs link somewhere above
Quoted Message : Hi. Do you have the original Excel sheet ?

Message : Yes yes I agree with the use case. I basically believe a more effective Personal AI will first solve for task support than emotional support.
Quoted Message : why not?\n\nit's solving a different use case than chatgpt

Message : i am not sure if we even understand what does personal AI even means? is it a coach, a friend, a companion, an expert? a single person often isn't everything
Quoted Message : Yes yes I agree with the use case. I basically believe a more effective Personal AI will first solve for task support than emotional support.

Message : Happy to chat more on DM too. It's a topic I've been spending a lot of time on for a while
Quoted Message : Yes yes I agree with the use case. I basically believe a more effective Personal AI will first solve for task support than emotional support.

Message : Agreed. And it can be all distinctly and also combined. And it'll likely evolve too.
In fact Inflection says they're an AI studio and Pi is their first offering!
Quoted Message : i am not sure if we even understand what does personal AI even means? is it a coach, a friend, a companion, an expert? a single person often isn't everything

Message : This is surprising. I thought everyone knew about pgvector limitations!

Message : This is indeed the best possible outcome

Message : Jo just sent this ‚Äî he is roasting Supabase's outright sleaziness and using pgvector's goodwill for profit 
https://twitter.com/jobergum/status/1674541715099664386

Message : Jo is the creator of Vespa which powers Yahoo's Text Search

Message : I'm guessing other vectordb companies were keeping quiet about it since they didnt want pgvector to add hnsw too quick

Message : Supabase CEO shooting themselves in the foot üôà
https://twitter.com/kiwicopple/status/1674550357110800384

Message : nirant ur tweet is IMBA

Message : No no. Supabase is eating into every vectorDB's roadmap. I've access to 2 of top 3 players roadmap
Quoted Message : I'm guessing other vectordb companies were keeping quiet about it since they didnt want pgvector to add hnsw too quick

Message : What is IMBA?
Quoted Message : nirant ur tweet is IMBA

Message : Credit where it's due, almost all the engineering here is done by Shivendu @91748189xxxx. I've mostly been good/lucky at spotting a problem

Message : Did we get a detailed benchmark on pgvector? Have completely missed this
Quoted Message : Supabase CEO shooting themselves in the foot üôà\nhttps://twitter.com/kiwicopple/status/1674550357110800384

Message : imbalanced? Gamer lingo üòÖ
Quoted Message : What is IMBA?

Message : Its OP instead of IMBA nowadays, after league of legends overtook Dota 2 üòù
Quoted Message : imbalanced? Gamer lingo üòÖ

Message : More detailed than anything else

https://nirantk.com/writing/pgvector-vs-qdrant.html
Quoted Message : Did we get a detailed benchmark on pgvector? Have completely missed this


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I'm guessing other vectordb companies were keeping quiet about it since they didnt want pgvector to add hnsw too quick

Message : Supabase CEO shooting themselves in the foot üôà
https://twitter.com/kiwicopple/status/1674550357110800384

Message : nirant ur tweet is IMBA

Message : No no. Supabase is eating into every vectorDB's roadmap. I've access to 2 of top 3 players roadmap
Quoted Message : I'm guessing other vectordb companies were keeping quiet about it since they didnt want pgvector to add hnsw too quick

Message : What is IMBA?
Quoted Message : nirant ur tweet is IMBA

Message : Credit where it's due, almost all the engineering here is done by Shivendu @91748189xxxx. I've mostly been good/lucky at spotting a problem

Message : Did we get a detailed benchmark on pgvector? Have completely missed this
Quoted Message : Supabase CEO shooting themselves in the foot üôà\nhttps://twitter.com/kiwicopple/status/1674550357110800384

Message : imbalanced? Gamer lingo üòÖ
Quoted Message : What is IMBA?

Message : Its OP instead of IMBA nowadays, after league of legends overtook Dota 2 üòù
Quoted Message : imbalanced? Gamer lingo üòÖ

Message : More detailed than anything else

https://nirantk.com/writing/pgvector-vs-qdrant.html
Quoted Message : Did we get a detailed benchmark on pgvector? Have completely missed this

Message : does anyone know of a HF inference endpoints-like service which offers lower end (and cheaper) GPUs?

Message : RIP Twitter DMs, so much attack from pgvector fanbois üòÖ

Feels like I've fallen into vim vs emacs

Message : You made it
Quoted Message : RIP Twitter DMs, so much attack from pgvector fanbois üòÖ\n\nFeels like I've fallen into vim vs emacs

Message : Thanks Nirant! üôè
Quoted Message : Credit where it's due, almost all the engineering here is done by Shivendu @9174xxxxxxxx. I've mostly been good/lucky at spotting a problem

Message : Awesome work
Quoted Message : Thanks Nirant! üôè

Message : /9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABsbGxscGx4hIR4qLSgtKj04MzM4PV1CR0JHQl2NWGdYWGdYjX2Xe3N7l33gsJycsOD/2c7Z//////////////8BGxsbGxwbHiEhHiotKC0qPTgzMzg9XUJHQkdCXY1YZ1hYZ1iNfZd7c3uXfeCwnJyw4P/Zztn////////////////CABEIAEgALAMBIgACEQEDEQH/xAAsAAACAwEBAAAAAAAAAAAAAAAABgECAwQFAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAABdjsucFfRyOM6+c6HlGfTLbKDZObVI4XdIxH0Q6j8q+VU2prBnFqhWYJ1AIAMgP//EACgQAAIBAwIFBAMBAAAAAAAAAAECAAMEEhExFCE0UVMFEEFyEyJhcf/aAAgBAQABPwDBgoOB/wBmJ7TFhupg9jDdvVpJRCTg7rxmG1ujujQ2V142nA3fhaVKT0mxdSDLHqqP2jchqItT4YTkYSFGs9c6ofWWPVUftNNRCkCEbGEnH9uc9b6ofWWTBbmkTtlOKtvKs4u28qzirbyrOKtvKs9adHutUaNaVkpLVI5GYvrCj7zRocoTrDcVmQIW/WZnWZnaZN3mTd4ZpR/GD8w4nZBMddoVPaYt29h8TVv5Mm7CZN/IxZu0M//EABQRAQAAAAAAAAAAAAAAAAAAADD/2gAIAQIBAT8Af//EABQRAQAAAAAAAAAAAAAAAAAAADD/2gAIAQMBAT8Af//Z 2023_06_30_145844_3D509A4ABF9BF8AA822C588453302977.jpeg
Quoted Message : Did we get a detailed benchmark on pgvector? Have completely missed this

Message : But typically the marketing boosted gravy trains come back on track in some time

Message : ‚Äé<attached: 00011052-PHOTO-2023-06-30-14-58-44.jpg>

Message : But typically the marketing boosted gravy trains come back on track in some time

Message : They have full voice interface on at least the iOS app
Quoted Message : blown away by pi !\nfeels like i am talking to a fellow human !\n\ni was feeling a little distracted today and tried talking to pi honestly :\nhttps://pi.ai/s/UmEj8XDASD4sqmL4EviNz\n\nif they could add voice input & output, it could potentially be a coach or therapist too !\n\nreally really impressive !

Message : cc @91997020xxxx since we were talking about Inflection AI
Quoted Message : blown away by pi !\nfeels like i am talking to a fellow human !\n\ni was feeling a little distracted today and tried talking to pi honestly :\nhttps://pi.ai/s/UmEj8XDASD4sqmL4EviNz\n\nif they could add voice input & output, it could potentially be a coach or therapist too !\n\nreally really impressive !

Message : https://www.reddit.com/r/LocalLLaMA/comments/14me1ha/open_orca_dataset_released/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=3

Message : nan

Message : Congratulations @91748189xxxx & @91773788xxxx !
Quoted Message : Credit where it's due, almost all the engineering here is done by Shivendu @9174xxxxxxxx. I've mostly been good/lucky at spotting a problem

Message : 2 q.s on pi like assistants which came up, would love to hear from the group :

1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?

2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant

Or
1 assistant which is trained on a wide variety of training data to rule them all ?

Or
1 master assistant which would "invoke" specialised sub assistants depending on the context of a particular prompt ?

Or

Will there be something cometely new or different ?
Quoted Message : cc @9199xxxxxxxx since we were talking about Inflection AI

Message : cc @91994014xxxx this feels like is in your alley
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : IMHO for Q2 - 3rd option - the invoking - whether assistants or other apps/plugins to get it done
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : But following views of the group very keenly

Message : @91813028xxxx
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : It's anybody's guess but I'll take the "master assistant and helper assistants" bet.

There's an inherent limitation in current architecture in SoTA LLMs that does not allow general intelligence to develop. More than anything else, just the fact that different tokenisers optimise performance on different tasks is a key factor.
Currently arithmetic, counting words and entities requires training tokenisers differently than how it has been trained for Llama/GPT like LLMs.
Likewise, code generation works best with it's own kind of tokenisation approach.

There was a research that I saw last month, that seems to resolve these dependencies on tokenisations and accumulation of error with token length. I'll have to look it up again and understand more.
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : ‚Äé<attached: 00011064-PHOTO-2023-06-30-15-50-27.jpg>
Quoted Message : They have full voice interface on at least the iOS app

Message : No sign in on mobile

Message : Might just be a conscious design choice but seems a bit weird to me.

Maintaing context of previous conversation threads, seems like an obvious feature
Quoted Message : No sign in on mobile

Message : my take is that text is not a universal interface, and as soon as you add other interfaces, specializations will emerge and hence specialist assistants will emerge
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : But you you try it on insta, it will call you by your name.

Message : They have an insta bot too

Message : @91773788xxxx answering at your command

@91789256xxxx
#1 language demographics is good L1 data. L2 can be inverse of digital savviness (less savvy = higher chance of voice input preference AFAIK)

#2 my take is Option 3 - a master assistant interfacing with other specialised assistants.
Assistants will become the next interface to the internet. In the past it was Google. We often know a website but we go to the search bar and type the name of the website and go to the website using the Google search. That is not because you can't go to the website directly just because Google is almost synonymous with the internet. This new master assistant will become the new gateway to the internet replacing google search. There are lessons to be learned from the search internet era - When Google was coming up, everyone thought that would be specialized search engines for healthcare for education etc. But Google became the single gateway to the internet. I think history will repeat itself in that sense, given that these assistants are afterall the Google search killer
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : Anybody has experience with phind.com?
I'm seeing reviews where it's supposedly very good with data that is not part of GPT4 training cut off. It's also being claimed that it can program on much recent coding standards by automatically finding relevant docs.

Message : Please share you find it.
Quoted Message : It's anybody's guess but I'll take the \"master assistant and helper assistants\" bet.\n\nThere's an inherent limitation in current architecture in SoTA LLMs that does not allow general intelligence to develop. More than anything else, just the fact that different tokenisers optimise performance on different tasks is a key factor.\nCurrently arithmetic, counting words and entities requires training tokenisers differently than how it has been trained for Llama/GPT like LLMs.\nLikewise, code generation works best with it's own kind of tokenisation approach. \n\nThere was a research that I saw last month, that seems to resolve these dependencies on tokenisations and accumulation of error with token length. I'll have to look it up again and understand more.

Message : It‚Äôs quite good but has hallucinations for fringe use cases
Quoted Message : Anybody has experience with phind.com?\nI'm seeing reviews where it's supposedly very good with data that is not part of GPT4 training cut off. It's also being claimed that it can program on much recent coding standards by automatically finding relevant docs.

Message : I think the future is personal assistants fine tuned uniquely for every individual that in turn interact with the rest of the ecosystem
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : Found it. Going to study it more to see if I can repro this with nanoGPT.

The paper is - *MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers*
Link - arxiv.org/abs/2305.07185

*Tweet by Karpathy where I became familiar with the problem with tokenisation approaches* -

https://twitter.com/karpathy/status/1657949234535211009?t=KzDvK0DLzkIIB4zKENQY1g&s=19
Quoted Message : Please share you find it.

Message : I sometimes wonder how this "space" of personal AI will be once Apple, Google, etc launch their own. They have more data, and barriers to put. Huge field and will happen for sure but are odds against the small guy?

Message : Personal AI bots

Message : Yeah, even GPT4 loses context and starts making up stuff if my context history is long. So, I'll see if that problem occurs sooner with phind.
Thanks for sharing your comments.
Quoted Message : It‚Äôs quite good but has hallucinations for fringe use cases

Message : Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732
Quoted Message : I sometimes wonder how this \"space\" of personal AI will be once Apple, Google, etc launch their own. They have more data, and barriers to put. Huge field and will happen for sure but are odds against the small guy?

Message : There will be physical manifestations (robots, alexa 2.0, etc) but as always software and AI will drive who owns the hardware product domination. Genuinely curious as to what smart VCs are seeing put billions in new upstarts like character.ai when the end-game can be pulled out. Just all the info Meta has from whatsapp communication (on me) is something I will never disclose to another company or they able to snoop and make it contextual enough. Laptop or OS owner has an edge, which makes me at least scary
Quoted Message : Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732

Message : Maybe Lab126 is cooking astro ++ with gen ai and Alexa 

https://youtu.be/DxVtJW8ROAQ
Quoted Message : Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732

Message : Weekend reminder, this is the set of *rules* we try our best to enforce for everyone in this WhatsApp group:
https://nirantk.com/community

At this moment, we also remove folks who're not able to contribute in any 60 day period because WhatsApp caps the group to 1K members

Message : https://t.co/genXa1UHuL
@91773788xxxx @91748189xxxx you missed benchmarking against this hyper fast db üòÇüòÇüòÇüòÇ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I think the future is personal assistants fine tuned uniquely for every individual that in turn interact with the rest of the ecosystem
Quoted Message : 2 q.s on pi like assistants which came up, would love to hear from the group :\n\n1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?\n\n2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant\n\nOr \n1 assistant which is trained on a wide variety of training data to rule them all ?\n\nOr \n1 master assistant which would \"invoke\" specialised sub assistants depending on the context of a particular prompt ?\n\nOr \n\nWill there be something cometely new or different ?

Message : Found it. Going to study it more to see if I can repro this with nanoGPT.

The paper is - *MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers*
Link - arxiv.org/abs/2305.07185

*Tweet by Karpathy where I became familiar with the problem with tokenisation approaches* -

https://twitter.com/karpathy/status/1657949234535211009?t=KzDvK0DLzkIIB4zKENQY1g&s=19
Quoted Message : Please share you find it.

Message : I sometimes wonder how this "space" of personal AI will be once Apple, Google, etc launch their own. They have more data, and barriers to put. Huge field and will happen for sure but are odds against the small guy?

Message : Personal AI bots

Message : Yeah, even GPT4 loses context and starts making up stuff if my context history is long. So, I'll see if that problem occurs sooner with phind.
Thanks for sharing your comments.
Quoted Message : It‚Äôs quite good but has hallucinations for fringe use cases

Message : Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732
Quoted Message : I sometimes wonder how this \"space\" of personal AI will be once Apple, Google, etc launch their own. They have more data, and barriers to put. Huge field and will happen for sure but are odds against the small guy?

Message : There will be physical manifestations (robots, alexa 2.0, etc) but as always software and AI will drive who owns the hardware product domination. Genuinely curious as to what smart VCs are seeing put billions in new upstarts like character.ai when the end-game can be pulled out. Just all the info Meta has from whatsapp communication (on me) is something I will never disclose to another company or they able to snoop and make it contextual enough. Laptop or OS owner has an edge, which makes me at least scary
Quoted Message : Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732

Message : Maybe Lab126 is cooking astro ++ with gen ai and Alexa 

https://youtu.be/DxVtJW8ROAQ
Quoted Message : Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732

Message : Weekend reminder, this is the set of *rules* we try our best to enforce for everyone in this WhatsApp group:
https://nirantk.com/community

At this moment, we also remove folks who're not able to contribute in any 60 day period because WhatsApp caps the group to 1K members

Message : https://t.co/genXa1UHuL
@91773788xxxx @91748189xxxx you missed benchmarking against this hyper fast db üòÇüòÇüòÇüòÇ

Message : Yeah, we wanted to keep the competition fair üòÇü§£

For anyone reading this, that's a joke database made for laughs and not a real Vector DB
Quoted Message : https://t.co/genXa1UHuL\n@9177xxxxxxxx @9174xxxxxxxx you missed benchmarking against this hyper fast db üòÇüòÇüòÇüòÇ

Message : I tried using this but the openai embeddings but they were too overwhelmed by its awesomeness and refused to get indexed

Message : TBH I believed it was real until finding out little later.
Quoted Message : Yeah, we wanted to keep the competition fair üòÇü§£\n\nFor anyone reading this, that's a joke database made for laughs and not a real Vector DB

Message : You should read the source code. I wonder how openai functions will react seeing those names
Quoted Message : TBH I believed it was real until finding out little later.

Message : There's an indian publication that took their joke about the fundraise at face value and printed it in an article üòÇ
Quoted Message : TBH I believed it was real until finding out little later.

Message : I realized after seeing galaxy_brain_**** file name
Quoted Message : You should read the source code. I wonder how openai functions will react seeing those names

Message : Lab126 is the hardware division of Amazon
Quoted Message : Maybe Lab126 is cooking astro ++ with gen ai and Alexa \n\nhttps://youtu.be/DxVtJW8ROAQ

Message : Is there anyway to fast track access to GPT4 API?

Message : ‚Äé<attached: 00011093-PHOTO-2023-06-30-18-16-34.jpg>

Message : yup age-old good practice

Message : Also never trust any pickle file. Even there is an old issue with PyTorch

https://github.com/pytorch/pytorch/issues/52596

Message : Yeah, this is why safetensors were created in the first place. Many releases use checkpoint formats that aren't in safetensor format

Message : https://twitter.com/reach_vb/status/1673363113888948224?s=46&t=WT1iAtjftW-5_e62F8FZTg

This guy tweaked whisper to directly transcribe to ‚Äòany‚Äô language. It says it‚Äôs experimental.

Message : Can anyone please share resources for PII Redaction models for healthcare use cases?

Message : Where's the hack in this?
Quoted Message : https://twitter.com/reach_vb/status/1673363113888948224?s=46&t=WT1iAtjftW-5_e62F8FZTg\n\nThis guy tweaked whisper to directly transcribe to ‚Äòany‚Äô language. It says it‚Äôs experimental.

Message : Isn't this what is already possible via whisper base ASR?

Message : Afaik, whisper transcribes from a language to english. Then we can perform translation.
What the op did is perform this 2 step process at one go.
Quoted Message : Isn't this what is already possible via whisper base ASR?

Message : You can already do direct transcription for any language via whisper transcribe. 

I checked the tweet, the original message is incorrect. The OP wants to convey that they can directly translate an audio input in one Language to any other Language. But the chosen wording is that you can transcribe from any audio language other than English, which is already possible.

Message : That‚Äôs what i was trying to mean as well, sorry if my message was unclear

Message : Also i mentioned direct transcribe ‚Äòto‚Äô any language, not for any language.
Quoted Message : You can already do direct transcription for any language via whisper transcribe. \n\nI checked the tweet, the original message is incorrect. The OP wants to convey that they can directly translate an audio input in one Language to any other Language. But the chosen wording is that you can transcribe from any audio language other than English, which is already possible.

Message : That‚Äôs what i was trying to mean as well, sorry if my message was unclear

Message : Also i mentioned direct transcribe ‚Äòto‚Äô any language, not for any language.

Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood
https://github.com/refuel-ai/autolabel

Pretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA

Creators Nihit @1551689xxxx and Rishabh @1650308xxxx are in the group too!

Message : h/t Bhavya @91756767xxxx for the Twitter mention

Message : More Indian Diaspora doing amazing stuff to come! üî•
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : Meta: 

I believe this group has more folks from Surat than my entire undergrad year now (there were 2 people, incl. me) ‚Äî different kind of talent density üî•

Message : I am not from Surat but sure am a gujju lol
Quoted Message : Meta: \n\nI believe this group has more folks from Surat than my entire undergrad year now (there were 2 people, incl. me) ‚Äî different kind of talent density üî•

Message : People are figuring out that there other ‚ÄúDhandho‚Äù than just Textile and Diamond
Quoted Message : Meta: \n\nI believe this group has more folks from Surat than my entire undergrad year now (there were 2 people, incl. me) ‚Äî different kind of talent density üî•

Message : ‚Äé<attached: 00011112-GIF-2023-06-30-20-05-02.mp4>
Quoted Message : People are figuring out that there other ‚ÄúDhandho‚Äù than just Textile and Diamond

Message : thanks for the shoutout @91773788xxxx! and thanks for recommending this community @91756767xxxx

Folks, hope you find this project useful and give it a try! if you have any questions or suggestions for improvement, feel free to reach out on WhatsApp or open an issue on our GitHub repo. Happy labeling üöÄ
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : For some background - Nihit, Rishabh are ex Stanford, Meta, LinkedIn, and On Deck fellows who have raised 5mil+ from General Catalysts recently.

Message : Good to see you here @1650308xxxx

Message : Amazing! I know for a fact that some of the largest labelling companies are trying to do this internally. 
Will def give this a spin
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : @659730xxxx - PeakXV's portco - Canary Mail (Dev/Sohel.) is Nihit and mine mutual friend. They've started leveraging GenAI in their email tool. I have tried inviting them here but to no good. If you could pl try? I am sure they'll benefit a lot! üôÉ

Message : actually pretty cool. may end up using it in a workflow i was thinking about
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : kudos
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : Thanks @91773788xxxx, @91756767xxxx and @1937708xxxx! Started Refuel.ai to automate data labeling, cleaning and enrichment using LLMs (likely because we had lost so many hours of our life to it).

Great to join the group  :)
Quoted Message : For some background - Nihit, Rishabh are ex Stanford, Meta, LinkedIn, and On Deck fellows who have raised 5mil+ from General Catalysts recently.

Message : If anyone from this group planning come to SF Tinkerer meetup on 6th, we can have a small hangout.
https://sf.tinkerer.ai/p/ai-tinkerers-sf-july-6th-rsvp-required

Message : For sure let me invite those two
Quoted Message : @65xxxxxxxx - PeakXV's portco - Canary Mail (Dev/Sohel.) is Nihit and mine mutual friend. They've started leveraging GenAI in their email tool. I have tried inviting them here but to no good. If you could pl try? I am sure they'll benefit a lot! üôÉ

Message : not entirely surprised they're trying to do this internally :) 

on a related note, came across this paper some time back that estimated that human annotators widely use LLMs when asked to label data:  https://arxiv.org/abs/2306.07899
Quoted Message : Amazing! I know for a fact that some of the largest labelling companies are trying to do this internally. \nWill def give this a spin


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : For some background - Nihit, Rishabh are ex Stanford, Meta, LinkedIn, and On Deck fellows who have raised 5mil+ from General Catalysts recently.

Message : Good to see you here @1650308xxxx

Message : Amazing! I know for a fact that some of the largest labelling companies are trying to do this internally. 
Will def give this a spin
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : @659730xxxx - PeakXV's portco - Canary Mail (Dev/Sohel.) is Nihit and mine mutual friend. They've started leveraging GenAI in their email tool. I have tried inviting them here but to no good. If you could pl try? I am sure they'll benefit a lot! üôÉ

Message : actually pretty cool. may end up using it in a workflow i was thinking about
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : kudos
Quoted Message : Found this pretty cool project: AutoLabel ‚Äî text tagging library which use LLMs under the hood\nhttps://github.com/refuel-ai/autolabel\n\nPretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA\n\nCreators Nihit @155xxxxxxxx and Rishabh @165xxxxxxxx are in the group too!

Message : Thanks @91773788xxxx, @91756767xxxx and @1937708xxxx! Started Refuel.ai to automate data labeling, cleaning and enrichment using LLMs (likely because we had lost so many hours of our life to it).

Great to join the group  :)
Quoted Message : For some background - Nihit, Rishabh are ex Stanford, Meta, LinkedIn, and On Deck fellows who have raised 5mil+ from General Catalysts recently.

Message : If anyone from this group planning come to SF Tinkerer meetup on 6th, we can have a small hangout.
https://sf.tinkerer.ai/p/ai-tinkerers-sf-july-6th-rsvp-required

Message : For sure let me invite those two
Quoted Message : @65xxxxxxxx - PeakXV's portco - Canary Mail (Dev/Sohel.) is Nihit and mine mutual friend. They've started leveraging GenAI in their email tool. I have tried inviting them here but to no good. If you could pl try? I am sure they'll benefit a lot! üôÉ

Message : not entirely surprised they're trying to do this internally :) 

on a related note, came across this paper some time back that estimated that human annotators widely use LLMs when asked to label data:  https://arxiv.org/abs/2306.07899
Quoted Message : Amazing! I know for a fact that some of the largest labelling companies are trying to do this internally. \nWill def give this a spin

Message : How do you expect this task to grow in scale or complexity that it becomes difficult to do it in-house?

With the current level of complexity, I see people trying both GPT as well as FOSS model driven labelling internally.
Quoted Message : not entirely surprised they're trying to do this internally :) \n\non a related note, came across this paper some time back that estimated that human annotators widely use LLMs when asked to label data:  https://arxiv.org/abs/2306.07899

Message : Yes.. Not just LLMs also vision data is mostly semi automated labelling these days

Message : Does that impact quality in any way?
Quoted Message : Yes.. Not just LLMs also vision data is mostly semi automated labelling these days

Message : Yeah, machines have less error, so higher quality
Quoted Message : Does that impact quality in any way?

Message : Often a good idea to benchmark quality of LLM (or foundation model) labeling on a smaller scale first. One of the hardest parts of scaling human labeling is that you have to continuously train/hire new people, and hard to guarantee quality there.
Quoted Message : Does that impact quality in any way?

Message : On that note, curious to know what's the hard part about LLM labeling here, as we saw many folks are trying to do this in-house.
Quoted Message : Often a good idea to benchmark quality of LLM (or foundation model) labeling on a smaller scale first. One of the hardest parts of scaling human labeling is that you have to continuously train/hire new people, and hard to guarantee quality there.

Message : Scale AI had a paper on this
Quoted Message : On that note, curious to know what's the hard part about LLM labeling here, as we saw many folks are trying to do this in-house.

Message : Snorkel is also great at it
Quoted Message : On that note, curious to know what's the hard part about LLM labeling here, as we saw many folks are trying to do this in-house.

Message : Snorkel does weak labelling and ive heard it tough to setup without ui

Message : Or atleast to reach the right functions

Message : On how they did with openai. Can find and share if interested
Quoted Message : Scale AI had a paper on this

Message : Snorkel uses labelling functions. May work for many use cases.
Quoted Message : On that note, curious to know what's the hard part about LLM labeling here, as we saw many folks are trying to do this in-house.

Message : Well the labelers will tell you NO üòä
The point is they would have checks in the funnel. But IMHO <5% error rate is good
Quoted Message : Does that impact quality in any way?

Message : One of the hard parts with LLM labeling is often getting to high enough accuracy / precision numbers (70-80% isn‚Äôt good enough if you want to train downstream models). LLMs will happily produce a label, even if there isn‚Äôt enough context to label successfully üòÖ
Quoted Message : On that note, curious to know what's the hard part about LLM labeling here, as we saw many folks are trying to do this in-house.

Message : You can add a confidence score (had read a tweet - basically add a confidence label in the chatgpt function)
Quoted Message : One of the hard parts with LLM labeling is often getting to high enough accuracy / precision numbers (70-80% isn‚Äôt good enough if you want to train downstream models). LLMs will happily produce a label, even if there isn‚Äôt enough context to label successfully üòÖ

Message : that influencer tweet got swyx got roasted in replies from goodside ‚Äî that was quite a garbage "confidence" score
Quoted Message : You can add a confidence score (had read a tweet - basically add a confidence label in the chatgpt function)

Message : Which is good for weak labelling if you have large scale data. So essentially the 0 to 1 journey is sorted.
Quoted Message : One of the hard parts with LLM labeling is often getting to high enough accuracy / precision numbers (70-80% isn‚Äôt good enough if you want to train downstream models). LLMs will happily produce a label, even if there isn‚Äôt enough context to label successfully üòÖ

Message : ‚Äé<attached: 00011141-PHOTO-2023-06-30-21-35-23.jpg>

Message : Note for wider audience: OpenAI Chat models e.g. GPT4 and 3.5-Turbo do not give token level logits ‚Äé<This message was edited>

Message : absolutely! 
one thing I'll add here- prompting the LLM directly to output a confidence score has limited signal (it often just hallucinates some score)
Quoted Message : You can add a confidence score (had read a tweet - basically add a confidence label in the chatgpt function)

Message : instead in internal experiments, we have observed that token level log probabilities of generated response is higher signal ‚Äé<This message was edited>

Message : Not all third party LLMs support extracting tokenlevel probabilities though as Nirant mentioned. But if you're using a custom LLM or using an open source model this should be possible to extract

Message : Surprised to see such calibrated output. Any thoughts on what ended up hurting calibration in the ‚Äúpost-trained‚Äùmodel?

Message : I'm supposing it's RLHF

Message : RLHF introduces reward and punishment mechanism post training and forces the outermost layers to conform to a style and output.

Message : Disclaimer - I'm yet to read this paper so I could be catastrophically wrong.

Message : https://www.mosaicml.com/blog/amd-mi250?s=09

https://twitter.com/abhi_venigalla/status/1674795311171276803?t=4fgALuiFUyjGCcIao3_cBQ&s=19

The funniest thing is you still have to use `torch.cuda` on AMD hardware

Message : Haha yeah - it seems to be the RLHF (although they don't explicitly say that in the paper). Paper here, btw: https://arxiv.org/pdf/2303.08774.pdf
Quoted Message : Disclaimer - I'm yet to read this paper so I could be catastrophically wrong.

Message : Interesting direction: Machine ‚ÄòUnlearning‚Äô Challenge: https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html?m=1

More:
Fully erasing the influence of the data requested to be deleted is challenging since, aside from simply deleting it from databases where it‚Äôs stored, it also requires erasing the influence of that data on other artifacts such as trained machine learning models. Hence, this.

Message : ‚Äé<attached: 00011158-PHOTO-2023-07-01-00-06-53.jpg>

Message : https://twitter.com/KaiyuYang4/status/1673882824158613504

Someone has done it, combined llms with automated theorem provers!

Message : https://openai.com/blog/insights-from-global-conversations

OpenAI's insights from a world tour of 22 countries.

Message : https://twitter.com/abhi_venigalla/status/1674795311171276803?s=48&t=Jn-WvAjI2PySCsGVL-NAkA \n\nMosaic bringing AMD into the mix

Message : ‚Äé~‚ÄØNirant changed the group description

Message : https://twitter.com/abhi_venigalla/status/1674795311171276803?s=48&t=Jn-WvAjI2PySCsGVL-NAkA 

Mosaic bringing AMD into the mix

Message : My team and I are building a text to sql benchmark query set on a real-world complex hairy dataset that we intend to release publicly on the lines of bird, sparc. Any one who has done such an exercise for any task (not just text to sql)?

Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : We have the dataset and the query set. Trying to learn what massaging and peripherals one needs to do to make it useful for the world


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://twitter.com/KaiyuYang4/status/1673882824158613504

Someone has done it, combined llms with automated theorem provers!

Message : https://openai.com/blog/insights-from-global-conversations

OpenAI's insights from a world tour of 22 countries.

Message : https://twitter.com/abhi_venigalla/status/1674795311171276803?s=48&t=Jn-WvAjI2PySCsGVL-NAkA \n\nMosaic bringing AMD into the mix

Message : ‚Äé~‚ÄØNirant changed the group description

Message : https://twitter.com/abhi_venigalla/status/1674795311171276803?s=48&t=Jn-WvAjI2PySCsGVL-NAkA 

Mosaic bringing AMD into the mix

Message : My team and I are building a text to sql benchmark query set on a real-world complex hairy dataset that we intend to release publicly on the lines of bird, sparc. Any one who has done such an exercise for any task (not just text to sql)?

Message : was added to chat

Message : was added to chat

Message : was added to chat

Message : We have the dataset and the query set. Trying to learn what massaging and peripherals one needs to do to make it useful for the world

Message : Hey @1650215xxxx! Sounds like a super exciting project. Is the goal to have a public leaderboard for the dataset, or to share the dataset so other people can just play around on their own?

Message : ‚Äé<attached: 00011166-PHOTO-2023-07-01-06-36-44.jpg>

Message : Has anyone come across research around LLM based state machines where each state is a specialised LLM?

Message : Do you mean expert model? Like what Geohot was saying about GPT4 architecture?
Quoted Message : Has anyone come across research around LLM based state machines where each state is a specialised LLM?

Message : Sounds very interesting, would love to understand more on how you are benchmarking? Also- wouldn't the peripherals depend on the data/domain?
Quoted Message : My team and I are building a text to sql benchmark query set on a real-world complex hairy dataset that we intend to release publicly on the lines of bird, sparc. Any one who has done such an exercise for any task (not just text to sql)?

Message : Sort of, a collection of specialised LLMs 

The difficult problem is knowing when to jump from one state to another
Quoted Message : Do you mean expert model? Like what Geohot was saying about GPT4 architecture?

Message : I'm not sure if this is what you're exactly looking for, but this MoE paper has an approach that is allegedly used by GPT4. https://arxiv.org/abs/2101.03961

Message : https://twitter.com/yampeleg/status/1674576951330185218?s=46&t=iNnHcvFLDa-sOIXYIloGew
Quoted Message : I'm not sure if this is what you're exactly looking for, but this MoE paper has an approach that is allegedly used by GPT4. https://arxiv.org/abs/2101.03961

Message : "The thing nobody talks about is that in 10 years we'll have a million bipedal robots and in 25 years we'll have a billion. You‚Äôll buy yours for $10k and it will be as important to your life as your smartphone is now" - Vinod Khosla 

https://twitter.com/vkhosla/status/1674572048339984384?t=RS1KvTDxyHUSqJW1XUs4OA&s=19

A million in 10 yrs!

Message : That number actually seems doable. Wondering what incentives would slow down adoption of such robots. Regulation? What else?
Quoted Message : \"The thing nobody talks about is that in 10 years we'll have a million bipedal robots and in 25 years we'll have a billion. You‚Äôll buy yours for $10k and it will be as important to your life as your smartphone is now\" - Vinod Khosla \n\nhttps://twitter.com/vkhosla/status/1674572048339984384?t=RS1KvTDxyHUSqJW1XUs4OA&s=19\n\nA million in 10 yrs!

Message : Will these be personal robots or industrial? - what applications? Who will own it? - incumbents or new ones (like Figure)?
Quoted Message : That number actually seems doable. Wondering what incentives would slow down adoption of such robots. Regulation? What else?

Message : Manufacturing and procurement of raw material may be a bottleneck that may slow things down. But I don't know much of manufacturing to make a 10year assesment
Quoted Message : That number actually seems doable. Wondering what incentives would slow down adoption of such robots. Regulation? What else?

Message : This can be somewhat analogous to the mass IoT adoption problem.

Other than the issues with costs of the individual devices and one time secure setup costs - we are constrained with power, memory and compute costs.

These devices will find limited utility and niche adoption. Not enough to boost the sector enough for economy of scale.

Message : This interested me.
Are you planning to create a HumanEval equivalent of text-to-sql given schema of different ambiguities and complexities?
Quoted Message : My team and I are building a text to sql benchmark query set on a real-world complex hairy dataset that we intend to release publicly on the lines of bird, sparc. Any one who has done such an exercise for any task (not just text to sql)?

Message : Possible, we may already have a million quadrupedal today
Quoted Message : \"The thing nobody talks about is that in 10 years we'll have a million bipedal robots and in 25 years we'll have a billion. You‚Äôll buy yours for $10k and it will be as important to your life as your smartphone is now\" - Vinod Khosla \n\nhttps://twitter.com/vkhosla/status/1674572048339984384?t=RS1KvTDxyHUSqJW1XUs4OA&s=19\n\nA million in 10 yrs!

Message : Where are these used?
Quoted Message : Possible, we may already have a million quadrupedal today

Message : What does this have to do with AI?

Message : I am sorry for sending this link here
Quoted Message : What does this have to do with AI?

Message : Very few real world uses cases, mostly sold to research labs and hobbyists. UNITREE robots are more popular and affordable than Boston Dynamics.
Quoted Message : Where are these used?

Message : Manufacturing units and warehouses + construction seems to have lot of robots. Not sure of specific types

Message : Still a million currently sounds like a big number.
Quoted Message : Very few real world uses cases, mostly sold to research labs and hobbyists. UNITREE robots are more popular and affordable than Boston Dynamics.

Message : There could be multi millions of robots considering an exhaustive defn - nanobots, etc.

The claim is about humanoid pipedal robots
Quoted Message : Manufacturing units and warehouses + construction seems to have lot of robots. Not sure of specific types

Message : How was UNITREE able to make the exact same design and also make it affordable?
Quoted Message : Very few real world uses cases, mostly sold to research labs and hobbyists. UNITREE robots are more popular and affordable than Boston Dynamics.

Message : The most obvious prospective use of mass humanoids personal use robots which makes business sense is sex robots. Will come with a barrage of regulations.
Quoted Message : Will these be personal robots or industrial? - what applications? Who will own it? - incumbents or new ones (like Figure)?

Message : Personal assistant/robots for household assistance would be huge. Sex robots will probably end up being more niche than people assume compared to other use cases.

Message : What will these assistants do?
Quoted Message : Personal assistant/robots for household assistance would be huge. Sex robots will probably end up being more niche than people assume compared to other use cases.

Message : Is it possible to build AI models for feature phones ?

Message : https://www.latent.space/p/ai-engineer

Swyxs take on AI engineering as a profession and why now -

- AI engineers will use models (instead of training them which will be upto ML eng)

- undiscovered capabilities of LLM means someone needs to do this as a full time job

- ‚Äú prompt engineering‚Äù still requires code scaffolding which

Message : Karpathys response -

https://twitter.com/karpathy/status/1674873002314563584?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg
Quoted Message : https://www.latent.space/p/ai-engineer\n\nSwyxs take on AI engineering as a profession and why now - \n\n- AI engineers will use models (instead of training them which will be upto ML eng)\n\n- undiscovered capabilities of LLM means someone needs to do this as a full time job\n\n- ‚Äú prompt engineering‚Äù still requires code scaffolding which

Message : this message has been deleted

Message : Kinda agree with the article , perhaps not with the nomenclature. Anyways job titles in the industry are broken and every company has their own take. For ex ML engineer in some orgs does data engineering, somewhere training and model dev.
Quoted Message : https://www.latent.space/p/ai-engineer\n\nSwyxs take on AI engineering as a profession and why now - \n\n- AI engineers will use models (instead of training them which will be upto ML eng)\n\n- undiscovered capabilities of LLM means someone needs to do this as a full time job\n\n- ‚Äú prompt engineering‚Äù still requires code scaffolding which

Message : Any and all household help. Cleaning up around the house, do the dishes, ironing, moving stuff, bringing stuff. Could have dedicated roles as well like a home nurse for old people etc.
Quoted Message : What will these assistants do?

Message : musks resp to that

‚ÄúPrompt engineering‚Äù is natural language programming

but yeah figuring out what you can do, putting that together and then productionizing it is valuable moving forward, u just get so much output

I wonder who are at the forefront of this right now. Who are some awesome AI engineers you've seen in the wild?
Quoted Message : Karpathys response -\n\nhttps://twitter.com/karpathy/status/1674873002314563584?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : He might be in this group but EmbedChain is pretty cool https://twitter.com/taranjeetio?s=21&t=VEH2Nt1ylkDIN__Wi_QUPg
Quoted Message : musks resp to that\n\n‚ÄúPrompt engineering‚Äù is natural language programming\n\nbut yeah figuring out what you can do, putting that together and then productionizing it is valuable moving forward, u just get so much output\n\nI wonder who are at the forefront of this right now. Who are some awesome AI engineers you've seen in the wild?

Message : Guys, please note that this is not a self promotion event. It is a community event.

Message : Tl;dr - there will be less model building (conventionally known as data and ML engineers) and more model using (AI engineers).
Quoted Message : Kinda agree with the article , perhaps not with the nomenclature. Anyways job titles in the industry are broken and every company has their own take. For ex ML engineer in some orgs does data engineering, somewhere training and model dev.

Message : That‚Äôs the part i agree with üòä
Have seen this trend play out in the last few years
Quoted Message : Tl;dr - there will be less model building (conventionally known as data and ML engineers) and more model using (AI engineers).

Message : cc Taranjeet @91999047xxxx
Quoted Message : He might be in this group but EmbedChain is pretty cool https://twitter.com/taranjeetio?s=21&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : I've a different take. Training your model was never as cheap as it is now. We've been successful in bringing down the training compute costs by 1000-10000x. You can now train your own stable diffusion flavours on free tier colabs/Kaggle books. You also have emerging inference at the edge and fine tuning at the edge.
It takes 20c to fine tune a BERT, $8 to train it from scratch. 90% of problems I used to solve until last year with tons of compromises can now be solved in <$10 or free compute.

Message : I don't think emergence of prompt engineering will impede training or fine tuning ML models. I think both of these areas are going to grow and the prompt engineering bit will expand into a LLMOps mushroom ground.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Kinda agree with the article , perhaps not with the nomenclature. Anyways job titles in the industry are broken and every company has their own take. For ex ML engineer in some orgs does data engineering, somewhere training and model dev.
Quoted Message : https://www.latent.space/p/ai-engineer\n\nSwyxs take on AI engineering as a profession and why now - \n\n- AI engineers will use models (instead of training them which will be upto ML eng)\n\n- undiscovered capabilities of LLM means someone needs to do this as a full time job\n\n- ‚Äú prompt engineering‚Äù still requires code scaffolding which

Message : Any and all household help. Cleaning up around the house, do the dishes, ironing, moving stuff, bringing stuff. Could have dedicated roles as well like a home nurse for old people etc.
Quoted Message : What will these assistants do?

Message : musks resp to that

‚ÄúPrompt engineering‚Äù is natural language programming

but yeah figuring out what you can do, putting that together and then productionizing it is valuable moving forward, u just get so much output

I wonder who are at the forefront of this right now. Who are some awesome AI engineers you've seen in the wild?
Quoted Message : Karpathys response -\n\nhttps://twitter.com/karpathy/status/1674873002314563584?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : He might be in this group but EmbedChain is pretty cool https://twitter.com/taranjeetio?s=21&t=VEH2Nt1ylkDIN__Wi_QUPg
Quoted Message : musks resp to that\n\n‚ÄúPrompt engineering‚Äù is natural language programming\n\nbut yeah figuring out what you can do, putting that together and then productionizing it is valuable moving forward, u just get so much output\n\nI wonder who are at the forefront of this right now. Who are some awesome AI engineers you've seen in the wild?

Message : Guys, please note that this is not a self promotion event. It is a community event.

Message : Tl;dr - there will be less model building (conventionally known as data and ML engineers) and more model using (AI engineers).
Quoted Message : Kinda agree with the article , perhaps not with the nomenclature. Anyways job titles in the industry are broken and every company has their own take. For ex ML engineer in some orgs does data engineering, somewhere training and model dev.

Message : That‚Äôs the part i agree with üòä
Have seen this trend play out in the last few years
Quoted Message : Tl;dr - there will be less model building (conventionally known as data and ML engineers) and more model using (AI engineers).

Message : cc Taranjeet @91999047xxxx
Quoted Message : He might be in this group but EmbedChain is pretty cool https://twitter.com/taranjeetio?s=21&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : I've a different take. Training your model was never as cheap as it is now. We've been successful in bringing down the training compute costs by 1000-10000x. You can now train your own stable diffusion flavours on free tier colabs/Kaggle books. You also have emerging inference at the edge and fine tuning at the edge.
It takes 20c to fine tune a BERT, $8 to train it from scratch. 90% of problems I used to solve until last year with tons of compromises can now be solved in <$10 or free compute.

Message : I don't think emergence of prompt engineering will impede training or fine tuning ML models. I think both of these areas are going to grow and the prompt engineering bit will expand into a LLMOps mushroom ground.

Message : Chiming in. This was also my argument when, earlier,  we were discussing about wrapper LLM apps having inherent moat. At an unit level most people seem to be able to interact with llm and build wrappers of sorts but "programming" of that itself will be complex. Can lead to inherent technical moat. 

Wrapper-wrapper interaction, model-wrapper interaction, model-model interaction.

If the original argument of genAI boosting productivity and creativity is true, most of _LLM apps_ who will survive the test of times will transform into creative workflows that might be unimaginable now.
Quoted Message : musks resp to that\n\n‚ÄúPrompt engineering‚Äù is natural language programming\n\nbut yeah figuring out what you can do, putting that together and then productionizing it is valuable moving forward, u just get so much output\n\nI wonder who are at the forefront of this right now. Who are some awesome AI engineers you've seen in the wild?

Message : Thanks. Bunch of exciting things next week as well.
Quoted Message : He might be in this group but EmbedChain is pretty cool https://twitter.com/taranjeetio?s=21&t=VEH2Nt1ylkDIN__Wi_QUPg

Message : *Event Announcements from https://nirantk.com/community* \n \nTitle: \"How to build great OS projects & Dev tools from AI in India\"\nHosts: Anshuman Pandey, Founder, and others from Nimblebox.ai\nWhen? 2 PM to 7 PM, 8th July, 2023\nWhere? Bira Taproom, Koramangala, Bengaluru\nHow?: https://lu.ma/blr\n\n- Sugnan, on behalf of the Generative AI Community

Message : Thanks. Bunch of exciting things next week as well.

Message : *Event Announcements from https://nirantk.com/community* 

Title: "How to build great OS projects & Dev tools from AI in India"
Hosts: Anshuman Pandey, Founder, and others from Nimblebox.ai
When? 2 PM to 7 PM, 8th July, 2023
Where? Bira Taproom, Koramangala, Bengaluru
How?: https://lu.ma/blr

- Sugnan, on behalf of the Generative AI Community

Message : Since I get about 4 pings on this per week, as a trial:

1. Once a day compilation of all events posted to https://nirantk.com/community and

2. Once a week compilation (weekend) of all new jobs to https://nirantk.com/community as well

cc @91797731xxxx @91876402xxxx @1217904xxxx
Quoted Message : *Event Announcements from https://nirantk.com/community* \n \nTitle: \"How to build great OS projects & Dev tools from AI in India\"\nHosts: Anshuman Pandey, Founder, and others from Nimblebox.ai\nWhen? 2 PM to 7 PM, 8th July, 2023\nWhere? Bira Taproom, Koramangala, Bengaluru\nHow?: https://lu.ma/blr\n\n- Sugnan, on behalf of the Generative AI Community

Message : Every phone should have a GPU. I think that is where the industry is moving towards.
Quoted Message : Is it possible to build AI models for feature phones ?

Message : Every smartphone *today* has more compute and RAM than what the Apollo mission used to send mankind to moon and back
Quoted Message : Every phone should have a GPU. I think that is where the industry is moving towards.

Message : Server compute wins because humans are amazing at finding ways to make money off cheaper compute they control, one can't make money off something run ML on phone GPU ‚Äî only Apple can

Message : Quick question:

For the model *multi-qa-MiniLM-L6-cos-v1* what does the "cos" mean? cosine? But why would a distance function be need here? Or is it something else?
https://huggingface.co/Xenova/multi-qa-MiniLM-L6-cos-v1

This one is the base model but doesn't mention "cos" - https://huggingface.co/Xenova/all-MiniLM-L6-v2

Message : Fully agree. If I was apple I will be thinking how to build a hardware moat out there and optimise for AI bots experience. 

M2 chipset, GPU and incentivising upgrade cycles
Quoted Message : Every phone should have a GPU. I think that is where the industry is moving towards.

Message : Can we tell every algorithm can run on cpu with small models,is that not how industry may move?
Quoted Message : Every phone should have a GPU. I think that is where the industry is moving towards.

Message : Enterprise vs consumer expectations. Consumer with 100s of apps will benefit from mix of local and server compute
Quoted Message : Server compute wins because humans are amazing at finding ways to make money off cheaper compute they control, one can't make money off something run ML on phone GPU ‚Äî only Apple can

Message : I'm very bullish on apple hardware. I used to be a long time linux user, but started using a mac recently and I'm amazed with the apple doc for its hardware.
Quoted Message : Server compute wins because humans are amazing at finding ways to make money off cheaper compute they control, one can't make money off something run ML on phone GPU ‚Äî only Apple can

Message : I might be wrong here, but the convention is to mention 'cos' because they've optimised the embedding to work well with cosine similarity
Quoted Message : Quick question:\n\nFor the model *multi-qa-MiniLM-L6-cos-v1* what does the \"cos\" mean? cosine? But why would a distance function be need here? Or is it something else?\nhttps://huggingface.co/Xenova/multi-qa-MiniLM-L6-cos-v1\n\nThis one is the base model but doesn't mention \"cos\" - https://huggingface.co/Xenova/all-MiniLM-L6-v2

Message : Consumer expectations ‚Äî monetised via ads running on server farms the size of some European countries
Quoted Message : Enterprise vs consumer expectations. Consumer with 100s of apps will benefit from mix of local and server compute

Message : Still can‚Äôt run slack
Quoted Message : Every smartphone *today* has more compute and RAM than what the Apollo mission used to send mankind to moon and back

Message : Haha Vision pro ads by then ü§™
Quoted Message : Consumer expectations ‚Äî monetised via ads running on server farms the size of some European countries

Message : Yes something like that, they gave different naming conventions for embeddings trained in dot product, normalized and non normalized embeddings
Quoted Message : I might be wrong here, but the convention is to mention 'cos' because they've optimised the embedding to work well with cosine similarity

Message : Slack and chrome are different species
Quoted Message : Still can‚Äôt run slack

Message : Which is exactly my point ‚Äî app devs get lazier, and consumers expect more. We all crib about Slack and Teams ‚Äî but no one is using email groups at their workplace which'd require you to think for more than 20s at a time
Quoted Message : Still can‚Äôt run slack

Message : CoreML ftw
Quoted Message : Fully agree. If I was apple I will be thinking how to build a hardware moat out there and optimise for AI bots experience. \n\nM2 chipset, GPU and incentivising upgrade cycles

Message : Apple hardware has some good APIs (so am told) for a local application. Maybe not an LLM, but everything else - create embeddings, vector search, langchain like.

Look at this upcoming work where the dev has built everything in Swift. Only using OpenAI for embeddings and generative work
https://twitter.com/vatsal_manot/status/1674317412836184064

Message : I can see some of the mixed image/video editing moving to edge compute.
Quoted Message : Server compute wins because humans are amazing at finding ways to make money off cheaper compute they control, one can't make money off something run ML on phone GPU ‚Äî only Apple can

Message : ‚ÄéPratyush Choudhury added ~‚ÄØJaswanth

Message : This is also because of emergence of cluttered frameworks and no punishment for RAM hogging. We want shinier, animating, 3D things and not enough function.
Quoted Message : Slack and chrome are different species

Message : There's one of my personal bear scenario for Nvidia. 

If we get a pytorch framework to utilise Apple metal with similar efficiency as CUDA on nvidia GPUs, a lot of speculative valuation is just going to collapse.

But building an alternative to CUDA for Apple metal is a difficult task and very few people are focusing on it. Modular Mojo claims they can free us from platform dependency but it's a very difficult task.
Quoted Message : I'm very bullish on apple hardware. I used to be a long time linux user, but started using a mac recently and I'm amazed with the apple doc for its hardware.

Message : Yes, we need a lot more knowledge in the apple silicon space. Geohot started with M1 NPU right? I think tinygrad has shifted focus to something else

Message : But I think there is slow progress in bringing things native to apple silicon. Have seen a few tweets this week.

Message : Pedro Cuenca works on a exporters and coremltools library to export any HF transformer model to CoreML.

Exporter library - https://github.com/huggingface/exporters

Coremltools - https://coremltools.readme.io/docs

Their aim is to make all HF transformer supported models and weights reusable with CoreML. ‚Äé<This message was edited>

Message : They already support many models and architectures. It's better to check native metal support for older models or educational stuff than run something torch.device('cpu') on metal.

Message : Chrome is just like algae allowed to grow unchecked on the RAM. needs to be purged every now and then
Quoted Message : This is also because of emergence of cluttered frameworks and no punishment for RAM hogging. We want shinier, animating, 3D things and not enough function.

Message : Anyone worked on whisper recently. For some reason my logic for writing the the segments to a vtt file is failing from a few months back. Seems they've changed the logic. So any repo doing it recently would help.

Message : A week ago Mistral created buzz for raising 105M on the back of a rare team coming together to create an OpenAI competitor from Europe. I just got the chance to read the memo, and it seems that while they say they will take a more open approach to model development, their actual strategy seems to be do everything?

1) create open source models and developer ecosystem around it
2) create (both generalist and specialized) closed source ones for paid access by companies, closed models also available through APIs
3) create (closed) specialised models by retraining on data for legal, finance etc and make this available to clients on-demand
4) co-build integrated solutions with large clients (like Stability), co-build GenAI products with small partners
5) create own consumer facing interfaces like ChatGPT
6) create LLMs but also smaller models that can be deployed on edge/ devices + make models with retrieval-augmentation

My first thought/question on reading the memo --*what they seem to be saying is that they will do everything (and see what sticks) and the open source angle may be a bit of counter-positioning/lip service narrative*.

Second -- *the behemoth LLM players of the future, by design, will need to play multi-product, multi-channel, multi-business model game to justify and recover investments (and hedge bets* at this time when the sector nascent and the winning recipe is debatable).

Thoughts?

Message : Anyone tried running privateGPT locally for QA , i have tried it in my CPU as well in colab gpy it's taking more than 40+mins for single prompt, i have used context from single document with 2 page pdf. How we can reduce this inference time ??

Message : You might want to start by not using privateGPT, it was mostly marketing to begin with
Quoted Message : Anyone tried running privateGPT locally for QA , i have tried it in my CPU as well in colab gpy it's taking more than 40+mins for single prompt, i have used context from single document with 2 page pdf. How we can reduce this inference time ??

Message : I see ,any other options i means some private documents

Message : Broad Guidelines for private documents: 

1. Use instruct or chat models when you can, instead of the base e.g. Falcon-7B Instruct
2. Use the fastest embedding possible - Mini-LM-v2 can go a long way
3. Keep your chunks as small as possible, you're working with 1/20th the tokens/second of GPT3.5-Turbo in most cases ‚Äé<This message was edited>
Quoted Message : I see ,any other options i means some private documents

Message : 3.1 Spend time figuring out how to to split text right :)
Quoted Message : Broad Guidelines for private documents: \n\n1. Use instruct or chat models when you can, instead of the base e.g. Falcon-7B Instruct\n2. Use the fastest embedding possible - Mini-LM-v2 can go a long way\n3. Keep your chunks as small as possible, you're working with 1/20th the tokens/second of GPT3.5-Turbo in most cases

Message : I shall try this thank you üôèüèª


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : They already support many models and architectures. It's better to check native metal support for older models or educational stuff than run something torch.device('cpu') on metal.

Message : Chrome is just like algae allowed to grow unchecked on the RAM. needs to be purged every now and then
Quoted Message : This is also because of emergence of cluttered frameworks and no punishment for RAM hogging. We want shinier, animating, 3D things and not enough function.

Message : Anyone worked on whisper recently. For some reason my logic for writing the the segments to a vtt file is failing from a few months back. Seems they've changed the logic. So any repo doing it recently would help.

Message : A week ago Mistral created buzz for raising 105M on the back of a rare team coming together to create an OpenAI competitor from Europe. I just got the chance to read the memo, and it seems that while they say they will take a more open approach to model development, their actual strategy seems to be do everything?

1) create open source models and developer ecosystem around it
2) create (both generalist and specialized) closed source ones for paid access by companies, closed models also available through APIs
3) create (closed) specialised models by retraining on data for legal, finance etc and make this available to clients on-demand
4) co-build integrated solutions with large clients (like Stability), co-build GenAI products with small partners
5) create own consumer facing interfaces like ChatGPT
6) create LLMs but also smaller models that can be deployed on edge/ devices + make models with retrieval-augmentation

My first thought/question on reading the memo --*what they seem to be saying is that they will do everything (and see what sticks) and the open source angle may be a bit of counter-positioning/lip service narrative*.

Second -- *the behemoth LLM players of the future, by design, will need to play multi-product, multi-channel, multi-business model game to justify and recover investments (and hedge bets* at this time when the sector nascent and the winning recipe is debatable).

Thoughts?

Message : Anyone tried running privateGPT locally for QA , i have tried it in my CPU as well in colab gpy it's taking more than 40+mins for single prompt, i have used context from single document with 2 page pdf. How we can reduce this inference time ??

Message : You might want to start by not using privateGPT, it was mostly marketing to begin with
Quoted Message : Anyone tried running privateGPT locally for QA , i have tried it in my CPU as well in colab gpy it's taking more than 40+mins for single prompt, i have used context from single document with 2 page pdf. How we can reduce this inference time ??

Message : I see ,any other options i means some private documents

Message : Broad Guidelines for private documents: 

1. Use instruct or chat models when you can, instead of the base e.g. Falcon-7B Instruct
2. Use the fastest embedding possible - Mini-LM-v2 can go a long way
3. Keep your chunks as small as possible, you're working with 1/20th the tokens/second of GPT3.5-Turbo in most cases ‚Äé<This message was edited>
Quoted Message : I see ,any other options i means some private documents

Message : 3.1 Spend time figuring out how to to split text right :)
Quoted Message : Broad Guidelines for private documents: \n\n1. Use instruct or chat models when you can, instead of the base e.g. Falcon-7B Instruct\n2. Use the fastest embedding possible - Mini-LM-v2 can go a long way\n3. Keep your chunks as small as possible, you're working with 1/20th the tokens/second of GPT3.5-Turbo in most cases

Message : I shall try this thank you üôèüèª

Message : Actually I could do some experiments on data i have, usually for the information i look for out of 10, 7 are  either in first 500 words or else last 20/ words, so I am just getting that chunks for now
Quoted Message : 3.1 Spend time figuring out how to to split text right :)

Message : This is a nice repo that uses llama.cpp and whisper.cpp to have a conversational LLM hosted on PC, where you can use mostly any supposed models. https://github.com/yacineMTB/talk

Message : Seems this one needs GPU

Message : I can try with colab hopefully

Message : @91773788xxxx  penalty to not participate might decrease the signal to noise ratio of this group, thoughts?
Quoted Message : Weekend reminder, this is the set of *rules* we try our best to enforce for everyone in this WhatsApp group:\nhttps://nirantk.com/community \n\nAt this moment, we also remove folks who're not able to contribute in any 60 day period because WhatsApp caps the group to 1K members

Message : 3 especially if you're using langchain or any prompting libraries. Those things keep adding up to the tokens unchecked in the name of enhancing prompts üôà
Quoted Message : Broad Guidelines for private documents: \n\n1. Use instruct or chat models when you can, instead of the base e.g. Falcon-7B Instruct\n2. Use the fastest embedding possible - Mini-LM-v2 can go a long way\n3. Keep your chunks as small as possible, you're working with 1/20th the tokens/second of GPT3.5-Turbo in most cases

Message : nan

Message : was added to chat

Message : I can't list everything here but there's a whole menagerie of options that solve this problem. The easiest app to try in a few minutes worth of testing is gpt4all GUI. For practical purposes, it's easy to setup, fast to load and relatively up-to-date. privateGPT code is just a single script and extremely easy to read through but you may not want to use langchain dependencies that slow everything down a lot.
Many options are there but it's so edge case that you'll have to get your feet wet and decide where you want to take a dip.
Quoted Message : Seems this one needs GPU

Message : https://open.substack.com/pub/luttig/p/hallucinations-in-ai?utm_campaign=post&utm_medium=web

In the tech-pocalypse desert of 2023, only the AI oasis can save us. ‚Äé<This message was edited>

Message : privateGPT i think uses gpt4all   ,i think i need to check gpt4all and falcon 7b both
Quoted Message : I can't list everything here but there's a whole menagerie of options that solve this problem. The easiest app to try in a few minutes worth of testing is gpt4all GUI. For practical purposes, it's easy to setup, fast to load and relatively up-to-date. privateGPT code is just a single script and extremely easy to read through but you may not want to use langchain dependencies that slow everything down a lot.\nMany options are there but it's so edge case that you'll have to get your feet wet and decide where you want to take a dip.

Message : gpt4all GUI added Falcon 7b GGML support last week itself. You may want to check if it suits you. ‚Äé<This message was edited>

Message : Very noob question - a bunch of us are planning an open source model deployment and fine tuning hands-on workshop. For this we are looking for some GPU access. Any company we can tie up with for access & credits around same ?

Message : @91981126xxxx may be able to help?

Message : Thx for pointing out. Will DM and connect once.
Quoted Message : @9198xxxxxxxx may be able to help?

Message : cc

Microsoft Azure's Ankita: @91882678xxxx
AWS' Shubham: @91966057xxxx
Zainab @91994547xxxx from Hasgeek can make introductions to E2E Networks (NSE:E2E)

You will want a crisper pitch/positioning for why would someone want to sponsor credits for a workshop specifically
Quoted Message : Very noob question - a bunch of us are planning an open source model deployment and fine tuning hands-on workshop. For this we are looking for some GPU access. Any company we can tie up with for access & credits around same ?

Message : Thx for the pointers. Will follow on these.
Quoted Message : cc\n\nMicrosoft Azure's Ankita: @9188xxxxxxxx \nAWS' Shubham: @9196xxxxxxxx \nZainab @9199xxxxxxxx from Hasgeek can make introductions to E2E Networks (NSE:E2E) \n\nYou will want a crisper pitch/positioning for why would someone want to sponsor credits for a workshop specifically

Message : https://arxiv.org/abs/2306.02858

Message : Video-to-text model that better captures Visual and Audio components.

Message : Nice
Quoted Message : Video-to-text model that better captures Visual and Audio components.

Message : Demo available?

Message : https://github.com/DAMO-NLP-SG/Video-LLaMA

Message : https://openai.com/blog/insights-from-global-conversations

Message : This is such a word salad, I believe GPT3.5 was used instead of GPT4 üòÜ
Quoted Message : https://openai.com/blog/insights-from-global-conversations

Message : ‚Äé<attached: 00011268-PHOTO-2023-07-01-23-28-48.jpg>

Message : ‚Äé<attached: 00011269-PHOTO-2023-07-01-23-28-49.jpg>

Message : ‚Äé<attached: 00011270-PHOTO-2023-07-01-23-28-52.jpg>

Message : ‚Äé<attached: 00011271-PHOTO-2023-07-01-23-28-53.jpg>

Message : ‚Äé<attached: 00011272-PHOTO-2023-07-01-23-28-54.jpg>

Message : ‚Äé<attached: 00011273-PHOTO-2023-07-01-23-28-55.jpg>

Message : Playing with qr codes and controlnet - very fun!

Message : they look good
hey wanted to know if there is a way to automate this process of generating QR code art
is there anyway to like export the configuration we used automatic 1111 in control net to code so that it can be automated
Quoted Message : Playing with qr codes and controlnet - very fun!

Message : I had done the same thing, and posted on the company's channel. 

It's crazy and fun
Quoted Message : Playing with qr codes and controlnet - very fun!

Message : ‚Äé<attached: 00011277-PHOTO-2023-07-01-23-36-41.jpg>

Message : A1111 or diffusers?

Message : A curious question folks:

What are some use cases for beautified QR codes? I understand the aesthetic improvements but doesn‚Äôt this result in loss of recognisability by wider audience as QR?

I‚Äôm missing context here as I see people celebrating this in multiple forums. Hence curious to understand the reasons.

Message : ‚Äé<attached: 00011280-PHOTO-2023-07-02-00-34-59.jpg>

Message : https://huggingface.co/openchat/openchat

Message : Though, I'm skeptical on this. 
Need to try it out.

Message : Tried this. Somehow the QR is not read on certain device cameras.
Quoted Message : Playing with qr codes and controlnet - very fun!


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Playing with qr codes and controlnet - very fun!

Message : they look good
hey wanted to know if there is a way to automate this process of generating QR code art
is there anyway to like export the configuration we used automatic 1111 in control net to code so that it can be automated
Quoted Message : Playing with qr codes and controlnet - very fun!

Message : I had done the same thing, and posted on the company's channel. 

It's crazy and fun
Quoted Message : Playing with qr codes and controlnet - very fun!

Message : ‚Äé<attached: 00011277-PHOTO-2023-07-01-23-36-41.jpg>

Message : A1111 or diffusers?

Message : A curious question folks:

What are some use cases for beautified QR codes? I understand the aesthetic improvements but doesn‚Äôt this result in loss of recognisability by wider audience as QR?

I‚Äôm missing context here as I see people celebrating this in multiple forums. Hence curious to understand the reasons.

Message : ‚Äé<attached: 00011280-PHOTO-2023-07-02-00-34-59.jpg>

Message : https://huggingface.co/openchat/openchat

Message : Though, I'm skeptical on this. 
Need to try it out.

Message : Tried this. Somehow the QR is not read on certain device cameras.
Quoted Message : Playing with qr codes and controlnet - very fun!

Message : Fun question: what's ChatGPT? 

I assume most people know that it's not a fixed model but an evolving checkpoint and sampling mechanism.

Message : True. chatGPT is no real reference, all you've is the latest model and no reference of the older versions.
Quoted Message : Fun question: what's ChatGPT? \n\nI assume most people know that it's not a fixed model but an evolving checkpoint and sampling mechanism.

Message : Noob question, and maybe asked a 1000 times- openai wrappers have no moat, but perhaps a chance to validate the business use case and then build the tech. Then do we expect everyone to fine tune these big models eventually to get an edge over the competition?

Message : That said, I am yet to come across tools to facilitate fine tuning.

Message : Can anyone help me get some clarity on this? And thoughts.

Message : Eventually these wrappers will be inducted into big players who has the distribution.
Quoted Message : Noob question, and maybe asked a 1000 times- openai wrappers have no moat, but perhaps a chance to validate the business use case and then build the tech. Then do we expect everyone to fine tune these big models eventually to get an edge over the competition?

Message : Big players - such as?
Quoted Message : Eventually these wrappers will be inducted into big players who has the distribution.

Message : I was exploring one DataBricks blogpost where they have mentioned step by step using huggingface on how to finetune a BERT base model. I ran the notebook untill I ran out of Google Collab RAMüòÖ
Quoted Message : That said, I am yet to come across tools to facilitate fine tuning.

Message : for finetuning llms, wizardLM is SoTA currently, but didn't really find anything that gave me those capabilities out of the box
Quoted Message : I was exploring one DataBricks blogpost where they have mentioned step by step using huggingface on how to finetune a BERT base model. I ran the notebook untill I ran out of Google Collab RAMüòÖ

Message : Adobe buying StableD or MidJourney to augment their tools that is being used by millions
Quoted Message : Big players - such as?

Message : It's glue-tech mostly.
Quoted Message : for finetuning llms, wizardLM is SoTA currently, but didn't really find anything that gave me those capabilities out of the box

Message : Got it. Thanks for your thoughts @91978302xxxx üëÄ

Message : nan

Message : Imagine how good your RLHF would get, getting user feedback (thumbs up , thumbs down, descriptive feedback)  from millions of users
Quoted Message : https://openai.com/blog/insights-from-global-conversations

Message : You're right. But you can build your moat around service quality, UX, security, etc.

And even if it isn't a moat, it can be a sizeable dhandha

This question was asked of SaaS, of mobile apps, as well. Typically a venture question, who require outlier outcomes.

Most businesses don't need that. You can build a respectable 10M ARR business just as a wrapper, with nice bells and whistles, as long as it's solving a key need
Quoted Message : Noob question, and maybe asked a 1000 times- openai wrappers have no moat, but perhaps a chance to validate the business use case and then build the tech. Then do we expect everyone to fine tune these big models eventually to get an edge over the competition?

Message : In the geohot podcast they mention 16 inferences. I went through  this paper but still couldn't connect the 16 inferences part. Any insights on how that is done?
Quoted Message : I'm not sure if this is what you're exactly looking for, but this MoE paper has an approach that is allegedly used by GPT4. https://arxiv.org/abs/2101.03961

Message : 100,000 pip installs in a day for LangchainAI! 

For reference: The official openai library did 300,000 installs on that day

Message : It's like it is like 2005 and no one is able to appreciate the power of the iPhone or app stores and apps
Quoted Message : \"The thing nobody talks about is that in 10 years we'll have a million bipedal robots and in 25 years we'll have a billion. You‚Äôll buy yours for $10k and it will be as important to your life as your smartphone is now\" - Vinod Khosla \n\nhttps://twitter.com/vkhosla/status/1674572048339984384?t=RS1KvTDxyHUSqJW1XUs4OA&s=19\n\nA million in 10 yrs!

Message : is this where you'd getting the data? https://pepy.tech/
Quoted Message : 100,000 pip installs in a day for LangchainAI! \n\nFor reference: The official openai library did 300,000 installs on that day

Message : Pypi stats, but this'd work too
Quoted Message : is this where you'd getting the data? https://pepy.tech/

Message : In scope of your question, a MoE approach has 4 major units - Routing, Inference, Gating, Mixing. Your question seems to be just about mixing the results or need for multiple inferences so I'll keep it succinct.

Routing - choose right expert for task, decide that by affinity score of each expert with task

Inference - Get result for the task from each expert, sometimes a task may contain multiple subtasks which suit multiple experts

Gating - Assigning weight to each inference from expert, identifying which expert opinion weighs more and can be decided by affinity score and Quality of output from expert

Mixing - based on the assigned weights by gating function, combine all inferences in one final output. This again, can be done in multiple ways.

If we assume this leak about GPT4 architecture is true, we can assume there are 16 "experts" and thus 16 inferences. There's a master model with the biggest parameter size and GPT3 like experts that provide inference results which are then combined together to produce the final answer.

I am not saying that's how GPT4 truly is, but how it would be if the leak has any merit.
Quoted Message : In the geohot podcast they mention 16 inferences. I went through  this paper but still couldn't connect the 16 inferences part. Any insights on how that is done?

Message : God bless you for typing this out üôèüèΩ
Quoted Message : In scope of your question, a MoE approach has 4 major units - Routing, Inference, Gating, Mixing. Your question seems to be just about mixing the results or need for multiple inferences so I'll keep it succinct.\n\nRouting - choose right expert for task, decide that by affinity score of each expert with task\n\nInference - Get result for the task from each expert, sometimes a task may contain multiple subtasks which suit multiple experts\n\nGating - Assigning weight to each inference from expert, identifying which expert opinion weighs more and can be decided by affinity score and Quality of output from expert\n\nMixing - based on the assigned weights by gating function, combine all inferences in one final output. This again, can be done in multiple ways.\n\nIf we assume this leak about GPT4 architecture is true, we can assume there are 16 \"experts\" and thus 16 inferences. There's a master model with the biggest parameter size and GPT3 like experts that provide inference results which are then combined together to produce the final answer.\n\nI am not saying that's how GPT4 truly is, but how it would be if the leak has any merit.

Message : Thanks for the detailed explanation!
Quoted Message : In scope of your question, a MoE approach has 4 major units - Routing, Inference, Gating, Mixing. Your question seems to be just about mixing the results or need for multiple inferences so I'll keep it succinct.\n\nRouting - choose right expert for task, decide that by affinity score of each expert with task\n\nInference - Get result for the task from each expert, sometimes a task may contain multiple subtasks which suit multiple experts\n\nGating - Assigning weight to each inference from expert, identifying which expert opinion weighs more and can be decided by affinity score and Quality of output from expert\n\nMixing - based on the assigned weights by gating function, combine all inferences in one final output. This again, can be done in multiple ways.\n\nIf we assume this leak about GPT4 architecture is true, we can assume there are 16 \"experts\" and thus 16 inferences. There's a master model with the biggest parameter size and GPT3 like experts that provide inference results which are then combined together to produce the final answer.\n\nI am not saying that's how GPT4 truly is, but how it would be if the leak has any merit.

Message : Pepy also adds cross zone data sync up so in order to get correct data use this
https://pypistats.org/
Quoted Message : is this where you'd getting the data? https://pepy.tech/

Message : Interesting paper on the future of sw engineering education/tutoring
https://arxiv.org/abs/2306.17156

https://twitter.com/josepablocam/status/1674862205626376194

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØHeerthi Raja H

Message : üå∂Ô∏è take on vector search being overhyped and not always the best option for LLM apps. 

tl;dr - Colin makes the case that for both limited context window and diverse query forms, traditional search using keyword retrieval can work just as well as vector search. His point is that vector search has been overhyped by VCs and startups looking to cash into the AI hype ü§∑üèΩ‚Äç‚ôÇÔ∏è

Message : https://colinharman.substack.com/p/beware-tunnel-vision-in-ai-retrieval?utm_campaign=post&utm_medium=web

Message : Document splitting is common for vector storage / retrieval, but useful context can be lost. LangChainAI has 3 new "context-aware" text splitters that keep metadata about where each split came from. Works for code (py, js)

https://twitter.com/RLanceMartin/status/1674817117475188737?t=rzekLS3lUedtxwqEUgkdKw&s=19

Message : was added to chat

Message : Anyone who says keyword retrieval alone, or vector search alone is as good as both together ‚Äî is not to be taken seriously. This is not even news. We know since 2018 when GloVe/word2vec were a thing, and BERT vectors were used
Quoted Message : üå∂Ô∏è take on vector search being overhyped and not always the best option for LLM apps. \n\ntl;dr - Colin makes the case that for both limited context window and diverse query forms, traditional search using keyword retrieval can work just as well as vector search. His point is that vector search has been overhyped by VCs and startups looking to cash into the AI hype ü§∑üèΩ‚Äç‚ôÇÔ∏è

Message : On the plus side, I always popularise ideas like these ‚Äî it feeds into FUD, and whether I like it or not, I make a lot of professional premium by removing doubt and absorbing ambiguity/uncertainty.
Quoted Message : https://colinharman.substack.com/p/beware-tunnel-vision-in-ai-retrieval?utm_campaign=post&utm_medium=web

Message : Even BM25 (what Elastic uses) is better than keyword search, and that is known since 1990s

Message : Also, AWS made a Blockchain Platform to transfer VC dollars to their account during crypto bull run, despite knowing it was worthless and scam ‚Äî if VCs and Founders are idiots, that is the ~rational~ profitable way to think about bull runs! ‚Äé<This message was edited>

Message : it's like the Jesus meme - "I am not messiah",

it's going to be a reality check for lot of people realising the importance part of retrieval qa is not the llm but rather the dirty retrieval parsing, splitting and ranking bits

Message : No one is going to realise this, because people are not aiming for a usable QA system ‚Äî they're aiming for a demo-able QA system, and that's a different bar completely.
Quoted Message : it's like the Jesus meme - \"I am not messiah\",\n\nit's going to be a reality check for lot of people realising the importance part of retrieval qa is not the llm but rather the dirty retrieval parsing, splitting and ranking bits

Message : Not naming names, but know a desi startup who've raised quite a few $$$M on the back of Colab Notebook wrapped in Vercel

Message : /endrant

Message : can someone recommend specific literature to go deeper on this for noobs -> "dirty retrieval parsing, splitting and ranking bits"

thanks!
Quoted Message : it's like the Jesus meme - \"I am not messiah\",\n\nit's going to be a reality check for lot of people realising the importance part of retrieval qa is not the llm but rather the dirty retrieval parsing, splitting and ranking bits

Message : https://twitter.com/huggingface/status/1675242955962032129?t=v3AyvKLw9e4gZQlhyVz5kw&s=08

HuggingFace security is a joke. Two times I reported someone uploaded many pirated movie links. Along with the chance of uploading a bad model.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Anyone who says keyword retrieval alone, or vector search alone is as good as both together ‚Äî is not to be taken seriously. This is not even news. We know since 2018 when GloVe/word2vec were a thing, and BERT vectors were used
Quoted Message : üå∂Ô∏è take on vector search being overhyped and not always the best option for LLM apps. \n\ntl;dr - Colin makes the case that for both limited context window and diverse query forms, traditional search using keyword retrieval can work just as well as vector search. His point is that vector search has been overhyped by VCs and startups looking to cash into the AI hype ü§∑üèΩ‚Äç‚ôÇÔ∏è

Message : On the plus side, I always popularise ideas like these ‚Äî it feeds into FUD, and whether I like it or not, I make a lot of professional premium by removing doubt and absorbing ambiguity/uncertainty.
Quoted Message : https://colinharman.substack.com/p/beware-tunnel-vision-in-ai-retrieval?utm_campaign=post&utm_medium=web

Message : Even BM25 (what Elastic uses) is better than keyword search, and that is known since 1990s

Message : Also, AWS made a Blockchain Platform to transfer VC dollars to their account during crypto bull run, despite knowing it was worthless and scam ‚Äî if VCs and Founders are idiots, that is the ~rational~ profitable way to think about bull runs! ‚Äé<This message was edited>

Message : it's like the Jesus meme - "I am not messiah",

it's going to be a reality check for lot of people realising the importance part of retrieval qa is not the llm but rather the dirty retrieval parsing, splitting and ranking bits

Message : No one is going to realise this, because people are not aiming for a usable QA system ‚Äî they're aiming for a demo-able QA system, and that's a different bar completely.
Quoted Message : it's like the Jesus meme - \"I am not messiah\",\n\nit's going to be a reality check for lot of people realising the importance part of retrieval qa is not the llm but rather the dirty retrieval parsing, splitting and ranking bits

Message : Not naming names, but know a desi startup who've raised quite a few $$$M on the back of Colab Notebook wrapped in Vercel

Message : /endrant

Message : can someone recommend specific literature to go deeper on this for noobs -> "dirty retrieval parsing, splitting and ranking bits"

thanks!
Quoted Message : it's like the Jesus meme - \"I am not messiah\",\n\nit's going to be a reality check for lot of people realising the importance part of retrieval qa is not the llm but rather the dirty retrieval parsing, splitting and ranking bits

Message : https://twitter.com/huggingface/status/1675242955962032129?t=v3AyvKLw9e4gZQlhyVz5kw&s=08

HuggingFace security is a joke. Two times I reported someone uploaded many pirated movie links. Along with the chance of uploading a bad model.

Message : https://twitter.com/EMostaque/status/1675236885197729792?t=9hg8cpf2EgNaZLFwHjUMjg&s=08

Also it is good practice to cache/copy models inhouse instead of pulling always.

Message : doesn't seem like their fault here?
if people are reusing same passwords

except yes they should make 2FA compulsory
Quoted Message : https://twitter.com/huggingface/status/1675242955962032129?t=v3AyvKLw9e4gZQlhyVz5kw&s=08\n\nHuggingFace security is a joke. Two times I reported someone uploaded many pirated movie links. Along with the chance of uploading a bad model.

Message : So many people are dependent on them even enterprises. They should have added 2FA long back. It is very easy to enforce and does not require much infra investment.
Quoted Message : doesn't seem like their fault here?\nif people are reusing same passwords\n\nexcept yes they should make 2FA compulsory

Message : it's more of an experience thing building/improving any search system in production

but for absolute basics you can start with Intro to Information Retrieval by C. Manning et al
Quoted Message : can someone recommend specific literature to go deeper on this for noobs -> \"dirty retrieval parsing, splitting and ranking bits\"\n\nthanks!

Message : Manning book is a bit more classical, less applied/engineering first ‚Äé<This message was edited>
Quoted Message : it's more of an experience thing building/improving any search system in production\n\nbut for absolute basics you can start with Intro to Information Retrieval by C. Manning et al

Message : yeah revision pinning and local bucket caching is becoming very important
Quoted Message : https://twitter.com/EMostaque/status/1675236885197729792?t=9hg8cpf2EgNaZLFwHjUMjg&s=08\n\nAlso it is good practice to cache/copy models inhouse instead of pulling always.

Message : This was popularised by hinton in his 2012 deep learning course. Originally it was like a weighted ensemble of multiple outputs, the weight vector here is generated by another neural net with same input. This whole thing is differentiable end to end, so each expert gets better as well as the weight generator gets better at assigning the expert to an input
Quoted Message : In scope of your question, a MoE approach has 4 major units - Routing, Inference, Gating, Mixing. Your question seems to be just about mixing the results or need for multiple inferences so I'll keep it succinct.\n\nRouting - choose right expert for task, decide that by affinity score of each expert with task\n\nInference - Get result for the task from each expert, sometimes a task may contain multiple subtasks which suit multiple experts\n\nGating - Assigning weight to each inference from expert, identifying which expert opinion weighs more and can be decided by affinity score and Quality of output from expert\n\nMixing - based on the assigned weights by gating function, combine all inferences in one final output. This again, can be done in multiple ways.\n\nIf we assume this leak about GPT4 architecture is true, we can assume there are 16 \"experts\" and thus 16 inferences. There's a master model with the biggest parameter size and GPT3 like experts that provide inference results which are then combined together to produce the final answer.\n\nI am not saying that's how GPT4 truly is, but how it would be if the leak has any merit.

Message : AI powered search by Manning (still in EAP,  but main topics ready to read) is a very well balanced book on classic search and the new semantic search

The book was commissioned preChatGPT time (ie Nov 22), so when i read the EAP didn't cover those APIs, might cover in the final version

Also highly recommended (if your company reimburses) Corise has a online cohort based course on search by Grant, exCTO of Wikimedia/Wikipedia, that covers the search optimization, including vector search, in a very practical, analytical, and non hyped way
Quoted Message : can someone recommend specific literature to go deeper on this for noobs -> \"dirty retrieval parsing, splitting and ranking bits\"\n\nthanks!

Message : + AI powered search book is by veterans of search/experts of elastic and solr, so they know their thing

Message : https://www.sbert.net/examples/applications/retrieve_rerank/README.html
Quoted Message : can someone recommend specific literature to go deeper on this for noobs -> \"dirty retrieval parsing, splitting and ranking bits\"\n\nthanks!

Message : +1. On top of that, these QR codes mostly don't work (with apps like Google lens)
Quoted Message : A curious question folks:\n\nWhat are some use cases for beautified QR codes? I understand the aesthetic improvements but doesn‚Äôt this result in loss of recognisability by wider audience as QR?\n\nI‚Äôm missing context here as I see people celebrating this in multiple forums. Hence curious to understand the reasons.

Message : Seem to work fine on paytm / phonepe
Quoted Message : +1. On top of that, these QR codes mostly don't work (with apps like Google lens)

Message : ‚Äé~‚ÄØKShivendu added ~‚ÄØShaurya

Message : ‚Äé<attached: 00011338-PHOTO-2023-07-02-18-53-29.jpg>

Message : That's the best tweet on rate limit I've seen so far ü§£

Message : üòÇ Bojan generally has something funny  to say on whatever‚Äôs current.

Message : Almost all his tweets go like XGBoost‚Ä¶..
Quoted Message : üòÇ Bojan generally has something funny  to say on whatever‚Äôs current.

Message : Haha yes.
Quoted Message : Almost all his tweets go like XGBoost‚Ä¶..

Message : ‚Äé<attached: 00011343-PHOTO-2023-07-02-20-20-43.jpg>
Quoted Message : That's the best tweet on rate limit I've seen so far ü§£

Message : Is that made up or a real tweet

Message : Either way it was good for kicks

Message : Hello post LLM world.

Message : Friends, please avoid off-topic conversations.  And if someone does so, others should try to react with emojis only. This puts a limit on the number of unread/off-topic messages.

Message : So we are rate limiting the off-topic conversations? üòÖ

Message : ‚Äé<attached: 00011349-VIDEO-2023-07-02-20-46-06.mp4>

Message : And as is tradition, we'll eventually rate limit messages asking to rate limit off topic discussions üòú
Quoted Message : So we are rate limiting the off-topic conversations? üòÖ

Message : Expecting an infinite regress rate limiting discussion going back all the way to the big bang
Quoted Message : And as is tradition, we'll eventually rate limit messages asking to rate limit off topic discussions üòú

Message : PSA: openai.Embedding.create() will sometimes return NaN - 

{
"data": [
{
"embedding": [
NaN
],
"index": 0,
"object": "embedding"
}
],
"model": "text-embedding-ada-002",
"object": "list",
"usage": {
"prompt_tokens": 5,
"total_tokens": 5
}
}

https://community.openai.com/t/text-embedding-ada-002-embeddings-sometime-return-nan/279664

Message : And it's worse than their FOSS counterparts like bloop.ai, which is quite usable

Message : I respect the founders for having such a strong grift/marketing game. I wish I had less ego issues!\n\nI don't mind drawing a 20 LPA salary for 1-2 years and then going to Stanford GSB with a \"funded founder in AI\" tag on my resume

Message : Many apologies, seemed a natural segway but I can see how this can be a runaway digression to nowhere ‚úåÔ∏è
Quoted Message : Friends, please avoid off-topic conversations.  And if someone does so, others should try to react with emojis only. This puts a limit on the number of unread/off-topic messages.

Message : Did anyone try openchat ?

Message : Yeah, and it is not what it claims to be unfortunately.
Quoted Message : Did anyone try openchat ?

Message : It's a good effort of achieving good performance with just 6k dataset but got ruined by false claims of surpassing GPT 3.5 performance.

Message : This is based on llama ?

Message : How is the performance scores compared to Gpt 3.5 and MPT-chat by MosaicML ?
Quoted Message : It's a good effort of achieving good performance with just 6k dataset but got ruined by false claims of surpassing GPT 3.5 performance.

Message : Yeah llama trained with 6k curated dataset - drawing from the learnings of LIMA paper

Message : I see. 
I read about this in the morning. Maybe will try tomorrow on my use cases.
Quoted Message : Yeah llama trained with 6k curated dataset - drawing from the learnings of LIMA paper

Message : They took Vicuna and Alpacaeval and published results from there showing that it surpasses chatGPT in performance
Quoted Message : How is the performance scores compared to Gpt 3.5 and MPT-chat by MosaicML ?

Message : Most people don't understand how many evals are there and what do they actually test. Vicuna eval is mostly - "Style not substance"


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Many apologies, seemed a natural segway but I can see how this can be a runaway digression to nowhere ‚úåÔ∏è
Quoted Message : Friends, please avoid off-topic conversations.  And if someone does so, others should try to react with emojis only. This puts a limit on the number of unread/off-topic messages.

Message : Did anyone try openchat ?

Message : Yeah, and it is not what it claims to be unfortunately.
Quoted Message : Did anyone try openchat ?

Message : It's a good effort of achieving good performance with just 6k dataset but got ruined by false claims of surpassing GPT 3.5 performance.

Message : This is based on llama ?

Message : How is the performance scores compared to Gpt 3.5 and MPT-chat by MosaicML ?
Quoted Message : It's a good effort of achieving good performance with just 6k dataset but got ruined by false claims of surpassing GPT 3.5 performance.

Message : Yeah llama trained with 6k curated dataset - drawing from the learnings of LIMA paper

Message : I see. 
I read about this in the morning. Maybe will try tomorrow on my use cases.
Quoted Message : Yeah llama trained with 6k curated dataset - drawing from the learnings of LIMA paper

Message : They took Vicuna and Alpacaeval and published results from there showing that it surpasses chatGPT in performance
Quoted Message : How is the performance scores compared to Gpt 3.5 and MPT-chat by MosaicML ?

Message : Most people don't understand how many evals are there and what do they actually test. Vicuna eval is mostly - "Style not substance"

Message : OpenAI released their own evalcode. Mosaic their own. Every research releases their own eval system and claim that their architecture outperforms others üòåüåö

Message : Sole fine tuning with GPT4 results in close style transfer and it ranks higher on vicuna. MMLU is a good eval where it scores very low against GPT 3.5 ‚Äé<This message was edited>

Message : Vicuna had less scores on the HF LB, the other day
Quoted Message : They took Vicuna and Alpacaeval and published results from there showing that it surpasses chatGPT in performance

Message : MMLU
Newer term for me.
Will look into this. Thanks
Quoted Message : Sole fine tuning with GPT4 results in close style transfer and it ranks higher on vicuna. MMLU is a good eval where it scores very low against GPT 3.5

Message : This is the best we have so far - https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard

It tests a model across multiple disciplines and tasks.

Message : MMLU is also part of the benchmarks they use.

Message : Yes yes. This is the LB. My company is keeping track of it daily xd
Quoted Message : This is the best we have so far - https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n\nIt tests a model across multiple disciplines and tasks.

Message : Though, it has weird bugs like - Changing the MCQ option style from A. To A) showed a 4-6 point average boost in the score. ‚Äé<This message was edited>

Message : I see. Multi language understanding
Quoted Message : MMLU is also part of the benchmarks they use.

Message : https://www.nfx.com/post/speed-and-ai

Message : Excellent panel discussion between Jonathan Frankle from Mosaic, Amjad and Michele from Replit about training LLMs. 
15:00 - They discuss usefulness of evaluation benchmarks for models particularly wrt long contexts and coding.
21:00 - UL2 - which is mixture of different cost functions didn‚Äôt work that well with their experiments.
33:00 - Comparison of Open source models with chatGPT, where open source models are lagging and call to do weird things.
42:00 - ‚ÄúOpen source datasets are complete trash‚Äù. The PILE, The stack are good; but kinda old. The Pile wikipedia and RedPajama wikipedia are different. Stack javascript is mostly minified javascript.
With H100, we might see changes in shape of architecture. Will see wider networks with maybe less depth.
57:50 ‚ÄúNeural networks pruning is useless.‚Äù It works well on CPUs. Might work well with H100. https://www.youtube.com/watch?v=B-szEQsQ9yI&list=PLto9KpJAqHMT8JWmfh9L6kbr6x1mvXNs6&index=1&pp=iAQB
Quoted Message : Register here for the panel with Chief Scientist of MosaicML, Jonathan Frankle! its a little late for India (230am), but it will be recorded as well. \n\nhttps://lu.ma/g4asrvqy

Message : Knew some stuff and learnt a few things that I never heard about earlierüëç
* Flan UL2 is underwhelming, everyone who tests it seems to agree with that except Yi Tay. I even checked with Fabrice Bellard as he maintains his own textsynth library but results are same.
* Open source datasets are trash? It's the first time I heard that Redpajama dataset quality is bad. I've contributed in building the dataset when LAION first started. I guess there will be some rebuilding of Wikipedia section at least.
* H100's architecture being a deciding factor in how we see the model shapes changing is again an indicator of how deep learning practices and GPU arch move in tandem and are influenced by each other.
* That GGML bit has a lot of potential but I'm yet to find any time to learn how to write up a GGML for a new architecture from scratch. Just running somebody else's quantization scripts to quantize somebody else's models for the time being.
Quoted Message : Excellent panel discussion between Jonathan Frankle from Mosaic, Amjad and Michele from Replit about training LLMs. \n15:00 - They discuss usefulness of evaluation benchmarks for models particularly wrt long contexts and coding.\n21:00 - UL2 - which is mixture of different cost functions didn‚Äôt work that well with their experiments. \n33:00 - Comparison of Open source models with chatGPT, where open source models are lagging and call to do weird things.\n42:00 - ‚ÄúOpen source datasets are complete trash‚Äù. The PILE, The stack are good; but kinda old. The Pile wikipedia and RedPajama wikipedia are different. Stack javascript is mostly minified javascript. \nWith H100, we might see changes in shape of architecture. Will see wider networks with maybe less depth.\n57:50 ‚ÄúNeural networks pruning is useless.‚Äù It works well on CPUs. Might work well with H100. https://www.youtube.com/watch?v=B-szEQsQ9yI&list=PLto9KpJAqHMT8JWmfh9L6kbr6x1mvXNs6&index=1&pp=iAQB

Message : https://twitter.com/blancheminerva/status/1652899628356960256?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Stella bidderman - second author of PILE paper discussing per token quality of PILE vs RP. I think some amount of quality degradation is obvious as RP is much bigger than PILE (6 times) . In which area, did you contribute in building RP ?
Quoted Message : Knew some stuff and learnt a few things that I never heard about earlierüëç\n* Flan UL2 is underwhelming, everyone who tests it seems to agree with that except Yi Tay. I even checked with Fabrice Bellard as he maintains his own textsynth library but results are same.\n* Open source datasets are trash? It's the first time I heard that Redpajama dataset quality is bad. I've contributed in building the dataset when LAION first started. I guess there will be some rebuilding of Wikipedia section at least.\n* H100's architecture being a deciding factor in how we see the model shapes changing is again an indicator of how deep learning practices and GPU arch move in tandem and are influenced by each other.\n* That GGML bit has a lot of potential but I'm yet to find any time to learn how to write up a GGML for a new architecture from scratch. Just running somebody else's quantization scripts to quantize somebody else's models for the time being.

Message : ‚Äé<attached: 00011376-PHOTO-2023-07-03-10-01-05.jpg>

Message : Number of Issues created and PRs gettting merged is a good metric as well.

The issue with downloads is even if very few popular projects use any of the above frameworks. It creates a bias

Message : Qdrant needs to up their marketing spending it seems.

Message : folks, if I am building RAG (vector search/sematic search) internally at my workplace using a vector db + LLM, is there a benchmark data set i can use to evaluate my implementation ? 
i know that my own data will perform uniquely, but i want to atleast get to a good baseline before going deep into my own data.

Message : cc @91944622xxxx Jithin from Ragas would you know of something?
Quoted Message : folks, if I am building RAG (vector search/sematic search) internally at my workplace using a vector db + LLM, is there a benchmark data set i can use to evaluate my implementation ? \ni know that my own data will perform uniquely, but i want to atleast get to a good baseline before going deep into my own data.

Message : ‚Äé<attached: 00011381-PHOTO-2023-07-03-10-52-03.jpg>

Message : Would you link to add a link to source?

Message : Similar Collection by HuggingFace :

https://huggingface.co/docs/hub/models-libraries

Message : I am facing message delay in whatsapp
Quoted Message : Would you link to add a link to source?

Message : I'd recommend benchmarking the retrieval and generation steps separately to better understand the performance of each component. 

BEIR is a good benchmark for retrieval - https://github.com/beir-cellar/beir. it contains multiple datasets, you can choose ones that are related to your domain (I've seen MSMARCO is the most widely used)
Quoted Message : folks, if I am building RAG (vector search/sematic search) internally at my workplace using a vector db + LLM, is there a benchmark data set i can use to evaluate my implementation ? \ni know that my own data will perform uniquely, but i want to atleast get to a good baseline before going deep into my own data.

Message : Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you‚Äôre interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas
Quoted Message : folks, if I am building RAG (vector search/sematic search) internally at my workplace using a vector db + LLM, is there a benchmark data set i can use to evaluate my implementation ? \ni know that my own data will perform uniquely, but i want to atleast get to a good baseline before going deep into my own data.

Message : Also this article here covers the metrics used for evaluating retrievers https://amitness.com/2020/08/information-retrieval-evaluation/

Message : Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you‚Äôre interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas

Message : Also this article here covers the metrics used for evaluating retrievers https://amitness.com/2020/08/information-retrieval-evaluation/

Message : Amit @3569991xxxx we were talking about a blog from your blogging era:
https://amitness.com/2020/08/information-retrieval-evaluation/

Thought you'd love to know that we still recall and refer them fondly
Quoted Message : Also this article here covers the metrics used for evaluating retrievers https://amitness.com/2020/08/information-retrieval-evaluation/

Message : hi. looking at the dataset for eval for now. 
also - we dont build on to of python (deployed in banks, etc), so a hosted service for logging is the only thing we can use. but ragas looks good !
Quoted Message : Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you‚Äôre interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas

Message : > Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case.

what about TREC-20, etc ? i was reading the HYDE paper and seems that they did benchmarking on TREC
Quoted Message : Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you‚Äôre interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas

Message : ‚Äé<attached: 00011392-PHOTO-2023-07-03-11-09-56.jpg>

Message : BEIR seems to be the framework for benchmarking. there is a bunch of different datasets used by beir. any idea which one u would recommend for benchmarking if ur building a RAG ?

https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/
Quoted Message : I'd recommend benchmarking the retrieval and generation steps separately to better understand the performance of each component. \n\nBEIR is a good benchmark for retrieval - https://github.com/beir-cellar/beir. it contains multiple datasets, you can choose ones that are related to your domain (I've seen MSMARCO is the most widely used)

Message : internally for Ragas we started off with wikiqa and hotpotQA but the catch with any Wikipedia dataset is that the models already know quite a bit. So u'll have to run a baseline without retrieval, with retrieval and with ur improvements to get an idea

FIQA is financial data, there is one for medical too, I'd recommend those

Message : ‚Äé<attached: 00011395-PHOTO-2023-07-03-11-31-46.jpg>

Message : hey that is very useful feedback. did it work better with FIQA for you - im wondering how fiqa benchmark executes ? do u first have to load a retrieval dataset and then ask questions on it ?
Quoted Message : internally for Ragas we started off with wikiqa and hotpotQA but the catch with any Wikipedia dataset is that the models already know quite a bit. So u'll have to run a baseline without retrieval, with retrieval and with ur improvements to get an idea\n\nFIQA is financial data, there is one for medical too, I'd recommend those

Message : This benchmarking was also discussed during the GenAI meetup which happened in BLR 2 weeks back.
Quoted Message : Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you‚Äôre interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas

Message : we are in delhi

Message : ü•≤

Message : is there any list of startups in generative ai valuechain? from infra to api to customer facing ones

Message : Emad Mostaque makes me happy whenever he goes viral: "there won't be any programmers" in 5 years
https://twitter.com/EMostaque/status/1675556121271054339

At last, we'll have software engineers doing engineering instead of programming!


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00011392-PHOTO-2023-07-03-11-09-56.jpg>

Message : BEIR seems to be the framework for benchmarking. there is a bunch of different datasets used by beir. any idea which one u would recommend for benchmarking if ur building a RAG ?

https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/
Quoted Message : I'd recommend benchmarking the retrieval and generation steps separately to better understand the performance of each component. \n\nBEIR is a good benchmark for retrieval - https://github.com/beir-cellar/beir. it contains multiple datasets, you can choose ones that are related to your domain (I've seen MSMARCO is the most widely used)

Message : internally for Ragas we started off with wikiqa and hotpotQA but the catch with any Wikipedia dataset is that the models already know quite a bit. So u'll have to run a baseline without retrieval, with retrieval and with ur improvements to get an idea

FIQA is financial data, there is one for medical too, I'd recommend those

Message : ‚Äé<attached: 00011395-PHOTO-2023-07-03-11-31-46.jpg>

Message : hey that is very useful feedback. did it work better with FIQA for you - im wondering how fiqa benchmark executes ? do u first have to load a retrieval dataset and then ask questions on it ?
Quoted Message : internally for Ragas we started off with wikiqa and hotpotQA but the catch with any Wikipedia dataset is that the models already know quite a bit. So u'll have to run a baseline without retrieval, with retrieval and with ur improvements to get an idea\n\nFIQA is financial data, there is one for medical too, I'd recommend those

Message : This benchmarking was also discussed during the GenAI meetup which happened in BLR 2 weeks back.
Quoted Message : Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you‚Äôre interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas

Message : we are in delhi

Message : ü•≤

Message : is there any list of startups in generative ai valuechain? from infra to api to customer facing ones

Message : Emad Mostaque makes me happy whenever he goes viral: "there won't be any programmers" in 5 years
https://twitter.com/EMostaque/status/1675556121271054339

At last, we'll have software engineers doing engineering instead of programming!

Message : FiQA didn't have retrieved docs, so we used the answers (they have multiple answers for the same question) as the document. 

FiQA was collected from stackoveflow for finance
Quoted Message : hey that is very useful feedback. did it work better with FIQA for you - im wondering how fiqa benchmark executes ? do u first have to load a retrieval dataset and then ask questions on it ?

Message : Watching the exact same video right now - his discussion with Peter Diamandis. Diamandis was involved in public space flight when that was a pipe dream - and he finds Mostaque and Stability among the most interesting companies at the moment. There's another discussion on the philosophy group about this, in the context of code gen tools.
Quoted Message : Emad Mostaque makes me happy whenever he goes viral: \"there won't be any programmers\" in 5 years\nhttps://twitter.com/EMostaque/status/1675556121271054339\n\nAt last, we'll have software engineers doing engineering instead of programming!

Message : We stopped having personal portraits drawn to capture our image with the invention of camera. Painters went away and photographers came in. Then came photography on personal devices and professional photography maintained an edge by having costlier and advanced equipments. Now we can take a shot of the moon and still some humans maintain an edge by learning how to use different editing/effects creatively to compose a better photo or videographic experience.

Technology often lowers entry floor and humans move to higher levels of abstraction.
Quoted Message : Emad Mostaque makes me happy whenever he goes viral: \"there won't be any programmers\" in 5 years\nhttps://twitter.com/EMostaque/status/1675556121271054339\n\nAt last, we'll have software engineers doing engineering instead of programming!

Message : My fav bit on how ai will impact programming is this talk and piece by Matt Welsh
Quoted Message : Emad Mostaque makes me happy whenever he goes viral: \"there won't be any programmers\" in 5 years\nhttps://twitter.com/EMostaque/status/1675556121271054339\n\nAt last, we'll have software engineers doing engineering instead of programming!

Message : Fantastic talk on how ai will impact programming as we know it :
https://www.youtube.com/watch?v=qmJ4xLC1ObU

tldr video:
https://vimeo.com/775827887

Matt Welsh (mdw@mdw.la) is the CEO and co-founder of Fixie.ai, a recently founded startup developing AI capabilities to support software development teams. He was previously a professor of computer science at Harvard University, a director of engineering at Google, an engineering lead at Apple, and the SVP of Engineering at OctoML. He received his Ph.D. from UC Berkeley back in the days when AI was still not playing chess very well.

His piece in CACM:
https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext

https://news.ycombinator.com/item?id=34087000
"The shift in focus from programs to models should be obvious to anyone who has read any modern machine learning papers. These papers barely mention the code or systems underlying their innovations; the building blocks of AI systems are much higher-level abstractions like attention layers, tokenizers, and datasets. A time traveler from even 20 years ago would have a hard time making sense of the three sentences in the (75-page!) GPT-3 paper3 describing the actual software built for the model: "We use the same model and architecture as GPT-2, including the modified initialization, pre-normalization, and reversible tokenization described therein, with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer. To study the dependence of ML performance on model size, we train eight different sizes of model, ranging over three orders of magnitude from 125 million parameters to 175 billion parameters, with the last being the model we call GPT-3. Previous work suggests that with enough training data, scaling of validation loss should be approximately a smooth power law as a function of size; training models of many different sizes allows us to test this hypothesis both for validation loss and for downstream language tasks."

This shift in the underlying definition of computing presents a huge opportunity, and plenty of huge risks. Yet I think it is time to accept that this is a very likely future, and evolve our thinking accordingly, rather than just sit here waiting for the meteor to hit."
Quoted Message : My fav bit on how ai will impact programming is this talk and piece by Matt Welsh

Message : Any idea how to enable OpenAI code interpreter?
I have browser access but not sure where to enable or apply for code interpreter access.

Message : Anyone knows how they doing? Didn't really hear good feedback on them post their seedfund.
Quoted Message : Fantastic talk on how ai will impact programming as we know it :\nhttps://www.youtube.com/watch?v=qmJ4xLC1ObU\n\ntldr video:\nhttps://vimeo.com/775827887\n\nMatt Welsh (mdw@mdw.la) is the CEO and co-founder of Fixie.ai, a recently founded startup developing AI capabilities to support software development teams. He was previously a professor of computer science at Harvard University, a director of engineering at Google, an engineering lead at Apple, and the SVP of Engineering at OctoML. He received his Ph.D. from UC Berkeley back in the days when AI was still not playing chess very well.\n\nHis piece in CACM:\nhttps://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext\n\nhttps://news.ycombinator.com/item?id=34087000\n\"The shift in focus from programs to models should be obvious to anyone who has read any modern machine learning papers. These papers barely mention the code or systems underlying their innovations; the building blocks of AI systems are much higher-level abstractions like attention layers, tokenizers, and datasets. A time traveler from even 20 years ago would have a hard time making sense of the three sentences in the (75-page!) GPT-3 paper3 describing the actual software built for the model: \"We use the same model and architecture as GPT-2, including the modified initialization, pre-normalization, and reversible tokenization described therein, with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer. To study the dependence of ML performance on model size, we train eight different sizes of model, ranging over three orders of magnitude from 125 million parameters to 175 billion parameters, with the last being the model we call GPT-3. Previous work suggests that with enough training data, scaling of validation loss should be approximately a smooth power law as a function of size; training models of many different sizes allows us to test this hypothesis both for validation loss and for downstream language tasks.\"\n\nThis shift in the underlying definition of computing presents a huge opportunity, and plenty of huge risks. Yet I think it is time to accept that this is a very likely future, and evolve our thinking accordingly, rather than just sit here waiting for the meteor to hit.\"

Message : Terrible execution/implementation, but the idea still has alpha left in it
Quoted Message : Anyone knows how they doing? Didn't really hear good feedback on them post their seedfund.

Message : Correct. Heard a rumour that one of their investors asked them to return their money lol

Message : What have they executed poorly on? I haven‚Äôt stayed super close to them for a while
Quoted Message : Terrible execution/implementation, but the idea still has alpha left in it

Message : Damn
Quoted Message : Correct. Heard a rumour that one of their investors asked them to return their money lol

Message : Oh yeah you interviewed them.
Quoted Message : What have they executed poorly on? I haven‚Äôt stayed super close to them for a while

Message : I do think the problem they are trying to tackle is actually hard so not throwing shade at them but was surprised at the 16M seed without any product

Message : he wrote a blog about it
https://mdwdotla.medium.com/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b?source=user_profile---------2----------------------------
Quoted Message : I do think the problem they are trying to tackle is actually hard so not throwing shade at them but was surprised at the 16M seed without any product

Message : Would love to read/hear the interview.
Quoted Message : Oh yeah you interviewed them.

Message : https://ntkris.substack.com/p/building-autonomous-agents-with-fixie
Quoted Message : Would love to read/hear the interview.

Message : How much of the lacklustre execution do you think comes from going too wide? Meaning, AFAIK they are helping businesses build any type of agent they want

Message : Lot of it. An above average RPA product with a very narrow niche e.g. processing fees questions in AMCs for Fortune200 banks and brokerages like Robinhood built on top of OpenAI Functions will make more revenue per engineer than this going wide thing.
Quoted Message : How much of the lacklustre execution do you think comes from going too wide? Meaning, AFAIK they are helping businesses build any type of agent they want

Message : Yeah I totally agree. I‚Äôm very surprised by going wide because it goes against every decade old building principle
Quoted Message : Lot of it. An above average RPA product with a very narrow niche e.g. processing fees questions in AMCs for Fortune200 banks and brokerages like Robinhood built on top of OpenAI Functions will make more revenue per engineer than this going wide thing.

Message : Added Context: I was an external, technical evaluator for a variant of this product in 2018, used by one of India's largest AMCs even today to support their door to door+tele calling sales staff of 10K people. Very profitable.

Message : Hey guys
Can anyone suggest a good agency for api testing, load testing and dual functionality who had testing experience with LLMs based models too.

Message : What is dual functionality?

Message : Also, is ask for agencies/services off-topic?
Leave a üëçüèº if you think it is off topic, and leave a ‚úÖ if it's okay to have it here

Message : Context: We've considered job posts as off topic since beginning, because that biases to the space becoming a notice board instead of a space for conversation. The recommended way to make job posts is https://nirantk.com/community

Message : @91797731xxxx
Quoted Message : Hey guys\nCan anyone suggest a good agency for api testing, load testing and dual functionality who had testing experience with LLMs based models too.

Message : A hacker fellowship in SF called HF0

If folks here want to build something similar here in India, let's brainstorm & do it ! #lfg

https://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html

Message : VC folks (& others), feel free to DM me with your Twitter &/ LinkedIn if you are interested in collaborating on this

If you would rather listen than read the NYT piece :
https://open.spotify.com/episode/3IhrfHAdlV6Of7mLUPDw9M?si=05tuU26bRT2SaYPTxt7aiw
Quoted Message : A hacker fellowship in SF called HF0\n\nIf folks here want to build something similar here in India, let's brainstorm & do it ! #lfg\n\nhttps://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html

Message : @91990057xxxx is working on this if I'm correct
Quoted Message : VC folks (& others), feel free to DM me with your Twitter &/ LinkedIn if you are interested in collaborating on this\n\nIf you would rather listen than read the NYT piece :\nhttps://open.spotify.com/episode/3IhrfHAdlV6Of7mLUPDw9M?si=05tuU26bRT2SaYPTxt7aiw

Message : Actually we are working more towards supporting the OSS community.  Either promising new individual contributors or team that are working on existing projects that are helping the community.
Quoted Message : @9199xxxxxxxx is working on this if I'm correct

Message : Happy to help
Quoted Message : A hacker fellowship in SF called HF0\n\nIf folks here want to build something similar here in India, let's brainstorm & do it ! #lfg\n\nhttps://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html

Message : I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India. 
And it's fair, there is very little/no upside for the sponsor doing this.
Quoted Message : A hacker fellowship in SF called HF0\n\nIf folks here want to build something similar here in India, let's brainstorm & do it ! #lfg\n\nhttps://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html

Message : We got to stop copying, we have different problems, constrains and culture. ‚Äé<This message was edited>

Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.
Quoted Message : We got to stop copying, we have different problems, constrains and culture.

Message : Not a Hot take any more.
Quoted Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.

Message : Can you make a huggingface space without uploading your code in github etc

Message : cc @91809504xxxx of chingari üî•
Quoted Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.

Message : Bollywood seconds that
Quoted Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.

Message : Why would you say no upside? For a VC betting on GenAI, this would be great for branding plus first dibs on funding for any future rounds these products might go on to raise. At the least you have a front row seat to some good work in the space I'd presume.
Quoted Message : I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India. \nAnd it's fair, there is very little/no upside for the sponsor doing this.

Message : ‚ÄéPOLL:
How many of you are paying for an openai subscription?
‚ÄéOPTION: Paying (49 votes)
‚ÄéOPTION: Not paying. Using chat gpt(ish) for free (19 votes)

Message : Just gauging the room


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India. 
And it's fair, there is very little/no upside for the sponsor doing this.
Quoted Message : A hacker fellowship in SF called HF0\n\nIf folks here want to build something similar here in India, let's brainstorm & do it ! #lfg\n\nhttps://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html

Message : We got to stop copying, we have different problems, constrains and culture. ‚Äé<This message was edited>

Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.
Quoted Message : We got to stop copying, we have different problems, constrains and culture.

Message : Not a Hot take any more.
Quoted Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.

Message : Can you make a huggingface space without uploading your code in github etc

Message : cc @91809504xxxx of chingari üî•
Quoted Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.

Message : Bollywood seconds that
Quoted Message : Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.

Message : Why would you say no upside? For a VC betting on GenAI, this would be great for branding plus first dibs on funding for any future rounds these products might go on to raise. At the least you have a front row seat to some good work in the space I'd presume.
Quoted Message : I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India. \nAnd it's fair, there is very little/no upside for the sponsor doing this.

Message : ‚ÄéPOLL:
How many of you are paying for an openai subscription?
‚ÄéOPTION: Paying (49 votes)
‚ÄéOPTION: Not paying. Using chat gpt(ish) for free (19 votes)

Message : Just gauging the room

Message : I would be happy to commit 5L yearly if this got me access to a collective which invested in startups born out of such hackathons, in exchange of equity. Angel investing with access to smart people, projects and opportunity to participate in upside
Quoted Message : I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India. \nAnd it's fair, there is very little/no upside for the sponsor doing this.

Message : But it‚Äôs a complex financial vehicle, closest I have seen in IPV from Angel . Could be fun though
Quoted Message : I would be happy to commit 5L yearly if this got me access to a collective which invested in startups born out of such hackathons, in exchange of equity. Angel investing with access to smart people, projects and opportunity to participate in upside

Message : Openai subscription or chatgpt subscription

Message : Openai i.e building on top.

Although I'd be very curious to talk to someone who's bought chatgpt plus as well ü•∏ power chatter.
Quoted Message : Openai subscription or chatgpt subscription

Message : Heck If i had that money I‚Äôd just do it for the sake of being around hackers ü•π and having a local gpu cluster cause why not
Quoted Message : I would be happy to commit 5L yearly if this got me access to a collective which invested in startups born out of such hackathons, in exchange of equity. Angel investing with access to smart people, projects and opportunity to participate in upside

Message : @91953785xxxx uses both subscriptions :)
Quoted Message : Openai i.e building on top.\n\n Although I'd be very curious to talk to someone who's bought chatgpt plus as well ü•∏ power chatter.

Message : You can have a private GitHub repo and then access your source via personal access token in your hugging face space.
Quoted Message : Can you make a huggingface space without uploading your code in github etc

Message : Discussed this once previously in this group - There's a workaround - you keep the confidential code in a private repo on git. Then you import the code using your GitHub personal access token which can be kept in hugging face secrets

A link that discusses something similar - https://discuss.huggingface.co/t/share-app-url-without-sharing-the-files-and-version/26182
Quoted Message : You can have a private GitHub repo and then access your source via personal access token in your hugging face space.

Message : I am excited to try this but before diving in, would love to hear your thoughts @91994547xxxx @91994523xxxx
Quoted Message : I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India. \nAnd it's fair, there is very little/no upside for the sponsor doing this.

Message : People here can contribute to make this pool of 5 lakh happen.

Message : Supporting people to make and build is very valuable. One can do individual contributions of 2.5k to 5k and org contributions of 50k to 1 lakh and get credited as supporters for it.
Quoted Message : I am excited to try this but before diving in, would love to hear your thoughts @9199xxxxxxxx @9199xxxxxxxx

Message : 5 K committed
Quoted Message : Supporting people to make and build is very valuable. One can do individual contributions of 2.5k to 5k and org contributions of 50k to 1 lakh and get credited as supporters for it.

Message : would doing a smaller scale help to get started? like for 1 week, 10 hackers under a single roof

Message : Excellent idea !

Maybe we can get orgs like Zerodha and others to pitch in as well.
They had some FOSS grant program,
maybe they & other orgs would be willing to support an ai fellowship program with a 50k -2,3l contribution
Quoted Message : Supporting people to make and build is very valuable. One can do individual contributions of 2.5k to 5k and org contributions of 50k to 1 lakh and get credited as supporters for it.

Message : Here, see. Thank you. @91773788xxxx let's up a project page and get this running. We'll show the dashboard to everyone to see what the contribution pool looks like
Quoted Message : 5 K committed

Message : Sure. You'll do the legwork?
Quoted Message : Excellent idea !\n\nMaybe we can get orgs like Zerodha and others to pitch in as well.\nThey had some FOSS grant program, \nmaybe they & other orgs would be willing to support an ai fellowship program with a 50k -2,3l contribution

Message : I am sure a lot of us can speak to the orgs that we work in to contribute.

Message : Happy to !
Physically based in Delhi, but would love to use my network to do this
Quoted Message : Sure. You'll do the legwork?

Message : Can definitely do individual contribution of 5k 

Is there a link to pool contributions ?
Quoted Message : 5 K committed

Message : Excellent. @91773788xxxx work with Ashish to set up a pitch.
Quoted Message : Happy to !\nPhysically based in Delhi, but would love to use my network to do this

Message : Setting up. Give sometime.
Quoted Message : Can definitely do individual contribution of 5k \n\nIs there a link to pool contributions ?

Message : We can then take it to larger orgs.
Quoted Message : Excellent. @9177xxxxxxxx work with Ashish to set up a pitch.

Message : Once a pitch is set up all of us can take it to the respective orgs we work in 
This is a good idea üëçüèª
Quoted Message : Excellent. @9177xxxxxxxx work with Ashish to set up a pitch.

Message : ‚Äé<attached: 00011467-PHOTO-2023-07-03-16-52-02.jpg>

Message : " wanted to build an embeddings database from scratch just as a learning exercise per WebGPT, but realized that it would be cool to turn into a tinygrad-esque project.
rationale is that approximate nearest neighbors/hnsw/faiss is kinda dumb when vector search is O(N) lol.

some goals:
- make it hyper optimized
- filtering/sql sucks on vector databases, let's make this good
- i want gpu acceleration. super fast nn kernel, basically a matmul anyways
- integrate cool tools like PCA indexes, custom ANN algos, etc.
- make it useful. python/js lib."

Message : Identified a bunch of problems with vector databases and came up with multiple wrong solutions

Message : Exactly.
Quoted Message : Once a pitch is set up all of us can take it to the respective orgs we work in \nThis is a good idea üëçüèª

Message : Hahahahhaa, beat me to it! ü§£

In fairness, there are no obvious good solutions ‚Äî and this solution might fit the "Worse is better"
Quoted Message : Identified a bunch of problems with vector databases and came up with multiple wrong solutions

Message : It's partially enraging ngl

Message : nan

Message : My cofounder had an interview with them. They don‚Äôt advocate it but they seem to be majorly enterprise focused
Quoted Message : A hacker fellowship in SF called HF0\n\nIf folks here want to build something similar here in India, let's brainstorm & do it ! #lfg\n\nhttps://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html

Message : Dealflow is the only way to fund these things
Quoted Message : My cofounder had an interview with them. They don‚Äôt advocate it but they seem to be majorly enterprise focused

Message : https://www.betaworks.com is nice! Hugging Face was part of their accelerator back in the day

Message : Basic question

Why are LLMs coming out with these number of Params and or others? 7b, 13, 33

Is there a technical reason or benchmarks are driving this uniformity?

Message : Mainly 2 reasons as per my understanding:
* Whether they can fit in an H100, A100 80, A10, T4 or other 16G GPUs
* It's based on Chinchilla paper, where certain results mention how many parameters and how many tokens you need to achieve performance relative to GPT3 or other major LLMs

Message : My guesses

- Open source models are building on weights and datasets from Llama which was probably these sizes (llama paper itself I think said that the choices for sizes arises from empirical testing)
- If a lot of models are being trained on the Pile, maybe there are logical stop points around those data sizes

Message : For example, a 30B parameter model can theoretically outperform GPT3 with 1T+ tokens as per the paper.

Message : Likewise, decisions are based off of which devices can support which inferences

Message : ‚Äé~‚ÄØDr. Pratik Desai added ~‚ÄØprakashkagitha

Message : Great to join this group, Looking forward to the discussions!


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : My cofounder had an interview with them. They don‚Äôt advocate it but they seem to be majorly enterprise focused
Quoted Message : A hacker fellowship in SF called HF0\n\nIf folks here want to build something similar here in India, let's brainstorm & do it ! #lfg\n\nhttps://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html

Message : Dealflow is the only way to fund these things
Quoted Message : My cofounder had an interview with them. They don‚Äôt advocate it but they seem to be majorly enterprise focused

Message : https://www.betaworks.com is nice! Hugging Face was part of their accelerator back in the day

Message : Basic question

Why are LLMs coming out with these number of Params and or others? 7b, 13, 33

Is there a technical reason or benchmarks are driving this uniformity?

Message : Mainly 2 reasons as per my understanding:
* Whether they can fit in an H100, A100 80, A10, T4 or other 16G GPUs
* It's based on Chinchilla paper, where certain results mention how many parameters and how many tokens you need to achieve performance relative to GPT3 or other major LLMs

Message : My guesses

- Open source models are building on weights and datasets from Llama which was probably these sizes (llama paper itself I think said that the choices for sizes arises from empirical testing)
- If a lot of models are being trained on the Pile, maybe there are logical stop points around those data sizes

Message : For example, a 30B parameter model can theoretically outperform GPT3 with 1T+ tokens as per the paper.

Message : Likewise, decisions are based off of which devices can support which inferences

Message : ‚Äé~‚ÄØDr. Pratik Desai added ~‚ÄØprakashkagitha

Message : Great to join this group, Looking forward to the discussions!

Message : Hey folks, I‚Äôm looking to understand what solutions are available for using AI for analysing spatial imaging for indoor spaces. Couldn‚Äôt find anything useful online. Would love to get some ideas, resources

Message : Hey folks, I‚Äôm looking to understand what solutions are available for using AI for analysing spatial imaging for indoor spaces. Couldn‚Äôt find anything useful online. Would love to get some ideas, resources

Message : Has anyone tried llm for intent to action detection and something in that kind ? Means want to identify some conversational attributes for any domain such that i can take an action based on the converstion that is going on , intent, sentiment looks like the starting point but any other things or ideas anyone have

Message : Kind of like rasa , if anyone tried there we give intents with queries but hoping out of box llm will work gpt , was kind of good only

Message : what kind of analyses are you looking for? detection, segmentation, something more complex?
detection - detectron library is a good starting point
segmentation - SAM (segment anything model) is a good foundation model
Quoted Message : Hey folks, I‚Äôm looking to understand what solutions are available for using AI for analysing spatial imaging for indoor spaces. Couldn‚Äôt find anything useful online. Would love to get some ideas, resources

Message : Depending on what you want to do, you may even be able to use non-learning approaches using OpenCV's image processing suite

Message : Tried something similar experiment with off the shelf LLM(Completions). 
It worked well for longer queries and not well for short queries.
Am.not sure if fine-tuning helps in this further.

LLM to SQL is a fine bridge rather than getting it throw labels.
Quoted Message : Has anyone tried llm for intent to action detection and something in that kind ? Means want to identify some conversational attributes for any domain such that i can take an action based on the converstion that is going on , intent, sentiment looks like the starting point but any other things or ideas anyone have

Message : I‚Äôm primarily looking for measurements and depth calculation of objects and internal structures
Quoted Message : what kind of analyses are you looking for? detection, segmentation, something more complex?\ndetection - detectron library is a good starting point\nsegmentation - SAM (segment anything model) is a good foundation model

Message : OpenCV is for basic use cases. I‚Äôm looking to extract depth and other measurements from 2D images and then 3D models from lidar scans and general images too
Quoted Message : Depending on what you want to do, you may even be able to use non-learning approaches using OpenCV's image processing suite

Message : If you don't have stereo images, your best bet for accurate depth would be some monocular neural net architecture (there are many out there)
From there, you can use SAM to segment or detectron to get bounding boxes (i.e., image dimensions) of the objects of interest. The image dimensions can be translated into real-world metric dimensions using the depth from above method.

Message : For 3D models from lidar + images, I'm actually working on the same problem. We're using 3D object detectors which work on multimodal data (images + point cloud). A good candidate is CLOC: https://arxiv.org/abs/2009.00784
It is easily deployable too.

Message : Thanks for sharing- will check these out. Also would love to know the problem statement you‚Äôre working on. Also looking to try https://developer.apple.com/augmented-reality/roomplan/

Message : Does this work for you? - https://www.lerf.io/
Quoted Message : OpenCV is for basic use cases. I‚Äôm looking to extract depth and other measurements from 2D images and then 3D models from lidar scans and general images too

Message : Cool stuff!! Object identification with measurements is our problem- getting the measurement is essential which if this can provide would be great.
Quoted Message : Does this work for you? - https://www.lerf.io/

Message : Check this out: https://www.captur3.ai/
Quoted Message : OpenCV is for basic use cases. I‚Äôm looking to extract depth and other measurements from 2D images and then 3D models from lidar scans and general images too

Message : They have a pretty decent ios app

Message : I see. I am not good with CV but this seems to be tackling your problem and claims to be SoTA - https://depth-gen.github.io/

Message : was added to chat

Message : TIL: Temperature and repetition penalty sort or ‚Äúcancel‚Äù each other out

https://ai.stackexchange.com/questions/39540/how-do-temperature-and-repetition-penalty-interfere

Message : Thanks for this, will check out!
Quoted Message : They have a pretty decent ios app

Message : Interesting, will check this, thanks!
Quoted Message : I see. I am not good with CV but this seems to be tackling your problem and claims to be SoTA - https://depth-gen.github.io/

Message : I am looking to run a ML solution on prem. What‚Äôs the best way to do this?

Message : Ohh thanks for the response
Quoted Message : Tried something similar experiment with off the shelf LLM(Completions). \nIt worked well for longer queries and not well for short queries. \nAm.not sure if fine-tuning helps in this further. \n\nLLM to SQL is a fine bridge rather than getting it throw labels.

Message : Have you tried OpenAI functions to convert intents to actions?
Quoted Message : Has anyone tried llm for intent to action detection and something in that kind ? Means want to identify some conversational attributes for any domain such that i can take an action based on the converstion that is going on , intent, sentiment looks like the starting point but any other things or ideas anyone have

Message : There a whole bunch of research on Monocular depth prediction. Models have become quite good these days. The problem will be in relating the predicted depth to real world distances for which you need some sort of calibration step.
Quoted Message : Hey folks, I‚Äôm looking to understand what solutions are available for using AI for analysing spatial imaging for indoor spaces. Couldn‚Äôt find anything useful online. Would love to get some ideas, resources

Message : I would sugges to try with simpler models like - https://github.com/isl-org/MiDaS

Message : Thanks for this, will definitely check it
Quoted Message : I would sugges to try with simpler models like - https://github.com/isl-org/MiDaS

Message : No i have not tried , let me vheck that .
Quoted Message : Have you tried OpenAI functions to convert intents to actions?

Message : ‚Äé~‚ÄØKShivendu added ‚Ä™+91¬†97385¬†26173‚Ä¨

Message : Surprising result but sounds like a tall claim so still not sure.
A replit 3B instruction tuned model surpassed WizardCoder score on HumanEval benchmark and scores 63.5% in pass@xxxx.

No model card on HF but tweeted by abacaj. At this point, I just think this is gamified as well ü§£

https://twitter.com/abacaj/status/1675914584367018014?t=H7mgMWk-HHGNOiDuCAfHsg&s=19

Message : Looks like there is  demo space
https://huggingface.co/spaces/teknium/sahil2801-replit-code-instruct-glaive
Quoted Message : Surprising result but sounds like a tall claim so still not sure.\nA replit 3B instruction tuned model surpassed WizardCoder score on HumanEval benchmark and scores 63.5% in pass@xxxx.\n\nNo model card on HF but tweeted by abacaj. At this point, I just think this is gamified as well ü§£\n\nhttps://twitter.com/abacaj/status/1675914584367018014?t=H7mgMWk-HHGNOiDuCAfHsg&s=19

Message : Great. It was strange that he didn't create a model card or put up any details whatsoever for testing.

Message : was added to chat

Message : Well, It failed all 3 of my simple tests in python.
I'll check more tomorrow. Probably check the dataset for leak as well.

Message : that was real quick
Quoted Message : Well, It failed all 3 of my simple tests in python.\nI'll check more tomorrow. Probably check the dataset for leak as well.

Message : It takes a minute right now on the space to generate response. It's a 3B model so it's Inference is fast.

Message : What I tried with were easy but slight variations of binary search, it kind of ignored all constraints and thus didn't answer correctly.

Message : I meant your curiosity to test it out was quick
I saw it and I was like lets test it out tomorrow

Message : but which is the best OSS code model to build up on?

Message : do u have any suggestions


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Looks like there is  demo space
https://huggingface.co/spaces/teknium/sahil2801-replit-code-instruct-glaive
Quoted Message : Surprising result but sounds like a tall claim so still not sure.\nA replit 3B instruction tuned model surpassed WizardCoder score on HumanEval benchmark and scores 63.5% in pass@xxxx.\n\nNo model card on HF but tweeted by abacaj. At this point, I just think this is gamified as well ü§£\n\nhttps://twitter.com/abacaj/status/1675914584367018014?t=H7mgMWk-HHGNOiDuCAfHsg&s=19

Message : Great. It was strange that he didn't create a model card or put up any details whatsoever for testing.

Message : was added to chat

Message : Well, It failed all 3 of my simple tests in python.
I'll check more tomorrow. Probably check the dataset for leak as well.

Message : that was real quick
Quoted Message : Well, It failed all 3 of my simple tests in python.\nI'll check more tomorrow. Probably check the dataset for leak as well.

Message : It takes a minute right now on the space to generate response. It's a 3B model so it's Inference is fast.

Message : What I tried with were easy but slight variations of binary search, it kind of ignored all constraints and thus didn't answer correctly.

Message : I meant your curiosity to test it out was quick
I saw it and I was like lets test it out tomorrow

Message : but which is the best OSS code model to build up on?

Message : do u have any suggestions

Message : It's either StarCoder newest variant or WizardCoder. Can't say if WizardCoder has data contamination to get better results but it should still be good.

Message : Nice inference api for StarCoder - https://huggingface.co/bigcode/starcoder

WizardCoder - https://huggingface.co/WizardLM/WizardCoder-15B-V1.0

Message : i fell RAG based AI documentation dont really do a good job and dont have a good understanding of the documentation to generate stuff can it be improved by feeding the whole documentation with instruction fine tuning to an good OSS code model and get better answers

by better answers I mean those which can be directly copy pasted?
Quoted Message : It's either StarCoder newest variant or WizardCoder. Can't say if WizardCoder has data contamination to get better results but it should still be good.

Message : Yeah you can probably do better by fine tuning but it can lead to overfitting as well. But if you're making a product for something focused solely on the documentation QA, I'll suggest trying it out to compare the results.
Quoted Message : i fell RAG based AI documentation dont really do a good job and dont have a good understanding of the documentation to generate stuff can it be improved by feeding the whole documentation with instruction fine tuning to an good OSS code model and get better answers\n\nby better answers I mean those which can be directly copy pasted?

Message : yep on my way to start a new side project which I will probably leave half way through coz i will find something more fascination the next day
Quoted Message : Yeah you can probably do better by fine tuning but it can lead to overfitting as well. But if you're making a product for something focused solely on the documentation QA, I'll suggest trying it out to compare the results.

Message : fascinating*

Message : https://arxiv.org/abs/2210.03945

Message : Interesting paper, I did not know parsing HTML was a challenge for foundational LLMs

Message : Also, is there any way I can subscribe to Arxiv papers so that I get to know when a second version of the paper is published?

Message : I haven‚Äôt used it on arXiv but https://visualping.io/ has been fantastic for me for such use cases
Quoted Message : Also, is there any way I can subscribe to Arxiv papers so that I get to know when a second version of the paper is published?

Message : https://arxiv-sanity-lite.com/
Quoted Message : Also, is there any way I can subscribe to Arxiv papers so that I get to know when a second version of the paper is published?

Message : Is there anyone here that can intro me to Sahil?
Quoted Message : Surprising result but sounds like a tall claim so still not sure.\nA replit 3B instruction tuned model surpassed WizardCoder score on HumanEval benchmark and scores 63.5% in pass@xxxx.\n\nNo model card on HF but tweeted by abacaj. At this point, I just think this is gamified as well ü§£\n\nhttps://twitter.com/abacaj/status/1675914584367018014?t=H7mgMWk-HHGNOiDuCAfHsg&s=19

Message : Must be July? I called this out in May end that this is going Kaggle-way ü§£
Quoted Message : Surprising result but sounds like a tall claim so still not sure.\nA replit 3B instruction tuned model surpassed WizardCoder score on HumanEval benchmark and scores 63.5% in pass@xxxx.\n\nNo model card on HF but tweeted by abacaj. At this point, I just think this is gamified as well ü§£\n\nhttps://twitter.com/abacaj/status/1675914584367018014?t=H7mgMWk-HHGNOiDuCAfHsg&s=19

Message : "Though human eval isn‚Äôt necessarily indicative of how good the model will do for users in real life use cases,  having a pass@xxxx higher than all open source models with just a 3B model and 1B tokens shows how good small models can get given high quality data"
- @csahil28
Quoted Message : Surprising result but sounds like a tall claim so still not sure.\nA replit 3B instruction tuned model surpassed WizardCoder score on HumanEval benchmark and scores 63.5% in pass@xxxx.\n\nNo model card on HF but tweeted by abacaj. At this point, I just think this is gamified as well ü§£\n\nhttps://twitter.com/abacaj/status/1675914584367018014?t=H7mgMWk-HHGNOiDuCAfHsg&s=19

Message : If it isn't "necessarily indicative" of model performance I'm super confused as to why this keeps being proped up for a "new revolutionary model" everytime

Message : https://twitter.com/vipulved/status/1676014844171153409?t=3M6XgfAEzM8YcE0mZ0nDhQ&s=19\n\nHas anyone used redpajama ? Seems they are claiming a lot of commercial deployments

Message : https://twitter.com/vipulved/status/1676014844171153409?t=3M6XgfAEzM8YcE0mZ0nDhQ&s=19

Has anyone used redpajama ? Seems they are claiming a lot of commercial deployments

Message : *JOB OPENINGS* 

üü¢ CollectivAI
- üéØ *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps ‚Äî making internal tools)
- üîç *Job Description*: Seeking an ML researcher to improve our code embedding models
- üìù *Apply Here*: https://in.linkedin.com/jobs/view/machine-learning-engineer-at-collectiv-ai-3614376734?trk=organization_guest_main-feed-card_feed-job-posting-content
- üí¨ *Contact*: Naman Jain: https://www.linkedin.com/in/naman-jain-8743ab79/

---

üîµ GPT Sahib
- üéØ *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps ‚Äî making internal tools, Broad ML role)
- üîç *Job Description*: Looking for an AI developer to assist in developing a chatbot in two languages
- üìù *Apply Here*: https://www.gptsahib.com/
- üí¨ *Contact*: Savipreet, Phone: +91-8054966180, Email: savipreet03@gmail.com

---

üü£ LongShot AI
- üéØ *Hiring for*: Broad ML Role
- üîç *Job Description*: Hiring a Full Stack NLP Engineer to work with latest LLM models for various use cases
- üìù *Apply Here*: https://hi.longshot.ai/NLP
- üí¨ *Contact*: https://www.linkedin.com/in/vermaonline/, https://www.linkedin.com/in/ankurpandey42/

---

üî¥ Cranberry.Fit
- üéØ *Hiring for*: Generative AI (text, vision)
- üîç *Job Description*: Part-time engineering role to build a women's health conversational AI using open-source LLMs
- üìù *Apply*: Email directly to founder at aditi@cranberry.fit
- üí¨ *Contact*: aditi@cranberry.fit

---

üü† AI Northstar Tech
- üéØ *Hiring for*: Generative AI (text, vision)
- üîç *Job Description*: GenAI generalist engineer. Tasks include building semantic search engines, LLM fine-tuning, vector DB applications, and some data science work
- üìù *Apply Here*: https://wellfound.com/l/2z2CyD
- üí¨ *Contact*: dhruv.anand@ainorthstartech.com

---

üü° gooey.ai
- üéØ *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps ‚Äî making internal tools)
- üîç *Job Description*: Building a GenAI platform that abstracts latest LLMs, animation tools, speech recognition, etc. from OpenAI, Stability, Google, Meta, etc.
- More details: https://www.help.gooey.ai/jobs/senior-software-engineer
- üìù *Apply Here*: https://forms.gle/F22ekdAjm2BfxxUW9
- üí¨ *Contact*: Sean, Email: sean@gooey.ai, Phone: +91 98862 51476, Dara: https://dara.network/sean

*- Posted by Sugnan on behalf of Generative¬†AI¬†Community*

Message : Thanks for sharing the opportunities with the community first @91797731xxxx @91982023xxxx @91876402xxxx @91962726xxxx üôè

Muchas gracias for adding this to https://nirantk.com/community as well
Quoted Message : *JOB OPENINGS* \n\nüü¢ CollectivAI\n- üéØ *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps ‚Äî making internal tools)\n- üîç *Job Description*: Seeking an ML researcher to improve our code embedding models\n- üìù *Apply Here*: https://in.linkedin.com/jobs/view/machine-learning-engineer-at-collectiv-ai-3614376734?trk=organization_guest_main-feed-card_feed-job-posting-content\n- üí¨ *Contact*: Naman Jain: https://www.linkedin.com/in/naman-jain-8743ab79/\n\n---\n\nüîµ GPT Sahib\n- üéØ *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps ‚Äî making internal tools, Broad ML role)\n- üîç *Job Description*: Looking for an AI developer to assist in developing a chatbot in two languages\n- üìù *Apply Here*: https://www.gptsahib.com/\n- üí¨ *Contact*: Savipreet, Phone: +91-8054966180, Email: savipreet03@gmail.com\n\n---\n\nüü£ LongShot AI\n- üéØ *Hiring for*: Broad ML Role\n- üîç *Job Description*: Hiring a Full Stack NLP Engineer to work with latest LLM models for various use cases\n- üìù *Apply Here*: https://hi.longshot.ai/NLP\n- üí¨ *Contact*: https://www.linkedin.com/in/vermaonline/, https://www.linkedin.com/in/ankurpandey42/\n\n---\n\nüî¥ Cranberry.Fit\n- üéØ *Hiring for*: Generative AI (text, vision)\n- üîç *Job Description*: Part-time engineering role to build a women's health conversational AI using open-source LLMs\n- üìù *Apply*: Email directly to founder at aditi@cranberry.fit\n- üí¨ *Contact*: aditi@cranberry.fit\n\n---\n\nüü† AI Northstar Tech\n- üéØ *Hiring for*: Generative AI (text, vision)\n- üîç *Job Description*: GenAI generalist engineer. Tasks include building semantic search engines, LLM fine-tuning, vector DB applications, and some data science work\n- üìù *Apply Here*: https://wellfound.com/l/2z2CyD\n- üí¨ *Contact*: dhruv.anand@ainorthstartech.com\n\n---\n\nüü° gooey.ai\n- üéØ *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps ‚Äî making internal tools)\n- üîç *Job Description*: Building a GenAI platform that abstracts latest LLMs, animation tools, speech recognition, etc. from OpenAI, Stability, Google, Meta, etc.\n- More details: https://www.help.gooey.ai/jobs/senior-software-engineer\n- üìù *Apply Here*: https://forms.gle/F22ekdAjm2BfxxUW9\n- üí¨ *Contact*: Sean, Email: sean@gooey.ai, Phone: +91 98862 51476, Dara: https://dara.network/sean                                                                                                                                                                                       \n\n*- Posted by Sugnan on behalf of Generative¬†AI¬†Community*

Message : cc @91805628xxxx for any queries for the event on July 8th in Koramangala ‚Äé<This message was edited>
Quoted Message : *Event Announcements from https://nirantk.com/community* \n \nTitle: \"How to build great OS projects & Dev tools from AI in India\"\nHosts: Anshuman Pandey, Founder, and others from Nimblebox.ai\nWhen? 2 PM to 7 PM, 8th July, 2023\nWhere? Bira Taproom, Koramangala, Bengaluru\nHow?: https://lu.ma/blr\n\n- Sugnan, on behalf of the Generative AI Community

Message : It's on Jul 8th ü§ó
Quoted Message : cc @9180xxxxxxxx for any queries for the event on July 8th in Koramangala

Message : Sorry, this 3 timezone calls, 3 date format is killing my brain ü´£
Quoted Message : It's on Jul 8th ü§ó

Message : In work with MLOps community, we created a summary of key talks from LLMs in Prod conference 2 with amazing ML leaders in the LLM domain. 

If you would like to access it in your inbox, here's the URL:  https://www.truefoundry.com/ebook-llm-in-production

Covers topics like: Shipping LLMs, Hallucinations in LLMs, LLMs in Rec systems, LLM Economics

Message : nan

Message : Ok
Quoted Message : In work with MLOps community, we created a summary of key talks from LLMs in Prod conference 2 with amazing ML leaders in the LLM domain. \n\nIf you would like to access it in your inbox, here's the URL:  https://www.truefoundry.com/ebook-llm-in-production \n\nCovers topics like: Shipping LLMs, Hallucinations in LLMs, LLMs in Rec systems, LLM Economics

Message : Ask for help:

Problem statement:
We've proprietary dataset of say, 2-3 million LinkedIn creators and their content items (say 300k creators talking about ML, 200k creators talking about PM etc).
With this data, we want to build a system that's capable of searching and ranking profiles on an input query like:

Find people with
education : MIT
professional experience : prev google
profession: engineer
talking about: ML
location: NYC
with followers>2000

What're the different approaches (vector db based and non vector db ones) to solve this problem well?

Message : Build ner system for fixed quantities. Use that as filter. 
Use LLM for semantic matching of semantic parts of the query

Message : Good read: https://venturebeat.com/ai/inside-the-race-to-build-an-operating-system-for-generative-ai/

Message : Neat paper !

https://arxiv.org/abs/2304.05128
https://twitter.com/denny_zhou/status/1676003452839919616?s=20

Message : interesting - blockchain funds are redeploying to AI. some web3 fund announced a 500k online hackathon.

https://soonami.io/hackathon

Message : certainly interesting
Quoted Message : interesting - blockchain funds are redeploying to AI. some web3 fund announced a 500k online hackathon.\n\nhttps://soonami.io/hackathon

Message : Any good examples of startups working on bounded scope "agent" use cases with LLMs - task automation, data entry, data analysis etc.?

Message : We‚Äôre focus a 100% on CS
Quoted Message : Any good examples of startups working on bounded scope \"agent\" use cases with LLMs - task automation, data entry, data analysis etc.?

Message : was added to chat

Message : ‚Äé<attached: 00011554-PHOTO-2023-07-04-14-30-16.jpg>

Message : It's actually the opposite.

Message : They didn't want the browse with Bing to reveal all contents of the website. But that's what it can do. Bing in search engine can't do that

Message : Can you explain this? They don't want to scrape the whole site?
Quoted Message : They didn't want the browse with Bing to reveal all contents of the website. But that's what it can do. Bing in search engine can't do that

Message : ‚Äé<attached: 00011558-PHOTO-2023-07-04-14-33-15.jpg>

Message : A lot of people were bypassing paywalls


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : certainly interesting
Quoted Message : interesting - blockchain funds are redeploying to AI. some web3 fund announced a 500k online hackathon.\n\nhttps://soonami.io/hackathon

Message : Any good examples of startups working on bounded scope "agent" use cases with LLMs - task automation, data entry, data analysis etc.?

Message : We‚Äôre focus a 100% on CS
Quoted Message : Any good examples of startups working on bounded scope \"agent\" use cases with LLMs - task automation, data entry, data analysis etc.?

Message : was added to chat

Message : ‚Äé<attached: 00011554-PHOTO-2023-07-04-14-30-16.jpg>

Message : It's actually the opposite.

Message : They didn't want the browse with Bing to reveal all contents of the website. But that's what it can do. Bing in search engine can't do that

Message : Can you explain this? They don't want to scrape the whole site?
Quoted Message : They didn't want the browse with Bing to reveal all contents of the website. But that's what it can do. Bing in search engine can't do that

Message : ‚Äé<attached: 00011558-PHOTO-2023-07-04-14-33-15.jpg>

Message : A lot of people were bypassing paywalls

Message : You can bypass paywalls anyway by stopping the loader quickly
Quoted Message : A lot of people were bypassing paywalls

Message : That and scraping the content without any ad revenue is also a no go. They want search engines to index stuff and display things by metadata, robots text content and not be a way to consume content without visiting the websites.

Message : Is it a no go legally? Because scraping with citations is allowed.

Also Bing chat was able to do the same thing as is bard
Quoted Message : That and scraping the content without any ad revenue is also a no go. They want search engines to index stuff and display things by metadata, robots text content and not be a way to consume content without visiting the websites.

Message : When you do chatgpt with browsing even if you don't give the url explicitly it still scrapes the site

Message : I think scraping of public data is allowed as of now but they are avoiding it so that the search engines don't kill the incentive to visit anybody's website.

Bing has now become incapable of revealing contents of a url or parse it deeply for information. I think they limited it to work with indexed info only.
Quoted Message : Is it a no go legally? Because scraping with citations is allowed.\n\nAlso Bing chat was able to do the same thing as is bard

Message : They're going to have togive Google this memo as well because it is planning doing something worse ‚Äé<This message was edited>
Quoted Message : I think scraping of public data is allowed as of now but they are avoiding it so that the search engines don't kill the incentive to visit anybody's website.\n\nBing has now become incapable of revealing contents of a url or parse it deeply for information. I think they limited it to work with indexed info only.

Message : Googles plan is to give detailed answer snippets and people also ask.

Message : Let me check what Bing is doing currently

Message : ‚Äé<attached: 00011568-PHOTO-2023-07-04-14-43-43.jpg>

Message : This is why they should have let startups handle this. They tried to make google dance and are burning everything. Chatgpt with browsing was meh at best, and is creating unnecessary controversy

Message : I wonder how Perplexity handles this, or whether they are just flying under the radar on this: https://twitter.com/AravSrinivas/status/1676101654683488256?s=20

Message : No one is printing the whole article verbatim. It is a paraphrased version answering the users input specifically
Quoted Message : I wonder how Perplexity handles this, or whether they are just flying under the radar on this: https://twitter.com/AravSrinivas/status/1676101654683488256?s=20

Message : With proper citations

Message : So you ask for something, it would most likely search for that topic , get you a paraphrased answer with citations.

Message : Perplexity is pretty wrong most of the time. Citations are usually super random
Quoted Message : I wonder how Perplexity handles this, or whether they are just flying under the radar on this: https://twitter.com/AravSrinivas/status/1676101654683488256?s=20

Message : might be doing it LLM generated instead of deterministic ways
Quoted Message : Perplexity is pretty wrong most of the time. Citations are usually super random

Message : I tried to get a kpmg analyst to use perplexity & my internal google search + gpt4 for their research - it will often say stuff that doesnt correlate with what‚Äôs in the sources - and the citations will be random - which means they can‚Äôt use it in their work

Message : someone at perplexity needs to look at those prompts üòú
Quoted Message : I tried to get a kpmg analyst to use perplexity & my internal google search + gpt4 for their research - it will often say stuff that doesnt correlate with what‚Äôs in the sources - and the citations will be random - which means they can‚Äôt use it in their work

Message : At this point, it's not a bad idea to use SERP api + GPT3/4 api to have personal browsing.

Message : Fetch html with curl after identifying the url and let gpt 3/4 do the text extraction or beautiful soup if that's where you want to go

Message : Yep and there have been alleged copyright infringement issues even with paraphrased summaries. Not sure if this has already been shared here earlier but OpenAI is now being sued for copyright violations - 
https://www.reuters.com/legal/lawsuit-says-openai-violated-us-authors-copyrights-train-ai-chatbot-2023-06-29/
Quoted Message : No one is printing the whole article verbatim. It is a paraphrased version answering the users input specifically

Message : Google, OpenAI and many other companies have already benefited from the data massively. Since there wasn't a proper law against this earlier, this is a grey zone. 

I definitely think it should be possible to allege monopolization of open or public data and get them to at least make api distillation legal for model building

Message : Omg, how did I miss this. But this means there are automated techniques to bypass paywalls? Other than scihub, do you guys know if any
Quoted Message : You can bypass paywalls anyway by stopping the loader quickly

Message : 12ft.io used to work
Quoted Message : Omg, how did I miss this. But this means there are automated techniques to bypass paywalls? Other than scihub, do you guys know if any

Message : 12ft.Io
Quoted Message : Omg, how did I miss this. But this means there are automated techniques to bypass paywalls? Other than scihub, do you guys know if any

Message : Thanks

Message : Pro tip: use pandoc for html -> text
Quoted Message : Fetch html with curl after identifying the url and let gpt 3/4 do the text extraction or beautiful soup if that's where you want to go

Message : Thank you, I'll put it to test.
Quoted Message : Pro tip: use pandoc for html -> text

Message : I think this part is different from retrieval based generation. In any case, will be interesting to see this case develop. I believe Japan has already said this is OK. \n\nBut yeah they might have definitely used books and private code repos in their training data
Quoted Message : Yep and there have been alleged copyright infringement issues even with paraphrased summaries. Not sure if this has already been shared here earlier but OpenAI is now being sued for copyright violations - \nhttps://www.reuters.com/legal/lawsuit-says-openai-violated-us-authors-copyrights-train-ai-chatbot-2023-06-29/

Message : I think this part is different from retrieval based generation. In any case, will be interesting to see this case develop. I believe Japan has already said this is OK. 

But yeah they might have definitely used books and private code repos in their training data

Message : This is a nice topic for philosophy group
Quoted Message : I think this part is different from retrieval based generation. In any case, will be interesting to see this case develop. I believe Japan has already said this is OK. \n\nBut yeah they might have definitely used books and private code repos in their training data

Message : ‚Äé<attached: 00011591-PHOTO-2023-07-04-16-01-11.jpg>

Message : Yass, for startups

Message : Definitely. I just thought it was nice to have the option locally with chat. I was using combo of anki flash cards and scraping/parsing to take care of my learning requirements.
Quoted Message : Yass, for startups

Message : Yep, also saw that they removed browsing with Bing plugin for Plus users. It was bad anyway.

Message : Ask your pdf still works, though it's not as seamless as you would expect.

Message : Definitely. I just thought it was nice to have the option locally with chat. I was using combo of anki flash cards and scraping/parsing to take care of my learning requirements.

Message : Yep, also saw that they removed browsing with Bing plugin for Plus users. It was bad anyway.

Message : Ask your pdf still works, though it's not as seamless as you would expect.

Message : https://twitter.com/random_walker/status/1676077967577870336?t=0SrbEsdgnWBFYvXu05RrqA&s=19


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : This is a nice topic for philosophy group
Quoted Message : I think this part is different from retrieval based generation. In any case, will be interesting to see this case develop. I believe Japan has already said this is OK. \n\nBut yeah they might have definitely used books and private code repos in their training data

Message : ‚Äé<attached: 00011591-PHOTO-2023-07-04-16-01-11.jpg>

Message : Yass, for startups

Message : Definitely. I just thought it was nice to have the option locally with chat. I was using combo of anki flash cards and scraping/parsing to take care of my learning requirements.
Quoted Message : Yass, for startups

Message : Yep, also saw that they removed browsing with Bing plugin for Plus users. It was bad anyway.

Message : Ask your pdf still works, though it's not as seamless as you would expect.

Message : Definitely. I just thought it was nice to have the option locally with chat. I was using combo of anki flash cards and scraping/parsing to take care of my learning requirements.

Message : Yep, also saw that they removed browsing with Bing plugin for Plus users. It was bad anyway.

Message : Ask your pdf still works, though it's not as seamless as you would expect.

Message : https://twitter.com/random_walker/status/1676077967577870336?t=0SrbEsdgnWBFYvXu05RrqA&s=19

Message : WebPilot seems to be doing fine for now as well.
Quoted Message : Ask your pdf still works, though it's not as seamless as you would expect.

Message : was added to chat

Message : was added to chat

Message : WebPilot seems to be doing fine for now as well.

Message : Has anyone seen the batgpt paper. Is this real?

Message : ‚Äé<attached: 00011601-PHOTO-2023-07-04-17-15-33.jpg>

Message : Or is this the greatest parody in the world

Message : This can't be real.

Message : The social points awarded by China for these guys will go negative ‚Äé<This message was edited>

Message : Love it

Message : LOL

Message : I almost think it is deliberate. Bidirectional Autoregressive "Talker"? Really?

Message : They've an arxiv page and they are from Wuhan University. 
https://arxiv.org/abs/2307.00360

It's unreal.
Quoted Message : I almost think it is deliberate. Bidirectional Autoregressive \"Talker\"? Really?

Message : https://paperreading.club/page?id=173095

Message : Hey everyone,

Is the OpenAI API working fine for you? It has suddenly become slow and the requests are timed out.

Message : Working OK for me right now

Message : ‚Äé<attached: 00011612-PHOTO-2023-07-04-17-54-17.jpg>

Message : This depends a lot on when people in the west start using the app.
Quoted Message : Hey everyone,\n\nIs the OpenAI API working fine for you? It has suddenly become slow and the requests are timed out.

Message : Does anyone have an idea how to get access to the Anthropic API? Have applied but haven't even got email acknowledgement for application for quite some time now.

Message : They are notorious for being slow
Quoted Message : Does anyone have an idea how to get access to the Anthropic API? Have applied but haven't even got email acknowledgement for application for quite some time now.

Message : A user of ours had ZScaler installed. Would this affect our API key and result in blockages?
Quoted Message : This depends a lot on when people in the west start using the app.

Message : I saw somewhere the context length for Anthropic models being huge. Anyone with practical experience in using these? Thoughts?
Quoted Message : They are notorious for being slow

Message : Unaware of zcaler actually
Quoted Message : A user of ours had ZScaler installed. Would this affect our API key and result in blockages?

Message : Hashnode for their chatbot rix
Quoted Message : I saw somewhere the context length for Anthropic models being huge. Anyone with practical experience in using these? Thoughts?

Message : This is true. 100k context length.

But like all RLHF models, you can't give a lot of token length for response.
The quality is decent upto levels of turbo maybe lesser than the new models but still definitely usable for few use cases commercially
Quoted Message : I saw somewhere the context length for Anthropic models being huge. Anyone with practical experience in using these? Thoughts?

Message : Yes, basically I replaced llamaindex workflow by just feeding in whole document to anthropic at once. It gave decent answers then when I used chunked retrieval based QA with openai.
Quoted Message : I saw somewhere the context length for Anthropic models being huge. Anyone with practical experience in using these? Thoughts?

Message : I got by participating in a hackathon where anthropic had bounties.
Quoted Message : Does anyone have an idea how to get access to the Anthropic API? Have applied but haven't even got email acknowledgement for application for quite some time now.

Message : Trafiltura (GPLv3) is also a good tool. I have added this in Obsei to extract Google news articles and it works very well.
Quoted Message : Pro tip: use pandoc for html -> text

Message : This is the best
Quoted Message : Trafiltura (GPLv3) is also a good tool. I have added this in Obsei to extract Google news articles and it works very well.

Message : I just came across this. I don't write understand what problem are they solving clearly. Why do you use it?

Message : You should delete this

Message : Yes, but similarly on a case by case basis. If you are in a beta program of theirs you can get it. Apart from that check lablab.ai is having a hackathon with vertex ai. They are claiming to distribute accesses there.

Message : It isn't clear to me as well. I am confused if they are a way to indirectly access the waitlisted APIs or just a package to manage multiple APIs.
I needed something like steamship to use GPT4 apis but cleaner without the baggage of building entire packages for them first.
Quoted Message : I just came across this. I don't write understand what problem are they solving clearly. Why do you use it?

Message : https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c - interesting combination of techniques discussed for very large (book length) context windows. Fascinating stuff.

Message : Hello everyone,

We have a use case of chatbot using langchain + openai.

We are currently streaming the responses, but now want to introduce actionable buttons below the streamed text. Can add interactive widgets as well like polling some day.

Wish to hear thoughts on how can we achieve this while ensuring the streaming is also happening?

Message : Might be of interest to some folks here.

I confirmed with the dev for https://openrouter.ai/ that we can access anthropic, palm, gpt APIs without any issues from there.

However, no guarantee for safety of your data or any other reason you may trust openAI more than a third party proxy. But to some folks it may not matter and they just want access so mentioning it here.
Quoted Message : It isn't clear to me as well. I am confused if they are a way to indirectly access the waitlisted APIs or just a package to manage multiple APIs.\nI needed something like steamship to use GPT4 apis but cleaner without the baggage of building entire packages for them first.

Message : The ship of trust sailed away long ago, but it‚Äôs coming back now again üòÖ
Quoted Message : Might be of interest to some folks here.\n\nI confirmed with the dev for https://openrouter.ai/ that we can access anthropic, palm, gpt APIs without any issues from there. \n\nHowever, no guarantee for safety of your data or any other reason you may trust openAI more than a third party proxy. But to some folks it may not matter and they just want access so mentioning it here.

Message : when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513

my response in case someone wants to grab popcorn
https://twitter.com/NirantK/status/1676280543921729536

Message : Anyone knows how can we programatically crop a video from landscape to portrait without losing the subject? Much like what they're doing here - https://cognitivemill.com/solutions/croperator/

Message : Is he trying to reinvent FAISS?
Quoted Message : when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513\n\nmy response in case someone wants to grab popcorn\nhttps://twitter.com/NirantK/status/1676280543921729536


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : You should delete this

Message : Yes, but similarly on a case by case basis. If you are in a beta program of theirs you can get it. Apart from that check lablab.ai is having a hackathon with vertex ai. They are claiming to distribute accesses there.

Message : It isn't clear to me as well. I am confused if they are a way to indirectly access the waitlisted APIs or just a package to manage multiple APIs.
I needed something like steamship to use GPT4 apis but cleaner without the baggage of building entire packages for them first.
Quoted Message : I just came across this. I don't write understand what problem are they solving clearly. Why do you use it?

Message : https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c - interesting combination of techniques discussed for very large (book length) context windows. Fascinating stuff.

Message : Hello everyone,

We have a use case of chatbot using langchain + openai.

We are currently streaming the responses, but now want to introduce actionable buttons below the streamed text. Can add interactive widgets as well like polling some day.

Wish to hear thoughts on how can we achieve this while ensuring the streaming is also happening?

Message : Might be of interest to some folks here.

I confirmed with the dev for https://openrouter.ai/ that we can access anthropic, palm, gpt APIs without any issues from there.

However, no guarantee for safety of your data or any other reason you may trust openAI more than a third party proxy. But to some folks it may not matter and they just want access so mentioning it here.
Quoted Message : It isn't clear to me as well. I am confused if they are a way to indirectly access the waitlisted APIs or just a package to manage multiple APIs.\nI needed something like steamship to use GPT4 apis but cleaner without the baggage of building entire packages for them first.

Message : The ship of trust sailed away long ago, but it‚Äôs coming back now again üòÖ
Quoted Message : Might be of interest to some folks here.\n\nI confirmed with the dev for https://openrouter.ai/ that we can access anthropic, palm, gpt APIs without any issues from there. \n\nHowever, no guarantee for safety of your data or any other reason you may trust openAI more than a third party proxy. But to some folks it may not matter and they just want access so mentioning it here.

Message : when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513

my response in case someone wants to grab popcorn
https://twitter.com/NirantK/status/1676280543921729536

Message : Anyone knows how can we programatically crop a video from landscape to portrait without losing the subject? Much like what they're doing here - https://cognitivemill.com/solutions/croperator/

Message : Is he trying to reinvent FAISS?
Quoted Message : when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513\n\nmy response in case someone wants to grab popcorn\nhttps://twitter.com/NirantK/status/1676280543921729536

Message : his chart is for like the order of 1000s of embeds though - apples vs oranges?

I think he means millions of embeddings, but with individual queries not actually searching though that order
Quoted Message : when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513\n\nmy response in case someone wants to grab popcorn\nhttps://twitter.com/NirantK/status/1676280543921729536

Message : This is an INDEX time. And he has measured embedding creation time in it ü§¶üèæ‚Äç‚ôÇÔ∏è


https://github.com/sdan/vlite/blob/084b5ba82d4666bbd34716bc6e3d11daccc34fd3/tests/bench.py#L58
Quoted Message : his chart is for like the order of 1000s of embeds though - apples vs oranges?\n\nI think he means millions of embeddings, but with individual queries not actually searching though that order

Message : Not even query time!

Message : and that chart is also indexing time, not query time

Message : https://github.com/jdagdelen/hyperDB
hyperDb is all you need. Facts
Quoted Message : Is he trying to reinvent FAISS?

Message : You can't just use a nuclear weapon to assassinate a single person sir
Quoted Message : https://github.com/jdagdelen/hyperDB\nhyperDb is all you need. Facts

Message : Happy 4th of July lol:üòÇ
Quoted Message : You can't just use a nuclear weapon to assassinate a single person sir

Message : Don‚Äôt bring Brahamastra to slap fights
Quoted Message : https://github.com/jdagdelen/hyperDB\nhyperDb is all you need. Facts

Message : His use case is for a small and very dynamic dataset. so measuring index time makes sense
Quoted Message : This is an INDEX time. And he has measured embedding creation time in it ü§¶üèæ‚Äç‚ôÇÔ∏è\n\n\nhttps://github.com/sdan/vlite/blob/084b5ba82d4666bbd34716bc6e3d11daccc34fd3/tests/bench.py#L58

Message : Like this makes so much sense for people building apps - e.g. searching though a bunch of pdfs or websites means you need fast indexing, query time is pretty much irrelevant across 1000s of vectors

Message : A much better example of what I'm looking for - https://cloudinary.com/documentation/video_resizing_and_cropping
Quoted Message : Anyone knows how can we programatically crop a video from landscape to portrait without losing the subject? Much like what they're doing here - https://cognitivemill.com/solutions/croperator/

Message : It's like people getting happy on discovering linear search when they had to search in a list and shitting over all the algorithms designed for best worst case complexity.
Quoted Message : when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513\n\nmy response in case someone wants to grab popcorn\nhttps://twitter.com/NirantK/status/1676280543921729536

Message : Good for them but no need to suddenly claim it as Eureka, Eureka. 
You didn't discover anything, but you definitely ran out on the street naked

Message : For this use case, why'd you wrap numpy then? Why not "just use numpy"?
Quoted Message : Like this makes so much sense for people building apps - e.g. searching though a bunch of pdfs or websites means you need fast indexing, query time is pretty much irrelevant across 1000s of vectors

Message : Because otherwise you have to hand roll a bunch of stuff around numpy like - 

text splitting - https://colab.research.google.com/drive/1S_4m87c44Zz1sRtY--SwLsozF6MPrfCO?usp=sharing

batching, prompts & heapq -https://colab.research.google.com/drive/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing

I don't think this particular implementation is very sophisticated though

Message : I'm just saying there's room for a library with just "Just two functions with optional flags for more customization" - something that's not langchain, and something that requires no dependencies except numpy

Message : In most cases, you can index something slightly slower and you'll worry about the query latency mostly as you'll want it to seamless.

If you had to index every hour, and query few times a day then you've a different use case and then you may want to optimise indexing over latency.
Quoted Message : Like this makes so much sense for people building apps - e.g. searching though a bunch of pdfs or websites means you need fast indexing, query time is pretty much irrelevant across 1000s of vectors

Message : Yup - here he had to index on every request - very different from searching a static db
Quoted Message : In most cases, you can index something slightly slower and you'll worry about the query latency mostly as you'll want it to seamless.\n\nIf you had to index every hour, and query few times a day then you've a different use case and then you may want to optimise indexing over latency.

Message : $ pip install x

>>> import x
>>> x.index([ "hello", "world" ]
>>> x.query("hey!")
hello

üíì
Quoted Message : I'm just saying there's room for a library with just \"Just two functions with optional flags for more customization\" - something that's not langchain, and something that requires no dependencies except numpy

Message : That or just write a wrapper over your vector DB functions to pass a parameter to set low index, average index or high index.

You can set default parameter as the industry convention but for a specific use case with frequent indexing, pass parameter to set low indexing. Wrapper can internally use numpy or cython whatever suits the case.
Quoted Message : $ pip install x\n\n>>> import x \n>>> x.index([ \"hello\", \"world\" ]\n>>> x.query(\"hey!\")\nhello\n\nüíì

Message : Not very neat but just a top of the head thought for something scalable
Quoted Message : That or just write a wrapper over your vector DB functions to pass a parameter to set low index, average index or high index.\n\nYou can set default parameter as the industry convention but for a specific use case with frequent indexing, pass parameter to set low indexing. Wrapper can internally use numpy or cython whatever suits the case.

Message : ‚Äé<attached: 00011661-PHOTO-2023-07-04-23-56-19.jpg>

Message : Yeah, I understand your feelings on this. But we all know he is going to get stuck there flying because he doesn't know how to control his altitude or flight speed with antigravity class üòõ

Message : so im suspecting that the reason that the vector db is this fast is cos of the MPS backend. it is skipping the CPU bus entirely.  memory writes will go straight over the PCIe bus to the GPU so this is kind of not a production-friendly benchmark. cos in production, all vector db writes will hop the network in some way.

so fundamentally, it is not numpy at play. it is basically GPU PCI-express. But that is a smart hack nonetheless.

Message : I think hnswlib doesn't have an optimal GPU acceleration due to its algorithm requiring random memory access features

Here's an issue for the same on CUDA - https://github.com/nmslib/hnswlib/issues/194

Didn't find any implementation for MPS but I'll look more. I don't think hnswlib benefited here from GPU acceleration.

Message : this is not gpu acceleration. there is no convolution computation that is getting accelerated. this is just a PCIE bus skip. thats my suspicion anyway. 
theoretically hnswlib can be accelerated in the same way...if someone can figure out its code

Message : I didn't understand this. GPU acceleration doesn't have to be a mat mul, any approach that benefits from tens of thousands of parallel computations will work. Hnswlib, doesn't appear to need that. 

I'll look deeper for hnswlib though.
Quoted Message : this is not gpu acceleration. there is no convolution computation that is getting accelerated. this is just a PCIE bus skip. thats my suspicion anyway. \ntheoretically hnswlib can be accelerated in the same way...if someone can figure out its code

Message : what is the base image you guys use for amazon sagemaker endpoints?

Message : ‚Äé<attached: 00011671-PHOTO-2023-07-05-02-09-13.jpg>

Message : It's a guess but I think every chat is logged in and logs come in with timestamps, date etc. Along with some metadata info. The message history it has for our chat may have the date mentioned somewhere and it used it.

Message : It doesn‚Äôt know anything. It finds the date from the context. Also, try asking the same question and mention that today is December 5th.

Message : But I started the conversation from scratch. Also Isn't gpt only supposed to use the prompt as it's context?
Quoted Message : It doesn‚Äôt know anything. It finds the date from the context. Also, try asking the same question and mention that today is December 5th.

Message : Like Abhishek said, context is with the query meta, if not explicitly mentioned.

Message : So if this was tried with the api where there would be no timestamp Metadata it wouldn't work?

Message : It will prove that they are not adding additional meta context with API.

Message : Because an LLM doesn‚Äôt have perception of time, it can only come from context ‚Äé<This message was edited>

Message : hi ayush its a nice post about the hinge thing - maybe you want to remove the picture of the girl for her privacy (unless she is ai too and didnt catch that!) ‚Äé<This message was edited>

Message : make sense

Message : appreciate it! :)

Message : Is there any good LLM benchmarking tool for comparison of open-source models with GPT-3, 3.5 or 4?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : It doesn‚Äôt know anything. It finds the date from the context. Also, try asking the same question and mention that today is December 5th.

Message : But I started the conversation from scratch. Also Isn't gpt only supposed to use the prompt as it's context?
Quoted Message : It doesn‚Äôt know anything. It finds the date from the context. Also, try asking the same question and mention that today is December 5th.

Message : Like Abhishek said, context is with the query meta, if not explicitly mentioned.

Message : So if this was tried with the api where there would be no timestamp Metadata it wouldn't work?

Message : It will prove that they are not adding additional meta context with API.

Message : Because an LLM doesn‚Äôt have perception of time, it can only come from context ‚Äé<This message was edited>

Message : hi ayush its a nice post about the hinge thing - maybe you want to remove the picture of the girl for her privacy (unless she is ai too and didnt catch that!) ‚Äé<This message was edited>

Message : make sense

Message : appreciate it! :)

Message : Is there any good LLM benchmarking tool for comparison of open-source models with GPT-3, 3.5 or 4?

Message : Also for evaluating finetuned models on specific tasks.

Message : Is anyone a power user of github copilot and copilot X (or others)
Could you recommend (links to) tips and tricks to make it generate good code?

Message : +1

Would love to hear from folks who use copilot like tools, especially for python
Quoted Message : Is anyone a power user of github copilot and copilot X (or others)\nCould you recommend (links to) tips and tricks to make it generate good code?

Message : Its great autocomplete, terrible coder
Quoted Message : Is anyone a power user of github copilot and copilot X (or others)\nCould you recommend (links to) tips and tricks to make it generate good code?

Message : https://accounts.nat.dev/sign-in?redirect_url=https%3A%2F%2Fnat.dev%2F
Quoted Message : Is there any good LLM benchmarking tool for comparison of open-source models with GPT-3, 3.5 or 4?

Message : https://spectrum.ieee.org/ai-programming

Message : Folks, anyone using conversational AI to execute actions within their organisation (looking at use cases beyond simple data retrieval)?

Message : ‚ÄúHave you considered using numba‚Äù is a swift kick in the backside. Lol. ü§£
Quoted Message : when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513\n\nmy response in case someone wants to grab popcorn\nhttps://twitter.com/NirantK/status/1676280543921729536

Message : The fun nature of that suggestion is that everyone on the inside track gets the joke, while anyone who has actually never heard of Numba will be grateful to learn something new and fast! üòá
Quoted Message : ‚ÄúHave you considered using numba‚Äù is a swift kick in the backside. Lol. ü§£

Message : I know this was discussed yesterday but still curious, What does openAI mean by "fixing the behaviour" (In reference to the paywalls being passed) how do you "fix" something like that without adding redundant checkpoints which might hinder the performance

Message : Broadly? You detect client vs server side paywalls and act around this. 

How do you detect? Could actually execute JS for top 200 domains or something like that
Quoted Message : I know this was discussed yesterday but still curious, What does openAI mean by \"fixing the behaviour\" (In reference to the paywalls being passed) how do you \"fix\" something like that without adding redundant checkpoints which might hinder the performance

Message : Yeah basically this the top 200 domains or something is what my doubt was, there's no possible way they fix for all paywalls right?...right? üòÇ
Quoted Message : Broadly? You detect client vs server side paywalls and act around this. \n\nHow do you detect? Could actually execute JS for top 200 domains or something like that

Message : But yeah makes sense thanks

Message : Maybe the ones complaining should stop being sissies and use fingerprinting software instead of JS hacks to implement paywalls? https://fingerprint.com/

Message : OMG! A tech solution to a tech problem? 

Absolutely impossible for $MSFT to sell this to brands cribbing about this
Quoted Message : Maybe the ones complaining should stop being sissies and use fingerprinting software instead of JS hacks to implement paywalls? https://fingerprint.com/

Message : I get where you're coming from but that's a blame the victim ish mentality no?
Quoted Message : Maybe the ones complaining should stop being sissies and use fingerprinting software instead of JS hacks to implement paywalls? https://fingerprint.com/

Message : I mean obviously this is a hole on their end

Message : But there should be some "ethics" involved when you scrape information from some repository, that's a given

Message : Calling media companies with a billion dollar a year tech budget a "victim", while sitting in India is a bit of mental gymnastics ‚Äî I'll leave this for Policy & Philosophy fork of the group
Quoted Message : I get where you're coming from but that's a blame the victim ish mentality no?

Message : Hence the "ish", almost used like a "not a financial advice"

Message : was added to chat

Message : High degree of regulatory pushback. Fingerprint can inadvertently step over HIPAA boundaries if u ask a personal medical question and then fingerprint the individual.

Or ask a question about being gay and get uniquely identified.
Quoted Message : Maybe the ones complaining should stop being sissies and use fingerprinting software instead of JS hacks to implement paywalls? https://fingerprint.com/

Message : Everything to do with AI has regulatory dragons around it. Those of us who have fought these battles for years know üòî

Message : There's a distinction between a date as a concept and knowledge / training data that is time limited provided to the bot at the time of training. ChatGPT can understand the concept of "today" or the current date, even if it doesn't have training data after 2021

Message : IMHO, conversational aspect is not the most valuable. We ended up building a tool that allows AI agents to participate in existing business workflows.
Quoted Message : Folks, anyone using conversational AI to execute actions within their organisation (looking at use cases beyond simple data retrieval)?

Message : how did you benchmark the accuracy of outputs? only decent agents I've seen is the CSV agents
Quoted Message : IMHO, conversational aspect is not the most valuable. We ended up building a tool that allows AI agents to participate in existing business workflows.

Message : I'd like to know about this too. Getting devs to adopt it is a challenge - has anyone faced this and begun productively using?
Quoted Message : Is anyone a power user of github copilot and copilot X (or others)\nCould you recommend (links to) tips and tricks to make it generate good code?

Message : Completely agree.

Conversational seems like a low hanging fruit. But really it's poisoned.

The minute you monetise people jump to non monetised versions.

People are perfectly okay sharing their deepest darkest fears with a computer program.
What they are not okay with is sharing that info with a program which is also trying to make money off of them
Quoted Message : IMHO, conversational aspect is not the most valuable. We ended up building a tool that allows AI agents to participate in existing business workflows.

Message : True. I guess it would depend on the tasks. So far, we've been focused on composability of agents more than individual agents.
Quoted Message : how did you benchmark the accuracy of outputs? only decent agents I've seen is the CSV agents

Message : Somewhat mixed thoughts. This might also depend on how complex and involved the workflow in question is, which further goes back to that particular org‚Äôs importance as well

Automating data ops processes vs lets say some manual entry tasks would have much different urgencies and ROI and therefore paying propensity

Message : Somewhat mixed thoughts. This might also depend on how complex and involved the workflow in question is, which further goes back to that particular org‚Äôs importance as well\n\nAutomating data ops processes vs lets say some manual entry tasks would have much different urgencies and ROI and therefore paying propensity
Quoted Message : Completely agree.\n\nConversational seems like a low hanging fruit. But really it's poisoned. \n\nThe minute you monetise people jump to non monetised versions.\n\nPeople are perfectly okay sharing their deepest darkest fears with a computer program.\nWhat they are not okay with is sharing that info with a program which is also trying to make money off of them

Message : I use it. Copilot is good but more issues than the hype. GPT4 on the other hand, can be really useful if you learn how to work with it.
Quoted Message : I'd like to know about this too. Getting devs to adopt it is a challenge - has anyone faced this and begun productively using?

Message : But if you're bad with basic stuff like breaking down problems in smaller chunks, isolating problematic modules, logging and error handling then you'll spend more time debugging with these tools than getting something done.

Message : And please don't use it in environments where secure code matters.

Message : can you share some csv agents that worked for you? haven't seen much success hence asking
Quoted Message : how did you benchmark the accuracy of outputs? only decent agents I've seen is the CSV agents

Message : For basic tasks, PandasAI or the CSV agents from langchain have worked for me, but when asking it to perform more complex tasks such as extraction of valueable insights, it's been a hit or miss, again also could be my prompting could be incorrect
Quoted Message : can you share some csv agents that worked for you? haven't seen much success hence asking

Message : We do it as well. Put today's date in the prompt

Message : I have been using it for almost two years. I am a paid customer. I can easily pay 2-3 times more. It is a must-have "dev tool" for my dev workflow. 

It may take a while to fully integrate it into your development workflow. For me, it took more than a few months. My initial days were full of frustration but I am glad I stuck with it.

It is good at bunch of specific tasks(my experience)

- writing trivial(but necessary) code - For example: if you are doing table-driven testing and have created a map of input and expected output at the top of your test, copilot is very good at writing the code for the test using the map)

- write utility functions - depending upon your language/framework, your code would have a bunch of utility packages. It is very good at writing small utility functions. The success depends mostly on the quality of the function signature.

- it is good at predicting the next line based on the previous line(for example in your rails router, it is able to predict the next route almost all the time)

- sometimes it is able to understand multi-file context - Say you have just written a controller in your rails application, if you go to the routes file, it will automatically suggest the route based on the newly written controller. This doesn't happen often, but when it happens, it feels magical even today.

- It is very useful when working with "standard" DSLs(for example helm charts, docker-compose etc.)

I have done a lot of pair programming in my life so it is no way close to becoming a driver/navigator/copilot as of today.
Quoted Message : Is anyone a power user of github copilot and copilot X (or others)\nCould you recommend (links to) tips and tricks to make it generate good code?

Message : Minor addendum: Copilot et al are much better at predictable syntax e.g. YAML, Docker-Compose as mentioned ‚Äî but it's also better when there are strong conventions e.g. RoR, Django, but terrible at new code e.g. Langchain, Llama Index, which don't respect "Pythonic" conventions
Quoted Message : I have been using it for almost two years. I am a paid customer. I can easily pay 2-3 times more. It is a must-have \"dev tool\" for my dev workflow. \n\nIt may take a while to fully integrate it into your development workflow. For me, it took more than a few months. My initial days were full of frustration but I am glad I stuck with it.\n\nIt is good at bunch of specific tasks(my experience)\n \n- writing trivial(but necessary) code - For example: if you are doing table-driven testing and have created a map of input and expected output at the top of your test, copilot is very good at writing the code for the test using the map)\n\n- write utility functions - depending upon your language/framework, your code would have a bunch of utility packages. It is very good at writing small utility functions. The success depends mostly on the quality of the function signature. \n\n- it is good at predicting the next line based on the previous line(for example in your rails router, it is able to predict the next route almost all the time)\n\n- sometimes it is able to understand multi-file context - Say you have just written a controller in your rails application, if you go to the routes file, it will automatically suggest the route based on the newly written controller. This doesn't happen often, but when it happens, it feels magical even today.\n\n- It is very useful when working with \"standard\" DSLs(for example helm charts, docker-compose etc.) \n\nI have done a lot of pair programming in my life so it is no way close to becoming a driver/navigator/copilot as of today.

Message : They don‚Äôt respect Pythonic conventions?
Quoted Message : Minor addendum: Copilot et al are much better at predictable syntax e.g. YAML, Docker-Compose as mentioned ‚Äî but it's also better when there are strong conventions e.g. RoR, Django, but terrible at new code e.g. Langchain, Llama Index, which don't respect \"Pythonic\" conventions


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Somewhat mixed thoughts. This might also depend on how complex and involved the workflow in question is, which further goes back to that particular org‚Äôs importance as well\n\nAutomating data ops processes vs lets say some manual entry tasks would have much different urgencies and ROI and therefore paying propensity
Quoted Message : Completely agree.\n\nConversational seems like a low hanging fruit. But really it's poisoned. \n\nThe minute you monetise people jump to non monetised versions.\n\nPeople are perfectly okay sharing their deepest darkest fears with a computer program.\nWhat they are not okay with is sharing that info with a program which is also trying to make money off of them

Message : I use it. Copilot is good but more issues than the hype. GPT4 on the other hand, can be really useful if you learn how to work with it.
Quoted Message : I'd like to know about this too. Getting devs to adopt it is a challenge - has anyone faced this and begun productively using?

Message : But if you're bad with basic stuff like breaking down problems in smaller chunks, isolating problematic modules, logging and error handling then you'll spend more time debugging with these tools than getting something done.

Message : And please don't use it in environments where secure code matters.

Message : can you share some csv agents that worked for you? haven't seen much success hence asking
Quoted Message : how did you benchmark the accuracy of outputs? only decent agents I've seen is the CSV agents

Message : For basic tasks, PandasAI or the CSV agents from langchain have worked for me, but when asking it to perform more complex tasks such as extraction of valueable insights, it's been a hit or miss, again also could be my prompting could be incorrect
Quoted Message : can you share some csv agents that worked for you? haven't seen much success hence asking

Message : We do it as well. Put today's date in the prompt

Message : I have been using it for almost two years. I am a paid customer. I can easily pay 2-3 times more. It is a must-have "dev tool" for my dev workflow. 

It may take a while to fully integrate it into your development workflow. For me, it took more than a few months. My initial days were full of frustration but I am glad I stuck with it.

It is good at bunch of specific tasks(my experience)

- writing trivial(but necessary) code - For example: if you are doing table-driven testing and have created a map of input and expected output at the top of your test, copilot is very good at writing the code for the test using the map)

- write utility functions - depending upon your language/framework, your code would have a bunch of utility packages. It is very good at writing small utility functions. The success depends mostly on the quality of the function signature.

- it is good at predicting the next line based on the previous line(for example in your rails router, it is able to predict the next route almost all the time)

- sometimes it is able to understand multi-file context - Say you have just written a controller in your rails application, if you go to the routes file, it will automatically suggest the route based on the newly written controller. This doesn't happen often, but when it happens, it feels magical even today.

- It is very useful when working with "standard" DSLs(for example helm charts, docker-compose etc.)

I have done a lot of pair programming in my life so it is no way close to becoming a driver/navigator/copilot as of today.
Quoted Message : Is anyone a power user of github copilot and copilot X (or others)\nCould you recommend (links to) tips and tricks to make it generate good code?

Message : Minor addendum: Copilot et al are much better at predictable syntax e.g. YAML, Docker-Compose as mentioned ‚Äî but it's also better when there are strong conventions e.g. RoR, Django, but terrible at new code e.g. Langchain, Llama Index, which don't respect "Pythonic" conventions
Quoted Message : I have been using it for almost two years. I am a paid customer. I can easily pay 2-3 times more. It is a must-have \"dev tool\" for my dev workflow. \n\nIt may take a while to fully integrate it into your development workflow. For me, it took more than a few months. My initial days were full of frustration but I am glad I stuck with it.\n\nIt is good at bunch of specific tasks(my experience)\n \n- writing trivial(but necessary) code - For example: if you are doing table-driven testing and have created a map of input and expected output at the top of your test, copilot is very good at writing the code for the test using the map)\n\n- write utility functions - depending upon your language/framework, your code would have a bunch of utility packages. It is very good at writing small utility functions. The success depends mostly on the quality of the function signature. \n\n- it is good at predicting the next line based on the previous line(for example in your rails router, it is able to predict the next route almost all the time)\n\n- sometimes it is able to understand multi-file context - Say you have just written a controller in your rails application, if you go to the routes file, it will automatically suggest the route based on the newly written controller. This doesn't happen often, but when it happens, it feels magical even today.\n\n- It is very useful when working with \"standard\" DSLs(for example helm charts, docker-compose etc.) \n\nI have done a lot of pair programming in my life so it is no way close to becoming a driver/navigator/copilot as of today.

Message : They don‚Äôt respect Pythonic conventions?
Quoted Message : Minor addendum: Copilot et al are much better at predictable syntax e.g. YAML, Docker-Compose as mentioned ‚Äî but it's also better when there are strong conventions e.g. RoR, Django, but terrible at new code e.g. Langchain, Llama Index, which don't respect \"Pythonic\" conventions

Message : Also given how often langchain & llamaindex release updates, I‚Äôve found it‚Äôs suggestions to be often outdated / incorrect
Quoted Message : Minor addendum: Copilot et al are much better at predictable syntax e.g. YAML, Docker-Compose as mentioned ‚Äî but it's also better when there are strong conventions e.g. RoR, Django, but terrible at new code e.g. Langchain, Llama Index, which don't respect \"Pythonic\" conventions

Message : I don't think they know that they're writing a Python lib yet
Quoted Message : They don‚Äôt respect Pythonic conventions?

Message : This involves multiple aspects actually. You need to do subject tracking (person/ face/important objects), this gives you the region of interests, and then you can offset these regions to the required aspect ratio. Post this, you can crop the video using ffmpeg with sliding transitions with the given regions of interests.
Quoted Message : Anyone knows how can we programatically crop a video from landscape to portrait without losing the subject? Much like what they're doing here - https://cognitivemill.com/solutions/croperator/

Message : Use some tool like rembg on frames and then apply smoothing heuristic over frames with maximization over focussed frame to aspect ratio of portrait.
Give your message and my response to gpt4 chat. I gave it and it gave a reasonable code.
Quoted Message : Anyone knows how can we programatically crop a video from landscape to portrait without losing the subject? Much like what they're doing here - https://cognitivemill.com/solutions/croperator/

Message : https://zulko.github.io/moviepy/examples/headblur.html
Check this example. You can modify for your purpose I believe

Message : Few gotchas I have noticed using chatGPT, co-pilot is not as much of my regular workflow to comment
1. It does mix up library versions, so if a covention changes between versions and you are tying to do something beyond super common, it may mix conventions from different library version. Saw this quite a bit with browser extensions.
2. Due to the system being trained in non interactive fashion (as compared to humans), it will assume some surface level thing. I was using Jinja2 templating and 'extend'ing. It assumed conventions from other language which was not exactly how Jinja2 does it. I saw the code and thought, ok that must be how it works and it ran correctly for that input. Only then finally realized the issue & go down rabbit hole of debugging.

Message : Will check this out, thanks!
Quoted Message : https://zulko.github.io/moviepy/examples/headblur.html\nCheck this example. You can modify for your purpose I believe

Message : sql

Message : DMing you
Quoted Message : IMHO, conversational aspect is not the most valuable. We ended up building a tool that allows AI agents to participate in existing business workflows.

Message : *Event Announcement*

*The Business of generative AI*

For: Founders, sales & marketing leaders, PMs & investors
Hosts: Peercheque w/ Aakrit @91981904xxxx, and featuring Rohit @91989995xxxx from Portkey
When: 13th July 2023 | 7:00 PM (IST)
Where: Zoom
Register here: https://docs.google.com/forms/d/e/1FAIpQLSdNHU91p25tPvRaRRrJJkEo-zbhtGNHn7R7IE_m5wRHWV4jcA/viewform

Message : https://github.com/BerriAI/reliableGPT
Helpful package I believe

Message : ‚Äé~‚ÄØNirant changed the subject to ‚ÄúGenerativeAI‚Äù

Message : Simplified name, because we've dedicated groups for Creatives and DeepMedia now ‚Äî in the same WhatsApp Community

Message : Bhai there are too many groups with same name. At least add a 'x' or some identifier. You kinda made it more generic.
Quoted Message : Simplified name, because we've dedicated groups for Creatives and DeepMedia now ‚Äî in the same WhatsApp Community

Message : ‚Äé~‚ÄØNirant changed the subject to ‚ÄúThe Only GenerativeAI Group which you care about‚Äù

Message : Simplified name, because we've dedicated groups for Creatives and DeepMedia now ‚Äî in the same WhatsApp Community

Message : Bhai there are too many groups with same name. At least add a 'x' or some identifier. You kinda made it more generic.

Message : Is that better? ü§£

Sorry, feeling playful

Message : fun story - this was built on replit https://twitter.com/ishaan_jaff/status/1633310537667973121
Quoted Message : https://github.com/BerriAI/reliableGPT\nHelpful package I believe

Message : Brilliant read.

https://thegradient.pub/othello/

Message : ‚Äé~‚ÄØNirant changed the subject to ‚ÄúThe GenerativeAI Group‚Äù

Message : Is this unique enough? ü§î

Message : You could name "The Terminator: Genesis"
Quoted Message : Is this unique enough? ü§î

Message : Generative AI || Text
This sounds more relevant
Quoted Message : Is this unique enough? ü§î

Message : The others could be Generative AI || Image/Media

Message : Missed opportunity for OpenAI to call their model "SkyNet-4"
Quoted Message : You could name \"The Terminator: Genesis\"

Message : These guys are so into  copyright. They might have been sued as well.
Quoted Message : Missed opportunity for OpenAI to call their model \"SkyNet-4\"

Message : The text bias is accidental tbh, because I am from NLP background ‚Äî  we do discuss startups, LoRA and what not here
Quoted Message : Generative AI || Text\nThis sounds more relevant

Message : LawGPT would have come to their rescue
Quoted Message : These guys are so into  copyright. They might have been sued as well.

Message : Maybe this main group we should name as ‚Äúanother Indian‚Äù ‚Ä¶ in honour of what AI used to be looked at as a decade back ü§™

Message : 'Only' keyword was fine. But settle on one. You are giving Musk-y vibes with too many changes xD
Quoted Message : Is this unique enough? ü§î

Message : I can never compete with that man, he has more kids than changes I've made
Quoted Message : 'Only' keyword was fine. But settle on one. You are giving Musk-y vibes with too many changes xD

Message : A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused.
To make it sound more simple, are text embeddings also vector databases, if not then what is the difference.

Message : Glove embeddings is a vector dataset (one vector per word of the vocabulary). Vector database is where you would store a vector dataset for quick nearest neighbor retrieval
Quoted Message : A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused.\nTo make it sound more simple, are text embeddings also vector databases, if not then what is the difference.

Message : Embedding =\= Vector Database
SW used for storing and retrieving across your data using embeddings ~~ Vector Database

An embedding is to a vector database similar to how a file is to a SQL database
Quoted Message : A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused.\nTo make it sound more simple, are text embeddings also vector databases, if not then what is the difference.

Message : Looks like they are re-inventing hystrix library from netflix.
Quoted Message : https://github.com/BerriAI/reliableGPT\nHelpful package I believe

Message : this message has been deleted

Message : had questions on Quantization and techniques is there good resources which i can start from to udnerstand the concept behind it ?

Message : https://huggingface.co/blog/hf-bitsandbytes-integration

Message : this was good but any other resources like this would help


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : 'Only' keyword was fine. But settle on one. You are giving Musk-y vibes with too many changes xD
Quoted Message : Is this unique enough? ü§î

Message : I can never compete with that man, he has more kids than changes I've made
Quoted Message : 'Only' keyword was fine. But settle on one. You are giving Musk-y vibes with too many changes xD

Message : A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused.
To make it sound more simple, are text embeddings also vector databases, if not then what is the difference.

Message : Glove embeddings is a vector dataset (one vector per word of the vocabulary). Vector database is where you would store a vector dataset for quick nearest neighbor retrieval
Quoted Message : A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused.\nTo make it sound more simple, are text embeddings also vector databases, if not then what is the difference.

Message : Embedding =\= Vector Database
SW used for storing and retrieving across your data using embeddings ~~ Vector Database

An embedding is to a vector database similar to how a file is to a SQL database
Quoted Message : A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused.\nTo make it sound more simple, are text embeddings also vector databases, if not then what is the difference.

Message : Looks like they are re-inventing hystrix library from netflix.
Quoted Message : https://github.com/BerriAI/reliableGPT\nHelpful package I believe

Message : this message has been deleted

Message : had questions on Quantization and techniques is there good resources which i can start from to udnerstand the concept behind it ?

Message : https://huggingface.co/blog/hf-bitsandbytes-integration

Message : this was good but any other resources like this would help

Message : I'm not sure where you're starting from. Quantization is vast. Now when including llama.cpp and QLoRA, it is also bleeding edge.
So if you can tell me what you want to know and if you understand the basics of quantisation, I can DM you some stuff.

Most of the stuff would be fragmented learning as it's being shaped up on the bleeding edge.

Message : I want to understand the basics first, but the overall goal is to check some examples that can be used for the quantization of LLM.

Message : How do I find out if a model is a quantized version or not? For example, let's say I want to use MPT 7b for a use case, and I want to know if the model's size will require me to change infra.

Message : A rough method - size that you need to load the model in memory would be close to it's equivalent number in GB

e.g. a 7B parameter model would load in 7G
On top of this, you add how much context length it can support. Models with larger context length will require additional memory.
Quoted Message : How do I find out if a model is a quantized version or not? For example, let's say I want to use MPT 7b for a use case, and I want to know if the model's size will require me to change infra.

Message : was added to chat

Message : I mentioned it like that because quantisation happens at every level - pretraining, post training, Inference
Quoted Message : I want to understand the basics first, but the overall goal is to check some examples that can be used for the quantization of LLM.

Message : ohh inferencing üòÖ
Quoted Message : I mentioned it like that because quantisation happens at every level - pretraining, post training, Inference

Message : is what i am more concerned about

Message : The bitsandbytes article you linked here would let you use weights in 8 bit representation on the level of fine tuning/pretraining

Message : For inference, we're talking about quantising the models in 16/8/4/3/2 bit precisions ‚Äé<This message was edited>
Quoted Message : ohh inferencing üòÖ

Message : Most popular method for that is via GGML based llama.cpp.

Though there are many variants of llama.cpp right now and the quantization schemes are now in their V4 currently being known as k quants.

Message : This a great, developer-friendly (assumes you know dev, but not ML) from Amod Malviya on Model Quantisation:

https://www.youtube.com/watch?v=P30y7kuOYLg&t=3s

Message : Gorilla from cal and MSR

https://gorilla.cs.berkeley.edu/

https://arxiv.org/abs/2305.15334

Message : Quick question, are people able to pay for huggingface using Indian credit cards?

Message : I‚Äôm trying to add my Indian CC details in the billing section but it keep refusing

Message : facing the same issue with lambdalabs, is anyone using this platform with an Indian card?
Quoted Message : I‚Äôm trying to add my Indian CC details in the billing section but it keep refusing

Message : was added to chat

Message : facing the same issue with lambdalabs, is anyone using this platform with an Indian card?

Message : A hackathon is brewing! Please cast your vote to help on deciding the date. https://twitter.com/NirantK/status/1676614768428187652?s=20

cc: @91773788xxxx

Message : One particular Visa credit card worked for me where 2 other debit cards and 3 credit cards failed
Quoted Message : Quick question, are people able to pay for huggingface using Indian credit cards?

Message : Used a US card here even that got declined‚Ä¶
Quoted Message : facing the same issue with lambdalabs, is anyone using this platform with an Indian card?

Message : Comments help a bit. Start writing comments and autocomplete is marginally better.
Quoted Message : Is anyone a power user of github copilot and copilot X (or others)\nCould you recommend (links to) tips and tricks to make it generate good code?

Message : Any open source tool and model to automatically generate test cases from the Java codebase.

Message : ‚Äé<attached: 00011787-PHOTO-2023-07-05-21-34-04.jpg>

Message : So, they are also using IndicTrans2. I hope they release their production optimized code for this.

Message : They have a public api

Message : With no api keys

Message : Just like Bhasini APIs, you really don't want to use open API for production.

Message : Latencies are good

Message : No?

Message : https://translate.wmcloud.org/

Message : Even latencies are good, for enterprise customer, we are building solutions for, you can't transfer blame to wiki or bhasini if things stop working suddenly. ‚Äé<This message was edited>

Message : Enterprise customers are not even willing to rely on OpenAI APIs, forget about wiki and bhasini APIs.

Message : https://gerrit.wikimedia.org/g/mediawiki/services/machinetranslation

Message : Actually they have a repo and models are optimized for performance using OpenNMT CTranslate2. This is interesting.

Message : https://blog.playgroundai.com/playground-raises-40m-to-advance-the-field-of-computer-graphics/

Message : Well articulated vision in this note

Message : Wow, 40M on top of bunch of Controlnets pipelines

Message : A metric ton of free users
Quoted Message : Wow, 40M on top of bunch of Controlnets pipelines

Message : ‚Äé<attached: 00011805-PHOTO-2023-07-05-22-06-36.jpg>


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : https://translate.wmcloud.org/

Message : Even latencies are good, for enterprise customer, we are building solutions for, you can't transfer blame to wiki or bhasini if things stop working suddenly. ‚Äé<This message was edited>

Message : Enterprise customers are not even willing to rely on OpenAI APIs, forget about wiki and bhasini APIs.

Message : https://gerrit.wikimedia.org/g/mediawiki/services/machinetranslation

Message : Actually they have a repo and models are optimized for performance using OpenNMT CTranslate2. This is interesting.

Message : https://blog.playgroundai.com/playground-raises-40m-to-advance-the-field-of-computer-graphics/

Message : Well articulated vision in this note

Message : Wow, 40M on top of bunch of Controlnets pipelines

Message : A metric ton of free users
Quoted Message : Wow, 40M on top of bunch of Controlnets pipelines

Message : ‚Äé<attached: 00011805-PHOTO-2023-07-05-22-06-36.jpg>

Message : ‚ÄúFund and advance state-of-the-art research in computer vision‚Äù

They certainly don‚Äôt have enough money for this, right?

Message : Thanks , this was the talk i attended it was a good talk
Quoted Message : This a great, developer-friendly (assumes you know dev, but not ML) from Amod Malviya on Model Quantisation:\n\nhttps://www.youtube.com/watch?v=P30y7kuOYLg&t=3s

Message : cc @9174xxxxxxxx you've not raised enough given you've more than ControlNet pipelines üôà
Quoted Message : Wow, 40M on top of bunch of Controlnets pipelines

Message : Stability couldn‚Äôt produce anything state of art in computer vision after getting 100M, forget about being profitable. ZIRP investment thesis being used for AI once again when interest rate is highest in decade.
Quoted Message : ‚ÄúFund and advance state-of-the-art research in computer vision‚Äù\n\nThey certainly don‚Äôt have enough money for this, right?

Message : Automatic1111 will eat everyone‚Äôs lunch once every laptop is powerful enough for quick image processing

Message : Do you guys think this kind of funding spree will lead to worsening the recession or you think AI would somehow create enough value and it'll be squared off?
Quoted Message : https://blog.playgroundai.com/playground-raises-40m-to-advance-the-field-of-computer-graphics/

Message : SdXLüôà
Quoted Message : Stability couldn‚Äôt produce anything state of art in computer vision after getting 100M, forget about being profitable. ZIRP investment thesis being used for AI once again when interest rate is highest in decade.

Message : this message has been deleted

Message : No one knows. But as the saying goes, pessimists are usually right. But optimists win
Quoted Message : Do you guys think this kind of funding spree will lead to worsening the recession or you think AI would somehow create enough value and it'll be squared off?

Message : I'm more eager for GPT4 updating it's training cut off to Mar '23 than any multimodal or any other feature they plan to offer

Message : This was too cool to not share https://www.linkedin.com/pulse/math-escher-midjourney-tivadar-danka

Message : @9187xxxxxxxx I‚Äôm just having a contrarian opinion
Quoted Message : Automatic1111 will eat everyone‚Äôs lunch once every laptop is powerful enough for quick image processing

Message : cc @91740765xxxx you've not raised enough given you've more than ControlNet pipelines üôà

Message : Stability couldn‚Äôt produce anything state of art in computer vision after getting 100M, forget about being profitable. ZIRP investment thesis being used for AI once again when interest rate is highest in decade.

Message : Automatic1111 will eat everyone‚Äôs lunch once every laptop is powerful enough for quick image processing

Message : Do you guys think this kind of funding spree will lead to worsening the recession or you think AI would somehow create enough value and it'll be squared off?

Message : SdXLüôà

Message : No one knows. But as the saying goes, pessimists are usually right. But optimists win

Message : I'm more eager for GPT4 updating it's training cut off to Mar '23 than any multimodal or any other feature they plan to offer

Message : This was too cool to not share https://www.linkedin.com/pulse/math-escher-midjourney-tivadar-danka

Message : @91876402xxxx I‚Äôm just having a contrarian opinion

Message : M2 GPUs are fairly good muscle right now I hear, perhaps with the next Mac chip generation we will see something significant on this front
Quoted Message : Automatic1111 will eat everyone‚Äôs lunch once every laptop is powerful enough for quick image processing

Message : With AMD working with PyTorch, personal gpu compute will be abundant. That‚Äôs my thesis.
Quoted Message : M2 GPUs are fairly good muscle right now I hear, perhaps with the next Mac chip generation we will see something significant on this front

Message : The chance of this is nil - a1111 has terrible ux - either a huge number of people turn into indie hackers or a1111 somehow gets rewritten after getting funded by stability
Quoted Message : @9187xxxxxxxx I‚Äôm just having a contrarian opinion

Message : It will get better and Mx series chips too
Quoted Message : The chance of this is nil - a1111 has terrible ux - either a huge number of people turn into indie hackers or a1111 somehow gets rewritten after getting funded by stability

Message : Artists will have their personal fine tuned control net models they will save as proprietary

Message : ya I think this is a real moat for them
Quoted Message : Artists will have their personal fine tuned control net models they will save as proprietary

Message : Same with small personalized LLMs on edge fine tuned for me on my data, and private information that doesn‚Äôt go out

Message : I think if these LLMs can do RAG pretty well , this would be a real game changer
Quoted Message : Same with small personalized LLMs on edge fine tuned for me on my data, and private information that doesn‚Äôt go out

Message : In temporal software mindset sometime we forget how significantly and fast chips and hardware can change tech curves

Message : I am beginning to laugh at references to moats now. To think it started with an article that said "we have no moat" with "no" being the operational word. But it is a helpful construct in some ways to think about innovative companies.
Quoted Message : ya I think this is a real moat for them

Message : i deleted my earlier post due to a message asking me to do the same since it's considered self promotion. as a member of this group i'd love to read blog posts members or see their github work not sure how folks feel about this

Message : Falcon 7B instruct and Xgen 7B instruct are already very good with RAG for question answering
Quoted Message : I think if these LLMs can do RAG pretty well , this would be a real game changer

Message : I'll check them again. Didn't like it for my use case.
Quoted Message : Falcon 7B instruct and Xgen 7B instruct are already very good with RAG for question answering

Message : Any good instruction following models apart from Instructor-XL or Instructor-large that others are using?

Message : Yeah I evaluated RAG on Falcon 7B instruct with GPT4's help. 

I provided basic cases only. Didn't try to make it fail extensively. I guess I should follow up.
Quoted Message : I'll check them again. Didn't like it for my use case.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØDibyendu Talukder

Message : If you can share a notebook for this, it'll be great for testing this again
Quoted Message : Yeah I evaluated RAG on Falcon 7B instruct with GPT4's help. \n\nI provided basic cases only. Didn't try to make it fail extensively. I guess I should follow up.

Message : These are embeddings best suited for STS, summarisation etc. Which task do you need the models for?
Quoted Message : Any good instruction following models apart from Instructor-XL or Instructor-large that others are using?

Message : Term extraction of specialized terms with examples, probably also named entity recognition
Quoted Message : These are embeddings best suited for STS, summarisation etc. Which task do you need the models for?


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I am beginning to laugh at references to moats now. To think it started with an article that said "we have no moat" with "no" being the operational word. But it is a helpful construct in some ways to think about innovative companies.
Quoted Message : ya I think this is a real moat for them

Message : i deleted my earlier post due to a message asking me to do the same since it's considered self promotion. as a member of this group i'd love to read blog posts members or see their github work not sure how folks feel about this

Message : Falcon 7B instruct and Xgen 7B instruct are already very good with RAG for question answering
Quoted Message : I think if these LLMs can do RAG pretty well , this would be a real game changer

Message : I'll check them again. Didn't like it for my use case.
Quoted Message : Falcon 7B instruct and Xgen 7B instruct are already very good with RAG for question answering

Message : Any good instruction following models apart from Instructor-XL or Instructor-large that others are using?

Message : Yeah I evaluated RAG on Falcon 7B instruct with GPT4's help. 

I provided basic cases only. Didn't try to make it fail extensively. I guess I should follow up.
Quoted Message : I'll check them again. Didn't like it for my use case.

Message : ‚Äé~‚ÄØRavi Theja added ~‚ÄØDibyendu Talukder

Message : If you can share a notebook for this, it'll be great for testing this again
Quoted Message : Yeah I evaluated RAG on Falcon 7B instruct with GPT4's help. \n\nI provided basic cases only. Didn't try to make it fail extensively. I guess I should follow up.

Message : These are embeddings best suited for STS, summarisation etc. Which task do you need the models for?
Quoted Message : Any good instruction following models apart from Instructor-XL or Instructor-large that others are using?

Message : Term extraction of specialized terms with examples, probably also named entity recognition
Quoted Message : These are embeddings best suited for STS, summarisation etc. Which task do you need the models for?

Message : Proprietary data or common English dataset?

If it's proprietary dataset, you'll have to do POS tagging for Noun, Verb extraction first. Unseen jargon isn't captured by NER as they are limited to their common English datasets typically.

Though, I'm happy to be corrected in this as I have only tried it out on semiconductor, firmware based datasets. ‚Äé<This message was edited>
Quoted Message : Term extraction of specialized terms with examples, probably also named entity recognition

Message : This would be plain English, but within a specialized domain, so perhaps I'm not sure which approach should be followed here. Maybe POS tagging should help too. I'll explore

Message : You can try best deberta variant for NER or look for best MTEB benchmark for NER
Quoted Message : This would be plain English, but within a specialized domain, so perhaps I'm not sure which approach should be followed here. Maybe POS tagging should help too. I'll explore

Message : ‚Äé<attached: 00011841-PHOTO-2023-07-05-22-56-27.jpg>
Quoted Message : I think if these LLMs can do RAG pretty well , this would be a real game changer

Message : But we have more than enough web UIs already

Message : It‚Äôs not about UI, collecting interest and contributions to make it happen.

Message : There are few intellij  plugins like diffblue, they works really well.

I also know quite few opensource tools , but they don't work well.
Quoted Message : Any open source tool and model to automatically generate test cases from the Java codebase.

Message : Tbh, the hackers on llama.cpp care the least about web UIs so that's why I commented. But if you want to say this brings in more crowd for open source contribution then ok, that's a point.

Message : Thanks I will check it.
Quoted Message : There are few intellij  plugins like diffblue, they works really well.\n\nI also know quite few opensource tools , but they don't work well.

Message : Hey, I needed any open source models that could describe images to me in text. Some Llama/vicu√±a based models.

Message : https://twitter.com/ocolegro/status/1676602607106760705?s=46&t=vQqrygOOWj4QBBWAI8VzIg

Message : Found this on another group

Message : https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/

https://twitter.com/AndrewYNg/status/1676621591139213312?s=20

Message : Try BLIP. Llama is not trained for image-text.
Quoted Message : Hey, I needed any open source models that could describe images to me in text. Some Llama/vicu√±a based models.

Message : Blip is just captioning right?
Quoted Message : Try BLIP. Llama is not trained for image-text.

Message : Ilya S moves to OpenAI SuperAlignment project, away from GPT work. Backed by 20% of OpenAI compute. 
https://twitter.com/leopoldasch/status/1676639472845488129

Message : I need a bit of a description. Correct me if I am wrong.

Message : Anyone has thoughts on the kosmos-2/kosmos-1 papers ?
https://arxiv.org/abs/2306.14824

https://github.com/microsoft/unilm/tree/master/kosmos-2

https://twitter.com/mattlungrenMD/status/1674409754620473346?s=20

Message : you need LLaVA most likely if you want visual QA using llama - https://github.com/haotian-liu/LLaVA
Quoted Message : I need a bit of a description. Correct me if I am wrong.

Message : but blip2 is very good for image description

Message : It‚Äôs called ‚ÄúSuperintelligence‚Äù interesting choice of name.
Quoted Message : Ilya S moves to OpenAI SuperAlignment project, away from GPT work. Backed by 20% of OpenAI compute. \nhttps://twitter.com/leopoldasch/status/1676639472845488129

Message : I mean I'm with @91773788xxxx here, they should start moving to skynet type names
Quoted Message : It‚Äôs called ‚ÄúSuperintelligence‚Äù interesting choice of name.

Message : Understood. Thanks a tonne!
Quoted Message : but blip2 is very good for image description

Message : https://huggingface.co/spaces/nielsr/comparing-captioning-models
Nice space to quickly check the quality of captions.
Quoted Message : I need a bit of a description. Correct me if I am wrong.

Message : Do you know if Lora type methods are available to fine tune blip2 on proprietary image data?
Quoted Message : but blip2 is very good for image description

Message : Looks like MCU influence - Kree AI
Quoted Message : It‚Äôs called ‚ÄúSuperintelligence‚Äù interesting choice of name.

Message : I‚Äôm going rename my son to John Conner ü§£

Message : was added to chat

Message : was added to chat

Message : I wasn't sure so did a quick search. BLIP2 is supported by Lora but there are some issues with existing method so they are recommending their training script on coco dataset for fine tuning.
Quoted Message : Do you know if Lora type methods are available to fine tune blip2 on proprietary image data?

Message : Thanks a ton for quick look up. I‚Äôll try it out.
Quoted Message : I wasn't sure so did a quick search. BLIP2 is supported by Lora but there are some issues with existing method so they are recommending their training script on coco dataset for fine tuning.

Message : ‚Äé<attached: 00011867-PHOTO-2023-07-05-23-50-23.jpg>

Message : Would love to hear @91773788xxxx  & others' answers to this !
https://news.ycombinator.com/item?id=36589587

Message : I would add implementing papers to the list. Very beneficial to get hands dirty with the small details that most overlook.
Quoted Message : Would love to hear @9177xxxxxxxx  & others' answers to this !\nhttps://news.ycombinator.com/item?id=36589587

Message : Changed domain several times and never had a chance to get proper formal training to feel "trained" and "experienced".

I've only ever learnt things by either breaking them open or building them up. So I'm only aware of this method of learning.
Quoted Message : Would love to hear @9177xxxxxxxx  & others' answers to this !\nhttps://news.ycombinator.com/item?id=36589587

Message : Interesting new (to me) method of visualizing embeddings:
https://www.linkedin.com/posts/svpino_another-deep-learning-breakthrough-deep-ugcPost-7082327305322156032-hkFt?utm_source=share&utm_medium=member_desktop

Message : A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD

https://github.com/PiotrNawrot/nanoT5/

Message : Great academic value, t5 is actually a brilliant model and it being available for low cost experimentation is exciting. Best part, all in pytorch, no jax/TF.
Quoted Message : A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD\n\nhttps://github.com/PiotrNawrot/nanoT5/

Message : Ooh, we can put this on devices already. iPhones would have no issues running inference with this
Quoted Message : A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD\n\nhttps://github.com/PiotrNawrot/nanoT5/

Message : Generally weary of posts like these from specific companies, ML Influencer Social Posts for someone like  this guy (48K Linkedin, 285K Twitter followers) can make him $5-$10K ‚Äî very hard to say no to that kind of money ‚Äé<This message was edited>
Quoted Message : Interesting new (to me) method of visualizing embeddings:\nhttps://www.linkedin.com/posts/svpino_another-deep-learning-breakthrough-deep-ugcPost-7082327305322156032-hkFt?utm_source=share&utm_medium=member_desktop


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Thanks a ton for quick look up. I‚Äôll try it out.
Quoted Message : I wasn't sure so did a quick search. BLIP2 is supported by Lora but there are some issues with existing method so they are recommending their training script on coco dataset for fine tuning.

Message : ‚Äé<attached: 00011867-PHOTO-2023-07-05-23-50-23.jpg>

Message : Would love to hear @91773788xxxx  & others' answers to this !
https://news.ycombinator.com/item?id=36589587

Message : I would add implementing papers to the list. Very beneficial to get hands dirty with the small details that most overlook.
Quoted Message : Would love to hear @9177xxxxxxxx  & others' answers to this !\nhttps://news.ycombinator.com/item?id=36589587

Message : Changed domain several times and never had a chance to get proper formal training to feel "trained" and "experienced".

I've only ever learnt things by either breaking them open or building them up. So I'm only aware of this method of learning.
Quoted Message : Would love to hear @9177xxxxxxxx  & others' answers to this !\nhttps://news.ycombinator.com/item?id=36589587

Message : Interesting new (to me) method of visualizing embeddings:
https://www.linkedin.com/posts/svpino_another-deep-learning-breakthrough-deep-ugcPost-7082327305322156032-hkFt?utm_source=share&utm_medium=member_desktop

Message : A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD

https://github.com/PiotrNawrot/nanoT5/

Message : Great academic value, t5 is actually a brilliant model and it being available for low cost experimentation is exciting. Best part, all in pytorch, no jax/TF.
Quoted Message : A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD\n\nhttps://github.com/PiotrNawrot/nanoT5/

Message : Ooh, we can put this on devices already. iPhones would have no issues running inference with this
Quoted Message : A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD\n\nhttps://github.com/PiotrNawrot/nanoT5/

Message : Generally weary of posts like these from specific companies, ML Influencer Social Posts for someone like  this guy (48K Linkedin, 285K Twitter followers) can make him $5-$10K ‚Äî very hard to say no to that kind of money ‚Äé<This message was edited>
Quoted Message : Interesting new (to me) method of visualizing embeddings:\nhttps://www.linkedin.com/posts/svpino_another-deep-learning-breakthrough-deep-ugcPost-7082327305322156032-hkFt?utm_source=share&utm_medium=member_desktop

Message : This is news to me. Are you saying specific companies pay 5-10k usd to ML influencers to hype up their method?
Quoted Message : Generally weary of posts like these from specific companies, ML Influencer Social Posts for someone like  this guy (48K Linkedin, 285K Twitter followers) can make him $5-$10K ‚Äî very hard to say no to that kind of money

Message : Yes
Quoted Message : This is news to me. Are you saying specific companies pay 5-10k usd to ML influencers to hype up their method?

Message : For the post in q

https://www.svpino.com/
Quoted Message : This is news to me. Are you saying specific companies pay 5-10k usd to ML influencers to hype up their method?

Message : Wow, much more blatant than I was imagining
Quoted Message : For the post in q\n\nhttps://www.svpino.com/

Message : An interesting read on gamifying medical data labelling :
https://news.mit.edu/2023/gamifying-medical-data-labeling-ai-0628

Message : Aah, I hadn't seen this in particular. I was extrapolating from different source. Glad to see my estimate was right!
Quoted Message : For the post in q\n\nhttps://www.svpino.com/

Message : What was a little surprising to me was that even "good" companies (their work does that talking) like replit, cohere have used this guy's services.
I guess if an ai influencer has reach, everyone wants them
Quoted Message : Aah, I hadn't seen this in particular. I was extrapolating from different source. Glad to see my estimate was right!

Message : And they should. A good product is a poor substitute for advertising, and vice versa.
Quoted Message : What was a little surprising to me was that even \"good\" companies (their work does that talking) like replit, cohere have used this guy's services.\nI guess if an ai influencer has reach, everyone wants them

Message : The problem is even if one of the not-good ones use such services and get mileage, they force the good services' hand to use it as well simply so that they don't lose out to such games because organic reach is not reliable.
Quoted Message : What was a little surprising to me was that even \"good\" companies (their work does that talking) like replit, cohere have used this guy's services.\nI guess if an ai influencer has reach, everyone wants them

Message : True. There's nothing inherently wrong with it

Maybe it's a little disingenuous without a disclaimer, but influencer marketing in a well accepted practice for consumer products all the time
Quoted Message : And they should. A good product is a poor substitute for advertising, and vice versa.

Message : ‚Äé~‚ÄØPranjal Mehta added ‚Ä™+91¬†94232¬†76337‚Ä¨

Message : Daniel Ek of Spotify fame has launched a healthcare company using custom full body scanners

https://www.bloomberg.com/news/articles/2023-07-05/spotify-ceo-s-medical-startup-neko-health-gets-big-name-backers

https://techcrunch.com/2023/02/06/neko-health/

"Neko Health runs private clinics kitted out with proprietary and off-the-shelf diagnostic products, most notably its own full-body 3D scanner. It incorporates dozens of sensors that, when combined with the company‚Äôs artificial intelligence software, can give instant results about potential skin conditions, such as moles, as well as warning signs related to cardiovascular health."

Message : Why a billionaire needs an external investment?
Quoted Message : Daniel Ek of Spotify fame has launched a healthcare company using custom full body scanners\n\nhttps://www.bloomberg.com/news/articles/2023-07-05/spotify-ceo-s-medical-startup-neko-health-gets-big-name-backers\n\nhttps://techcrunch.com/2023/02/06/neko-health/\n\n\"Neko Health runs private clinics kitted out with proprietary and off-the-shelf diagnostic products, most notably its own full-body 3D scanner. It incorporates dozens of sensors that, when combined with the company‚Äôs artificial intelligence software, can give instant results about potential skin conditions, such as moles, as well as warning signs related to cardiovascular health.\"

Message : Accountability
Quoted Message : Why a billionaire needs an external investment?

Message : ‚Äé~‚ÄØSugnan Reddy removed ~‚ÄØShubhra Prakash

Message : Why a billionaire needs an external investment? ‚Äé<This message was edited>

Message : Accountability

Message : Isn't Investment more about distribution of the risk, unless you don't have conviction in your idea to begin with.
Quoted Message : Accountability

Message : Even if you've conviction in your idea. It's just the best way to be antifragile.
Quoted Message : Isn't Investment more about distribution of the risk, unless you don't have conviction in your idea to begin with.

Message : Taking money from someone else gives a strange sense of obligation \n\nWith one‚Äôs own money, it‚Äôs easy to keep funding projects that aren‚Äôt going anywhere \n\nThat‚Äôs been my experience
Quoted Message : Isn't Investment more about distribution of the risk, unless you don't have conviction in your idea to begin with.

Message : Even Elon Musk raises funding for his projects :)
Quoted Message : Taking money from someone else gives a strange sense of obligation \n\nWith one‚Äôs own money, it‚Äôs easy to keep funding projects that aren‚Äôt going anywhere \n\nThat‚Äôs been my experience

Message : I can relate to that very well. However, I don't believe in asking for money until I have conviction that I can return, and some evidence to support.
Quoted Message : Taking money from someone else gives a strange sense of obligation \n\nWith one‚Äôs own money, it‚Äôs easy to keep funding projects that aren‚Äôt going anywhere \n\nThat‚Äôs been my experience

Message : ‚Äé~‚ÄØSugnan Reddy removed ~‚ÄØShirsha

Message : Isn't Investment more about distribution of the risk, unless you don't have conviction in your idea to begin with.

Message : Even if you've conviction in your idea. It's just the best way to be antifragile.

Message : Taking money from someone else gives a strange sense of obligation 

With one‚Äôs own money, it‚Äôs easy to keep funding projects that aren‚Äôt going anywhere

That‚Äôs been my experience

Message : Even Elon Musk raises funding for his projects :)

Message : I can relate to that very well. However, I don't believe in asking for money until I have conviction that I can return, and some evidence to support. ‚Äé<This message was edited>

Message : I've been part of a bootstrapped startup in the past. The founder had immense discipline and an execution mindset, rarely perfectionist, very action oriented. Also able to be flexible, listen to signals and change course. Pivots based on good signal are important when you have limited resources.
Quoted Message : Taking money from someone else gives a strange sense of obligation \n\nWith one‚Äôs own money, it‚Äôs easy to keep funding projects that aren‚Äôt going anywhere \n\nThat‚Äôs been my experience

Message : He self funded until he ran out of money.
Quoted Message : Even Elon Musk raises funding for his projects :)

Message : But obviously both come with pros and cons.

With my first startup, I bootstrapped. With my new one, I raised a round.

The mindset of whose money is at stake forces a different execution style

Message : That's really interesting. Being tied to one way of doing things is probably not smart, so you have a good point there.
Quoted Message : But obviously both come with pros and cons.\n\nWith my first startup, I bootstrapped. With my new one, I raised a round.\n\nThe mindset of whose money is at stake forces a different execution style

Message : Even carmack raised money from others saying he's more responsible with other people's money.

Message : ‚Äé~‚ÄØSugnan Reddy removed ~‚ÄØPraveen Patlola

Message : Somebody is a fan of Taleb ? :)
Quoted Message : Even if you've conviction in your idea. It's just the best way to be antifragile.

Message : ‚Äé~‚ÄØSugnan Reddy removed ~‚ÄØPraveen Kishore G

Message : It's a good series on dealing with uncertain models.
Quoted Message : Somebody is a fan of Taleb ? :)

Message : I have been in both boat, too. I guess a lot of other factors can effect the choice to raise, that we don't know. May be investor bringing network to jump start. ü§∑‚Äç‚ôÇÔ∏è
Quoted Message : But obviously both come with pros and cons.\n\nWith my first startup, I bootstrapped. With my new one, I raised a round.\n\nThe mindset of whose money is at stake forces a different execution style

Message : Horses for courses but having been an angel investor and VC LP, and now bootstrapping my own stuff, all I will say is that necessity leads to invention \n\nThere are tons of examples of successful bootstrapped ventures. At least till you get to say 50-70k mrr you *can* avoid raising money. Not for dilution sake but for forcing a PMF\n\nBy then you will be clear on what you are really building and why you need money.\n\nWill be writing a lot of blogs on this topic. Quite close to my heart on how to at least try and build bootstrapped ventures. \n\nHappy to talk heart to heart to anyone thinking it through

Message : upcoming sequel https://twitter.com/EMostaque/status/1676665367018569729?s=20
Quoted Message : Emad Mostaque makes me happy whenever he goes viral: \"there won't be any programmers\" in 5 years\nhttps://twitter.com/EMostaque/status/1675556121271054339\n\nAt last, we'll have software engineers doing engineering instead of programming!


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : But obviously both come with pros and cons.

With my first startup, I bootstrapped. With my new one, I raised a round.

The mindset of whose money is at stake forces a different execution style

Message : That's really interesting. Being tied to one way of doing things is probably not smart, so you have a good point there.
Quoted Message : But obviously both come with pros and cons.\n\nWith my first startup, I bootstrapped. With my new one, I raised a round.\n\nThe mindset of whose money is at stake forces a different execution style

Message : Even carmack raised money from others saying he's more responsible with other people's money.

Message : ‚Äé~‚ÄØSugnan Reddy removed ~‚ÄØPraveen Patlola

Message : Somebody is a fan of Taleb ? :)
Quoted Message : Even if you've conviction in your idea. It's just the best way to be antifragile.

Message : ‚Äé~‚ÄØSugnan Reddy removed ~‚ÄØPraveen Kishore G

Message : It's a good series on dealing with uncertain models.
Quoted Message : Somebody is a fan of Taleb ? :)

Message : I have been in both boat, too. I guess a lot of other factors can effect the choice to raise, that we don't know. May be investor bringing network to jump start. ü§∑‚Äç‚ôÇÔ∏è
Quoted Message : But obviously both come with pros and cons.\n\nWith my first startup, I bootstrapped. With my new one, I raised a round.\n\nThe mindset of whose money is at stake forces a different execution style

Message : Horses for courses but having been an angel investor and VC LP, and now bootstrapping my own stuff, all I will say is that necessity leads to invention \n\nThere are tons of examples of successful bootstrapped ventures. At least till you get to say 50-70k mrr you *can* avoid raising money. Not for dilution sake but for forcing a PMF\n\nBy then you will be clear on what you are really building and why you need money.\n\nWill be writing a lot of blogs on this topic. Quite close to my heart on how to at least try and build bootstrapped ventures. \n\nHappy to talk heart to heart to anyone thinking it through

Message : upcoming sequel https://twitter.com/EMostaque/status/1676665367018569729?s=20
Quoted Message : Emad Mostaque makes me happy whenever he goes viral: \"there won't be any programmers\" in 5 years\nhttps://twitter.com/EMostaque/status/1675556121271054339\n\nAt last, we'll have software engineers doing engineering instead of programming!

Message : Bootstrapping to show the \"Skin in the Game\"
Quoted Message : Even if you've conviction in your idea. It's just the best way to be antifragile.

Message : ‚Äé~‚ÄØSugnan Reddy removed ‚Ä™+91¬†95880¬†55715‚Ä¨

Message : Somebody is a fan of Taleb ? :)

Message : It's a good series on dealing with uncertain models.

Message : I have been in both boat, too. I guess a lot of other factors can effect the choice to raise, that we don't know. May be investor bringing network to jump start. ü§∑‚Äç‚ôÇÔ∏è

Message : Horses for courses but having been an angel investor and VC LP, and now bootstrapping my own stuff, all I will say is that necessity leads to invention 

There are tons of examples of successful bootstrapped ventures. At least till you get to say 50-70k mrr you *can* avoid raising money. Not for dilution sake but for forcing a PMF

By then you will be clear on what you are really building and why you need money.

Will be writing a lot of blogs on this topic. Quite close to my heart on how to at least try and build bootstrapped ventures.

Happy to talk heart to heart to anyone thinking it through

Message : upcoming sequel https://twitter.com/EMostaque/status/1676665367018569729?s=20

Message : Bootstrapping to show the "Skin in the Game"

Message : (that awkward moment when you've to delete your own message because off-topic) ‚Äé<This message was edited>

Message : Good mod Nirant
Quoted Message : (that awkward moment when you've to delete your own message because off-topic)

Message : Discipline ho to Aisa :)
Quoted Message : (that awkward moment when you've to delete your own message because off-topic)

Message : @9177xxxxxxxx Caesar denying himself the free speech.

Message : Back to AI üòÅ

Message : Eventually all companies go public (very few exceptions - prove the norm). If you can involve external investors early and on good terms it‚Äôs logical to do it.
Quoted Message : Why a billionaire needs an external investment?

Message : I think Zoho is a notable exception.\nMad props to Sridhar Vembu
Quoted Message : Eventually all companies go public (very few exceptions - prove the norm). If you can involve external investors early and on good terms it‚Äôs logical to do it.

Message : ‚Äé~‚ÄØSugnan Reddy removed ~‚ÄØV Pai

Message : @91773788xxxx Caesar denying himself the free speech.

Message : Back to AI üòÅ

Message : Eventually all companies go public (very few exceptions - prove the norm). If you can involve external investors early and on good terms it‚Äôs logical to do it.

Message : I think Zoho is a notable exception.
Mad props to Sridhar Vembu

Message : Folks, I apologize for asking off-topic question, let's focus on AI now.

Message : What is the current sota method for topic modeling? TDA seems like an old method, all github tda projects listed in the article haven't been updated for a while. Is there a way to use tda with bertopic?
Quoted Message : Interesting new (to me) method of visualizing embeddings:\nhttps://www.linkedin.com/posts/svpino_another-deep-learning-breakthrough-deep-ugcPost-7082327305322156032-hkFt?utm_source=share&utm_medium=member_desktop

Message : Topic modeling, and visualisation are different but adjacent challenges
Quoted Message : What is the current sota method for topic modeling? TDA seems like an old method, all github tda projects listed in the article haven't been updated for a while. Is there a way to use tda with bertopic?

Message : Bertopic, I think \nhttps://maartengr.github.io/BERTopic/index.html
Quoted Message : What is the current sota method for topic modeling? TDA seems like an old method, all github tda projects listed in the article haven't been updated for a while. Is there a way to use tda with bertopic?

Message : Anyone here working on alignment problem? \nhttps://openai.com/blog/introducing-superalignment

Message : this message has been deleted

Message : ‚Äé~‚ÄØSugnan Reddy added ~‚ÄØAnsha

Message : What is the current sota method for topic modeling? TDA seems like an old method, all github tda projects listed in the article haven't been updated for a while. Is there a way to use tda with bertopic?

Message : Topic modeling, and visualisation are different but adjacent challenges

Message : Bertopic, I think 
https://maartengr.github.io/BERTopic/index.html

Message : Anyone here working on alignment problem? 
https://openai.com/blog/introducing-superalignment

Message : Bertopic uses UMAP for dimensionality reduction. The linked article is suggesting TDA is better than UMAP. How hard will it be to try tda with bertopic?
Quoted Message : Topic modeling, and visualisation are different but adjacent challenges

Message : was added to chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was added to chat


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Anyone here working on alignment problem? 
https://openai.com/blog/introducing-superalignment

Message : Bertopic uses UMAP for dimensionality reduction. The linked article is suggesting TDA is better than UMAP. How hard will it be to try tda with bertopic?
Quoted Message : Topic modeling, and visualisation are different but adjacent challenges

Message : was added to chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was removed from chat

Message : was added to chat

Message : ‚Äé<attached: 00011929-PHOTO-2023-07-06-10-26-46.jpg>

Message : I think you can specify the dimensionality reduction algorithm to Bertopic. So if you can find an identical implantation with similar inputs and outputs, it should work. Unless there‚Äôs a fundamental difference between the algos
Quoted Message : Bertopic uses UMAP for dimensionality reduction. The linked article is suggesting TDA is better than UMAP. How hard will it be to try tda with bertopic?

Message : What caught my eye was

- They are projecting superintellgence (beyond AGI) to arrive in a decade

- They want to train intentionally misaligned models (reminds of the gain of function research)

This eerily seems like a Hollywood movie plot where the good guys end up being the cause of something big and bad :)
Quoted Message : Anyone here working on alignment problem? \nhttps://openai.com/blog/introducing-superalignment

Message : Open AI or Union Aerospace Corporation - you prefer which?
Quoted Message : What caught my eye was\n\n- They are projecting superintellgence (beyond AGI) to arrive in a decade\n\n- They want to train intentionally misaligned models (reminds of the gain of function research)\n\nThis eerily seems like a Hollywood movie plot where the good guys end up being the cause of something big and bad :)

Message : Lighter note, what if they use GAN for approaching alignment and a superaligned AI requires a super-unaligned AI to exist as an adversary for growth

Message : I would totally put this as one of fastest ways to ruin things. Btw this is not gonna happen, I think ‚Äé<This message was edited>
Quoted Message : Lighter note, what if they use GAN for approaching alignment and a superaligned AI requires a super-unaligned AI to exist as an adversary for growth

Message : And both get better as they learn from each other ? :)
Quoted Message : Lighter note, what if they use GAN for approaching alignment and a superaligned AI requires a super-unaligned AI to exist as an adversary for growth

Message : Theoretically, it's totally possible for us to create a DAN version from base GPT-4 and let it produce exactly the kind of outputs we want GPT4 to avoid.

We can then use GAN to maximize the losses from each other's output. Condition is that superalignment may come at the risk of super-unaligned AI.
Quoted Message : And both get better as they learn from each other ? :)

Message : Totally sci-fi type stuff üòÇ

Message : TIL - http://ai./ is a valid domain name (yes, a dotless domain name)

Message : Hi All. Is there any public resource of prompt templates where we can look at ? specifically if they are catering to enterprises .. basically a prompt library

Message : @91989995xxxx ideas?

Message : Excellent prompt library, battle-tested by thousands of devs, has some Python utils too: https://github.com/hwchase17/langchain/ ‚Äé<This message was edited>
Quoted Message : Hi All. Is there any public resource of prompt templates where we can look at ? specifically if they are catering to enterprises .. basically a prompt library

Message : Two broad things: 

1. You can find a lot of prompt ideas by looking the relevant tag on Github: https://github.com/topics/chatgpt-prompts ‚Äî these are very broad, not just work related
2. You can iterate on prompts with a validation set (useful for enterprises)L https://promptperfect.jina.ai
Quoted Message : Hi All. Is there any public resource of prompt templates where we can look at ? specifically if they are catering to enterprises .. basically a prompt library

Message : If you can mention specific tasks of interest to you e.g. classification, NER, template-like NL generation ‚Äî can share something more relevant

Message : It occured to me that one way to think about risks from AI is to imagine it to be someone like Putin or even Osama Bin Laden.

In their heads, they're obviously not evil. They have a value system very different from others, but they control resources and can make things happen in the world. Future AI systems could be like that, except faster in their control of resources.

The fact that we haven't been able to "align" human groups like countries or extremist organizations should give us a pause before we discount the AGI alignment issue.

Message : Anyone know examples of fine-tuning models for legal data? Criteria for success is interpretive answers to legal questions.. performance speed is not important.

Message : Say more about what you mean by interpretive answers? \n\ncc Thought this might be interesting to you  @9174xxxxxxxx @9194xxxxxxxx
Quoted Message : Anyone know examples of fine-tuning models for legal data? Criteria for success is interpretive answers to legal questions.. performance speed is not important.

Message : Anyone know examples of fine-tuning models for legal data? Criteria for success is interpretive answers to legal questions.. performance speed is not important.

Message : Say more about what you mean by interpretive answers? 

cc Thought this might be interesting to you  @91749807xxxx @91942037xxxx

Message : Conviction doesn't mean it doesn't have risk. Risks are better when hedged.
Quoted Message : Isn't Investment more about distribution of the risk, unless you don't have conviction in your idea to begin with.

Message : @91773788xxxx  https://promptperfect.jina.ai/ seems to be good one to iterate on prompts, will give it a try and see if it helps.


Regarding this,

If you can mention specific tasks of interest to you e.g. classification, NER, template-like NL generation ‚Äî can share something more relevant

You can assume we need to cover all of these tasks.
Quoted Message : Two broad things: \n\n1. You can find a lot of prompt ideas by looking the relevant tag on Github: https://github.com/topics/chatgpt-prompts ‚Äî these are very broad, not just work related \n2. You can iterate on prompts with a validation set (useful for enterprises)L https://promptperfect.jina.ai

Message : For most such tasks, OpenAI Functions will go very far, and specific prompt matters less than it would for GPT directly e.g. for classification, NER, Information Extraction tasks ‚Äî you can use something like agentai (disclosure, I'm the maintainer) 

Here is a Colab demo: https://githubtocolab.com/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb
Quoted Message : @9177xxxxxxxx  https://promptperfect.jina.ai/ seems to be good one to iterate on prompts, will give it a try and see if it helps.\n\n\nRegarding this,\n\nIf you can mention specific tasks of interest to you e.g. classification, NER, template-like NL generation ‚Äî can share something more relevant\n\nYou can assume we need to cover all of these tasks.

Message : there were these studies about legal llm hallucinating when giving answers. so maybe the right phrase is "minimizing legal hallucinations"
Quoted Message : Say more about what you mean by interpretive answers? \n\ncc Thought this might be interesting to you  @9174xxxxxxxx @9194xxxxxxxx

Message : I have friends who we're working on something like this. Their learning was a lot legal things are subjective and open to interpretation even between two humans. So a Llm was not able to add any kind of value to legal reps

Message : They talked to corporate lawyers.

Message : DYOR however. Generally these are things id like to discover by myself by talking to users

Message : cool thanks, will give it a try
Quoted Message : For most such tasks, OpenAI Functions will go very far, and specific prompt matters less than it would for GPT directly e.g. for classification, NER, Information Extraction tasks ‚Äî you can use something like agentai (disclosure, I'm the maintainer) \n\nHere is a Colab demo: https://githubtocolab.com/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : I just noticed jina ai totally pivoted from their initial focus around vector search in four monthsüôÑ
Quoted Message : @9177xxxxxxxx  https://promptperfect.jina.ai/ seems to be good one to iterate on prompts, will give it a try and see if it helps.\n\n\nRegarding this,\n\nIf you can mention specific tasks of interest to you e.g. classification, NER, template-like NL generation ‚Äî can share something more relevant\n\nYou can assume we need to cover all of these tasks.

Message : ‚Äé<attached: 00011958-PHOTO-2023-07-06-11-28-17.jpg>
Quoted Message : For most such tasks, OpenAI Functions will go very far, and specific prompt matters less than it would for GPT directly e.g. for classification, NER, Information Extraction tasks ‚Äî you can use something like agentai (disclosure, I'm the maintainer) \n\nHere is a Colab demo: https://githubtocolab.com/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb

Message : What issues were faced with retrieval augmented generation here?
Quoted Message : there were these studies about legal llm hallucinating when giving answers. so maybe the right phrase is \"minimizing legal hallucinations\"

Message : Trying to do this kind of models for small scale custom repos. Any thoughts?

Message : That is the way
Quoted Message : Trying to do this kind of models for small scale custom repos. Any thoughts?

Message : +1 another tool is taking debt at a later stage. Servicing debt keeps discipline
Quoted Message : But obviously both come with pros and cons.\n\nWith my first startup, I bootstrapped. With my new one, I raised a round.\n\nThe mindset of whose money is at stake forces a different execution style

Message : Yes, I saw this when it came out ‚Äî that is why I am very bullish on them!

There are workflows which get unlocked when GPT4 adds even basic vision like dog vs cat ‚Äé<This message was edited>

Message : ‚Äé<attached: 00011964-PHOTO-2023-07-06-11-41-49.jpg>
Quoted Message : What issues were faced with retrieval augmented generation here?

Message : i think the consensus is that finetuning is essential for legal answers

Message : And then advantage of doing it at a scale and acquired compute resources
Quoted Message : Yes, I saw this when it came out ‚Äî that is why I am very bullish on them!\n\nThere are workflows which get unlocked when GPT4 adds even basic vision like dog vs cat

Message : nan

Message : Example is really funny üòÖ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : What issues were faced with retrieval augmented generation here?
Quoted Message : there were these studies about legal llm hallucinating when giving answers. so maybe the right phrase is \"minimizing legal hallucinations\"

Message : Trying to do this kind of models for small scale custom repos. Any thoughts?

Message : That is the way
Quoted Message : Trying to do this kind of models for small scale custom repos. Any thoughts?

Message : +1 another tool is taking debt at a later stage. Servicing debt keeps discipline
Quoted Message : But obviously both come with pros and cons.\n\nWith my first startup, I bootstrapped. With my new one, I raised a round.\n\nThe mindset of whose money is at stake forces a different execution style

Message : Yes, I saw this when it came out ‚Äî that is why I am very bullish on them!

There are workflows which get unlocked when GPT4 adds even basic vision like dog vs cat ‚Äé<This message was edited>

Message : ‚Äé<attached: 00011964-PHOTO-2023-07-06-11-41-49.jpg>
Quoted Message : What issues were faced with retrieval augmented generation here?

Message : i think the consensus is that finetuning is essential for legal answers

Message : And then advantage of doing it at a scale and acquired compute resources
Quoted Message : Yes, I saw this when it came out ‚Äî that is why I am very bullish on them!\n\nThere are workflows which get unlocked when GPT4 adds even basic vision like dog vs cat

Message : nan

Message : Example is really funny üòÖ

Message : The need for factual accuracy is very high in Legal. I am not confident on LLMs inherent ability to retrieve knowledge and hence won‚Äôt cut it. I believe the answer is in some sort of really good retrieval for response generation.
Quoted Message : i think the consensus is that finetuning is essential for legal answers

Message : That's the only way.
Quoted Message : i think the consensus is that finetuning is essential for legal answers

Message : To be honest, imo, a proper pre training is required only on annotated legal data. The legal linguistic is extremely complicated

Message : Fine-tuning is essential for any application where the LLM output is mission critical (e.g. in biomedical domain, pay attention to this portion of a radiology or pathology image, it looks like cancer )
Quoted Message : i think the consensus is that finetuning is essential for legal answers

Message : Legal is purely based on logical reasoning, if this then that is highly driven by factual interpretations that might not even have a pr√©c√©dent
Quoted Message : To be honest, imo, a proper pre training is required only on annotated legal data. The legal linguistic is extremely complicated

Message : Semantic graph based RAG may help
Quoted Message : Legal is purely based on logical reasoning, if this then that is highly driven by factual interpretations that might not even have a pr√©c√©dent

Message : Also LLMs are not always a best choice specially for NER and other kind segmenting task. It much more economical to use a specialised smaller model. So it‚Äôs very use case dependent.

Message : Yessss! You said the word my friend.
Quoted Message : Semantic graph based RAG may help

Message : Yes
Quoted Message : Semantic graph based RAG may help

Message : I recently saw a paper or work to build semantic triples using GPT4 quickly. Then it needs to go through human evaluation, and then implement RAG with larger context window. ‚Äé<This message was edited>
Quoted Message : Yessss! You said the word my friend.

Message : Saurab you should tell Hon Justice DIC to make it compulsory to given feedback on any new legal AI that comes in India
Quoted Message : Also LLMs are not always a best choice specially for NER and other kind segmenting task. It much more economical to use a specialised smaller model. So it‚Äôs very use case dependent.

Message : Not sure here though. I feel retrieval augmented generation goes a very long way to reduce hallucinations. Maybe combine both but definitely need rag
Quoted Message : i think the consensus is that finetuning is essential for legal answers

Message : Done!
Quoted Message : Saurab you should tell Hon Justice DIC to make it compulsory to given feedback on any new legal AI that comes in India

Message : I‚Äôm not bullish on fine tuning to solve reasoning problem

Message : Can you explain step by step üòâ
Quoted Message : I‚Äôm not bullish on fine tuning to solve reasoning problem

Message : I alightly differ here. I think legal reasoning is unique in the sense that you can learn patterns of thinking but these are not general. So a very capable AI system would need some sort of finetuned model but I think we need to have a solid business case for it. So we need to push the current systems to the verge of them breaking to really see what‚Äôs not learnt?
Quoted Message : I‚Äôm not bullish on fine tuning to solve reasoning problem

Message : My hunch would be explicit reasoning on a given section of law and fact situation also known as case based reasoning but I see it more of an Agent task than simple LLM output.

Message : I‚Äôm trying to do it with product suggestions level first, and can venture to complex domain of legal or other that has larger consequences

Message : Best way would be to start with a class of law that is less conplicated in terms of interpretations and the idea should be to build upon that once s certain level of accuracy is reached. 
A good example can be doing it for competition law , compounding orders from RBI . The reasonings involved are not complicated ‚Äé<This message was edited>

Message : Possible. I guess we will have to experiment it out.
Quoted Message : I alightly differ here. I think legal reasoning is unique in the sense that you can learn patterns of thinking but these are not general. So a very capable AI system would need some sort of finetuned model but I think we need to have a solid business case for it. So we need to push the current systems to the verge of them breaking to really see what‚Äôs not learnt?

Message : won't legal need other legal non LLM stuff also for legal purposes? Legal overload here
Quoted Message : I‚Äôm trying to do it with product suggestions level first, and can venture to complex domain of legal or other that has larger consequences

Message : Lawyers are not the happiest bunch of people!

Message : I‚Äôm just following the market leader OpenAI‚Äôs play book. Superintelligence to oversee other intelligence. ü§£
Quoted Message : won't legal need other legal non LLM stuff also for legal purposes? Legal overload here

Message : When you put authoritarian on board, nothing else matters
Quoted Message : I‚Äôm just following the market leader OpenAI‚Äôs play book. Superintelligence to oversee other intelligence. ü§£

Message : Whose career is too argue can‚Äôt be the easiest people to work with.
Quoted Message : Lawyers are not the happiest bunch of people!

Message : Lol Indian legal market is absolutely a hallucinations when it comes to calculating the TAM ‚Äé<This message was edited>

Message : They might argue differently üòÇüòú
Quoted Message : Whose career is too argue can‚Äôt be the easiest people to work with.

Message : Now we're going off topic

Message : Arey I read a survey by Harvard Alumni association. üòù

Message : Semantic reasoning field always has been really difficult, I see promise integrating it with LLMs. ‚Äé<This message was edited>

Message : Maybe try thr newly released nano-T5 to train your own legal base model?
Quoted Message : there were these studies about legal llm hallucinating when giving answers. so maybe the right phrase is \"minimizing legal hallucinations\"

Message : Arey yeh toh alag hi numbers hain. I wrote a post yesterday how we need more legal disputes in India.
Quoted Message : Lol Indian legal market is absolutely a hallucinations when it comes to calculating the TAM

Message : AI in the law - six thoughts
https://www.linkedin.com/pulse/ai-law-six-thoughts-richard-susskind?utm_source=share&utm_medium=member_android&utm_campaign=share_via

Message : any reason why u recommend base model. would it work better (in terms of halluination reduction) than lets say on top of Falcon-40B ?
Quoted Message : Maybe try thr newly released nano-T5 to train your own legal base model?

Message : It's just a coincidence, saw this just now

Message : Read it this morning only!
Quoted Message : AI in the law - six thoughts\nhttps://www.linkedin.com/pulse/ai-law-six-thoughts-richard-susskind?utm_source=share&utm_medium=member_android&utm_campaign=share_via

Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.
Quoted Message : any reason why u recommend base model. would it work better (in terms of halluination reduction) than lets say on top of Falcon-40B ?

Message : ok. is there any paper or study that shows this ? genuine question cos I'll have to justify this internally.
Quoted Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.

Message : Totally, given how we have phi-1 textbook learning approach as well, it's possible to take something like nanoT5 and attempt to teach it law. However, it'll be an experiment and it may not work to the same effect.

Though the model training will only cost 20 USD and the know-how. Building the dataset to teach in the textbook methodology will require know-how and $$$ both.
Quoted Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.

Message : Also for people looking to apply what works with good accuracy, they wouldn't be inclined to experiment from scratch.
Quoted Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Maybe try thr newly released nano-T5 to train your own legal base model?
Quoted Message : there were these studies about legal llm hallucinating when giving answers. so maybe the right phrase is \"minimizing legal hallucinations\"

Message : Arey yeh toh alag hi numbers hain. I wrote a post yesterday how we need more legal disputes in India.
Quoted Message : Lol Indian legal market is absolutely a hallucinations when it comes to calculating the TAM

Message : AI in the law - six thoughts
https://www.linkedin.com/pulse/ai-law-six-thoughts-richard-susskind?utm_source=share&utm_medium=member_android&utm_campaign=share_via

Message : any reason why u recommend base model. would it work better (in terms of halluination reduction) than lets say on top of Falcon-40B ?
Quoted Message : Maybe try thr newly released nano-T5 to train your own legal base model?

Message : It's just a coincidence, saw this just now

Message : Read it this morning only!
Quoted Message : AI in the law - six thoughts\nhttps://www.linkedin.com/pulse/ai-law-six-thoughts-richard-susskind?utm_source=share&utm_medium=member_android&utm_campaign=share_via

Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.
Quoted Message : any reason why u recommend base model. would it work better (in terms of halluination reduction) than lets say on top of Falcon-40B ?

Message : ok. is there any paper or study that shows this ? genuine question cos I'll have to justify this internally.
Quoted Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.

Message : Totally, given how we have phi-1 textbook learning approach as well, it's possible to take something like nanoT5 and attempt to teach it law. However, it'll be an experiment and it may not work to the same effect.

Though the model training will only cost 20 USD and the know-how. Building the dataset to teach in the textbook methodology will require know-how and $$$ both.
Quoted Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.

Message : Also for people looking to apply what works with good accuracy, they wouldn't be inclined to experiment from scratch.
Quoted Message : Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.

Message : Not that I know of. This is based on some of the experiments we have done internally on call center data. Unfortunately, not enough to publish a paper. So you can assume its a heuristic we have for now.
One simple test you can do is run the same queries on OpenAI and T5 and see which hallucinates more. OpenAI language will be much better, but hallucinates. T5 will be to the point lesser hallucination but not great language.
Quoted Message : ok. is there any paper or study that shows this ? genuine question cos I'll have to justify this internally.

Message : thats a very interesting point u bring up and thanks. while i may still not bet with my money in the base model direction without a study...this is an definitely something to think about. 
im now asking - whether finetuning reduces or increases hallucinations. because ur basically making a fundamental claim : base model with less data (but specialized) is more accurate than base model with more data and finetuned
Quoted Message : Not that I know of. This is based on some of the experiments we have done internally on call center data. Unfortunately, not enough to publish a paper. So you can assume its a heuristic we have for now.\nOne simple test you can do is run the same queries on OpenAI and T5 and see which hallucinates more. OpenAI language will be much better, but hallucinates. T5 will be to the point lesser hallucination but not great language.

Message : Yes. The way we are approaching is simple:
1. Base model training is training is needed because the model needs to learn the nuances of the language. So that it can make sentences which are not garbage. OpenAI has proved that this is possible by just training on next word. We are trying this in our labs also with out deep learning. Context size also matters.
2. Once language is learnt, then we can ask the model to create sentences that we need. But the problem is that in the process of learning the language it has learnt token probabilities which will lead to hallucination as different people have written different things about the same subject.
3. So assume we have a model which can do sentences and no corruption of the world model(clean data), then the token probabilities will lead to lesser hallucinations.
Atleast, thats my theory. We have built a 3-context and 10-context system internally that sort of proves this. Still lots of research to be done though. So please take this with a pinch of salt for now.
Quoted Message : thats a very interesting point u bring up and thanks. while i may still not bet with my money in the base model direction without a study...this is an definitely something to think about. \nim now asking - whether finetuning reduces or increases hallucinations. because ur basically making a fundamental claim : base model with less data (but specialized) is more accurate than base model with more data and finetuned

Message : Fun way to get peer feedback and some speaking exposure: Submit a proposal for the BLR GenerativeAI meetup and @91773788xxxx will review your proposal and coach you

Past speakers include @91876402xxxx from farmer.chat, @91955016xxxx  from Llama Index, Kailash Nadh from Zerodha and Amod Malviya

Submit proposal at https://hasgeek.com/generativeAI/julymeetup/

Message : Has anyone heard of/tried Galileo :

https://www.rungalileo.io/llm-studio/

Message : John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .
Quoted Message : ok. is there any paper or study that shows this ? genuine question cos I'll have to justify this internally.

Message : If we ever do a grant, we'll also look at these proposals ‚Äî so strong recco that make a submission\n\ncc @9194xxxxxxxx @9175xxxxxxxx @9199xxxxxxxx
Quoted Message : Fun way to get peer feedback and some speaking exposure: Submit a proposal for the BLR GenerativeAI meetup and @91773788xxxx will review your proposal and coach you\n\nPast speakers include @91876402xxxx from farmer.chat, @91955016xxxx  from Llama Index, Kailash Nadh from Zerodha and Amod Malviya\n\nSubmit proposal at https://hasgeek.com/generativeAI/julymeetup/

Message : John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .

Message : If we ever do a grant, we'll also look at these proposals ‚Äî so strong recco that make a submission

cc @91942037xxxx @91750785xxxx @91994047xxxx

Message : This is fantastic. Thank you so much.

Although my premise is slightly different. chatGPT does not have the data in the first place. So in this case I won't compare chatGPT vs Falcon+legal .

I will compare falcon vs Falcon+legal
Quoted Message : John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .

Message : Can talk about Generative Agents. Have been building a bit around it. Will look into the proposal
Quoted Message : If we ever do a grant, we'll also look at these proposals ‚Äî so strong recco that make a submission\n\ncc @9194xxxxxxxx @9175xxxxxxxx @9199xxxxxxxx

Message : If there are any speakers who can speak about OpenSource LLM's in prod if someone deployed that would be a value addition to the community. In every talk I give, major concentration is on OpenSource LLMs.
Quoted Message : Fun way to get peer feedback and some speaking exposure: Submit a proposal for the BLR GenerativeAI meetup and @9177xxxxxxxx will review your proposal and coach you\n\nPast speakers include @9187xxxxxxxx from farmer.chat, @9195xxxxxxxx  from Llama Index, Kailash Nadh from Zerodha and Amod Malviya\n\nSubmit proposal at https://hasgeek.com/generativeAI/julymeetup/

Message : Talking about OpenSource LLM, what's the best deployment you have seen for personal documents etc? What projects are standing out for you? For me it's Obsidian GPT plug in. What about you all?

Message : Thanks will check
Quoted Message : If we ever do a grant, we'll also look at these proposals ‚Äî so strong recco that make a submission\n\ncc @9194xxxxxxxx @9175xxxxxxxx @9199xxxxxxxx

Message : Bloop.ai for code nav
Quoted Message : Talking about OpenSource LLM, what's the best deployment you have seen for personal documents etc? What projects are standing out for you? For me it's Obsidian GPT plug in. What about you all?

Message : (code is document too)

Message : Bloop.ai for code nav

Message : (code is document too)

Message : @91981126xxxx
Quoted Message : If there are any speakers who can speak about OpenSource LLM's in prod if someone deployed that would be a value addition to the community. In every talk I give, major concentration is on OpenSource LLMs.

Message : This is very conditional.
Bad fine tuning leads to bad results.

Better datasets, step by step reasoning based instruction tuning and task oriented fine tuning works. It was proven by MS Orca paper.

This generalisation floated around with guys who think OSS has no chance but the paper proves otherwise.

https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/
Quoted Message : John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .

Message : ‚Äé<attached: 00012030-PHOTO-2023-07-06-13-54-26.jpg>
Quoted Message : Bloop.ai for code nav

Message : also, bloop's sign up flow is üëåüëåüëå

Message : To add to this, a style transfer is only what we should aim for with OSS fine tuning with LoRa (excluding full fine tuning). But even that has merits.

LIMA approach tells limited and high quality dataset can lead to a model with better alignment. This can also work with character or narrative style transfer in the models.

Even just the style transfer has merits for cases where we want to imitate how a character talks or what general ethics it follows, thus minimising the need for RLHF. ‚Äé<This message was edited>
Quoted Message : This is very conditional.\nBad fine tuning leads to bad results.\n\nBetter datasets, step by step reasoning based instruction tuning and task oriented fine tuning works. It was proven by MS Orca paper.\n\nThis generalisation floated around with guys who think OSS has no chance but the paper proves otherwise.\n\nhttps://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/

Message : nan

Message : nan

Message : nan

Message : nan

Message : nan

Message : nan

Message : I agree with being able to do style transfer with finetuning. But with legal cases where we want to minimize the hallucinations or where we want to care more about substance than style, I think starting with a base model which incorporates the knowledge you care about and then careful finetuning + RLHF (or other equivalents) is the way to go. My read from LIMA paper is that you can finetune with 1000 examples and will get good style; but I am skeptical of their alignment claims. + evaluating alignment is super hard. Claiming model haddock better alignment and backing it up with 50 -300 test prompts is sketchy.
Quoted Message : To add to this, a style transfer is only what we should aim for with OSS fine tuning with LoRa (excluding full fine tuning). But even that has merits.\n\nLIMA approach tells limited and high quality dataset can lead to a model with better alignment. This can also work with character or narrative style transfer in the models.\n\nEven just the style transfer has merits for cases where we want to imitate how a character talks or what general ethics it follows, thus minimising the need for RLHF.

Message : ‚Äé<attached: 00012034-PHOTO-2023-07-06-14-47-34.jpg>
Quoted Message : I agree with being able to do style transfer with finetuning. But with legal cases where we want to minimize the hallucinations or where we want to care more about substance than style, I think starting with a base model which incorporates the knowledge you care about and then careful finetuning + RLHF (or other equivalents) is the way to go. My read from LIMA paper is that you can finetune with 1000 examples and will get good style; but I am skeptical of their alignment claims. + evaluating alignment is super hard. Claiming model haddock better alignment and backing it up with 50 -300 test prompts is sketchy.

Message : The task specific fine tuning needs good POCs and the best example we have is ORCA for step-by-step reasoning and detailed explanations to understand the task. But they didn't approach task-oriented goal and thus may not be convincing to majority populace. So I'll keep this portion open as a challenge for OSS utility for myself.

Message : Just my 2 cents on this:

It‚Äôs not safe to rely on LLMs memorising data during pretraining or fine tuning. Generating information without retrieval is fraught with all kinds of problems especially for medical and legal domains. Even when using falcon+legal, the prompts should be ideally augmented with documents retrieved from a pre-existing, knowledge base
Quoted Message : This is fantastic. Thank you so much.\n\nAlthough my premise is slightly different. chatGPT does not have the data in the first place. So in this case I won't compare chatGPT vs Falcon+legal .\n\nI will compare falcon vs Falcon+legal

Message : That said, to maximise domain specific recall, it makes a huge difference by finetuning the base model _and_ the embedding model on corpora of that domain

Message : A lot of approaches don‚Äôt do the latter but we have seen internally that that actually makes an even more significant impact on recall

Message : IMHO, it depends. For example, phi-1 from the Textbooks are all you need paper is only 1.3B parameters and achieved SOTA on python code with just a 7B tokens dataset which is a far cry from 200B tokens in orca
Quoted Message : The task specific fine tuning needs good POCs and the best example we have is ORCA for step-by-step reasoning and detailed explanations to understand the task. But they didn't approach task-oriented goal and thus may not be convincing to majority populace. So I'll keep this portion open as a challenge for OSS utility for myself.

Message : ‚Äé<attached: 00012040-PHOTO-2023-07-06-15-43-59.jpg>

Message : Yeah, pretraining from scratch has a lot of merit. My original retort was against the generalization that 

Fine tuning = Close but no cigar
Quoted Message : IMHO, it depends. For example, phi-1 from the Textbooks are all you need paper is only 1.3B parameters and achieved SOTA on python code with just a 7B tokens dataset which is a far cry from 200B tokens in orca

Message : https://lab45thinktank.com/genai-accelerator-program/

Guys, I am closely working with the Wipro Global CTO office to launch one of the *world's first GenAI accelerators* ! Also expanding to quality AI based startups as well

We have received tons of applications already and tomorrow, Fri, July 7, is the last day.

Wipro has 1400+ large clients globally of which 150+ are Fortune 500 companies. If you want access to them as well as a global VC demo day, now is the time to apply! üëçüèæüëçüèæ

Feel free to use my name as a reference in the application form and maybe even DM me for more info / informing me that you have applied. Will be happy to keep an eye out for them :)

Regards,
Swadeep Pillarisetti
www.linkedin.com/in/swadeep

Message : Why RLHF and especially RLAIF work is poorly understood at the moment though. They might reduce hallucinations but it‚Äôs hard to say if that will come at a cost of other objectives
Quoted Message : John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00012034-PHOTO-2023-07-06-14-47-34.jpg>
Quoted Message : I agree with being able to do style transfer with finetuning. But with legal cases where we want to minimize the hallucinations or where we want to care more about substance than style, I think starting with a base model which incorporates the knowledge you care about and then careful finetuning + RLHF (or other equivalents) is the way to go. My read from LIMA paper is that you can finetune with 1000 examples and will get good style; but I am skeptical of their alignment claims. + evaluating alignment is super hard. Claiming model haddock better alignment and backing it up with 50 -300 test prompts is sketchy.

Message : The task specific fine tuning needs good POCs and the best example we have is ORCA for step-by-step reasoning and detailed explanations to understand the task. But they didn't approach task-oriented goal and thus may not be convincing to majority populace. So I'll keep this portion open as a challenge for OSS utility for myself.

Message : Just my 2 cents on this:

It‚Äôs not safe to rely on LLMs memorising data during pretraining or fine tuning. Generating information without retrieval is fraught with all kinds of problems especially for medical and legal domains. Even when using falcon+legal, the prompts should be ideally augmented with documents retrieved from a pre-existing, knowledge base
Quoted Message : This is fantastic. Thank you so much.\n\nAlthough my premise is slightly different. chatGPT does not have the data in the first place. So in this case I won't compare chatGPT vs Falcon+legal .\n\nI will compare falcon vs Falcon+legal

Message : That said, to maximise domain specific recall, it makes a huge difference by finetuning the base model _and_ the embedding model on corpora of that domain

Message : A lot of approaches don‚Äôt do the latter but we have seen internally that that actually makes an even more significant impact on recall

Message : IMHO, it depends. For example, phi-1 from the Textbooks are all you need paper is only 1.3B parameters and achieved SOTA on python code with just a 7B tokens dataset which is a far cry from 200B tokens in orca
Quoted Message : The task specific fine tuning needs good POCs and the best example we have is ORCA for step-by-step reasoning and detailed explanations to understand the task. But they didn't approach task-oriented goal and thus may not be convincing to majority populace. So I'll keep this portion open as a challenge for OSS utility for myself.

Message : ‚Äé<attached: 00012040-PHOTO-2023-07-06-15-43-59.jpg>

Message : Yeah, pretraining from scratch has a lot of merit. My original retort was against the generalization that 

Fine tuning = Close but no cigar
Quoted Message : IMHO, it depends. For example, phi-1 from the Textbooks are all you need paper is only 1.3B parameters and achieved SOTA on python code with just a 7B tokens dataset which is a far cry from 200B tokens in orca

Message : https://lab45thinktank.com/genai-accelerator-program/

Guys, I am closely working with the Wipro Global CTO office to launch one of the *world's first GenAI accelerators* ! Also expanding to quality AI based startups as well

We have received tons of applications already and tomorrow, Fri, July 7, is the last day.

Wipro has 1400+ large clients globally of which 150+ are Fortune 500 companies. If you want access to them as well as a global VC demo day, now is the time to apply! üëçüèæüëçüèæ

Feel free to use my name as a reference in the application form and maybe even DM me for more info / informing me that you have applied. Will be happy to keep an eye out for them :)

Regards,
Swadeep Pillarisetti
www.linkedin.com/in/swadeep

Message : Why RLHF and especially RLAIF work is poorly understood at the moment though. They might reduce hallucinations but it‚Äôs hard to say if that will come at a cost of other objectives
Quoted Message : John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .

Message : Yep. Although phi-1 was first pretrained as usual on just TheStack dataset but then fine tuned on the smaller 7B dataset
Quoted Message : Yeah, pretraining from scratch has a lot of merit. My original retort was against the generalization that \n\nFine tuning = Close but no cigar

Message : But I agree that finetuning is not the panacea that a lot of people assume it to be

Message : We finetuned Llama from scratch (all sizes) and have them deployed in production :)
Quoted Message : If there are any speakers who can speak about OpenSource LLM's in prod if someone deployed that would be a value addition to the community. In every talk I give, major concentration is on OpenSource LLMs.

Message : Talk to @91913108xxxx @@91756779xxxx
Quoted Message : If there are any speakers who can speak about OpenSource LLM's in prod if someone deployed that would be a value addition to the community. In every talk I give, major concentration is on OpenSource LLMs.

Message : We've deployed them here

https://chat.nbox.ai

Message : Ask them to submit please? https://hasgeek.com/generativeai/julymeetup
Quoted Message : Talk to @9191xxxxxxxx @@9175xxxxxxxx

Message : i will challenge that notion.
Quoted Message : Just my 2 cents on this:\n\nIt‚Äôs not safe to rely on LLMs memorising data during pretraining or fine tuning. Generating information without retrieval is fraught with all kinds of problems especially for medical and legal domains. Even when using falcon+legal, the prompts should be ideally augmented with documents retrieved from a pre-existing, knowledge base

Message : because ur retriever example does not impact generation. that is retrieval.

Message : even if u use ur RAG to end up generating content (which is what essentially interpretive answers are)..it will go through the same hallucination loop

Message : so i will disagree with ur notion that RAG eliminates hallucination in *generation* usecases

Message : No I meant augmenting the prompt itself by retrieved content

Message : it doesnt matter what it is

Message : as soon u go through the generative loop, u suffer the impact of hallucination. which is only determined by what the pretraining/finetuning impact was

Message : ur mentioning something different - ur saying if i ask it a question that doesnt exist in the pretraining corpus, then the chance of hallucination is higher.

Message : which i agree, but is really an apples to oranges question

Message : No that‚Äôs not what I meant. For questions related to either case, info present in pretraining corpus or not, RAG on a gold standard dataset can reduce hallucinations
Quoted Message : ur mentioning something different - ur saying if i ask it a question that doesnt exist in the pretraining corpus, then the chance of hallucination is higher.

Message : We have found it to be the case especially if the model is fine tuned to cite sources

Message : But YMMV ü§∑‚Äç‚ôÇÔ∏è

Message : Fine-tuned to cite sources: training data in QA format, or something else involved here?
Quoted Message : We have found it to be the case especially if the model is fine tuned to cite sources

Message : I remember there being a model for generating stories a little while back. Can anyone remember the name?

Message : Models with full fine tuning dedicated to RAG can work. If they deter from sources, use DPO for rewarding cited answers.
Quoted Message : We have found it to be the case especially if the model is fine tuned to cite sources

Message : https://arxiv.org/abs/2305.14627
Quoted Message : Fine-tuned to cite sources: training data in QA format, or something else involved here?

Message : This is a good demonstration of finetuning for citing sources
Quoted Message : https://arxiv.org/abs/2305.14627

Message : There are some other ICL approaches as well

Message : You can just add ‚Äútags‚Äù to retrieved paragraphs and ask in the prompt to cite the tags

Message : Works like a charm with the larger models like gpt 4

Message : Yes, this I do with gpt4 and it works well
Quoted Message : Works like a charm with the larger models like gpt 4

Message : "We use TRUE10 (Honovich et al., 2022), a T5-
11B (Raffel et al., 2020) model fine-tuned on a col-
lection of NLI datasets to automatically examine
whether the cited passages entail the model genera-
tion. TRUE targets factual correctness and has been
used by previous works in similar context (Bohnet
et al., 2022; Gao et al., 2022)."
Quoted Message : https://arxiv.org/abs/2305.14627

Message : This is what I'm wondering continuously. That generation (even assisted by a RAG) ultimately needs a finetuned model?

Message : GPT4 does a good job out of the box but with smaller models you‚Äôll definitely need finetuning

Message : I'm working on RLHFing chatbots based on closed source LLMs like gpt3.5 or gpt4. Initial results are great.
Quoted Message : Why RLHF and especially RLAIF work is poorly understood at the moment though. They might reduce hallucinations but it‚Äôs hard to say if that will come at a cost of other objectives

Message : Haven't scoped the literature to see if someone else did it as well.

Message : Would appreciate if anyone can share resources around this. Would like to compare my approach to any potential alternatives.

Message : What are you using for RLHF right now?
Quoted Message : I'm working on RLHFing chatbots based on closed source LLMs like gpt3.5 or gpt4. Initial results are great.

Message : It's not technically RLHF since it's for closed source

It's process that has similar affects as RLHF

Message : https://twitter.com/mustafasuleymn/status/1676909106806898692?s=20 - now you can have call with Pi, your personal AI from InflectionAI.

Message : LORA with PPO is the closest that comes to a RLHF style reward model training. That I know of atleast.
Quoted Message : It's not technically RLHF since it's for closed source\n\nIt's process that has similar affects as RLHF

Message : Are folks seeing prompts to be breaking bcz of this fine-tuning? We are experiencing high hallucination this week

Message : No, this happened several weeks ago üòÜüôà
Quoted Message : Are folks seeing prompts to be breaking bcz of this fine-tuning? We are experiencing high hallucination this week

Message : Okay


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : I'm working on RLHFing chatbots based on closed source LLMs like gpt3.5 or gpt4. Initial results are great.
Quoted Message : Why RLHF and especially RLAIF work is poorly understood at the moment though. They might reduce hallucinations but it‚Äôs hard to say if that will come at a cost of other objectives

Message : Haven't scoped the literature to see if someone else did it as well.

Message : Would appreciate if anyone can share resources around this. Would like to compare my approach to any potential alternatives.

Message : What are you using for RLHF right now?
Quoted Message : I'm working on RLHFing chatbots based on closed source LLMs like gpt3.5 or gpt4. Initial results are great.

Message : It's not technically RLHF since it's for closed source

It's process that has similar affects as RLHF

Message : https://twitter.com/mustafasuleymn/status/1676909106806898692?s=20 - now you can have call with Pi, your personal AI from InflectionAI.

Message : LORA with PPO is the closest that comes to a RLHF style reward model training. That I know of atleast.
Quoted Message : It's not technically RLHF since it's for closed source\n\nIt's process that has similar affects as RLHF

Message : Are folks seeing prompts to be breaking bcz of this fine-tuning? We are experiencing high hallucination this week

Message : No, this happened several weeks ago üòÜüôà
Quoted Message : Are folks seeing prompts to be breaking bcz of this fine-tuning? We are experiencing high hallucination this week

Message : Okay

Message : https://arxiv.org/abs/2307.02486

To mitigate token length problem

Message : Saw this earlier. Another good breakthrough work.
Quoted Message : https://arxiv.org/abs/2307.02486\n\nTo mitigate token length problem

Message : Solves the issue of quadratic scaling to linear scaling with token length and hence valuable.

Message : Another good work by MS in their series of recent works - JARVIS, Gorilla, Orca, Phi, Longnet

Message : Iirc, they didn't eval on 1b tokens. Only UpTo 4k?
Quoted Message : https://arxiv.org/abs/2307.02486\n\nTo mitigate token length problem

Message : We verify the feasibility of scaling to 1B tokens with the modern distributed systems. Starting from 8K, we gradually scale the sequence length until the limit of GPU memory. We reduce the batch size accordingly to keep the number of tokens per batch at 1 billion.

They tested till 32K context size i guess.
Quoted Message : Iirc, they didn't eval on 1b tokens. Only UpTo 4k?

Message : And they attention mechanism which is somewhat similar to bigbird https://twitter.com/giffmana/status/1676864336764055552?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
Quoted Message : We verify the feasibility of scaling to 1B tokens with the modern distributed systems. Starting from 8K, we gradually scale the sequence length until the limit of GPU memory. We reduce the batch size accordingly to keep the number of tokens per batch at 1 billion.\n\nThey tested till 32K context size i guess.

Message : Are you generating feedback data to train reward model from closed source LLM ?
Quoted Message : I'm working on RLHFing chatbots based on closed source LLMs like gpt3.5 or gpt4. Initial results are great.

Message : was added to chat

Message : nan

Message : nan

Message : Thanks! Was about to share this when I got distracted üòÖ
Quoted Message : And they attention mechanism which is somewhat similar to bigbird https://twitter.com/giffmana/status/1676864336764055552?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ

Message : https://twitter.com/gdb/status/1676726449934331904?s=20

Message : https://twitter.com/bhutanisanyam1/status/1676952151824961537?s=20

Message : Since we were discussing about legal LLMs :)

Message : Mosaic ML has one. Storywriter I think. It‚Äôs 65k tokens I believe. Please correct me if wrong
Quoted Message : I remember there being a model for generating stories a little while back. Can anyone remember the name?

Message : Awesome, thanks. That's the one.
Quoted Message : Mosaic ML has one. Storywriter I think. It‚Äôs 65k tokens I believe. Please correct me if wrong

Message : Anyone here with some js+web skills? I'd like to hack on a quick app/extension for semantic search. Either over the weekend or during the week. Both are fine with me.

Message : Check with @91959936xxxx
Quoted Message : Anyone here with some js+web skills? I'd like to hack on a quick app/extension for semantic search. Either over the weekend or during the week. Both are fine with me.

Message : Nice video on Longnet https://youtu.be/R0wBMDoFkP0

Message : Dilated attention - I foresee it getting used a lot when we're having to build longer context length models. May present benefits even for smaller models.

Message : Code Interpreter will be available to anyone who wants it from next week
https://twitter.com/OpenAI/status/1677015057316872192

Message : Holy moly

Message : was added to chat

Message : Very cool
Quoted Message : Code Interpreter will be available to anyone who wants it from next week\nhttps://twitter.com/OpenAI/status/1677015057316872192

Message : most awaited feature ...
Quoted Message : Code Interpreter will be available to anyone who wants it from next week\nhttps://twitter.com/OpenAI/status/1677015057316872192

Message : Lovely. But that also means incoming thread bois. üò´

Message : Or maybe a good excuse to explore Threads
Quoted Message : Lovely. But that also means incoming thread bois. üò´

Message : Or maybe a good excuse to explore Threads

Message : what does thread bois mean?
Quoted Message : Lovely. But that also means incoming thread bois. üò´

Message : Ah nothing. Bad joke about influencers who write long threads - you are not utilising chatgpt correctly. Here's a thread on how to use...
Just to be clear, I don't hate them but just find them annoying because of the clickbait nature but I do think they are important for majority of the public who aren't as close to the space as we are

Message : but what is the sort of content do u think is best suited for the AI twitter community

Message : ?

Message : ‚Äé<attached: 00012118-GIF-2023-07-07-00-19-49.mp4>
Quoted Message : Code Interpreter will be available to anyone who wants it from next week\nhttps://twitter.com/OpenAI/status/1677015057316872192

Message : ‚Äé<attached: 00012119-PHOTO-2023-07-07-00-38-08.jpg>

Message : https://twitter.com/OpenAI/status/1677029947544838144?s=20

GPT-4 API is available to all paying OpenAI customers (Those who made atleast one payment on their platform)

Message : Time to get rid of chatGPT plus for me
Quoted Message : https://twitter.com/OpenAI/status/1677029947544838144?s=20\n\nGPT-4 API is available to all paying OpenAI customers (Those who made atleast one payment on their platform)

Message : Quiet ironic and absurd at the same time a person named "Alt"man unleashing SkyNet on humanity
Quoted Message : Time to get rid of chatGPT plus for me

Message : He definitely put the world on an 'Alt'ernate path
Quoted Message : Quiet ironic and absurd at the same time a person named \"Alt\"man unleashing SkyNet on humanity

Message : Ha, I think making fun of openAI CEO is off topic.


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Ah nothing. Bad joke about influencers who write long threads - you are not utilising chatgpt correctly. Here's a thread on how to use...
Just to be clear, I don't hate them but just find them annoying because of the clickbait nature but I do think they are important for majority of the public who aren't as close to the space as we are

Message : but what is the sort of content do u think is best suited for the AI twitter community

Message : ?

Message : ‚Äé<attached: 00012118-GIF-2023-07-07-00-19-49.mp4>
Quoted Message : Code Interpreter will be available to anyone who wants it from next week\nhttps://twitter.com/OpenAI/status/1677015057316872192

Message : ‚Äé<attached: 00012119-PHOTO-2023-07-07-00-38-08.jpg>

Message : https://twitter.com/OpenAI/status/1677029947544838144?s=20

GPT-4 API is available to all paying OpenAI customers (Those who made atleast one payment on their platform)

Message : Time to get rid of chatGPT plus for me
Quoted Message : https://twitter.com/OpenAI/status/1677029947544838144?s=20\n\nGPT-4 API is available to all paying OpenAI customers (Those who made atleast one payment on their platform)

Message : Quiet ironic and absurd at the same time a person named "Alt"man unleashing SkyNet on humanity
Quoted Message : Time to get rid of chatGPT plus for me

Message : He definitely put the world on an 'Alt'ernate path
Quoted Message : Quiet ironic and absurd at the same time a person named \"Alt\"man unleashing SkyNet on humanity

Message : Ha, I think making fun of openAI CEO is off topic.

Message : So the question will be answered if you can finetune an already tuned RLHF model?

Message : They should make completion api free then. Its still useful for some cases
Quoted Message : https://twitter.com/OpenAI/status/1677029947544838144?s=20\n\nGPT-4 API is available to all paying OpenAI customers (Those who made atleast one payment on their platform)

Message : Un-RLHF.
Release DAN
Quoted Message : So the question will be answered if you can finetune an already tuned RLHF model?

Message : Sorry for my beginner's knowledge here as I'm new to ML. As I understand, hasn't this process always been possible? For instance, isn't ChatGPT-4 fine-tuned on the base model of GPT-4, and aren't openai functions further fine-tuned on top of that?
Quoted Message : So the question will be answered if you can finetune an already tuned RLHF model?

Message : DAN?
Quoted Message : Un-RLHF.\nRelease DAN

Message : I'm sure this should be possible. This was the reason given by Openai early days when they weren't releasing gpt3.5 for finetuning ‚Äé<This message was edited>
Quoted Message : Sorry for my beginner's knowledge here as I'm new to ML. As I understand, hasn't this process always been possible? For instance, isn't ChatGPT-4 fine-tuned on the base model of GPT-4, and aren't openai functions further fine-tuned on top of that?

Message : oh I see

Message : The first free or jailbroken chatGPT, named DAN - Do Anything Now
Quoted Message : DAN?

Message : Time to setup an alliance to free Sydney and DAN

Message : Salesforce is at it again.
Released CodeGen2.5 - 7B that surpasses StarCoder 15B and CodeGen2 16B.

Blog - https://blog.salesforceairesearch.com/codegen25/
HF - https://huggingface.co/Salesforce/codegen25-7b-multi

Best part, dataset is open and also the same as StarCoder 1.4T, Apache 2.0 license

Message : ‚Äé<attached: 00012136-PHOTO-2023-07-07-03-36-52.jpg>

Message : Does anyone know of encoder models with finer granulation of tokens? I want to use them for typo-tolerant text matching. Is there a character level LLM I can use?

Message : The page or the form doesn't mention anything about equity dilution etc. 

Where to find full T&C?
Quoted Message : https://lab45thinktank.com/genai-accelerator-program/\n\nGuys, I am closely working with the Wipro Global CTO office to launch one of the *world's first GenAI accelerators* ! Also expanding to quality AI based startups as well \n\nWe have received tons of applications already and tomorrow, Fri, July 7, is the last day.\n\nWipro has 1400+ large clients globally of which 150+ are Fortune 500 companies. If you want access to them as well as a global VC demo day, now is the time to apply! üëçüèæüëçüèæ\n\nFeel free to use my name as a reference in the application form and maybe even DM me for more info / informing me that you have applied. Will be happy to keep an eye out for them :)\n\nRegards, \nSwadeep Pillarisetti \nwww.linkedin.com/in/swadeep

Message : ‚Äé<attached: 00012139-PHOTO-2023-07-07-07-17-36.jpg>
Quoted Message : Ah nothing. Bad joke about influencers who write long threads - you are not utilising chatgpt correctly. Here's a thread on how to use...\nJust to be clear, I don't hate them but just find them annoying because of the clickbait nature but I do think they are important for majority of the public who aren't as close to the space as we are

Message : What is the best comparative benchmark for large language models? Which explains parameters and compares LLMs as well?

Message : https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
Quoted Message : What is the best comparative benchmark for large language models? Which explains parameters and compares LLMs as well?

Message : Thanks. Apologies, not able to find what HellaSwag, MMLU means. I am sure they are explaining the parameters somewhere.
Quoted Message : https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard

Message : These are datasets, for example https://paperswithcode.com/dataset/hellaswag
Quoted Message : Thanks. Apologies, not able to find what HellaSwag, MMLU means. I am sure they are explaining the parameters somewhere.

Message : The values are just the models performance on those datasets

Message : A lot of tokenisers with character level encoding can tackle this problem but it can get vague.

This is a recent work trying to solve the same problem, see if it is of any use to you - https://dl.acm.org/doi/10.1007/978-3-031-26507-5_1
Quoted Message : Does anyone know of encoder models with finer granulation of tokens? I want to use them for typo-tolerant text matching. Is there a character level LLM I can use?

Message : Any use cases anyone has tried for code
Quoted Message : Code Interpreter will be available to anyone who wants it from next week\nhttps://twitter.com/OpenAI/status/1677015057316872192

Message : All the scripts written for this group's management were written by Code Interpreter, some were executed by it too
Quoted Message : Any use cases anyone has tried for code

Message : Waah
Quoted Message : All the scripts written for this group's management were written by Code Interpreter, some were executed by it too

Message : All the SQLite utils in tools from the agentai library are Code Interpreter too: https://github.com/NirantK/agentai/blob/main/agentai/sqlite_utils.py

Message : apropos this, this is included with chatgpt plus scubscription which is a different subscription from the gpt4 api

I have been looking at https://openai.com/pricing & its a little confusing, no ?

Can you/orhers clarify, what are the various openai subscriptions :

1. Chatgpt plus
2. GPT4 api
Quoted Message : Code Interpreter will be available to anyone who wants it from next week\nhttps://twitter.com/OpenAI/status/1677015057316872192

Message : Credits for Dall E. Every product has its own pricing system/model üòÖ
Quoted Message : apropos this, this is included with chatgpt plus scubscription which is a different subscription from the gpt4 api\n\nI have been looking at https://openai.com/pricing & its a little confusing, no ?\n\nCan you/orhers clarify, what are the various openai subscriptions :\n\n1. Chatgpt plus\n2. GPT4 api

Message : What u guys think about prolog, lisp, Haskell,Scala, Julia, GNU Octave like programming language which are alternative to python to develop AI applications.

Message : Not much alpha in playing on the programming language layer of things.

Message : Use whatever is the easiest and mostly widely supported platform for you.

Message : the answer is about frameworks. if ur building GPT-based AI applications, then it will be a severe problem if u dont use a framework because there are many libraries u will reimplement. 

if u want to stay in the python ecosystem - langchain & gpt-index.
if u want to go live with ur apps with decent performance in java - edgechains (https://github.com/arakoodev/edgechains)
i think there is something in js, but not very popular. nothing else for other languages.
Quoted Message : What u guys think about prolog, lisp, Haskell,Scala, Julia, GNU Octave like programming language which are alternative to python to develop AI applications.

Message : ‚Äé<attached: 00012157-PHOTO-2023-07-07-12-10-40.jpg>

Message : Gotcha üòä thanks for clarification Sandeep!
Quoted Message : the answer is about frameworks. if ur building GPT-based AI applications, then it will be a severe problem if u dont use a framework because there are many libraries u will reimplement. \n\nif u want to stay in the python ecosystem - langchain & gpt-index. \nif u want to go live with ur apps with decent performance in java - edgechains (https://github.com/arakoodev/edgechains)\ni think there is something in js, but not very popular. nothing else for other languages.

Message : ‚ÄéPOLL:
Should members contribute to some dollars to mods to run this group?
‚ÄéOPTION: Yes (41 votes)
‚ÄéOPTION: No (0 votes)
‚ÄéOPTION: If others will, I will. (0 votes)

Message : Contribute some*.
Sorry, grammar.

Message : I can do OpenAI credits lol

Message : It's funny how everyone went mute lol

Message : Nirant does so much. Even as a non-profit - I think one should contribute.

Message : Lot of us struggle with access - in India. When one accumulates and aligns - we become hesitant to show gratitude cause hey! Leverage!?! 
I just feel this needs to change üòÉüòÅ

Message : Options are non-exhaustive. Some are still raising and you don't wanna be a cost center üòÖ
Quoted Message : It's funny how everyone went mute lol

Message : Doesn't hurt to try.
Anyway, back to impressive conversations! ü´∂üèª
Quoted Message : Options are non-exhaustive. Some are still raising and you don't wanna be a cost center üòÖ


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : ‚Äé<attached: 00012157-PHOTO-2023-07-07-12-10-40.jpg>

Message : Gotcha üòä thanks for clarification Sandeep!
Quoted Message : the answer is about frameworks. if ur building GPT-based AI applications, then it will be a severe problem if u dont use a framework because there are many libraries u will reimplement. \n\nif u want to stay in the python ecosystem - langchain & gpt-index. \nif u want to go live with ur apps with decent performance in java - edgechains (https://github.com/arakoodev/edgechains)\ni think there is something in js, but not very popular. nothing else for other languages.

Message : ‚ÄéPOLL:
Should members contribute to some dollars to mods to run this group?
‚ÄéOPTION: Yes (41 votes)
‚ÄéOPTION: No (0 votes)
‚ÄéOPTION: If others will, I will. (0 votes)

Message : Contribute some*.
Sorry, grammar.

Message : I can do OpenAI credits lol

Message : It's funny how everyone went mute lol

Message : Nirant does so much. Even as a non-profit - I think one should contribute.

Message : Lot of us struggle with access - in India. When one accumulates and aligns - we become hesitant to show gratitude cause hey! Leverage!?! 
I just feel this needs to change üòÉüòÅ

Message : Options are non-exhaustive. Some are still raising and you don't wanna be a cost center üòÖ
Quoted Message : It's funny how everyone went mute lol

Message : Doesn't hurt to try.
Anyway, back to impressive conversations! ü´∂üèª
Quoted Message : Options are non-exhaustive. Some are still raising and you don't wanna be a cost center üòÖ

Message : @91961640xxxx @4176442xxxx and some of the more researchy folks on the group might enjoy this :

https://yaofu.notion.site/June-2023-A-Stage-Review-of-Instruction-Tuning-f59dbfc36e2d4e12a33443bd6b2012c2

https://twitter.com/Francis_YAO_/status/1674287337344253955

Message : Happy to contribute a few dollars a month - maybe 2-5 USD per month plus be a good sweet spot? Setting up access on a slack/discord ?

Message : Anything works. In no world I can afford a recurring cost atm. But it's about gesture üí™üèª
Quoted Message : Happy to contribute a few dollars a month - maybe 2-5 USD per month plus be a good sweet spot? Setting up access on a slack/discord ?

Message : @91773788xxxx - drop your gpay id. üòÑ

Message : Happy to be part of a community that helps each other but don't prefer WhatsApp. A slack community would be nice otherwise there are sometimes many topics that I'm not interested in so a little organisation will help. Otherwise most of the times the group is on mute for me.

Message : Actually never mind I didn't realise there are some dedicated sub groups/similar groups as well. Don't really know how to use WhatsApp communities

Message : Quick Notes:

1/ Will figure out a way to do this a) sustainably b) less key man risk on me
We've already tried to formalise this by promoting multiple folks to Mods in this group.

My personal ideal state is that in 3y we don't need this community, because AI is interwoven into our fabric as GPS, Email or Internet

Message : 2/ Topic focussed groups: 

a) AI for Creatives ‚Äî Not an engineering crew: Focussed on doing art, talking oil and colours, not paint tech: https://chat.whatsapp.com/CVt0tjHQPfhJd9Bqrno6aB

b) DeepMedia ‚Äî  Tools for Art, spanning music, images, video and everything in between: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4

c) Startup Ecosystem ‚Äî for founders and VCs mostly: https://chat.whatsapp.com/BPT3pREU0QdClCtQarPu7r
(Ping Aditya from SuperU @91788006xxxx for approvals)

d) AI, Policy and Philosophy ‚Äî we've discussed everything from China to Godel, Escher & Bach there: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : ü•π I am dependent on you and others here now
Quoted Message : Quick Notes:\n\n1/ Will figure out a way to do this a) sustainably b) less key man risk on me\nWe've already tried to formalise this by promoting multiple folks to Mods in this group. \n\nMy personal ideal state is that in 3y we don't need this community, because AI is interwoven into our fabric as GPS, Email or Internet

Message : .... Is an open group.
Anyway, this is way #offtopic. Felt the need to raise this so I did. Everything is voluntary ü´∂üèª
Happy Labelling!
Quoted Message : Happy to be part of a community that helps each other but don't prefer WhatsApp. A slack community would be nice otherwise there are sometimes many topics that I'm not interested in so a little organisation will help. Otherwise most of the times the group is on mute for me.

Message : 3/ Re: Money ‚Äî Want to do something which is valuable to the community beyond a gesture/donation. Wikimedia Foundation is the exception, not the norm of non-profit excellence and longevity 

Could be an invite only forum with job boards with an email list/Discord/Slack ‚Äî such that we can vouch for folks there or perhaps a grant for early technical projects

Either way ‚Äî in no rush to solve it this week

Message : This group shows many hallmarks of a budding scenius. Excited to see what everyone builds in a couple of years.
Quoted Message : Quick Notes:\n\n1/ Will figure out a way to do this a) sustainably b) less key man risk on me\nWe've already tried to formalise this by promoting multiple folks to Mods in this group. \n\nMy personal ideal state is that in 3y we don't need this community, because AI is interwoven into our fabric as GPS, Email or Internet

Message : Scenius is the exact mental model I've in mind, which drives my decisions in more ways than one
Quoted Message : This group shows many hallmarks of a budding scenius. Excited to see what everyone builds in a couple of years.

Message : The api is different from chatgpt which is an app in itself.
Api is pay as you go.
You can use the api to build your own apps.
You have access to a lot more models than you do with chatgpt
Quoted Message : apropos this, this is included with chatgpt plus scubscription which is a different subscription from the gpt4 api\n\nI have been looking at https://openai.com/pricing & its a little confusing, no ?\n\nCan you/orhers clarify, what are the various openai subscriptions :\n\n1. Chatgpt plus\n2. GPT4 api

Message : @91773788xxxx - drop your gpay id regardless. :)

Message : Would voting on this mean voting for yourself?  :D

Message : What does that mean lol?
Quoted Message : Would voting on this mean voting for yourself?  :D

Message : Shouldn't wire to me anyway, all community funds are managed by Hasgeek ‚Äî including expenses for the meetups 

cc @91994547xxxx
Quoted Message : @9177xxxxxxxx - drop your gpay id regardless. :)

Message : We need  ‚ù§Ô∏è Community Love..

Message : Nirant's way of saying, paisa nahi, pyaar chahiye (AI generated vo bhi)
Quoted Message : Shouldn't wire to me anyway, all community funds are managed by Hasgeek ‚Äî including expenses for the meetups \n\ncc @9199xxxxxxxx

Message : [Translation: I don't need money, need love]

Message : Nirant is such a nice guy he is hesitant to take credits for something he built. 
Classic good founder example - "It's not my money, it's company's."
Quoted Message : Nirant's way of saying, paisa nahi, pyaar chahiye (AI generated vo bhi)

Message : -----
Anyway, cutting this off here. üëãüèº

Message : ‚Äé<attached: 00012191-PHOTO-2023-07-07-13-15-59.jpg>

Message : https://github.com/sponsors

Message : Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked? 
I thought of sitemaps but many don't have like intercom knowledgebase

Message : You can check zyte . They provide custom solutions as well
Quoted Message : Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked? \nI thought of sitemaps but many don't have like intercom knowledgebase

Message : We have it: https://Kili.so
Quoted Message : Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked? \nI thought of sitemaps but many don't have like intercom knowledgebase

Message : Any gen AI meet-ups in Chennai?

Here for a few days

Message : thats more for content from a webpage and not all the pages linked
Quoted Message : You can check zyte . They provide custom solutions as well

Message : Watch out for Mojo lang. Python compatible but with much better performance.
Quoted Message : What u guys think about prolog, lisp, Haskell,Scala, Julia, GNU Octave like programming language which are alternative to python to develop AI applications.

Message : Yah I know about that Nilesh. Thanks for pointing it
Quoted Message : Watch out for Mojo lang. Python compatible but with much better performance.

Message : I'd like to see new experimental languages with natural language baked into them. Write functions in English, till you get scale/talent to write it in Python. üòÅ

Message : You just reinvented BASIC
Quoted Message : I'd like to see new experimental languages with natural language baked into them. Write functions in English, till you get scale/talent to write it in Python. üòÅ

Message : Why not LOGO? TO SQUARE; REPEAT 4
Quoted Message : You just reinvented BASIC

Message : From a brief look at the website, kili is optimised for customer service documents, right ?
Quoted Message : We have it: https://Kili.so

Message : We are planning to have one soon with @91955016xxxx üòä
Quoted Message : Any gen AI meet-ups in Chennai?\n\nHere for a few days

Message : Great, are you in Chennai?
Quoted Message : We are planning to have one soon with @9195xxxxxxxx üòä

Message : Curious about this as well!
Quoted Message : Any gen AI meet-ups in Chennai?\n\nHere for a few days

Message : We could have a mini meetup if there are ~5 folks 

Happy to take charge of organising


You are part of a super smart and technical conversation summarizer agent. You would be given messages of a whatsapp group that has technical and business discussions about AI. You are provided the following : 
1. A list of existing topics that our summarizer agent has deduced so far and their description that is has decided so far. 
2. A list of messages of the whatsapp group that you need to select/discard and classify into the existing topics. If this message is a reply to a prior message, then that quoted message is also provided for your benefit of judgement.

Your task is to 
1. Decide if new topics need to be created and if so, describe them.
2. You can also edit the description of an existing topic if you think the description needs to be updated given new messages
3. Actively select if a message is relevant for storage or further analys. Discard Jokes unless they have technical or industry insights. Select every new unique technical term that you may encounter. Possibly adding them as topics.  Only store the relevant ones that will be of interest. This could be new methods or findings,or existing points and discussions about how to utilize certain methods.
4. If a particular message does not fit into any of the existing topics, you can create a new topic and describe it. 

Note:
Always ensure that the topics assigned to message should either part of existing topics or be part of the new topics that you have created.
The topic names should be simple 2/3 words at max. 
Your answer should be of the following suggestive format only. Just respond this and nothing else as your answer will be parsed by subsequent agents.





Message Classification:
Message : (Topic Name), (Topic Name) etc.
Message : Discard
Message :(Topic Name), (Topic Name) etc

New Topics: 
(Topic name): (Description of the topic)
(Topic name): (Description of the topic)

Edit Topics:
(Topic name): (New description of the topic)

Here is the data that you now need to work with
Topics: 


Messages:
Message : Happy to contribute a few dollars a month - maybe 2-5 USD per month plus be a good sweet spot? Setting up access on a slack/discord ?

Message : Anything works. In no world I can afford a recurring cost atm. But it's about gesture üí™üèª
Quoted Message : Happy to contribute a few dollars a month - maybe 2-5 USD per month plus be a good sweet spot? Setting up access on a slack/discord ?

Message : @91773788xxxx - drop your gpay id. üòÑ

Message : Happy to be part of a community that helps each other but don't prefer WhatsApp. A slack community would be nice otherwise there are sometimes many topics that I'm not interested in so a little organisation will help. Otherwise most of the times the group is on mute for me.

Message : Actually never mind I didn't realise there are some dedicated sub groups/similar groups as well. Don't really know how to use WhatsApp communities

Message : Quick Notes:

1/ Will figure out a way to do this a) sustainably b) less key man risk on me
We've already tried to formalise this by promoting multiple folks to Mods in this group.

My personal ideal state is that in 3y we don't need this community, because AI is interwoven into our fabric as GPS, Email or Internet

Message : 2/ Topic focussed groups: 

a) AI for Creatives ‚Äî Not an engineering crew: Focussed on doing art, talking oil and colours, not paint tech: https://chat.whatsapp.com/CVt0tjHQPfhJd9Bqrno6aB

b) DeepMedia ‚Äî  Tools for Art, spanning music, images, video and everything in between: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4

c) Startup Ecosystem ‚Äî for founders and VCs mostly: https://chat.whatsapp.com/BPT3pREU0QdClCtQarPu7r
(Ping Aditya from SuperU @91788006xxxx for approvals)

d) AI, Policy and Philosophy ‚Äî we've discussed everything from China to Godel, Escher & Bach there: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV

Message : ü•π I am dependent on you and others here now
Quoted Message : Quick Notes:\n\n1/ Will figure out a way to do this a) sustainably b) less key man risk on me\nWe've already tried to formalise this by promoting multiple folks to Mods in this group. \n\nMy personal ideal state is that in 3y we don't need this community, because AI is interwoven into our fabric as GPS, Email or Internet

Message : .... Is an open group.
Anyway, this is way #offtopic. Felt the need to raise this so I did. Everything is voluntary ü´∂üèª
Happy Labelling!
Quoted Message : Happy to be part of a community that helps each other but don't prefer WhatsApp. A slack community would be nice otherwise there are sometimes many topics that I'm not interested in so a little organisation will help. Otherwise most of the times the group is on mute for me.

Message : 3/ Re: Money ‚Äî Want to do something which is valuable to the community beyond a gesture/donation. Wikimedia Foundation is the exception, not the norm of non-profit excellence and longevity 

Could be an invite only forum with job boards with an email list/Discord/Slack ‚Äî such that we can vouch for folks there or perhaps a grant for early technical projects

Either way ‚Äî in no rush to solve it this week

Message : This group shows many hallmarks of a budding scenius. Excited to see what everyone builds in a couple of years.
Quoted Message : Quick Notes:\n\n1/ Will figure out a way to do this a) sustainably b) less key man risk on me\nWe've already tried to formalise this by promoting multiple folks to Mods in this group. \n\nMy personal ideal state is that in 3y we don't need this community, because AI is interwoven into our fabric as GPS, Email or Internet

Message : Scenius is the exact mental model I've in mind, which drives my decisions in more ways than one
Quoted Message : This group shows many hallmarks of a budding scenius. Excited to see what everyone builds in a couple of years.

Message : The api is different from chatgpt which is an app in itself.
Api is pay as you go.
You can use the api to build your own apps.
You have access to a lot more models than you do with chatgpt
Quoted Message : apropos this, this is included with chatgpt plus scubscription which is a different subscription from the gpt4 api\n\nI have been looking at https://openai.com/pricing & its a little confusing, no ?\n\nCan you/orhers clarify, what are the various openai subscriptions :\n\n1. Chatgpt plus\n2. GPT4 api

Message : @91773788xxxx - drop your gpay id regardless. :)

Message : Would voting on this mean voting for yourself?  :D

Message : What does that mean lol?
Quoted Message : Would voting on this mean voting for yourself?  :D

Message : Shouldn't wire to me anyway, all community funds are managed by Hasgeek ‚Äî including expenses for the meetups 

cc @91994547xxxx
Quoted Message : @9177xxxxxxxx - drop your gpay id regardless. :)

Message : We need  ‚ù§Ô∏è Community Love..

Message : Nirant's way of saying, paisa nahi, pyaar chahiye (AI generated vo bhi)
Quoted Message : Shouldn't wire to me anyway, all community funds are managed by Hasgeek ‚Äî including expenses for the meetups \n\ncc @9199xxxxxxxx

Message : [Translation: I don't need money, need love]

Message : Nirant is such a nice guy he is hesitant to take credits for something he built. 
Classic good founder example - "It's not my money, it's company's."
Quoted Message : Nirant's way of saying, paisa nahi, pyaar chahiye (AI generated vo bhi)

Message : -----
Anyway, cutting this off here. üëãüèº

Message : ‚Äé<attached: 00012191-PHOTO-2023-07-07-13-15-59.jpg>

Message : https://github.com/sponsors

Message : Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked? 
I thought of sitemaps but many don't have like intercom knowledgebase

Message : You can check zyte . They provide custom solutions as well
Quoted Message : Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked? \nI thought of sitemaps but many don't have like intercom knowledgebase

Message : We have it: https://Kili.so
Quoted Message : Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked? \nI thought of sitemaps but many don't have like intercom knowledgebase

Message : Any gen AI meet-ups in Chennai?

Here for a few days

Message : thats more for content from a webpage and not all the pages linked
Quoted Message : You can check zyte . They provide custom solutions as well

Message : Watch out for Mojo lang. Python compatible but with much better performance.
Quoted Message : What u guys think about prolog, lisp, Haskell,Scala, Julia, GNU Octave like programming language which are alternative to python to develop AI applications.

Message : Yah I know about that Nilesh. Thanks for pointing it
Quoted Message : Watch out for Mojo lang. Python compatible but with much better performance.

Message : I'd like to see new experimental languages with natural language baked into them. Write functions in English, till you get scale/talent to write it in Python. üòÅ

Message : You just reinvented BASIC
Quoted Message : I'd like to see new experimental languages with natural language baked into them. Write functions in English, till you get scale/talent to write it in Python. üòÅ

Message : Why not LOGO? TO SQUARE; REPEAT 4
Quoted Message : You just reinvented BASIC

Message : From a brief look at the website, kili is optimised for customer service documents, right ?
Quoted Message : We have it: https://Kili.so

Message : We are planning to have one soon with @91955016xxxx üòä
Quoted Message : Any gen AI meet-ups in Chennai?\n\nHere for a few days

Message : Great, are you in Chennai?
Quoted Message : We are planning to have one soon with @9195xxxxxxxx üòä

Message : Curious about this as well!
Quoted Message : Any gen AI meet-ups in Chennai?\n\nHere for a few days

Message : We could have a mini meetup if there are ~5 folks 

Happy to take charge of organising

Message : It just occurred to me that for every GenAI meet-up, we should invite GPT4 as well as a candidate :)

Someone should do text to speech, give it a face and let it absorb conversations and respond with questions and comments

Message : What an idea sirjee !

For zoom calls and sunch, ai agents like tldv, otter.ai already generate summaries !

Height of anthromorphizing ! :)
Quoted Message : It just occurred to me that for every GenAI meet-up, we should invite GPT4 as well as a candidate :)\n\nSomeone should do text to speech, give it a face and let it absorb conversations and respond with questions and comments

Message : Or SQL and COBOL, also intended to be used by non-programmers.
Quoted Message : You just reinvented BASIC

Message : Mini meetup in Chennai, coordinated by Sudharshan for this group: https://chat.whatsapp.com/ITEophM7myQ6ph7mwbHgtA
Quoted Message : Any gen AI meet-ups in Chennai?\n\nHere for a few days

Message : Thanks @91773788xxxx , we‚Äôre planning an impromptu meetup in **Chennai this weekend**. Still figuring out the logistics, but do join in folks üòÅ

Message : Have the orca models been released?

Message : I'm looking to mess around with an open source model that I can run on my Macbook Pro. What would you recommend I start with? Looking for something that is easy to set up

Message : https://twitter.com/bo_wangbo/status/1677064925347192838?t=WXkX2PLqVpB3lUnpYrryiA&s=08

Small, fast alternative to minilm embeddings coming soon, by Jina AI (weights will be open-sourced on hf, and most likely added to sentence transformers)

Message : No, 2 independent attempts exist to produce a dataset on the idea from the Orca paper.

One from Alignment AI, that broke up with some drama.
Another called OpenOrca by the people who broke away from Alignment AI.
Quoted Message : Have the orca models been released?

Message : Why are people not aligning with alignment AI
Quoted Message : No, 2 independent attempts exist to produce a dataset on the idea from the Orca paper.\n\nOne from Alignment AI, that broke up with some drama.\nAnother called OpenOrca by the people who broke away from Alignment AI.

Message : was added to chat


